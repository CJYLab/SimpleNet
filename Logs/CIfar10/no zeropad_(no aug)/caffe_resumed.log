
G:\Caffe\examples\cifar10>REM go to the caffe root 

G:\Caffe\examples\cifar10>cd ../../ 

G:\Caffe>set BIN=build/x64/Release 

G:\Caffe>"build/x64/Release/caffe.exe" train --solver=examples/cifar10/cifar10_full_relu_solver_bn.prototxt --snapshot=examples/cifar10_full_relu_bn_iter_226000.solverstate 
I0217 13:16:40.342716  8728 caffe.cpp:218] Using GPUs 0
I0217 13:16:40.507266  8728 caffe.cpp:223] GPU 0: GeForce GTX 980
I0217 13:16:40.765312  8728 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0217 13:16:40.765312  8728 solver.cpp:48] Initializing solver from parameters: 
test_iter: 400
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 500
snapshot_prefix: "examples/cifar10_full_relu_bn"
solver_mode: GPU
device_id: 0
random_seed: 1705
net: "examples/cifar10/cifar10_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 253000
stepvalue: 295000
stepvalue: 320000
stepvalue: 370000
type: "AdaDelta"
I0217 13:16:40.766305  8728 solver.cpp:91] Creating training net from net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0217 13:16:40.766305  8728 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0217 13:16:40.766305  8728 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0217 13:16:40.766305  8728 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0217 13:16:40.767305  8728 net.cpp:58] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "relu1"
  top: "relu1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "drop1_0"
  type: "Dropout"
  bottom: "relu1_0"
  top: "relu1_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "drop2_0"
  type: "Dropout"
  bottom: "relu2"
  top: "relu2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "drop2_2"
  type: "Dropout"
  bottom: "relu2_2"
  top: "relu2_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "relu3"
  top: "relu3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "relu4"
  top: "relu4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "drop4_1"
  type: "Dropout"
  bottom: "relu4_1"
  top: "relu4_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "drop4_2"
  type: "Dropout"
  bottom: "relu4_2"
  top: "relu4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "drop4_0"
  type: "Dropout"
  bottom: "relu4_0"
  top: "relu4_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "drop4_3"
  type: "Dropout"
  bottom: "cccp4"
  top: "cccp4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop4_5"
  type: "Dropout"
  bottom: "poolcp5"
  top: "poolcp5"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0217 13:16:40.767305  8728 layer_factory.cpp:58] Creating layer cifar
I0217 13:16:40.768306  8728 net.cpp:100] Creating Layer cifar
I0217 13:16:40.768306  8728 net.cpp:408] cifar -> data
I0217 13:16:40.768306  8728 net.cpp:408] cifar -> label
I0217 13:16:40.768306  8728 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0217 13:16:40.770323  7836 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0217 13:16:40.778306  7836 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_train_lmdb
I0217 13:16:40.789305  8728 data_layer.cpp:41] output data size: 100,3,32,32
I0217 13:16:40.792304  8728 net.cpp:150] Setting up cifar
I0217 13:16:40.792304  8728 net.cpp:157] Top shape: 100 3 32 32 (307200)
I0217 13:16:40.792304  8728 net.cpp:157] Top shape: 100 (100)
I0217 13:16:40.792304  8728 net.cpp:165] Memory required for data: 1229200
I0217 13:16:40.792304  8728 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0217 13:16:40.792304  8728 net.cpp:100] Creating Layer label_cifar_1_split
I0217 13:16:40.792304  8728 net.cpp:434] label_cifar_1_split <- label
I0217 13:16:40.792304  8728 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0217 13:16:40.792304  8728 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0217 13:16:40.792304  8728 net.cpp:150] Setting up label_cifar_1_split
I0217 13:16:40.792304  8728 net.cpp:157] Top shape: 100 (100)
I0217 13:16:40.792304  8728 net.cpp:157] Top shape: 100 (100)
I0217 13:16:40.792304  8728 net.cpp:165] Memory required for data: 1230000
I0217 13:16:40.792304  8728 layer_factory.cpp:58] Creating layer conv1
I0217 13:16:40.792304  8728 net.cpp:100] Creating Layer conv1
I0217 13:16:40.792304  8728 net.cpp:434] conv1 <- data
I0217 13:16:40.792304  8728 net.cpp:408] conv1 -> conv1
I0217 13:16:40.793305  6564 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0217 13:16:41.015357  8728 net.cpp:150] Setting up conv1
I0217 13:16:41.015357  8728 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0217 13:16:41.015357  8728 net.cpp:165] Memory required for data: 27444400
I0217 13:16:41.015357  8728 layer_factory.cpp:58] Creating layer bn1
I0217 13:16:41.015357  8728 net.cpp:100] Creating Layer bn1
I0217 13:16:41.015357  8728 net.cpp:434] bn1 <- conv1
I0217 13:16:41.016357  8728 net.cpp:408] bn1 -> bn1
I0217 13:16:41.016357  8728 net.cpp:150] Setting up bn1
I0217 13:16:41.016357  8728 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0217 13:16:41.016357  8728 net.cpp:165] Memory required for data: 53658800
I0217 13:16:41.016357  8728 layer_factory.cpp:58] Creating layer scale1
I0217 13:16:41.016357  8728 net.cpp:100] Creating Layer scale1
I0217 13:16:41.016357  8728 net.cpp:434] scale1 <- bn1
I0217 13:16:41.016357  8728 net.cpp:408] scale1 -> scale1
I0217 13:16:41.016357  8728 layer_factory.cpp:58] Creating layer scale1
I0217 13:16:41.016357  8728 net.cpp:150] Setting up scale1
I0217 13:16:41.016357  8728 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0217 13:16:41.016357  8728 net.cpp:165] Memory required for data: 79873200
I0217 13:16:41.016357  8728 layer_factory.cpp:58] Creating layer relu1
I0217 13:16:41.016357  8728 net.cpp:100] Creating Layer relu1
I0217 13:16:41.016357  8728 net.cpp:434] relu1 <- scale1
I0217 13:16:41.016357  8728 net.cpp:408] relu1 -> relu1
I0217 13:16:41.016357  8728 net.cpp:150] Setting up relu1
I0217 13:16:41.016357  8728 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0217 13:16:41.016357  8728 net.cpp:165] Memory required for data: 106087600
I0217 13:16:41.016357  8728 layer_factory.cpp:58] Creating layer drop2_1
I0217 13:16:41.016357  8728 net.cpp:100] Creating Layer drop2_1
I0217 13:16:41.016357  8728 net.cpp:434] drop2_1 <- relu1
I0217 13:16:41.016357  8728 net.cpp:395] drop2_1 -> relu1 (in-place)
I0217 13:16:41.016357  8728 net.cpp:150] Setting up drop2_1
I0217 13:16:41.016357  8728 net.cpp:157] Top shape: 100 64 32 32 (6553600)
I0217 13:16:41.017359  8728 net.cpp:165] Memory required for data: 132302000
I0217 13:16:41.017359  8728 layer_factory.cpp:58] Creating layer conv1_0
I0217 13:16:41.017359  8728 net.cpp:100] Creating Layer conv1_0
I0217 13:16:41.017359  8728 net.cpp:434] conv1_0 <- relu1
I0217 13:16:41.017359  8728 net.cpp:408] conv1_0 -> conv1_0
I0217 13:16:41.019357  8728 net.cpp:150] Setting up conv1_0
I0217 13:16:41.019357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.019357  8728 net.cpp:165] Memory required for data: 184730800
I0217 13:16:41.019357  8728 layer_factory.cpp:58] Creating layer bn1_0
I0217 13:16:41.019357  8728 net.cpp:100] Creating Layer bn1_0
I0217 13:16:41.019357  8728 net.cpp:434] bn1_0 <- conv1_0
I0217 13:16:41.019357  8728 net.cpp:408] bn1_0 -> bn1_0
I0217 13:16:41.019357  8728 net.cpp:150] Setting up bn1_0
I0217 13:16:41.019357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.019357  8728 net.cpp:165] Memory required for data: 237159600
I0217 13:16:41.019357  8728 layer_factory.cpp:58] Creating layer scale1_0
I0217 13:16:41.019357  8728 net.cpp:100] Creating Layer scale1_0
I0217 13:16:41.019357  8728 net.cpp:434] scale1_0 <- bn1_0
I0217 13:16:41.019357  8728 net.cpp:408] scale1_0 -> scale1_0
I0217 13:16:41.019357  8728 layer_factory.cpp:58] Creating layer scale1_0
I0217 13:16:41.019357  8728 net.cpp:150] Setting up scale1_0
I0217 13:16:41.019357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.019357  8728 net.cpp:165] Memory required for data: 289588400
I0217 13:16:41.019357  8728 layer_factory.cpp:58] Creating layer relu1_0
I0217 13:16:41.019357  8728 net.cpp:100] Creating Layer relu1_0
I0217 13:16:41.019357  8728 net.cpp:434] relu1_0 <- scale1_0
I0217 13:16:41.019357  8728 net.cpp:408] relu1_0 -> relu1_0
I0217 13:16:41.019357  8728 net.cpp:150] Setting up relu1_0
I0217 13:16:41.019357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.019357  8728 net.cpp:165] Memory required for data: 342017200
I0217 13:16:41.019357  8728 layer_factory.cpp:58] Creating layer drop1_0
I0217 13:16:41.019357  8728 net.cpp:100] Creating Layer drop1_0
I0217 13:16:41.019357  8728 net.cpp:434] drop1_0 <- relu1_0
I0217 13:16:41.019357  8728 net.cpp:395] drop1_0 -> relu1_0 (in-place)
I0217 13:16:41.019357  8728 net.cpp:150] Setting up drop1_0
I0217 13:16:41.019357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.019357  8728 net.cpp:165] Memory required for data: 394446000
I0217 13:16:41.019357  8728 layer_factory.cpp:58] Creating layer conv2
I0217 13:16:41.019357  8728 net.cpp:100] Creating Layer conv2
I0217 13:16:41.019357  8728 net.cpp:434] conv2 <- relu1_0
I0217 13:16:41.019357  8728 net.cpp:408] conv2 -> conv2
I0217 13:16:41.022357  8728 net.cpp:150] Setting up conv2
I0217 13:16:41.022357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.022357  8728 net.cpp:165] Memory required for data: 446874800
I0217 13:16:41.022357  8728 layer_factory.cpp:58] Creating layer bn2
I0217 13:16:41.022357  8728 net.cpp:100] Creating Layer bn2
I0217 13:16:41.022357  8728 net.cpp:434] bn2 <- conv2
I0217 13:16:41.022357  8728 net.cpp:408] bn2 -> bn2
I0217 13:16:41.022357  8728 net.cpp:150] Setting up bn2
I0217 13:16:41.022357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.022357  8728 net.cpp:165] Memory required for data: 499303600
I0217 13:16:41.022357  8728 layer_factory.cpp:58] Creating layer scale2
I0217 13:16:41.022357  8728 net.cpp:100] Creating Layer scale2
I0217 13:16:41.022357  8728 net.cpp:434] scale2 <- bn2
I0217 13:16:41.022357  8728 net.cpp:408] scale2 -> scale2
I0217 13:16:41.022357  8728 layer_factory.cpp:58] Creating layer scale2
I0217 13:16:41.022357  8728 net.cpp:150] Setting up scale2
I0217 13:16:41.022357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.023357  8728 net.cpp:165] Memory required for data: 551732400
I0217 13:16:41.023357  8728 layer_factory.cpp:58] Creating layer relu2
I0217 13:16:41.023357  8728 net.cpp:100] Creating Layer relu2
I0217 13:16:41.023357  8728 net.cpp:434] relu2 <- scale2
I0217 13:16:41.023357  8728 net.cpp:408] relu2 -> relu2
I0217 13:16:41.023357  8728 net.cpp:150] Setting up relu2
I0217 13:16:41.023357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.023357  8728 net.cpp:165] Memory required for data: 604161200
I0217 13:16:41.023357  8728 layer_factory.cpp:58] Creating layer drop2_0
I0217 13:16:41.023357  8728 net.cpp:100] Creating Layer drop2_0
I0217 13:16:41.023357  8728 net.cpp:434] drop2_0 <- relu2
I0217 13:16:41.023357  8728 net.cpp:395] drop2_0 -> relu2 (in-place)
I0217 13:16:41.023357  8728 net.cpp:150] Setting up drop2_0
I0217 13:16:41.023357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.023357  8728 net.cpp:165] Memory required for data: 656590000
I0217 13:16:41.023357  8728 layer_factory.cpp:58] Creating layer conv2_1
I0217 13:16:41.023357  8728 net.cpp:100] Creating Layer conv2_1
I0217 13:16:41.023357  8728 net.cpp:434] conv2_1 <- relu2
I0217 13:16:41.023357  8728 net.cpp:408] conv2_1 -> conv2_1
I0217 13:16:41.026357  8728 net.cpp:150] Setting up conv2_1
I0217 13:16:41.026357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.026357  8728 net.cpp:165] Memory required for data: 709018800
I0217 13:16:41.026357  8728 layer_factory.cpp:58] Creating layer bn2_1
I0217 13:16:41.026357  8728 net.cpp:100] Creating Layer bn2_1
I0217 13:16:41.026357  8728 net.cpp:434] bn2_1 <- conv2_1
I0217 13:16:41.026357  8728 net.cpp:408] bn2_1 -> bn2_1
I0217 13:16:41.026357  8728 net.cpp:150] Setting up bn2_1
I0217 13:16:41.026357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.026357  8728 net.cpp:165] Memory required for data: 761447600
I0217 13:16:41.026357  8728 layer_factory.cpp:58] Creating layer scale2_1
I0217 13:16:41.026357  8728 net.cpp:100] Creating Layer scale2_1
I0217 13:16:41.026357  8728 net.cpp:434] scale2_1 <- bn2_1
I0217 13:16:41.026357  8728 net.cpp:408] scale2_1 -> scale2_1
I0217 13:16:41.026357  8728 layer_factory.cpp:58] Creating layer scale2_1
I0217 13:16:41.026357  8728 net.cpp:150] Setting up scale2_1
I0217 13:16:41.026357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.026357  8728 net.cpp:165] Memory required for data: 813876400
I0217 13:16:41.026357  8728 layer_factory.cpp:58] Creating layer relu2_1
I0217 13:16:41.026357  8728 net.cpp:100] Creating Layer relu2_1
I0217 13:16:41.026357  8728 net.cpp:434] relu2_1 <- scale2_1
I0217 13:16:41.026357  8728 net.cpp:408] relu2_1 -> relu2_1
I0217 13:16:41.027357  8728 net.cpp:150] Setting up relu2_1
I0217 13:16:41.027357  8728 net.cpp:157] Top shape: 100 128 32 32 (13107200)
I0217 13:16:41.027357  8728 net.cpp:165] Memory required for data: 866305200
I0217 13:16:41.027357  8728 layer_factory.cpp:58] Creating layer pool2_1
I0217 13:16:41.027357  8728 net.cpp:100] Creating Layer pool2_1
I0217 13:16:41.027357  8728 net.cpp:434] pool2_1 <- relu2_1
I0217 13:16:41.027357  8728 net.cpp:408] pool2_1 -> pool2_1
I0217 13:16:41.027357  8728 net.cpp:150] Setting up pool2_1
I0217 13:16:41.027357  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.027357  8728 net.cpp:165] Memory required for data: 879412400
I0217 13:16:41.027357  8728 layer_factory.cpp:58] Creating layer drop2_1
I0217 13:16:41.027357  8728 net.cpp:100] Creating Layer drop2_1
I0217 13:16:41.027357  8728 net.cpp:434] drop2_1 <- pool2_1
I0217 13:16:41.027357  8728 net.cpp:395] drop2_1 -> pool2_1 (in-place)
I0217 13:16:41.027357  8728 net.cpp:150] Setting up drop2_1
I0217 13:16:41.027357  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.027357  8728 net.cpp:165] Memory required for data: 892519600
I0217 13:16:41.027357  8728 layer_factory.cpp:58] Creating layer conv2_2
I0217 13:16:41.027357  8728 net.cpp:100] Creating Layer conv2_2
I0217 13:16:41.027357  8728 net.cpp:434] conv2_2 <- pool2_1
I0217 13:16:41.027357  8728 net.cpp:408] conv2_2 -> conv2_2
I0217 13:16:41.030357  8728 net.cpp:150] Setting up conv2_2
I0217 13:16:41.030357  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.030357  8728 net.cpp:165] Memory required for data: 905626800
I0217 13:16:41.030357  8728 layer_factory.cpp:58] Creating layer bn2_2
I0217 13:16:41.030357  8728 net.cpp:100] Creating Layer bn2_2
I0217 13:16:41.030357  8728 net.cpp:434] bn2_2 <- conv2_2
I0217 13:16:41.030357  8728 net.cpp:408] bn2_2 -> bn2_2
I0217 13:16:41.030357  8728 net.cpp:150] Setting up bn2_2
I0217 13:16:41.030357  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.030357  8728 net.cpp:165] Memory required for data: 918734000
I0217 13:16:41.030357  8728 layer_factory.cpp:58] Creating layer scale2_2
I0217 13:16:41.030357  8728 net.cpp:100] Creating Layer scale2_2
I0217 13:16:41.030357  8728 net.cpp:434] scale2_2 <- bn2_2
I0217 13:16:41.030357  8728 net.cpp:408] scale2_2 -> scale2_2
I0217 13:16:41.031358  8728 layer_factory.cpp:58] Creating layer scale2_2
I0217 13:16:41.031358  8728 net.cpp:150] Setting up scale2_2
I0217 13:16:41.031358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.031358  8728 net.cpp:165] Memory required for data: 931841200
I0217 13:16:41.031358  8728 layer_factory.cpp:58] Creating layer relu2_2
I0217 13:16:41.031358  8728 net.cpp:100] Creating Layer relu2_2
I0217 13:16:41.031358  8728 net.cpp:434] relu2_2 <- scale2_2
I0217 13:16:41.031358  8728 net.cpp:408] relu2_2 -> relu2_2
I0217 13:16:41.031358  8728 net.cpp:150] Setting up relu2_2
I0217 13:16:41.031358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.031358  8728 net.cpp:165] Memory required for data: 944948400
I0217 13:16:41.031358  8728 layer_factory.cpp:58] Creating layer drop2_2
I0217 13:16:41.031358  8728 net.cpp:100] Creating Layer drop2_2
I0217 13:16:41.031358  8728 net.cpp:434] drop2_2 <- relu2_2
I0217 13:16:41.031358  8728 net.cpp:395] drop2_2 -> relu2_2 (in-place)
I0217 13:16:41.031358  8728 net.cpp:150] Setting up drop2_2
I0217 13:16:41.031358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.031358  8728 net.cpp:165] Memory required for data: 958055600
I0217 13:16:41.031358  8728 layer_factory.cpp:58] Creating layer conv3
I0217 13:16:41.031358  8728 net.cpp:100] Creating Layer conv3
I0217 13:16:41.031358  8728 net.cpp:434] conv3 <- relu2_2
I0217 13:16:41.031358  8728 net.cpp:408] conv3 -> conv3
I0217 13:16:41.033357  8728 net.cpp:150] Setting up conv3
I0217 13:16:41.034358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.034358  8728 net.cpp:165] Memory required for data: 971162800
I0217 13:16:41.034358  8728 layer_factory.cpp:58] Creating layer bn3
I0217 13:16:41.034358  8728 net.cpp:100] Creating Layer bn3
I0217 13:16:41.034358  8728 net.cpp:434] bn3 <- conv3
I0217 13:16:41.034358  8728 net.cpp:408] bn3 -> bn3
I0217 13:16:41.034358  8728 net.cpp:150] Setting up bn3
I0217 13:16:41.034358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.034358  8728 net.cpp:165] Memory required for data: 984270000
I0217 13:16:41.034358  8728 layer_factory.cpp:58] Creating layer scale3
I0217 13:16:41.034358  8728 net.cpp:100] Creating Layer scale3
I0217 13:16:41.034358  8728 net.cpp:434] scale3 <- bn3
I0217 13:16:41.034358  8728 net.cpp:408] scale3 -> scale3
I0217 13:16:41.034358  8728 layer_factory.cpp:58] Creating layer scale3
I0217 13:16:41.034358  8728 net.cpp:150] Setting up scale3
I0217 13:16:41.034358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.034358  8728 net.cpp:165] Memory required for data: 997377200
I0217 13:16:41.034358  8728 layer_factory.cpp:58] Creating layer relu3
I0217 13:16:41.034358  8728 net.cpp:100] Creating Layer relu3
I0217 13:16:41.034358  8728 net.cpp:434] relu3 <- scale3
I0217 13:16:41.034358  8728 net.cpp:408] relu3 -> relu3
I0217 13:16:41.034358  8728 net.cpp:150] Setting up relu3
I0217 13:16:41.034358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.034358  8728 net.cpp:165] Memory required for data: 1010484400
I0217 13:16:41.034358  8728 layer_factory.cpp:58] Creating layer drop3
I0217 13:16:41.034358  8728 net.cpp:100] Creating Layer drop3
I0217 13:16:41.034358  8728 net.cpp:434] drop3 <- relu3
I0217 13:16:41.034358  8728 net.cpp:395] drop3 -> relu3 (in-place)
I0217 13:16:41.034358  8728 net.cpp:150] Setting up drop3
I0217 13:16:41.034358  8728 net.cpp:157] Top shape: 100 128 16 16 (3276800)
I0217 13:16:41.034358  8728 net.cpp:165] Memory required for data: 1023591600
I0217 13:16:41.034358  8728 layer_factory.cpp:58] Creating layer conv4
I0217 13:16:41.034358  8728 net.cpp:100] Creating Layer conv4
I0217 13:16:41.034358  8728 net.cpp:434] conv4 <- relu3
I0217 13:16:41.034358  8728 net.cpp:408] conv4 -> conv4
I0217 13:16:41.038362  8728 net.cpp:150] Setting up conv4
I0217 13:16:41.038362  8728 net.cpp:157] Top shape: 100 256 16 16 (6553600)
I0217 13:16:41.038362  8728 net.cpp:165] Memory required for data: 1049806000
I0217 13:16:41.038362  8728 layer_factory.cpp:58] Creating layer pool4
I0217 13:16:41.038362  8728 net.cpp:100] Creating Layer pool4
I0217 13:16:41.038362  8728 net.cpp:434] pool4 <- conv4
I0217 13:16:41.038362  8728 net.cpp:408] pool4 -> pool4
I0217 13:16:41.038362  8728 net.cpp:150] Setting up pool4
I0217 13:16:41.038362  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.038362  8728 net.cpp:165] Memory required for data: 1056359600
I0217 13:16:41.038362  8728 layer_factory.cpp:58] Creating layer bn4
I0217 13:16:41.038362  8728 net.cpp:100] Creating Layer bn4
I0217 13:16:41.038362  8728 net.cpp:434] bn4 <- pool4
I0217 13:16:41.038861  8728 net.cpp:408] bn4 -> bn4
I0217 13:16:41.038861  8728 net.cpp:150] Setting up bn4
I0217 13:16:41.038861  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.038861  8728 net.cpp:165] Memory required for data: 1062913200
I0217 13:16:41.038861  8728 layer_factory.cpp:58] Creating layer scale4
I0217 13:16:41.038861  8728 net.cpp:100] Creating Layer scale4
I0217 13:16:41.038861  8728 net.cpp:434] scale4 <- bn4
I0217 13:16:41.038861  8728 net.cpp:408] scale4 -> scale4
I0217 13:16:41.038861  8728 layer_factory.cpp:58] Creating layer scale4
I0217 13:16:41.038861  8728 net.cpp:150] Setting up scale4
I0217 13:16:41.038861  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.038861  8728 net.cpp:165] Memory required for data: 1069466800
I0217 13:16:41.038861  8728 layer_factory.cpp:58] Creating layer relu4
I0217 13:16:41.038861  8728 net.cpp:100] Creating Layer relu4
I0217 13:16:41.038861  8728 net.cpp:434] relu4 <- scale4
I0217 13:16:41.038861  8728 net.cpp:408] relu4 -> relu4
I0217 13:16:41.039361  8728 net.cpp:150] Setting up relu4
I0217 13:16:41.039361  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.039361  8728 net.cpp:165] Memory required for data: 1076020400
I0217 13:16:41.039361  8728 layer_factory.cpp:58] Creating layer drop4
I0217 13:16:41.039361  8728 net.cpp:100] Creating Layer drop4
I0217 13:16:41.039361  8728 net.cpp:434] drop4 <- relu4
I0217 13:16:41.039361  8728 net.cpp:395] drop4 -> relu4 (in-place)
I0217 13:16:41.039861  8728 net.cpp:150] Setting up drop4
I0217 13:16:41.039861  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.039861  8728 net.cpp:165] Memory required for data: 1082574000
I0217 13:16:41.039861  8728 layer_factory.cpp:58] Creating layer conv4_1
I0217 13:16:41.039861  8728 net.cpp:100] Creating Layer conv4_1
I0217 13:16:41.039861  8728 net.cpp:434] conv4_1 <- relu4
I0217 13:16:41.039861  8728 net.cpp:408] conv4_1 -> conv4_1
I0217 13:16:41.046361  8728 net.cpp:150] Setting up conv4_1
I0217 13:16:41.046361  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.046361  8728 net.cpp:165] Memory required for data: 1089127600
I0217 13:16:41.046361  8728 layer_factory.cpp:58] Creating layer bn4_1
I0217 13:16:41.046361  8728 net.cpp:100] Creating Layer bn4_1
I0217 13:16:41.046361  8728 net.cpp:434] bn4_1 <- conv4_1
I0217 13:16:41.046361  8728 net.cpp:408] bn4_1 -> bn4_1
I0217 13:16:41.046361  8728 net.cpp:150] Setting up bn4_1
I0217 13:16:41.046361  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.046361  8728 net.cpp:165] Memory required for data: 1095681200
I0217 13:16:41.046361  8728 layer_factory.cpp:58] Creating layer scale4_1
I0217 13:16:41.046361  8728 net.cpp:100] Creating Layer scale4_1
I0217 13:16:41.046361  8728 net.cpp:434] scale4_1 <- bn4_1
I0217 13:16:41.046361  8728 net.cpp:408] scale4_1 -> scale4_1
I0217 13:16:41.046361  8728 layer_factory.cpp:58] Creating layer scale4_1
I0217 13:16:41.046861  8728 net.cpp:150] Setting up scale4_1
I0217 13:16:41.046861  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.046861  8728 net.cpp:165] Memory required for data: 1102234800
I0217 13:16:41.046861  8728 layer_factory.cpp:58] Creating layer relu4_1
I0217 13:16:41.046861  8728 net.cpp:100] Creating Layer relu4_1
I0217 13:16:41.046861  8728 net.cpp:434] relu4_1 <- scale4_1
I0217 13:16:41.046861  8728 net.cpp:408] relu4_1 -> relu4_1
I0217 13:16:41.046861  8728 net.cpp:150] Setting up relu4_1
I0217 13:16:41.046861  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.046861  8728 net.cpp:165] Memory required for data: 1108788400
I0217 13:16:41.046861  8728 layer_factory.cpp:58] Creating layer drop4_1
I0217 13:16:41.046861  8728 net.cpp:100] Creating Layer drop4_1
I0217 13:16:41.046861  8728 net.cpp:434] drop4_1 <- relu4_1
I0217 13:16:41.046861  8728 net.cpp:395] drop4_1 -> relu4_1 (in-place)
I0217 13:16:41.046861  8728 net.cpp:150] Setting up drop4_1
I0217 13:16:41.046861  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.046861  8728 net.cpp:165] Memory required for data: 1115342000
I0217 13:16:41.046861  8728 layer_factory.cpp:58] Creating layer conv4_2
I0217 13:16:41.046861  8728 net.cpp:100] Creating Layer conv4_2
I0217 13:16:41.046861  8728 net.cpp:434] conv4_2 <- relu4_1
I0217 13:16:41.046861  8728 net.cpp:408] conv4_2 -> conv4_2
I0217 13:16:41.053380  8728 net.cpp:150] Setting up conv4_2
I0217 13:16:41.053380  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.053380  8728 net.cpp:165] Memory required for data: 1121895600
I0217 13:16:41.053380  8728 layer_factory.cpp:58] Creating layer bn4_2
I0217 13:16:41.053380  8728 net.cpp:100] Creating Layer bn4_2
I0217 13:16:41.053380  8728 net.cpp:434] bn4_2 <- conv4_2
I0217 13:16:41.053380  8728 net.cpp:408] bn4_2 -> bn4_2
I0217 13:16:41.053380  8728 net.cpp:150] Setting up bn4_2
I0217 13:16:41.053380  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.053380  8728 net.cpp:165] Memory required for data: 1128449200
I0217 13:16:41.053380  8728 layer_factory.cpp:58] Creating layer scale4_2
I0217 13:16:41.053380  8728 net.cpp:100] Creating Layer scale4_2
I0217 13:16:41.053380  8728 net.cpp:434] scale4_2 <- bn4_2
I0217 13:16:41.053380  8728 net.cpp:408] scale4_2 -> scale4_2
I0217 13:16:41.053380  8728 layer_factory.cpp:58] Creating layer scale4_2
I0217 13:16:41.053380  8728 net.cpp:150] Setting up scale4_2
I0217 13:16:41.053380  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.053380  8728 net.cpp:165] Memory required for data: 1135002800
I0217 13:16:41.053380  8728 layer_factory.cpp:58] Creating layer relu4_2
I0217 13:16:41.053380  8728 net.cpp:100] Creating Layer relu4_2
I0217 13:16:41.053380  8728 net.cpp:434] relu4_2 <- scale4_2
I0217 13:16:41.053380  8728 net.cpp:408] relu4_2 -> relu4_2
I0217 13:16:41.053380  8728 net.cpp:150] Setting up relu4_2
I0217 13:16:41.053380  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.053380  8728 net.cpp:165] Memory required for data: 1141556400
I0217 13:16:41.053380  8728 layer_factory.cpp:58] Creating layer drop4_2
I0217 13:16:41.053380  8728 net.cpp:100] Creating Layer drop4_2
I0217 13:16:41.053380  8728 net.cpp:434] drop4_2 <- relu4_2
I0217 13:16:41.053380  8728 net.cpp:395] drop4_2 -> relu4_2 (in-place)
I0217 13:16:41.053380  8728 net.cpp:150] Setting up drop4_2
I0217 13:16:41.054364  8728 net.cpp:157] Top shape: 100 256 8 8 (1638400)
I0217 13:16:41.054364  8728 net.cpp:165] Memory required for data: 1148110000
I0217 13:16:41.054364  8728 layer_factory.cpp:58] Creating layer pool4_2
I0217 13:16:41.054364  8728 net.cpp:100] Creating Layer pool4_2
I0217 13:16:41.054364  8728 net.cpp:434] pool4_2 <- relu4_2
I0217 13:16:41.054364  8728 net.cpp:408] pool4_2 -> pool4_2
I0217 13:16:41.054364  8728 net.cpp:150] Setting up pool4_2
I0217 13:16:41.054364  8728 net.cpp:157] Top shape: 100 256 4 4 (409600)
I0217 13:16:41.054364  8728 net.cpp:165] Memory required for data: 1149748400
I0217 13:16:41.054364  8728 layer_factory.cpp:58] Creating layer conv4_0
I0217 13:16:41.054364  8728 net.cpp:100] Creating Layer conv4_0
I0217 13:16:41.054364  8728 net.cpp:434] conv4_0 <- pool4_2
I0217 13:16:41.054364  8728 net.cpp:408] conv4_0 -> conv4_0
I0217 13:16:41.064407  8728 net.cpp:150] Setting up conv4_0
I0217 13:16:41.064407  8728 net.cpp:157] Top shape: 100 512 4 4 (819200)
I0217 13:16:41.064407  8728 net.cpp:165] Memory required for data: 1153025200
I0217 13:16:41.064407  8728 layer_factory.cpp:58] Creating layer bn4_0
I0217 13:16:41.064407  8728 net.cpp:100] Creating Layer bn4_0
I0217 13:16:41.064407  8728 net.cpp:434] bn4_0 <- conv4_0
I0217 13:16:41.065381  8728 net.cpp:408] bn4_0 -> bn4_0
I0217 13:16:41.065381  8728 net.cpp:150] Setting up bn4_0
I0217 13:16:41.065381  8728 net.cpp:157] Top shape: 100 512 4 4 (819200)
I0217 13:16:41.065381  8728 net.cpp:165] Memory required for data: 1156302000
I0217 13:16:41.065381  8728 layer_factory.cpp:58] Creating layer scale4_0
I0217 13:16:41.065381  8728 net.cpp:100] Creating Layer scale4_0
I0217 13:16:41.065381  8728 net.cpp:434] scale4_0 <- bn4_0
I0217 13:16:41.065381  8728 net.cpp:408] scale4_0 -> scale4_0
I0217 13:16:41.065381  8728 layer_factory.cpp:58] Creating layer scale4_0
I0217 13:16:41.065381  8728 net.cpp:150] Setting up scale4_0
I0217 13:16:41.065381  8728 net.cpp:157] Top shape: 100 512 4 4 (819200)
I0217 13:16:41.065381  8728 net.cpp:165] Memory required for data: 1159578800
I0217 13:16:41.065381  8728 layer_factory.cpp:58] Creating layer relu4_0
I0217 13:16:41.065381  8728 net.cpp:100] Creating Layer relu4_0
I0217 13:16:41.065381  8728 net.cpp:434] relu4_0 <- scale4_0
I0217 13:16:41.065381  8728 net.cpp:408] relu4_0 -> relu4_0
I0217 13:16:41.065381  8728 net.cpp:150] Setting up relu4_0
I0217 13:16:41.065381  8728 net.cpp:157] Top shape: 100 512 4 4 (819200)
I0217 13:16:41.065381  8728 net.cpp:165] Memory required for data: 1162855600
I0217 13:16:41.065381  8728 layer_factory.cpp:58] Creating layer drop4_0
I0217 13:16:41.065381  8728 net.cpp:100] Creating Layer drop4_0
I0217 13:16:41.065381  8728 net.cpp:434] drop4_0 <- relu4_0
I0217 13:16:41.066380  8728 net.cpp:395] drop4_0 -> relu4_0 (in-place)
I0217 13:16:41.066380  8728 net.cpp:150] Setting up drop4_0
I0217 13:16:41.066380  8728 net.cpp:157] Top shape: 100 512 4 4 (819200)
I0217 13:16:41.066380  8728 net.cpp:165] Memory required for data: 1166132400
I0217 13:16:41.066380  8728 layer_factory.cpp:58] Creating layer cccp4
I0217 13:16:41.066380  8728 net.cpp:100] Creating Layer cccp4
I0217 13:16:41.066380  8728 net.cpp:434] cccp4 <- relu4_0
I0217 13:16:41.066380  8728 net.cpp:408] cccp4 -> cccp4
I0217 13:16:41.074381  8728 net.cpp:150] Setting up cccp4
I0217 13:16:41.074381  8728 net.cpp:157] Top shape: 100 2048 4 4 (3276800)
I0217 13:16:41.074381  8728 net.cpp:165] Memory required for data: 1179239600
I0217 13:16:41.074381  8728 layer_factory.cpp:58] Creating layer relu_cccp4
I0217 13:16:41.074381  8728 net.cpp:100] Creating Layer relu_cccp4
I0217 13:16:41.074381  8728 net.cpp:434] relu_cccp4 <- cccp4
I0217 13:16:41.074381  8728 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0217 13:16:41.074381  8728 net.cpp:150] Setting up relu_cccp4
I0217 13:16:41.074381  8728 net.cpp:157] Top shape: 100 2048 4 4 (3276800)
I0217 13:16:41.074381  8728 net.cpp:165] Memory required for data: 1192346800
I0217 13:16:41.074381  8728 layer_factory.cpp:58] Creating layer drop4_3
I0217 13:16:41.074381  8728 net.cpp:100] Creating Layer drop4_3
I0217 13:16:41.074381  8728 net.cpp:434] drop4_3 <- cccp4
I0217 13:16:41.074381  8728 net.cpp:395] drop4_3 -> cccp4 (in-place)
I0217 13:16:41.074381  8728 net.cpp:150] Setting up drop4_3
I0217 13:16:41.074381  8728 net.cpp:157] Top shape: 100 2048 4 4 (3276800)
I0217 13:16:41.075379  8728 net.cpp:165] Memory required for data: 1205454000
I0217 13:16:41.075379  8728 layer_factory.cpp:58] Creating layer cccp5
I0217 13:16:41.075379  8728 net.cpp:100] Creating Layer cccp5
I0217 13:16:41.075379  8728 net.cpp:434] cccp5 <- cccp4
I0217 13:16:41.075379  8728 net.cpp:408] cccp5 -> cccp5
I0217 13:16:41.079378  8728 net.cpp:150] Setting up cccp5
I0217 13:16:41.079378  8728 net.cpp:157] Top shape: 100 256 4 4 (409600)
I0217 13:16:41.079378  8728 net.cpp:165] Memory required for data: 1207092400
I0217 13:16:41.079378  8728 layer_factory.cpp:58] Creating layer relu_cccp5
I0217 13:16:41.079378  8728 net.cpp:100] Creating Layer relu_cccp5
I0217 13:16:41.079378  8728 net.cpp:434] relu_cccp5 <- cccp5
I0217 13:16:41.079378  8728 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0217 13:16:41.080379  8728 net.cpp:150] Setting up relu_cccp5
I0217 13:16:41.080379  8728 net.cpp:157] Top shape: 100 256 4 4 (409600)
I0217 13:16:41.080379  8728 net.cpp:165] Memory required for data: 1208730800
I0217 13:16:41.080379  8728 layer_factory.cpp:58] Creating layer poolcp5
I0217 13:16:41.080379  8728 net.cpp:100] Creating Layer poolcp5
I0217 13:16:41.080379  8728 net.cpp:434] poolcp5 <- cccp5
I0217 13:16:41.080379  8728 net.cpp:408] poolcp5 -> poolcp5
I0217 13:16:41.080379  8728 net.cpp:150] Setting up poolcp5
I0217 13:16:41.080379  8728 net.cpp:157] Top shape: 100 256 2 2 (102400)
I0217 13:16:41.080379  8728 net.cpp:165] Memory required for data: 1209140400
I0217 13:16:41.080379  8728 layer_factory.cpp:58] Creating layer drop4_5
I0217 13:16:41.080379  8728 net.cpp:100] Creating Layer drop4_5
I0217 13:16:41.080379  8728 net.cpp:434] drop4_5 <- poolcp5
I0217 13:16:41.080379  8728 net.cpp:395] drop4_5 -> poolcp5 (in-place)
I0217 13:16:41.080379  8728 net.cpp:150] Setting up drop4_5
I0217 13:16:41.080379  8728 net.cpp:157] Top shape: 100 256 2 2 (102400)
I0217 13:16:41.080379  8728 net.cpp:165] Memory required for data: 1209550000
I0217 13:16:41.080379  8728 layer_factory.cpp:58] Creating layer cccp6
I0217 13:16:41.080379  8728 net.cpp:100] Creating Layer cccp6
I0217 13:16:41.080379  8728 net.cpp:434] cccp6 <- poolcp5
I0217 13:16:41.080379  8728 net.cpp:408] cccp6 -> cccp6
I0217 13:16:41.086374  8728 net.cpp:150] Setting up cccp6
I0217 13:16:41.086374  8728 net.cpp:157] Top shape: 100 256 2 2 (102400)
I0217 13:16:41.086374  8728 net.cpp:165] Memory required for data: 1209959600
I0217 13:16:41.086374  8728 layer_factory.cpp:58] Creating layer relu_cccp6
I0217 13:16:41.086374  8728 net.cpp:100] Creating Layer relu_cccp6
I0217 13:16:41.086374  8728 net.cpp:434] relu_cccp6 <- cccp6
I0217 13:16:41.086374  8728 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0217 13:16:41.087365  8728 net.cpp:150] Setting up relu_cccp6
I0217 13:16:41.087365  8728 net.cpp:157] Top shape: 100 256 2 2 (102400)
I0217 13:16:41.087365  8728 net.cpp:165] Memory required for data: 1210369200
I0217 13:16:41.087365  8728 layer_factory.cpp:58] Creating layer poolcp6
I0217 13:16:41.087365  8728 net.cpp:100] Creating Layer poolcp6
I0217 13:16:41.087365  8728 net.cpp:434] poolcp6 <- cccp6
I0217 13:16:41.087365  8728 net.cpp:408] poolcp6 -> poolcp6
I0217 13:16:41.087365  8728 net.cpp:150] Setting up poolcp6
I0217 13:16:41.087365  8728 net.cpp:157] Top shape: 100 256 1 1 (25600)
I0217 13:16:41.087365  8728 net.cpp:165] Memory required for data: 1210471600
I0217 13:16:41.087365  8728 layer_factory.cpp:58] Creating layer ip1
I0217 13:16:41.087365  8728 net.cpp:100] Creating Layer ip1
I0217 13:16:41.087365  8728 net.cpp:434] ip1 <- poolcp6
I0217 13:16:41.087365  8728 net.cpp:408] ip1 -> ip1
I0217 13:16:41.087365  8728 net.cpp:150] Setting up ip1
I0217 13:16:41.087365  8728 net.cpp:157] Top shape: 100 10 (1000)
I0217 13:16:41.087365  8728 net.cpp:165] Memory required for data: 1210475600
I0217 13:16:41.087365  8728 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0217 13:16:41.087365  8728 net.cpp:100] Creating Layer ip1_ip1_0_split
I0217 13:16:41.087365  8728 net.cpp:434] ip1_ip1_0_split <- ip1
I0217 13:16:41.087365  8728 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0217 13:16:41.087365  8728 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0217 13:16:41.087365  8728 net.cpp:150] Setting up ip1_ip1_0_split
I0217 13:16:41.087365  8728 net.cpp:157] Top shape: 100 10 (1000)
I0217 13:16:41.087365  8728 net.cpp:157] Top shape: 100 10 (1000)
I0217 13:16:41.087365  8728 net.cpp:165] Memory required for data: 1210483600
I0217 13:16:41.087365  8728 layer_factory.cpp:58] Creating layer accuracy_training
I0217 13:16:41.087365  8728 net.cpp:100] Creating Layer accuracy_training
I0217 13:16:41.087365  8728 net.cpp:434] accuracy_training <- ip1_ip1_0_split_0
I0217 13:16:41.087365  8728 net.cpp:434] accuracy_training <- label_cifar_1_split_0
I0217 13:16:41.087365  8728 net.cpp:408] accuracy_training -> accuracy_training
I0217 13:16:41.087365  8728 net.cpp:150] Setting up accuracy_training
I0217 13:16:41.087365  8728 net.cpp:157] Top shape: (1)
I0217 13:16:41.087365  8728 net.cpp:165] Memory required for data: 1210483604
I0217 13:16:41.087365  8728 layer_factory.cpp:58] Creating layer loss
I0217 13:16:41.087365  8728 net.cpp:100] Creating Layer loss
I0217 13:16:41.087365  8728 net.cpp:434] loss <- ip1_ip1_0_split_1
I0217 13:16:41.087365  8728 net.cpp:434] loss <- label_cifar_1_split_1
I0217 13:16:41.087365  8728 net.cpp:408] loss -> loss
I0217 13:16:41.087365  8728 layer_factory.cpp:58] Creating layer loss
I0217 13:16:41.087365  8728 net.cpp:150] Setting up loss
I0217 13:16:41.088374  8728 net.cpp:157] Top shape: (1)
I0217 13:16:41.088374  8728 net.cpp:160]     with loss weight 1
I0217 13:16:41.088374  8728 net.cpp:165] Memory required for data: 1210483608
I0217 13:16:41.088374  8728 net.cpp:226] loss needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:228] accuracy_training does not need backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] ip1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] poolcp6 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu_cccp6 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] cccp6 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop4_5 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] poolcp5 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu_cccp5 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] cccp5 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop4_3 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu_cccp4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] cccp4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop4_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu4_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale4_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn4_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv4_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] pool4_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop4_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu4_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale4_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn4_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv4_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop4_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu4_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale4_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn4_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv4_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] pool4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv4 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop3 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu3 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale3 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn3 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv3 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop2_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu2_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale2_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn2_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv2_2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop2_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] pool2_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu2_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale2_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn2_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv2_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop2_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv2 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop1_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu1_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale1_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn1_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv1_0 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] drop2_1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] relu1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] scale1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] bn1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:226] conv1 needs backward computation.
I0217 13:16:41.088374  8728 net.cpp:228] label_cifar_1_split does not need backward computation.
I0217 13:16:41.088374  8728 net.cpp:228] cifar does not need backward computation.
I0217 13:16:41.088374  8728 net.cpp:270] This network produces output accuracy_training
I0217 13:16:41.088374  8728 net.cpp:270] This network produces output loss
I0217 13:16:41.088374  8728 net.cpp:283] Network initialization done.
I0217 13:16:41.089375  8728 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0217 13:16:41.089375  8728 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0217 13:16:41.089375  8728 solver.cpp:181] Creating test net (#0) specified by net file: examples/cifar10/cifar10_full_relu_train_test_bn.prototxt
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0217 13:16:41.089375  8728 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0217 13:16:41.089375  8728 net.cpp:58] Initializing net from parameters: 
name: "CIFAR10_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "examples/cifar10/mean.binaryproto"
  }
  data_param {
    source: "examples/cifar10/cifar10_test_lmdb"
    batch_size: 25
    backend: LMDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "relu1"
  top: "relu1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "drop1_0"
  type: "Dropout"
  bottom: "relu1_0"
  top: "relu1_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "drop2_0"
  type: "Dropout"
  bottom: "relu2"
  top: "relu2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop2_1"
  type: "Dropout"
  bottom: "pool2_1"
  top: "pool2_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "drop2_2"
  type: "Dropout"
  bottom: "relu2_2"
  top: "relu2_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "drop3"
  type: "Dropout"
  bottom: "relu3"
  top: "relu3"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "drop4"
  type: "Dropout"
  bottom: "relu4"
  top: "relu4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "drop4_1"
  type: "Dropout"
  bottom: "relu4_1"
  top: "relu4_1"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "drop4_2"
  type: "Dropout"
  bottom: "relu4_2"
  top: "relu4_2"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "drop4_0"
  type: "Dropout"
  bottom: "relu4_0"
  top: "relu4_0"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 2048
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "drop4_3"
  type: "Dropout"
  bottom: "cccp4"
  top: "cccp4"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "drop4_5"
  type: "Dropout"
  bottom: "poolcp5"
  top: "poolcp5"
  dropout_param {
    dropout_ratio: 0.2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 10
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0217 13:16:41.089375  8728 layer_factory.cpp:58] Creating layer cifar
I0217 13:16:41.090374  8728 net.cpp:100] Creating Layer cifar
I0217 13:16:41.090374  8728 net.cpp:408] cifar -> data
I0217 13:16:41.090374  8728 net.cpp:408] cifar -> label
I0217 13:16:41.090374  8728 data_transformer.cpp:25] Loading mean file from: examples/cifar10/mean.binaryproto
I0217 13:16:41.091378  7408 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0217 13:16:41.097393  7408 db_lmdb.cpp:40] Opened lmdb examples/cifar10/cifar10_test_lmdb
I0217 13:16:41.098378  8728 data_layer.cpp:41] output data size: 25,3,32,32
I0217 13:16:41.099375  8728 net.cpp:150] Setting up cifar
I0217 13:16:41.099375  8728 net.cpp:157] Top shape: 25 3 32 32 (76800)
I0217 13:16:41.099375  8728 net.cpp:157] Top shape: 25 (25)
I0217 13:16:41.099375  8728 net.cpp:165] Memory required for data: 307300
I0217 13:16:41.099375  8728 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0217 13:16:41.099375  8728 net.cpp:100] Creating Layer label_cifar_1_split
I0217 13:16:41.099375  8728 net.cpp:434] label_cifar_1_split <- label
I0217 13:16:41.099375  8728 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0217 13:16:41.099375  8728 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0217 13:16:41.099375  8728 net.cpp:150] Setting up label_cifar_1_split
I0217 13:16:41.099375  8728 net.cpp:157] Top shape: 25 (25)
I0217 13:16:41.099375  8728 net.cpp:157] Top shape: 25 (25)
I0217 13:16:41.099375  8728 net.cpp:165] Memory required for data: 307500
I0217 13:16:41.099375  8728 layer_factory.cpp:58] Creating layer conv1
I0217 13:16:41.099375  8728 net.cpp:100] Creating Layer conv1
I0217 13:16:41.099375  8728 net.cpp:434] conv1 <- data
I0217 13:16:41.099375  8728 net.cpp:408] conv1 -> conv1
I0217 13:16:41.100365  4412 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0217 13:16:41.101366  8728 net.cpp:150] Setting up conv1
I0217 13:16:41.101366  8728 net.cpp:157] Top shape: 25 64 32 32 (1638400)
I0217 13:16:41.101366  8728 net.cpp:165] Memory required for data: 6861100
I0217 13:16:41.101366  8728 layer_factory.cpp:58] Creating layer bn1
I0217 13:16:41.101366  8728 net.cpp:100] Creating Layer bn1
I0217 13:16:41.101366  8728 net.cpp:434] bn1 <- conv1
I0217 13:16:41.101366  8728 net.cpp:408] bn1 -> bn1
I0217 13:16:41.101366  8728 net.cpp:150] Setting up bn1
I0217 13:16:41.101366  8728 net.cpp:157] Top shape: 25 64 32 32 (1638400)
I0217 13:16:41.101366  8728 net.cpp:165] Memory required for data: 13414700
I0217 13:16:41.101366  8728 layer_factory.cpp:58] Creating layer scale1
I0217 13:16:41.101366  8728 net.cpp:100] Creating Layer scale1
I0217 13:16:41.101366  8728 net.cpp:434] scale1 <- bn1
I0217 13:16:41.101366  8728 net.cpp:408] scale1 -> scale1
I0217 13:16:41.101366  8728 layer_factory.cpp:58] Creating layer scale1
I0217 13:16:41.101366  8728 net.cpp:150] Setting up scale1
I0217 13:16:41.101366  8728 net.cpp:157] Top shape: 25 64 32 32 (1638400)
I0217 13:16:41.102365  8728 net.cpp:165] Memory required for data: 19968300
I0217 13:16:41.102365  8728 layer_factory.cpp:58] Creating layer relu1
I0217 13:16:41.102365  8728 net.cpp:100] Creating Layer relu1
I0217 13:16:41.102365  8728 net.cpp:434] relu1 <- scale1
I0217 13:16:41.102365  8728 net.cpp:408] relu1 -> relu1
I0217 13:16:41.102365  8728 net.cpp:150] Setting up relu1
I0217 13:16:41.102365  8728 net.cpp:157] Top shape: 25 64 32 32 (1638400)
I0217 13:16:41.102365  8728 net.cpp:165] Memory required for data: 26521900
I0217 13:16:41.102365  8728 layer_factory.cpp:58] Creating layer drop2_1
I0217 13:16:41.102365  8728 net.cpp:100] Creating Layer drop2_1
I0217 13:16:41.102365  8728 net.cpp:434] drop2_1 <- relu1
I0217 13:16:41.102365  8728 net.cpp:395] drop2_1 -> relu1 (in-place)
I0217 13:16:41.102365  8728 net.cpp:150] Setting up drop2_1
I0217 13:16:41.102365  8728 net.cpp:157] Top shape: 25 64 32 32 (1638400)
I0217 13:16:41.102365  8728 net.cpp:165] Memory required for data: 33075500
I0217 13:16:41.102365  8728 layer_factory.cpp:58] Creating layer conv1_0
I0217 13:16:41.102365  8728 net.cpp:100] Creating Layer conv1_0
I0217 13:16:41.102365  8728 net.cpp:434] conv1_0 <- relu1
I0217 13:16:41.102365  8728 net.cpp:408] conv1_0 -> conv1_0
I0217 13:16:41.104365  8728 net.cpp:150] Setting up conv1_0
I0217 13:16:41.104365  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.104365  8728 net.cpp:165] Memory required for data: 46182700
I0217 13:16:41.104365  8728 layer_factory.cpp:58] Creating layer bn1_0
I0217 13:16:41.104365  8728 net.cpp:100] Creating Layer bn1_0
I0217 13:16:41.104365  8728 net.cpp:434] bn1_0 <- conv1_0
I0217 13:16:41.104365  8728 net.cpp:408] bn1_0 -> bn1_0
I0217 13:16:41.105365  8728 net.cpp:150] Setting up bn1_0
I0217 13:16:41.105365  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.105365  8728 net.cpp:165] Memory required for data: 59289900
I0217 13:16:41.105365  8728 layer_factory.cpp:58] Creating layer scale1_0
I0217 13:16:41.105365  8728 net.cpp:100] Creating Layer scale1_0
I0217 13:16:41.105365  8728 net.cpp:434] scale1_0 <- bn1_0
I0217 13:16:41.105365  8728 net.cpp:408] scale1_0 -> scale1_0
I0217 13:16:41.105365  8728 layer_factory.cpp:58] Creating layer scale1_0
I0217 13:16:41.105365  8728 net.cpp:150] Setting up scale1_0
I0217 13:16:41.105365  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.105365  8728 net.cpp:165] Memory required for data: 72397100
I0217 13:16:41.105365  8728 layer_factory.cpp:58] Creating layer relu1_0
I0217 13:16:41.105365  8728 net.cpp:100] Creating Layer relu1_0
I0217 13:16:41.105365  8728 net.cpp:434] relu1_0 <- scale1_0
I0217 13:16:41.105365  8728 net.cpp:408] relu1_0 -> relu1_0
I0217 13:16:41.105365  8728 net.cpp:150] Setting up relu1_0
I0217 13:16:41.105365  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.105365  8728 net.cpp:165] Memory required for data: 85504300
I0217 13:16:41.105365  8728 layer_factory.cpp:58] Creating layer drop1_0
I0217 13:16:41.105365  8728 net.cpp:100] Creating Layer drop1_0
I0217 13:16:41.105365  8728 net.cpp:434] drop1_0 <- relu1_0
I0217 13:16:41.105365  8728 net.cpp:395] drop1_0 -> relu1_0 (in-place)
I0217 13:16:41.105365  8728 net.cpp:150] Setting up drop1_0
I0217 13:16:41.105365  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.105365  8728 net.cpp:165] Memory required for data: 98611500
I0217 13:16:41.105365  8728 layer_factory.cpp:58] Creating layer conv2
I0217 13:16:41.105365  8728 net.cpp:100] Creating Layer conv2
I0217 13:16:41.106364  8728 net.cpp:434] conv2 <- relu1_0
I0217 13:16:41.106364  8728 net.cpp:408] conv2 -> conv2
I0217 13:16:41.109364  8728 net.cpp:150] Setting up conv2
I0217 13:16:41.109364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.109364  8728 net.cpp:165] Memory required for data: 111718700
I0217 13:16:41.109364  8728 layer_factory.cpp:58] Creating layer bn2
I0217 13:16:41.109364  8728 net.cpp:100] Creating Layer bn2
I0217 13:16:41.109364  8728 net.cpp:434] bn2 <- conv2
I0217 13:16:41.109364  8728 net.cpp:408] bn2 -> bn2
I0217 13:16:41.109364  8728 net.cpp:150] Setting up bn2
I0217 13:16:41.109364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.109364  8728 net.cpp:165] Memory required for data: 124825900
I0217 13:16:41.109364  8728 layer_factory.cpp:58] Creating layer scale2
I0217 13:16:41.109364  8728 net.cpp:100] Creating Layer scale2
I0217 13:16:41.109364  8728 net.cpp:434] scale2 <- bn2
I0217 13:16:41.109364  8728 net.cpp:408] scale2 -> scale2
I0217 13:16:41.109364  8728 layer_factory.cpp:58] Creating layer scale2
I0217 13:16:41.109364  8728 net.cpp:150] Setting up scale2
I0217 13:16:41.109364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.109364  8728 net.cpp:165] Memory required for data: 137933100
I0217 13:16:41.109364  8728 layer_factory.cpp:58] Creating layer relu2
I0217 13:16:41.109364  8728 net.cpp:100] Creating Layer relu2
I0217 13:16:41.109364  8728 net.cpp:434] relu2 <- scale2
I0217 13:16:41.109364  8728 net.cpp:408] relu2 -> relu2
I0217 13:16:41.109364  8728 net.cpp:150] Setting up relu2
I0217 13:16:41.109364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.109364  8728 net.cpp:165] Memory required for data: 151040300
I0217 13:16:41.109364  8728 layer_factory.cpp:58] Creating layer drop2_0
I0217 13:16:41.109364  8728 net.cpp:100] Creating Layer drop2_0
I0217 13:16:41.109364  8728 net.cpp:434] drop2_0 <- relu2
I0217 13:16:41.109364  8728 net.cpp:395] drop2_0 -> relu2 (in-place)
I0217 13:16:41.109364  8728 net.cpp:150] Setting up drop2_0
I0217 13:16:41.109364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.109364  8728 net.cpp:165] Memory required for data: 164147500
I0217 13:16:41.109364  8728 layer_factory.cpp:58] Creating layer conv2_1
I0217 13:16:41.109364  8728 net.cpp:100] Creating Layer conv2_1
I0217 13:16:41.109364  8728 net.cpp:434] conv2_1 <- relu2
I0217 13:16:41.109364  8728 net.cpp:408] conv2_1 -> conv2_1
I0217 13:16:41.113364  8728 net.cpp:150] Setting up conv2_1
I0217 13:16:41.113364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.113364  8728 net.cpp:165] Memory required for data: 177254700
I0217 13:16:41.113364  8728 layer_factory.cpp:58] Creating layer bn2_1
I0217 13:16:41.113364  8728 net.cpp:100] Creating Layer bn2_1
I0217 13:16:41.113364  8728 net.cpp:434] bn2_1 <- conv2_1
I0217 13:16:41.113364  8728 net.cpp:408] bn2_1 -> bn2_1
I0217 13:16:41.113364  8728 net.cpp:150] Setting up bn2_1
I0217 13:16:41.113364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.113364  8728 net.cpp:165] Memory required for data: 190361900
I0217 13:16:41.113364  8728 layer_factory.cpp:58] Creating layer scale2_1
I0217 13:16:41.113364  8728 net.cpp:100] Creating Layer scale2_1
I0217 13:16:41.113364  8728 net.cpp:434] scale2_1 <- bn2_1
I0217 13:16:41.113364  8728 net.cpp:408] scale2_1 -> scale2_1
I0217 13:16:41.113364  8728 layer_factory.cpp:58] Creating layer scale2_1
I0217 13:16:41.113364  8728 net.cpp:150] Setting up scale2_1
I0217 13:16:41.113364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.113364  8728 net.cpp:165] Memory required for data: 203469100
I0217 13:16:41.113364  8728 layer_factory.cpp:58] Creating layer relu2_1
I0217 13:16:41.113364  8728 net.cpp:100] Creating Layer relu2_1
I0217 13:16:41.113364  8728 net.cpp:434] relu2_1 <- scale2_1
I0217 13:16:41.113364  8728 net.cpp:408] relu2_1 -> relu2_1
I0217 13:16:41.114364  8728 net.cpp:150] Setting up relu2_1
I0217 13:16:41.114364  8728 net.cpp:157] Top shape: 25 128 32 32 (3276800)
I0217 13:16:41.114364  8728 net.cpp:165] Memory required for data: 216576300
I0217 13:16:41.114364  8728 layer_factory.cpp:58] Creating layer pool2_1
I0217 13:16:41.114364  8728 net.cpp:100] Creating Layer pool2_1
I0217 13:16:41.114364  8728 net.cpp:434] pool2_1 <- relu2_1
I0217 13:16:41.114364  8728 net.cpp:408] pool2_1 -> pool2_1
I0217 13:16:41.114364  8728 net.cpp:150] Setting up pool2_1
I0217 13:16:41.114364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.114364  8728 net.cpp:165] Memory required for data: 219853100
I0217 13:16:41.114364  8728 layer_factory.cpp:58] Creating layer drop2_1
I0217 13:16:41.114364  8728 net.cpp:100] Creating Layer drop2_1
I0217 13:16:41.114364  8728 net.cpp:434] drop2_1 <- pool2_1
I0217 13:16:41.114364  8728 net.cpp:395] drop2_1 -> pool2_1 (in-place)
I0217 13:16:41.114364  8728 net.cpp:150] Setting up drop2_1
I0217 13:16:41.114364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.114364  8728 net.cpp:165] Memory required for data: 223129900
I0217 13:16:41.114364  8728 layer_factory.cpp:58] Creating layer conv2_2
I0217 13:16:41.114364  8728 net.cpp:100] Creating Layer conv2_2
I0217 13:16:41.114364  8728 net.cpp:434] conv2_2 <- pool2_1
I0217 13:16:41.114364  8728 net.cpp:408] conv2_2 -> conv2_2
I0217 13:16:41.117364  8728 net.cpp:150] Setting up conv2_2
I0217 13:16:41.117364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.117364  8728 net.cpp:165] Memory required for data: 226406700
I0217 13:16:41.117364  8728 layer_factory.cpp:58] Creating layer bn2_2
I0217 13:16:41.117364  8728 net.cpp:100] Creating Layer bn2_2
I0217 13:16:41.117364  8728 net.cpp:434] bn2_2 <- conv2_2
I0217 13:16:41.117364  8728 net.cpp:408] bn2_2 -> bn2_2
I0217 13:16:41.117364  8728 net.cpp:150] Setting up bn2_2
I0217 13:16:41.117364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.117364  8728 net.cpp:165] Memory required for data: 229683500
I0217 13:16:41.117364  8728 layer_factory.cpp:58] Creating layer scale2_2
I0217 13:16:41.117364  8728 net.cpp:100] Creating Layer scale2_2
I0217 13:16:41.117364  8728 net.cpp:434] scale2_2 <- bn2_2
I0217 13:16:41.117364  8728 net.cpp:408] scale2_2 -> scale2_2
I0217 13:16:41.118365  8728 layer_factory.cpp:58] Creating layer scale2_2
I0217 13:16:41.118365  8728 net.cpp:150] Setting up scale2_2
I0217 13:16:41.118365  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.118365  8728 net.cpp:165] Memory required for data: 232960300
I0217 13:16:41.118365  8728 layer_factory.cpp:58] Creating layer relu2_2
I0217 13:16:41.118365  8728 net.cpp:100] Creating Layer relu2_2
I0217 13:16:41.118365  8728 net.cpp:434] relu2_2 <- scale2_2
I0217 13:16:41.118365  8728 net.cpp:408] relu2_2 -> relu2_2
I0217 13:16:41.118365  8728 net.cpp:150] Setting up relu2_2
I0217 13:16:41.118365  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.118365  8728 net.cpp:165] Memory required for data: 236237100
I0217 13:16:41.118365  8728 layer_factory.cpp:58] Creating layer drop2_2
I0217 13:16:41.118365  8728 net.cpp:100] Creating Layer drop2_2
I0217 13:16:41.118365  8728 net.cpp:434] drop2_2 <- relu2_2
I0217 13:16:41.118365  8728 net.cpp:395] drop2_2 -> relu2_2 (in-place)
I0217 13:16:41.118365  8728 net.cpp:150] Setting up drop2_2
I0217 13:16:41.118365  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.118365  8728 net.cpp:165] Memory required for data: 239513900
I0217 13:16:41.118365  8728 layer_factory.cpp:58] Creating layer conv3
I0217 13:16:41.118365  8728 net.cpp:100] Creating Layer conv3
I0217 13:16:41.118365  8728 net.cpp:434] conv3 <- relu2_2
I0217 13:16:41.118365  8728 net.cpp:408] conv3 -> conv3
I0217 13:16:41.121364  8728 net.cpp:150] Setting up conv3
I0217 13:16:41.121364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.121364  8728 net.cpp:165] Memory required for data: 242790700
I0217 13:16:41.121364  8728 layer_factory.cpp:58] Creating layer bn3
I0217 13:16:41.121364  8728 net.cpp:100] Creating Layer bn3
I0217 13:16:41.121364  8728 net.cpp:434] bn3 <- conv3
I0217 13:16:41.121364  8728 net.cpp:408] bn3 -> bn3
I0217 13:16:41.121364  8728 net.cpp:150] Setting up bn3
I0217 13:16:41.121364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.121364  8728 net.cpp:165] Memory required for data: 246067500
I0217 13:16:41.121364  8728 layer_factory.cpp:58] Creating layer scale3
I0217 13:16:41.121364  8728 net.cpp:100] Creating Layer scale3
I0217 13:16:41.121364  8728 net.cpp:434] scale3 <- bn3
I0217 13:16:41.121364  8728 net.cpp:408] scale3 -> scale3
I0217 13:16:41.121364  8728 layer_factory.cpp:58] Creating layer scale3
I0217 13:16:41.121364  8728 net.cpp:150] Setting up scale3
I0217 13:16:41.121364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.121364  8728 net.cpp:165] Memory required for data: 249344300
I0217 13:16:41.121364  8728 layer_factory.cpp:58] Creating layer relu3
I0217 13:16:41.121364  8728 net.cpp:100] Creating Layer relu3
I0217 13:16:41.122364  8728 net.cpp:434] relu3 <- scale3
I0217 13:16:41.122364  8728 net.cpp:408] relu3 -> relu3
I0217 13:16:41.122364  8728 net.cpp:150] Setting up relu3
I0217 13:16:41.122364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.122364  8728 net.cpp:165] Memory required for data: 252621100
I0217 13:16:41.122364  8728 layer_factory.cpp:58] Creating layer drop3
I0217 13:16:41.122364  8728 net.cpp:100] Creating Layer drop3
I0217 13:16:41.122364  8728 net.cpp:434] drop3 <- relu3
I0217 13:16:41.122364  8728 net.cpp:395] drop3 -> relu3 (in-place)
I0217 13:16:41.122364  8728 net.cpp:150] Setting up drop3
I0217 13:16:41.122364  8728 net.cpp:157] Top shape: 25 128 16 16 (819200)
I0217 13:16:41.122364  8728 net.cpp:165] Memory required for data: 255897900
I0217 13:16:41.122364  8728 layer_factory.cpp:58] Creating layer conv4
I0217 13:16:41.122364  8728 net.cpp:100] Creating Layer conv4
I0217 13:16:41.122364  8728 net.cpp:434] conv4 <- relu3
I0217 13:16:41.122364  8728 net.cpp:408] conv4 -> conv4
I0217 13:16:41.126364  8728 net.cpp:150] Setting up conv4
I0217 13:16:41.126364  8728 net.cpp:157] Top shape: 25 256 16 16 (1638400)
I0217 13:16:41.126364  8728 net.cpp:165] Memory required for data: 262451500
I0217 13:16:41.126364  8728 layer_factory.cpp:58] Creating layer pool4
I0217 13:16:41.126364  8728 net.cpp:100] Creating Layer pool4
I0217 13:16:41.126364  8728 net.cpp:434] pool4 <- conv4
I0217 13:16:41.126364  8728 net.cpp:408] pool4 -> pool4
I0217 13:16:41.126364  8728 net.cpp:150] Setting up pool4
I0217 13:16:41.126364  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.126364  8728 net.cpp:165] Memory required for data: 264089900
I0217 13:16:41.126364  8728 layer_factory.cpp:58] Creating layer bn4
I0217 13:16:41.126364  8728 net.cpp:100] Creating Layer bn4
I0217 13:16:41.126364  8728 net.cpp:434] bn4 <- pool4
I0217 13:16:41.126364  8728 net.cpp:408] bn4 -> bn4
I0217 13:16:41.126364  8728 net.cpp:150] Setting up bn4
I0217 13:16:41.126364  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.126364  8728 net.cpp:165] Memory required for data: 265728300
I0217 13:16:41.126364  8728 layer_factory.cpp:58] Creating layer scale4
I0217 13:16:41.126364  8728 net.cpp:100] Creating Layer scale4
I0217 13:16:41.126364  8728 net.cpp:434] scale4 <- bn4
I0217 13:16:41.126364  8728 net.cpp:408] scale4 -> scale4
I0217 13:16:41.126364  8728 layer_factory.cpp:58] Creating layer scale4
I0217 13:16:41.126364  8728 net.cpp:150] Setting up scale4
I0217 13:16:41.126364  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.126364  8728 net.cpp:165] Memory required for data: 267366700
I0217 13:16:41.126364  8728 layer_factory.cpp:58] Creating layer relu4
I0217 13:16:41.126364  8728 net.cpp:100] Creating Layer relu4
I0217 13:16:41.126364  8728 net.cpp:434] relu4 <- scale4
I0217 13:16:41.126364  8728 net.cpp:408] relu4 -> relu4
I0217 13:16:41.127364  8728 net.cpp:150] Setting up relu4
I0217 13:16:41.127364  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.127364  8728 net.cpp:165] Memory required for data: 269005100
I0217 13:16:41.127364  8728 layer_factory.cpp:58] Creating layer drop4
I0217 13:16:41.127364  8728 net.cpp:100] Creating Layer drop4
I0217 13:16:41.127364  8728 net.cpp:434] drop4 <- relu4
I0217 13:16:41.127364  8728 net.cpp:395] drop4 -> relu4 (in-place)
I0217 13:16:41.127364  8728 net.cpp:150] Setting up drop4
I0217 13:16:41.127364  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.127364  8728 net.cpp:165] Memory required for data: 270643500
I0217 13:16:41.127364  8728 layer_factory.cpp:58] Creating layer conv4_1
I0217 13:16:41.127364  8728 net.cpp:100] Creating Layer conv4_1
I0217 13:16:41.127364  8728 net.cpp:434] conv4_1 <- relu4
I0217 13:16:41.127364  8728 net.cpp:408] conv4_1 -> conv4_1
I0217 13:16:41.133368  8728 net.cpp:150] Setting up conv4_1
I0217 13:16:41.133368  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.133368  8728 net.cpp:165] Memory required for data: 272281900
I0217 13:16:41.133368  8728 layer_factory.cpp:58] Creating layer bn4_1
I0217 13:16:41.133368  8728 net.cpp:100] Creating Layer bn4_1
I0217 13:16:41.133368  8728 net.cpp:434] bn4_1 <- conv4_1
I0217 13:16:41.133368  8728 net.cpp:408] bn4_1 -> bn4_1
I0217 13:16:41.134367  8728 net.cpp:150] Setting up bn4_1
I0217 13:16:41.134367  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.134367  8728 net.cpp:165] Memory required for data: 273920300
I0217 13:16:41.134367  8728 layer_factory.cpp:58] Creating layer scale4_1
I0217 13:16:41.134367  8728 net.cpp:100] Creating Layer scale4_1
I0217 13:16:41.134367  8728 net.cpp:434] scale4_1 <- bn4_1
I0217 13:16:41.134367  8728 net.cpp:408] scale4_1 -> scale4_1
I0217 13:16:41.134367  8728 layer_factory.cpp:58] Creating layer scale4_1
I0217 13:16:41.134367  8728 net.cpp:150] Setting up scale4_1
I0217 13:16:41.134367  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.134367  8728 net.cpp:165] Memory required for data: 275558700
I0217 13:16:41.134367  8728 layer_factory.cpp:58] Creating layer relu4_1
I0217 13:16:41.134367  8728 net.cpp:100] Creating Layer relu4_1
I0217 13:16:41.134367  8728 net.cpp:434] relu4_1 <- scale4_1
I0217 13:16:41.134367  8728 net.cpp:408] relu4_1 -> relu4_1
I0217 13:16:41.134367  8728 net.cpp:150] Setting up relu4_1
I0217 13:16:41.135365  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.135365  8728 net.cpp:165] Memory required for data: 277197100
I0217 13:16:41.135365  8728 layer_factory.cpp:58] Creating layer drop4_1
I0217 13:16:41.135365  8728 net.cpp:100] Creating Layer drop4_1
I0217 13:16:41.135365  8728 net.cpp:434] drop4_1 <- relu4_1
I0217 13:16:41.135365  8728 net.cpp:395] drop4_1 -> relu4_1 (in-place)
I0217 13:16:41.135365  8728 net.cpp:150] Setting up drop4_1
I0217 13:16:41.135365  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.135365  8728 net.cpp:165] Memory required for data: 278835500
I0217 13:16:41.135365  8728 layer_factory.cpp:58] Creating layer conv4_2
I0217 13:16:41.135365  8728 net.cpp:100] Creating Layer conv4_2
I0217 13:16:41.135365  8728 net.cpp:434] conv4_2 <- relu4_1
I0217 13:16:41.135365  8728 net.cpp:408] conv4_2 -> conv4_2
I0217 13:16:41.143882  8728 net.cpp:150] Setting up conv4_2
I0217 13:16:41.143882  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.143882  8728 net.cpp:165] Memory required for data: 280473900
I0217 13:16:41.143882  8728 layer_factory.cpp:58] Creating layer bn4_2
I0217 13:16:41.143882  8728 net.cpp:100] Creating Layer bn4_2
I0217 13:16:41.143882  8728 net.cpp:434] bn4_2 <- conv4_2
I0217 13:16:41.143882  8728 net.cpp:408] bn4_2 -> bn4_2
I0217 13:16:41.144395  8728 net.cpp:150] Setting up bn4_2
I0217 13:16:41.144395  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.144395  8728 net.cpp:165] Memory required for data: 282112300
I0217 13:16:41.144395  8728 layer_factory.cpp:58] Creating layer scale4_2
I0217 13:16:41.144395  8728 net.cpp:100] Creating Layer scale4_2
I0217 13:16:41.144395  8728 net.cpp:434] scale4_2 <- bn4_2
I0217 13:16:41.144395  8728 net.cpp:408] scale4_2 -> scale4_2
I0217 13:16:41.144395  8728 layer_factory.cpp:58] Creating layer scale4_2
I0217 13:16:41.144881  8728 net.cpp:150] Setting up scale4_2
I0217 13:16:41.144881  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.145382  8728 net.cpp:165] Memory required for data: 283750700
I0217 13:16:41.145382  8728 layer_factory.cpp:58] Creating layer relu4_2
I0217 13:16:41.145382  8728 net.cpp:100] Creating Layer relu4_2
I0217 13:16:41.145382  8728 net.cpp:434] relu4_2 <- scale4_2
I0217 13:16:41.145382  8728 net.cpp:408] relu4_2 -> relu4_2
I0217 13:16:41.145382  8728 net.cpp:150] Setting up relu4_2
I0217 13:16:41.145882  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.145882  8728 net.cpp:165] Memory required for data: 285389100
I0217 13:16:41.145882  8728 layer_factory.cpp:58] Creating layer drop4_2
I0217 13:16:41.145882  8728 net.cpp:100] Creating Layer drop4_2
I0217 13:16:41.145882  8728 net.cpp:434] drop4_2 <- relu4_2
I0217 13:16:41.145882  8728 net.cpp:395] drop4_2 -> relu4_2 (in-place)
I0217 13:16:41.145882  8728 net.cpp:150] Setting up drop4_2
I0217 13:16:41.145882  8728 net.cpp:157] Top shape: 25 256 8 8 (409600)
I0217 13:16:41.145882  8728 net.cpp:165] Memory required for data: 287027500
I0217 13:16:41.145882  8728 layer_factory.cpp:58] Creating layer pool4_2
I0217 13:16:41.145882  8728 net.cpp:100] Creating Layer pool4_2
I0217 13:16:41.145882  8728 net.cpp:434] pool4_2 <- relu4_2
I0217 13:16:41.145882  8728 net.cpp:408] pool4_2 -> pool4_2
I0217 13:16:41.145882  8728 net.cpp:150] Setting up pool4_2
I0217 13:16:41.145882  8728 net.cpp:157] Top shape: 25 256 4 4 (102400)
I0217 13:16:41.145882  8728 net.cpp:165] Memory required for data: 287437100
I0217 13:16:41.145882  8728 layer_factory.cpp:58] Creating layer conv4_0
I0217 13:16:41.145882  8728 net.cpp:100] Creating Layer conv4_0
I0217 13:16:41.145882  8728 net.cpp:434] conv4_0 <- pool4_2
I0217 13:16:41.145882  8728 net.cpp:408] conv4_0 -> conv4_0
I0217 13:16:41.156406  8728 net.cpp:150] Setting up conv4_0
I0217 13:16:41.156406  8728 net.cpp:157] Top shape: 25 512 4 4 (204800)
I0217 13:16:41.156406  8728 net.cpp:165] Memory required for data: 288256300
I0217 13:16:41.156406  8728 layer_factory.cpp:58] Creating layer bn4_0
I0217 13:16:41.156406  8728 net.cpp:100] Creating Layer bn4_0
I0217 13:16:41.156406  8728 net.cpp:434] bn4_0 <- conv4_0
I0217 13:16:41.156406  8728 net.cpp:408] bn4_0 -> bn4_0
I0217 13:16:41.157407  8728 net.cpp:150] Setting up bn4_0
I0217 13:16:41.157407  8728 net.cpp:157] Top shape: 25 512 4 4 (204800)
I0217 13:16:41.157407  8728 net.cpp:165] Memory required for data: 289075500
I0217 13:16:41.157407  8728 layer_factory.cpp:58] Creating layer scale4_0
I0217 13:16:41.157407  8728 net.cpp:100] Creating Layer scale4_0
I0217 13:16:41.157407  8728 net.cpp:434] scale4_0 <- bn4_0
I0217 13:16:41.157407  8728 net.cpp:408] scale4_0 -> scale4_0
I0217 13:16:41.157407  8728 layer_factory.cpp:58] Creating layer scale4_0
I0217 13:16:41.157407  8728 net.cpp:150] Setting up scale4_0
I0217 13:16:41.157407  8728 net.cpp:157] Top shape: 25 512 4 4 (204800)
I0217 13:16:41.157407  8728 net.cpp:165] Memory required for data: 289894700
I0217 13:16:41.157407  8728 layer_factory.cpp:58] Creating layer relu4_0
I0217 13:16:41.157407  8728 net.cpp:100] Creating Layer relu4_0
I0217 13:16:41.157407  8728 net.cpp:434] relu4_0 <- scale4_0
I0217 13:16:41.157407  8728 net.cpp:408] relu4_0 -> relu4_0
I0217 13:16:41.157407  8728 net.cpp:150] Setting up relu4_0
I0217 13:16:41.157407  8728 net.cpp:157] Top shape: 25 512 4 4 (204800)
I0217 13:16:41.157407  8728 net.cpp:165] Memory required for data: 290713900
I0217 13:16:41.157407  8728 layer_factory.cpp:58] Creating layer drop4_0
I0217 13:16:41.157407  8728 net.cpp:100] Creating Layer drop4_0
I0217 13:16:41.157407  8728 net.cpp:434] drop4_0 <- relu4_0
I0217 13:16:41.157407  8728 net.cpp:395] drop4_0 -> relu4_0 (in-place)
I0217 13:16:41.157407  8728 net.cpp:150] Setting up drop4_0
I0217 13:16:41.158407  8728 net.cpp:157] Top shape: 25 512 4 4 (204800)
I0217 13:16:41.158407  8728 net.cpp:165] Memory required for data: 291533100
I0217 13:16:41.158407  8728 layer_factory.cpp:58] Creating layer cccp4
I0217 13:16:41.158407  8728 net.cpp:100] Creating Layer cccp4
I0217 13:16:41.158407  8728 net.cpp:434] cccp4 <- relu4_0
I0217 13:16:41.158407  8728 net.cpp:408] cccp4 -> cccp4
I0217 13:16:41.166398  8728 net.cpp:150] Setting up cccp4
I0217 13:16:41.166398  8728 net.cpp:157] Top shape: 25 2048 4 4 (819200)
I0217 13:16:41.166398  8728 net.cpp:165] Memory required for data: 294809900
I0217 13:16:41.166398  8728 layer_factory.cpp:58] Creating layer relu_cccp4
I0217 13:16:41.166398  8728 net.cpp:100] Creating Layer relu_cccp4
I0217 13:16:41.166398  8728 net.cpp:434] relu_cccp4 <- cccp4
I0217 13:16:41.166398  8728 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0217 13:16:41.167407  8728 net.cpp:150] Setting up relu_cccp4
I0217 13:16:41.167407  8728 net.cpp:157] Top shape: 25 2048 4 4 (819200)
I0217 13:16:41.167407  8728 net.cpp:165] Memory required for data: 298086700
I0217 13:16:41.167407  8728 layer_factory.cpp:58] Creating layer drop4_3
I0217 13:16:41.167407  8728 net.cpp:100] Creating Layer drop4_3
I0217 13:16:41.167407  8728 net.cpp:434] drop4_3 <- cccp4
I0217 13:16:41.167407  8728 net.cpp:395] drop4_3 -> cccp4 (in-place)
I0217 13:16:41.167407  8728 net.cpp:150] Setting up drop4_3
I0217 13:16:41.167407  8728 net.cpp:157] Top shape: 25 2048 4 4 (819200)
I0217 13:16:41.167407  8728 net.cpp:165] Memory required for data: 301363500
I0217 13:16:41.167407  8728 layer_factory.cpp:58] Creating layer cccp5
I0217 13:16:41.167407  8728 net.cpp:100] Creating Layer cccp5
I0217 13:16:41.167407  8728 net.cpp:434] cccp5 <- cccp4
I0217 13:16:41.167407  8728 net.cpp:408] cccp5 -> cccp5
I0217 13:16:41.172406  8728 net.cpp:150] Setting up cccp5
I0217 13:16:41.172406  8728 net.cpp:157] Top shape: 25 256 4 4 (102400)
I0217 13:16:41.172406  8728 net.cpp:165] Memory required for data: 301773100
I0217 13:16:41.172406  8728 layer_factory.cpp:58] Creating layer relu_cccp5
I0217 13:16:41.172406  8728 net.cpp:100] Creating Layer relu_cccp5
I0217 13:16:41.172406  8728 net.cpp:434] relu_cccp5 <- cccp5
I0217 13:16:41.172406  8728 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0217 13:16:41.172406  8728 net.cpp:150] Setting up relu_cccp5
I0217 13:16:41.172406  8728 net.cpp:157] Top shape: 25 256 4 4 (102400)
I0217 13:16:41.172406  8728 net.cpp:165] Memory required for data: 302182700
I0217 13:16:41.172406  8728 layer_factory.cpp:58] Creating layer poolcp5
I0217 13:16:41.172406  8728 net.cpp:100] Creating Layer poolcp5
I0217 13:16:41.172406  8728 net.cpp:434] poolcp5 <- cccp5
I0217 13:16:41.172406  8728 net.cpp:408] poolcp5 -> poolcp5
I0217 13:16:41.172406  8728 net.cpp:150] Setting up poolcp5
I0217 13:16:41.172406  8728 net.cpp:157] Top shape: 25 256 2 2 (25600)
I0217 13:16:41.172406  8728 net.cpp:165] Memory required for data: 302285100
I0217 13:16:41.172406  8728 layer_factory.cpp:58] Creating layer drop4_5
I0217 13:16:41.172406  8728 net.cpp:100] Creating Layer drop4_5
I0217 13:16:41.172406  8728 net.cpp:434] drop4_5 <- poolcp5
I0217 13:16:41.172406  8728 net.cpp:395] drop4_5 -> poolcp5 (in-place)
I0217 13:16:41.172406  8728 net.cpp:150] Setting up drop4_5
I0217 13:16:41.172406  8728 net.cpp:157] Top shape: 25 256 2 2 (25600)
I0217 13:16:41.172406  8728 net.cpp:165] Memory required for data: 302387500
I0217 13:16:41.172406  8728 layer_factory.cpp:58] Creating layer cccp6
I0217 13:16:41.172406  8728 net.cpp:100] Creating Layer cccp6
I0217 13:16:41.172406  8728 net.cpp:434] cccp6 <- poolcp5
I0217 13:16:41.172406  8728 net.cpp:408] cccp6 -> cccp6
I0217 13:16:41.178411  8728 net.cpp:150] Setting up cccp6
I0217 13:16:41.178411  8728 net.cpp:157] Top shape: 25 256 2 2 (25600)
I0217 13:16:41.178411  8728 net.cpp:165] Memory required for data: 302489900
I0217 13:16:41.178411  8728 layer_factory.cpp:58] Creating layer relu_cccp6
I0217 13:16:41.178411  8728 net.cpp:100] Creating Layer relu_cccp6
I0217 13:16:41.178411  8728 net.cpp:434] relu_cccp6 <- cccp6
I0217 13:16:41.178411  8728 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0217 13:16:41.179411  8728 net.cpp:150] Setting up relu_cccp6
I0217 13:16:41.179411  8728 net.cpp:157] Top shape: 25 256 2 2 (25600)
I0217 13:16:41.179411  8728 net.cpp:165] Memory required for data: 302592300
I0217 13:16:41.179411  8728 layer_factory.cpp:58] Creating layer poolcp6
I0217 13:16:41.179411  8728 net.cpp:100] Creating Layer poolcp6
I0217 13:16:41.179411  8728 net.cpp:434] poolcp6 <- cccp6
I0217 13:16:41.179411  8728 net.cpp:408] poolcp6 -> poolcp6
I0217 13:16:41.179411  8728 net.cpp:150] Setting up poolcp6
I0217 13:16:41.179411  8728 net.cpp:157] Top shape: 25 256 1 1 (6400)
I0217 13:16:41.179411  8728 net.cpp:165] Memory required for data: 302617900
I0217 13:16:41.179411  8728 layer_factory.cpp:58] Creating layer ip1
I0217 13:16:41.179411  8728 net.cpp:100] Creating Layer ip1
I0217 13:16:41.179411  8728 net.cpp:434] ip1 <- poolcp6
I0217 13:16:41.179411  8728 net.cpp:408] ip1 -> ip1
I0217 13:16:41.179411  8728 net.cpp:150] Setting up ip1
I0217 13:16:41.179411  8728 net.cpp:157] Top shape: 25 10 (250)
I0217 13:16:41.179411  8728 net.cpp:165] Memory required for data: 302618900
I0217 13:16:41.179411  8728 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0217 13:16:41.179411  8728 net.cpp:100] Creating Layer ip1_ip1_0_split
I0217 13:16:41.179411  8728 net.cpp:434] ip1_ip1_0_split <- ip1
I0217 13:16:41.179411  8728 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0217 13:16:41.179411  8728 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0217 13:16:41.179411  8728 net.cpp:150] Setting up ip1_ip1_0_split
I0217 13:16:41.179411  8728 net.cpp:157] Top shape: 25 10 (250)
I0217 13:16:41.179411  8728 net.cpp:157] Top shape: 25 10 (250)
I0217 13:16:41.179411  8728 net.cpp:165] Memory required for data: 302620900
I0217 13:16:41.179411  8728 layer_factory.cpp:58] Creating layer accuracy
I0217 13:16:41.179411  8728 net.cpp:100] Creating Layer accuracy
I0217 13:16:41.179411  8728 net.cpp:434] accuracy <- ip1_ip1_0_split_0
I0217 13:16:41.179411  8728 net.cpp:434] accuracy <- label_cifar_1_split_0
I0217 13:16:41.179411  8728 net.cpp:408] accuracy -> accuracy
I0217 13:16:41.179411  8728 net.cpp:150] Setting up accuracy
I0217 13:16:41.179411  8728 net.cpp:157] Top shape: (1)
I0217 13:16:41.179411  8728 net.cpp:165] Memory required for data: 302620904
I0217 13:16:41.179411  8728 layer_factory.cpp:58] Creating layer loss
I0217 13:16:41.179411  8728 net.cpp:100] Creating Layer loss
I0217 13:16:41.179411  8728 net.cpp:434] loss <- ip1_ip1_0_split_1
I0217 13:16:41.179411  8728 net.cpp:434] loss <- label_cifar_1_split_1
I0217 13:16:41.179411  8728 net.cpp:408] loss -> loss
I0217 13:16:41.179411  8728 layer_factory.cpp:58] Creating layer loss
I0217 13:16:41.180411  8728 net.cpp:150] Setting up loss
I0217 13:16:41.180411  8728 net.cpp:157] Top shape: (1)
I0217 13:16:41.180411  8728 net.cpp:160]     with loss weight 1
I0217 13:16:41.180411  8728 net.cpp:165] Memory required for data: 302620908
I0217 13:16:41.180411  8728 net.cpp:226] loss needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:228] accuracy does not need backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] ip1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] poolcp6 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu_cccp6 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] cccp6 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop4_5 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] poolcp5 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu_cccp5 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] cccp5 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop4_3 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu_cccp4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] cccp4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop4_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu4_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale4_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn4_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv4_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] pool4_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop4_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu4_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale4_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn4_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv4_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop4_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu4_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale4_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn4_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv4_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] pool4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv4 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop3 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu3 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale3 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn3 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv3 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop2_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu2_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale2_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn2_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv2_2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop2_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] pool2_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu2_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale2_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn2_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv2_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop2_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv2 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop1_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu1_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale1_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn1_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv1_0 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] drop2_1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] relu1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] scale1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] bn1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:226] conv1 needs backward computation.
I0217 13:16:41.180411  8728 net.cpp:228] label_cifar_1_split does not need backward computation.
I0217 13:16:41.180411  8728 net.cpp:228] cifar does not need backward computation.
I0217 13:16:41.180411  8728 net.cpp:270] This network produces output accuracy
I0217 13:16:41.180411  8728 net.cpp:270] This network produces output loss
I0217 13:16:41.180411  8728 net.cpp:283] Network initialization done.
I0217 13:16:41.180411  8728 solver.cpp:60] Solver scaffolding done.
I0217 13:16:41.184412  8728 caffe.cpp:242] Resuming from examples/cifar10_full_relu_bn_iter_226000.solverstate
I0217 13:16:41.233402  8728 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar10_full_relu_bn_iter_226000.caffemodel
I0217 13:16:41.233402  8728 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0217 13:16:41.237943  8728 sgd_solver.cpp:318] SGDSolver: restoring history
I0217 13:16:41.265297  8728 caffe.cpp:252] Starting Optimization
I0217 13:16:41.266294  8728 solver.cpp:279] Solving CIFAR10_full
I0217 13:16:41.266294  8728 solver.cpp:280] Learning Rate Policy: multistep
I0217 13:16:41.272292  8728 solver.cpp:337] Iteration 226000, Testing net (#0)
I0217 13:16:41.277293  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:16:47.370836  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 13:16:47.370836  8728 solver.cpp:404]     Test net output #1: loss = 0.174893 (* 1 = 0.174893 loss)
I0217 13:16:47.747011  8728 solver.cpp:228] Iteration 226000, loss = 0.00514284
I0217 13:16:47.747011  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:16:47.747011  8728 solver.cpp:244]     Train net output #1: loss = 0.00514284 (* 1 = 0.00514284 loss)
I0217 13:16:47.747011  8728 sgd_solver.cpp:106] Iteration 226000, lr = 0.001
I0217 13:17:05.487248  8728 solver.cpp:228] Iteration 226100, loss = 0.00464071
I0217 13:17:05.487248  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:17:05.487248  8728 solver.cpp:244]     Train net output #1: loss = 0.00464071 (* 1 = 0.00464071 loss)
I0217 13:17:05.487248  8728 sgd_solver.cpp:106] Iteration 226100, lr = 0.001
I0217 13:17:23.206187  8728 solver.cpp:228] Iteration 226200, loss = 0.00497432
I0217 13:17:23.206187  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:17:23.206187  8728 solver.cpp:244]     Train net output #1: loss = 0.00497432 (* 1 = 0.00497432 loss)
I0217 13:17:23.206187  8728 sgd_solver.cpp:106] Iteration 226200, lr = 0.001
I0217 13:17:40.849236  8728 solver.cpp:228] Iteration 226300, loss = 0.00792853
I0217 13:17:40.849236  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:17:40.849236  8728 solver.cpp:244]     Train net output #1: loss = 0.00792853 (* 1 = 0.00792853 loss)
I0217 13:17:40.849236  8728 sgd_solver.cpp:106] Iteration 226300, lr = 0.001
I0217 13:17:58.616267  8728 solver.cpp:228] Iteration 226400, loss = 0.00584246
I0217 13:17:58.616267  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:17:58.616267  8728 solver.cpp:244]     Train net output #1: loss = 0.00584246 (* 1 = 0.00584246 loss)
I0217 13:17:58.616267  8728 sgd_solver.cpp:106] Iteration 226400, lr = 0.001
I0217 13:18:16.240108  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_226500.caffemodel
I0217 13:18:16.383113  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_226500.solverstate
I0217 13:18:16.457114  8728 solver.cpp:337] Iteration 226500, Testing net (#0)
I0217 13:18:16.457114  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:18:22.481204  8728 solver.cpp:404]     Test net output #0: accuracy = 0.943301
I0217 13:18:22.481204  8728 solver.cpp:404]     Test net output #1: loss = 0.17829 (* 1 = 0.17829 loss)
I0217 13:18:22.551758  8728 solver.cpp:228] Iteration 226500, loss = 0.00952551
I0217 13:18:22.551758  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:18:22.551758  8728 solver.cpp:244]     Train net output #1: loss = 0.00952551 (* 1 = 0.00952551 loss)
I0217 13:18:22.551758  8728 sgd_solver.cpp:106] Iteration 226500, lr = 0.001
I0217 13:18:40.204740  8728 solver.cpp:228] Iteration 226600, loss = 0.00547682
I0217 13:18:40.204740  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:18:40.204740  8728 solver.cpp:244]     Train net output #1: loss = 0.00547682 (* 1 = 0.00547682 loss)
I0217 13:18:40.204740  8728 sgd_solver.cpp:106] Iteration 226600, lr = 0.001
I0217 13:18:57.890636  8728 solver.cpp:228] Iteration 226700, loss = 0.00401515
I0217 13:18:57.890636  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:18:57.890636  8728 solver.cpp:244]     Train net output #1: loss = 0.00401515 (* 1 = 0.00401515 loss)
I0217 13:18:57.890636  8728 sgd_solver.cpp:106] Iteration 226700, lr = 0.001
I0217 13:19:15.766046  8728 solver.cpp:228] Iteration 226800, loss = 0.0061522
I0217 13:19:15.766046  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:19:15.766046  8728 solver.cpp:244]     Train net output #1: loss = 0.00615219 (* 1 = 0.00615219 loss)
I0217 13:19:15.766046  8728 sgd_solver.cpp:106] Iteration 226800, lr = 0.001
I0217 13:19:33.654225  8728 solver.cpp:228] Iteration 226900, loss = 0.0121913
I0217 13:19:33.654225  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:19:33.654225  8728 solver.cpp:244]     Train net output #1: loss = 0.0121913 (* 1 = 0.0121913 loss)
I0217 13:19:33.654225  8728 sgd_solver.cpp:106] Iteration 226900, lr = 0.001
I0217 13:19:51.422351  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_227000.caffemodel
I0217 13:19:51.569869  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_227000.solverstate
I0217 13:19:51.644371  8728 solver.cpp:337] Iteration 227000, Testing net (#0)
I0217 13:19:51.644870  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:19:57.734328  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944801
I0217 13:19:57.734328  8728 solver.cpp:404]     Test net output #1: loss = 0.177376 (* 1 = 0.177376 loss)
I0217 13:19:57.805392  8728 solver.cpp:228] Iteration 227000, loss = 0.0153184
I0217 13:19:57.805392  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 13:19:57.805392  8728 solver.cpp:244]     Train net output #1: loss = 0.0153184 (* 1 = 0.0153184 loss)
I0217 13:19:57.805392  8728 sgd_solver.cpp:106] Iteration 227000, lr = 0.001
I0217 13:20:15.896263  8728 solver.cpp:228] Iteration 227100, loss = 0.00703729
I0217 13:20:15.896263  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:20:15.896263  8728 solver.cpp:244]     Train net output #1: loss = 0.00703729 (* 1 = 0.00703729 loss)
I0217 13:20:15.896263  8728 sgd_solver.cpp:106] Iteration 227100, lr = 0.001
I0217 13:20:33.998245  8728 solver.cpp:228] Iteration 227200, loss = 0.00665423
I0217 13:20:33.998245  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:20:33.998245  8728 solver.cpp:244]     Train net output #1: loss = 0.00665423 (* 1 = 0.00665423 loss)
I0217 13:20:33.998245  8728 sgd_solver.cpp:106] Iteration 227200, lr = 0.001
I0217 13:20:51.785612  8728 solver.cpp:228] Iteration 227300, loss = 0.0104708
I0217 13:20:51.785612  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:20:51.785612  8728 solver.cpp:244]     Train net output #1: loss = 0.0104708 (* 1 = 0.0104708 loss)
I0217 13:20:51.785612  8728 sgd_solver.cpp:106] Iteration 227300, lr = 0.001
I0217 13:21:09.601933  8728 solver.cpp:228] Iteration 227400, loss = 0.00445417
I0217 13:21:09.601933  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:21:09.601933  8728 solver.cpp:244]     Train net output #1: loss = 0.00445417 (* 1 = 0.00445417 loss)
I0217 13:21:09.601933  8728 sgd_solver.cpp:106] Iteration 227400, lr = 0.001
I0217 13:21:27.463596  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_227500.caffemodel
I0217 13:21:27.610605  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_227500.solverstate
I0217 13:21:27.699642  8728 solver.cpp:337] Iteration 227500, Testing net (#0)
I0217 13:21:27.699642  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:21:34.083647  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9438
I0217 13:21:34.083647  8728 solver.cpp:404]     Test net output #1: loss = 0.175415 (* 1 = 0.175415 loss)
I0217 13:21:34.155161  8728 solver.cpp:228] Iteration 227500, loss = 0.00236223
I0217 13:21:34.155161  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:21:34.155161  8728 solver.cpp:244]     Train net output #1: loss = 0.00236223 (* 1 = 0.00236223 loss)
I0217 13:21:34.155161  8728 sgd_solver.cpp:106] Iteration 227500, lr = 0.001
I0217 13:21:52.023581  8728 solver.cpp:228] Iteration 227600, loss = 0.0157292
I0217 13:21:52.023581  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:21:52.023581  8728 solver.cpp:244]     Train net output #1: loss = 0.0157292 (* 1 = 0.0157292 loss)
I0217 13:21:52.023581  8728 sgd_solver.cpp:106] Iteration 227600, lr = 0.001
I0217 13:22:09.921718  8728 solver.cpp:228] Iteration 227700, loss = 0.00740174
I0217 13:22:09.921718  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:22:09.921718  8728 solver.cpp:244]     Train net output #1: loss = 0.00740174 (* 1 = 0.00740174 loss)
I0217 13:22:09.921718  8728 sgd_solver.cpp:106] Iteration 227700, lr = 0.001
I0217 13:22:27.783785  8728 solver.cpp:228] Iteration 227800, loss = 0.00564107
I0217 13:22:27.783785  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:22:27.783785  8728 solver.cpp:244]     Train net output #1: loss = 0.00564107 (* 1 = 0.00564107 loss)
I0217 13:22:27.783785  8728 sgd_solver.cpp:106] Iteration 227800, lr = 0.001
I0217 13:22:45.528401  8728 solver.cpp:228] Iteration 227900, loss = 0.0108206
I0217 13:22:45.528401  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 13:22:45.528401  8728 solver.cpp:244]     Train net output #1: loss = 0.0108206 (* 1 = 0.0108206 loss)
I0217 13:22:45.528401  8728 sgd_solver.cpp:106] Iteration 227900, lr = 0.001
I0217 13:23:03.215117  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_228000.caffemodel
I0217 13:23:03.352607  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_228000.solverstate
I0217 13:23:03.421106  8728 solver.cpp:337] Iteration 228000, Testing net (#0)
I0217 13:23:03.421106  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:23:09.517349  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944401
I0217 13:23:09.517349  8728 solver.cpp:404]     Test net output #1: loss = 0.17617 (* 1 = 0.17617 loss)
I0217 13:23:09.589390  8728 solver.cpp:228] Iteration 228000, loss = 0.00451974
I0217 13:23:09.589390  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:23:09.589390  8728 solver.cpp:244]     Train net output #1: loss = 0.00451974 (* 1 = 0.00451974 loss)
I0217 13:23:09.589390  8728 sgd_solver.cpp:106] Iteration 228000, lr = 0.001
I0217 13:23:27.408586  8728 solver.cpp:228] Iteration 228100, loss = 0.011101
I0217 13:23:27.408586  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:23:27.408586  8728 solver.cpp:244]     Train net output #1: loss = 0.0111009 (* 1 = 0.0111009 loss)
I0217 13:23:27.408586  8728 sgd_solver.cpp:106] Iteration 228100, lr = 0.001
I0217 13:23:45.302539  8728 solver.cpp:228] Iteration 228200, loss = 0.0071744
I0217 13:23:45.302539  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:23:45.302539  8728 solver.cpp:244]     Train net output #1: loss = 0.00717439 (* 1 = 0.00717439 loss)
I0217 13:23:45.302539  8728 sgd_solver.cpp:106] Iteration 228200, lr = 0.001
I0217 13:24:03.158759  8728 solver.cpp:228] Iteration 228300, loss = 0.0094217
I0217 13:24:03.158759  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:24:03.158759  8728 solver.cpp:244]     Train net output #1: loss = 0.00942169 (* 1 = 0.00942169 loss)
I0217 13:24:03.158759  8728 sgd_solver.cpp:106] Iteration 228300, lr = 0.001
I0217 13:24:20.918025  8728 solver.cpp:228] Iteration 228400, loss = 0.00741403
I0217 13:24:20.918510  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:24:20.918510  8728 solver.cpp:244]     Train net output #1: loss = 0.00741402 (* 1 = 0.00741402 loss)
I0217 13:24:20.918510  8728 sgd_solver.cpp:106] Iteration 228400, lr = 0.001
I0217 13:24:38.610309  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_228500.caffemodel
I0217 13:24:38.751246  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_228500.solverstate
I0217 13:24:38.820261  8728 solver.cpp:337] Iteration 228500, Testing net (#0)
I0217 13:24:38.820261  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:24:44.853407  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9418
I0217 13:24:44.853407  8728 solver.cpp:404]     Test net output #1: loss = 0.181947 (* 1 = 0.181947 loss)
I0217 13:24:44.925822  8728 solver.cpp:228] Iteration 228500, loss = 0.00366954
I0217 13:24:44.925822  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:24:44.925822  8728 solver.cpp:244]     Train net output #1: loss = 0.00366953 (* 1 = 0.00366953 loss)
I0217 13:24:44.925822  8728 sgd_solver.cpp:106] Iteration 228500, lr = 0.001
I0217 13:25:02.645793  8728 solver.cpp:228] Iteration 228600, loss = 0.0165503
I0217 13:25:02.645793  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:25:02.645793  8728 solver.cpp:244]     Train net output #1: loss = 0.0165503 (* 1 = 0.0165503 loss)
I0217 13:25:02.645793  8728 sgd_solver.cpp:106] Iteration 228600, lr = 0.001
I0217 13:25:20.433401  8728 solver.cpp:228] Iteration 228700, loss = 0.00307445
I0217 13:25:20.433401  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:25:20.433401  8728 solver.cpp:244]     Train net output #1: loss = 0.00307444 (* 1 = 0.00307444 loss)
I0217 13:25:20.433401  8728 sgd_solver.cpp:106] Iteration 228700, lr = 0.001
I0217 13:25:38.204603  8728 solver.cpp:228] Iteration 228800, loss = 0.00530993
I0217 13:25:38.204603  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:25:38.204603  8728 solver.cpp:244]     Train net output #1: loss = 0.00530992 (* 1 = 0.00530992 loss)
I0217 13:25:38.204603  8728 sgd_solver.cpp:106] Iteration 228800, lr = 0.001
I0217 13:25:55.986506  8728 solver.cpp:228] Iteration 228900, loss = 0.0178613
I0217 13:25:55.986506  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 13:25:55.986506  8728 solver.cpp:244]     Train net output #1: loss = 0.0178612 (* 1 = 0.0178612 loss)
I0217 13:25:55.986506  8728 sgd_solver.cpp:106] Iteration 228900, lr = 0.001
I0217 13:26:13.686583  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_229000.caffemodel
I0217 13:26:13.824607  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_229000.solverstate
I0217 13:26:13.891647  8728 solver.cpp:337] Iteration 229000, Testing net (#0)
I0217 13:26:13.891647  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:26:19.950489  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9436
I0217 13:26:19.951001  8728 solver.cpp:404]     Test net output #1: loss = 0.17776 (* 1 = 0.17776 loss)
I0217 13:26:20.021539  8728 solver.cpp:228] Iteration 229000, loss = 0.0111973
I0217 13:26:20.021539  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:26:20.021539  8728 solver.cpp:244]     Train net output #1: loss = 0.0111973 (* 1 = 0.0111973 loss)
I0217 13:26:20.021539  8728 sgd_solver.cpp:106] Iteration 229000, lr = 0.001
I0217 13:26:37.790415  8728 solver.cpp:228] Iteration 229100, loss = 0.011466
I0217 13:26:37.790415  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:26:37.790415  8728 solver.cpp:244]     Train net output #1: loss = 0.011466 (* 1 = 0.011466 loss)
I0217 13:26:37.790415  8728 sgd_solver.cpp:106] Iteration 229100, lr = 0.001
I0217 13:26:55.548070  8728 solver.cpp:228] Iteration 229200, loss = 0.00268348
I0217 13:26:55.548070  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:26:55.548070  8728 solver.cpp:244]     Train net output #1: loss = 0.00268348 (* 1 = 0.00268348 loss)
I0217 13:26:55.548070  8728 sgd_solver.cpp:106] Iteration 229200, lr = 0.001
I0217 13:27:13.312052  8728 solver.cpp:228] Iteration 229300, loss = 0.00875535
I0217 13:27:13.312052  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:27:13.312052  8728 solver.cpp:244]     Train net output #1: loss = 0.00875534 (* 1 = 0.00875534 loss)
I0217 13:27:13.312052  8728 sgd_solver.cpp:106] Iteration 229300, lr = 0.001
I0217 13:27:31.130425  8728 solver.cpp:228] Iteration 229400, loss = 0.00239755
I0217 13:27:31.130425  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:27:31.130425  8728 solver.cpp:244]     Train net output #1: loss = 0.00239754 (* 1 = 0.00239754 loss)
I0217 13:27:31.130425  8728 sgd_solver.cpp:106] Iteration 229400, lr = 0.001
I0217 13:27:48.865104  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_229500.caffemodel
I0217 13:27:49.001608  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_229500.solverstate
I0217 13:27:49.070111  8728 solver.cpp:337] Iteration 229500, Testing net (#0)
I0217 13:27:49.070111  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:27:55.137892  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944101
I0217 13:27:55.137892  8728 solver.cpp:404]     Test net output #1: loss = 0.178124 (* 1 = 0.178124 loss)
I0217 13:27:55.209419  8728 solver.cpp:228] Iteration 229500, loss = 0.00479265
I0217 13:27:55.209419  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:27:55.209419  8728 solver.cpp:244]     Train net output #1: loss = 0.00479265 (* 1 = 0.00479265 loss)
I0217 13:27:55.209419  8728 sgd_solver.cpp:106] Iteration 229500, lr = 0.001
I0217 13:28:12.963562  8728 solver.cpp:228] Iteration 229600, loss = 0.0063104
I0217 13:28:12.963562  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:28:12.963562  8728 solver.cpp:244]     Train net output #1: loss = 0.0063104 (* 1 = 0.0063104 loss)
I0217 13:28:12.963562  8728 sgd_solver.cpp:106] Iteration 229600, lr = 0.001
I0217 13:28:30.818084  8728 solver.cpp:228] Iteration 229700, loss = 0.00369335
I0217 13:28:30.818084  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:28:30.818084  8728 solver.cpp:244]     Train net output #1: loss = 0.00369334 (* 1 = 0.00369334 loss)
I0217 13:28:30.818084  8728 sgd_solver.cpp:106] Iteration 229700, lr = 0.001
I0217 13:28:48.654386  8728 solver.cpp:228] Iteration 229800, loss = 0.00584867
I0217 13:28:48.654386  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:28:48.654386  8728 solver.cpp:244]     Train net output #1: loss = 0.00584867 (* 1 = 0.00584867 loss)
I0217 13:28:48.654386  8728 sgd_solver.cpp:106] Iteration 229800, lr = 0.001
I0217 13:29:06.419245  8728 solver.cpp:228] Iteration 229900, loss = 0.00473764
I0217 13:29:06.419245  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:29:06.419245  8728 solver.cpp:244]     Train net output #1: loss = 0.00473764 (* 1 = 0.00473764 loss)
I0217 13:29:06.419245  8728 sgd_solver.cpp:106] Iteration 229900, lr = 0.001
I0217 13:29:24.113239  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_230000.caffemodel
I0217 13:29:24.253756  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_230000.solverstate
I0217 13:29:24.319784  8728 solver.cpp:337] Iteration 230000, Testing net (#0)
I0217 13:29:24.319784  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:29:30.381409  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9439
I0217 13:29:30.381409  8728 solver.cpp:404]     Test net output #1: loss = 0.178982 (* 1 = 0.178982 loss)
I0217 13:29:30.453474  8728 solver.cpp:228] Iteration 230000, loss = 0.00550861
I0217 13:29:30.453474  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:29:30.453474  8728 solver.cpp:244]     Train net output #1: loss = 0.00550861 (* 1 = 0.00550861 loss)
I0217 13:29:30.453474  8728 sgd_solver.cpp:106] Iteration 230000, lr = 0.001
I0217 13:29:48.206149  8728 solver.cpp:228] Iteration 230100, loss = 0.00663851
I0217 13:29:48.206630  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:29:48.206630  8728 solver.cpp:244]     Train net output #1: loss = 0.00663851 (* 1 = 0.00663851 loss)
I0217 13:29:48.206630  8728 sgd_solver.cpp:106] Iteration 230100, lr = 0.001
I0217 13:30:05.985194  8728 solver.cpp:228] Iteration 230200, loss = 0.00807217
I0217 13:30:05.985694  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:30:05.985694  8728 solver.cpp:244]     Train net output #1: loss = 0.00807217 (* 1 = 0.00807217 loss)
I0217 13:30:05.985694  8728 sgd_solver.cpp:106] Iteration 230200, lr = 0.001
I0217 13:30:23.737366  8728 solver.cpp:228] Iteration 230300, loss = 0.00309786
I0217 13:30:23.737366  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:30:23.737366  8728 solver.cpp:244]     Train net output #1: loss = 0.00309785 (* 1 = 0.00309785 loss)
I0217 13:30:23.737366  8728 sgd_solver.cpp:106] Iteration 230300, lr = 0.001
I0217 13:30:41.505774  8728 solver.cpp:228] Iteration 230400, loss = 0.00280918
I0217 13:30:41.505774  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:30:41.505774  8728 solver.cpp:244]     Train net output #1: loss = 0.00280917 (* 1 = 0.00280917 loss)
I0217 13:30:41.505774  8728 sgd_solver.cpp:106] Iteration 230400, lr = 0.001
I0217 13:30:59.205296  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_230500.caffemodel
I0217 13:30:59.343338  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_230500.solverstate
I0217 13:30:59.409333  8728 solver.cpp:337] Iteration 230500, Testing net (#0)
I0217 13:30:59.409333  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:31:05.471870  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9425
I0217 13:31:05.471870  8728 solver.cpp:404]     Test net output #1: loss = 0.1793 (* 1 = 0.1793 loss)
I0217 13:31:05.542891  8728 solver.cpp:228] Iteration 230500, loss = 0.0063173
I0217 13:31:05.542891  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:31:05.542891  8728 solver.cpp:244]     Train net output #1: loss = 0.0063173 (* 1 = 0.0063173 loss)
I0217 13:31:05.542891  8728 sgd_solver.cpp:106] Iteration 230500, lr = 0.001
I0217 13:31:23.326998  8728 solver.cpp:228] Iteration 230600, loss = 0.00181824
I0217 13:31:23.327481  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:31:23.327481  8728 solver.cpp:244]     Train net output #1: loss = 0.00181823 (* 1 = 0.00181823 loss)
I0217 13:31:23.327481  8728 sgd_solver.cpp:106] Iteration 230600, lr = 0.001
I0217 13:31:41.071059  8728 solver.cpp:228] Iteration 230700, loss = 0.00640562
I0217 13:31:41.071059  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:31:41.071059  8728 solver.cpp:244]     Train net output #1: loss = 0.00640561 (* 1 = 0.00640561 loss)
I0217 13:31:41.071059  8728 sgd_solver.cpp:106] Iteration 230700, lr = 0.001
I0217 13:31:58.819032  8728 solver.cpp:228] Iteration 230800, loss = 0.00315738
I0217 13:31:58.819032  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:31:58.819032  8728 solver.cpp:244]     Train net output #1: loss = 0.00315738 (* 1 = 0.00315738 loss)
I0217 13:31:58.819032  8728 sgd_solver.cpp:106] Iteration 230800, lr = 0.001
I0217 13:32:16.617969  8728 solver.cpp:228] Iteration 230900, loss = 0.00429811
I0217 13:32:16.617969  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:32:16.617969  8728 solver.cpp:244]     Train net output #1: loss = 0.0042981 (* 1 = 0.0042981 loss)
I0217 13:32:16.617969  8728 sgd_solver.cpp:106] Iteration 230900, lr = 0.001
I0217 13:32:34.645319  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_231000.caffemodel
I0217 13:32:34.783998  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_231000.solverstate
I0217 13:32:34.848001  8728 solver.cpp:337] Iteration 231000, Testing net (#0)
I0217 13:32:34.848001  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:32:40.954628  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9443
I0217 13:32:40.954628  8728 solver.cpp:404]     Test net output #1: loss = 0.179256 (* 1 = 0.179256 loss)
I0217 13:32:41.025658  8728 solver.cpp:228] Iteration 231000, loss = 0.00582927
I0217 13:32:41.025658  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:32:41.025658  8728 solver.cpp:244]     Train net output #1: loss = 0.00582926 (* 1 = 0.00582926 loss)
I0217 13:32:41.025658  8728 sgd_solver.cpp:106] Iteration 231000, lr = 0.001
I0217 13:32:58.871107  8728 solver.cpp:228] Iteration 231100, loss = 0.0063195
I0217 13:32:58.871107  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:32:58.871107  8728 solver.cpp:244]     Train net output #1: loss = 0.0063195 (* 1 = 0.0063195 loss)
I0217 13:32:58.871107  8728 sgd_solver.cpp:106] Iteration 231100, lr = 0.001
I0217 13:33:16.773365  8728 solver.cpp:228] Iteration 231200, loss = 0.00570374
I0217 13:33:16.773365  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:33:16.773365  8728 solver.cpp:244]     Train net output #1: loss = 0.00570374 (* 1 = 0.00570374 loss)
I0217 13:33:16.773365  8728 sgd_solver.cpp:106] Iteration 231200, lr = 0.001
I0217 13:33:34.596663  8728 solver.cpp:228] Iteration 231300, loss = 0.00664803
I0217 13:33:34.596663  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:33:34.596663  8728 solver.cpp:244]     Train net output #1: loss = 0.00664803 (* 1 = 0.00664803 loss)
I0217 13:33:34.596663  8728 sgd_solver.cpp:106] Iteration 231300, lr = 0.001
I0217 13:33:52.355974  8728 solver.cpp:228] Iteration 231400, loss = 0.00400396
I0217 13:33:52.355974  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:33:52.355974  8728 solver.cpp:244]     Train net output #1: loss = 0.00400395 (* 1 = 0.00400395 loss)
I0217 13:33:52.355974  8728 sgd_solver.cpp:106] Iteration 231400, lr = 0.001
I0217 13:34:10.084146  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_231500.caffemodel
I0217 13:34:10.222192  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_231500.solverstate
I0217 13:34:10.288714  8728 solver.cpp:337] Iteration 231500, Testing net (#0)
I0217 13:34:10.288714  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:34:16.347450  8728 solver.cpp:404]     Test net output #0: accuracy = 0.943
I0217 13:34:16.347450  8728 solver.cpp:404]     Test net output #1: loss = 0.180147 (* 1 = 0.180147 loss)
I0217 13:34:16.419412  8728 solver.cpp:228] Iteration 231500, loss = 0.012302
I0217 13:34:16.419412  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:34:16.419412  8728 solver.cpp:244]     Train net output #1: loss = 0.012302 (* 1 = 0.012302 loss)
I0217 13:34:16.419412  8728 sgd_solver.cpp:106] Iteration 231500, lr = 0.001
I0217 13:34:34.261886  8728 solver.cpp:228] Iteration 231600, loss = 0.00485824
I0217 13:34:34.261886  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:34:34.261886  8728 solver.cpp:244]     Train net output #1: loss = 0.00485823 (* 1 = 0.00485823 loss)
I0217 13:34:34.261886  8728 sgd_solver.cpp:106] Iteration 231600, lr = 0.001
I0217 13:34:52.226536  8728 solver.cpp:228] Iteration 231700, loss = 0.00418446
I0217 13:34:52.226536  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:34:52.226536  8728 solver.cpp:244]     Train net output #1: loss = 0.00418445 (* 1 = 0.00418445 loss)
I0217 13:34:52.226536  8728 sgd_solver.cpp:106] Iteration 231700, lr = 0.001
I0217 13:35:10.033424  8728 solver.cpp:228] Iteration 231800, loss = 0.00671841
I0217 13:35:10.033898  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:35:10.033898  8728 solver.cpp:244]     Train net output #1: loss = 0.0067184 (* 1 = 0.0067184 loss)
I0217 13:35:10.033898  8728 sgd_solver.cpp:106] Iteration 231800, lr = 0.001
I0217 13:35:28.746722  8728 solver.cpp:228] Iteration 231900, loss = 0.00321526
I0217 13:35:28.746722  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:35:28.746722  8728 solver.cpp:244]     Train net output #1: loss = 0.00321525 (* 1 = 0.00321525 loss)
I0217 13:35:28.746722  8728 sgd_solver.cpp:106] Iteration 231900, lr = 0.001
I0217 13:35:47.086901  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_232000.caffemodel
I0217 13:35:47.232501  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_232000.solverstate
I0217 13:35:47.300482  8728 solver.cpp:337] Iteration 232000, Testing net (#0)
I0217 13:35:47.300482  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:35:53.476145  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9433
I0217 13:35:53.476145  8728 solver.cpp:404]     Test net output #1: loss = 0.182518 (* 1 = 0.182518 loss)
I0217 13:35:53.548920  8728 solver.cpp:228] Iteration 232000, loss = 0.00828866
I0217 13:35:53.548920  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:35:53.548920  8728 solver.cpp:244]     Train net output #1: loss = 0.00828865 (* 1 = 0.00828865 loss)
I0217 13:35:53.548920  8728 sgd_solver.cpp:106] Iteration 232000, lr = 0.001
I0217 13:36:11.984838  8728 solver.cpp:228] Iteration 232100, loss = 0.00429812
I0217 13:36:11.984838  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:36:11.984838  8728 solver.cpp:244]     Train net output #1: loss = 0.00429811 (* 1 = 0.00429811 loss)
I0217 13:36:11.984838  8728 sgd_solver.cpp:106] Iteration 232100, lr = 0.001
I0217 13:36:30.493325  8728 solver.cpp:228] Iteration 232200, loss = 0.00601603
I0217 13:36:30.493325  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:36:30.493835  8728 solver.cpp:244]     Train net output #1: loss = 0.00601602 (* 1 = 0.00601602 loss)
I0217 13:36:30.493835  8728 sgd_solver.cpp:106] Iteration 232200, lr = 0.001
I0217 13:36:49.092566  8728 solver.cpp:228] Iteration 232300, loss = 0.0114396
I0217 13:36:49.092566  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:36:49.092566  8728 solver.cpp:244]     Train net output #1: loss = 0.0114396 (* 1 = 0.0114396 loss)
I0217 13:36:49.092566  8728 sgd_solver.cpp:106] Iteration 232300, lr = 0.001
I0217 13:37:07.683074  8728 solver.cpp:228] Iteration 232400, loss = 0.004441
I0217 13:37:07.683074  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:37:07.683074  8728 solver.cpp:244]     Train net output #1: loss = 0.004441 (* 1 = 0.004441 loss)
I0217 13:37:07.683074  8728 sgd_solver.cpp:106] Iteration 232400, lr = 0.001
I0217 13:37:26.191812  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_232500.caffemodel
I0217 13:37:26.336858  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_232500.solverstate
I0217 13:37:26.406869  8728 solver.cpp:337] Iteration 232500, Testing net (#0)
I0217 13:37:26.406869  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:37:32.869303  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9423
I0217 13:37:32.869303  8728 solver.cpp:404]     Test net output #1: loss = 0.184028 (* 1 = 0.184028 loss)
I0217 13:37:32.941809  8728 solver.cpp:228] Iteration 232500, loss = 0.00210952
I0217 13:37:32.941809  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:37:32.941809  8728 solver.cpp:244]     Train net output #1: loss = 0.00210952 (* 1 = 0.00210952 loss)
I0217 13:37:32.941809  8728 sgd_solver.cpp:106] Iteration 232500, lr = 0.001
I0217 13:37:50.896962  8728 solver.cpp:228] Iteration 232600, loss = 0.00328406
I0217 13:37:50.896962  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:37:50.896962  8728 solver.cpp:244]     Train net output #1: loss = 0.00328405 (* 1 = 0.00328405 loss)
I0217 13:37:50.896962  8728 sgd_solver.cpp:106] Iteration 232600, lr = 0.001
I0217 13:38:08.872829  8728 solver.cpp:228] Iteration 232700, loss = 0.00580708
I0217 13:38:08.872829  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:38:08.872829  8728 solver.cpp:244]     Train net output #1: loss = 0.00580708 (* 1 = 0.00580708 loss)
I0217 13:38:08.872829  8728 sgd_solver.cpp:106] Iteration 232700, lr = 0.001
I0217 13:38:26.733695  8728 solver.cpp:228] Iteration 232800, loss = 0.00528831
I0217 13:38:26.733695  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:38:26.733695  8728 solver.cpp:244]     Train net output #1: loss = 0.00528831 (* 1 = 0.00528831 loss)
I0217 13:38:26.733695  8728 sgd_solver.cpp:106] Iteration 232800, lr = 0.001
I0217 13:38:44.469754  8728 solver.cpp:228] Iteration 232900, loss = 0.0104776
I0217 13:38:44.470237  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 13:38:44.470237  8728 solver.cpp:244]     Train net output #1: loss = 0.0104776 (* 1 = 0.0104776 loss)
I0217 13:38:44.470237  8728 sgd_solver.cpp:106] Iteration 232900, lr = 0.001
I0217 13:39:02.290923  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_233000.caffemodel
I0217 13:39:02.427469  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_233000.solverstate
I0217 13:39:02.494493  8728 solver.cpp:337] Iteration 233000, Testing net (#0)
I0217 13:39:02.494493  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:39:08.607048  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9434
I0217 13:39:08.607048  8728 solver.cpp:404]     Test net output #1: loss = 0.182122 (* 1 = 0.182122 loss)
I0217 13:39:08.679570  8728 solver.cpp:228] Iteration 233000, loss = 0.00195967
I0217 13:39:08.679570  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:39:08.679570  8728 solver.cpp:244]     Train net output #1: loss = 0.00195967 (* 1 = 0.00195967 loss)
I0217 13:39:08.679570  8728 sgd_solver.cpp:106] Iteration 233000, lr = 0.001
I0217 13:39:26.623250  8728 solver.cpp:228] Iteration 233100, loss = 0.00427131
I0217 13:39:26.623738  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:39:26.623738  8728 solver.cpp:244]     Train net output #1: loss = 0.00427131 (* 1 = 0.00427131 loss)
I0217 13:39:26.623738  8728 sgd_solver.cpp:106] Iteration 233100, lr = 0.001
I0217 13:39:44.571768  8728 solver.cpp:228] Iteration 233200, loss = 0.00207408
I0217 13:39:44.571768  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:39:44.571768  8728 solver.cpp:244]     Train net output #1: loss = 0.00207407 (* 1 = 0.00207407 loss)
I0217 13:39:44.571768  8728 sgd_solver.cpp:106] Iteration 233200, lr = 0.001
I0217 13:40:02.549396  8728 solver.cpp:228] Iteration 233300, loss = 0.00150047
I0217 13:40:02.549396  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:40:02.549896  8728 solver.cpp:244]     Train net output #1: loss = 0.00150046 (* 1 = 0.00150046 loss)
I0217 13:40:02.549896  8728 sgd_solver.cpp:106] Iteration 233300, lr = 0.001
I0217 13:40:20.486131  8728 solver.cpp:228] Iteration 233400, loss = 0.00973432
I0217 13:40:20.486131  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:40:20.486604  8728 solver.cpp:244]     Train net output #1: loss = 0.00973431 (* 1 = 0.00973431 loss)
I0217 13:40:20.486604  8728 sgd_solver.cpp:106] Iteration 233400, lr = 0.001
I0217 13:40:38.342188  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_233500.caffemodel
I0217 13:40:38.481184  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_233500.solverstate
I0217 13:40:38.561713  8728 solver.cpp:337] Iteration 233500, Testing net (#0)
I0217 13:40:38.561713  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:40:44.641703  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9448
I0217 13:40:44.641703  8728 solver.cpp:404]     Test net output #1: loss = 0.179703 (* 1 = 0.179703 loss)
I0217 13:40:44.713214  8728 solver.cpp:228] Iteration 233500, loss = 0.00902059
I0217 13:40:44.713214  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:40:44.713214  8728 solver.cpp:244]     Train net output #1: loss = 0.00902059 (* 1 = 0.00902059 loss)
I0217 13:40:44.713214  8728 sgd_solver.cpp:106] Iteration 233500, lr = 0.001
I0217 13:41:02.581795  8728 solver.cpp:228] Iteration 233600, loss = 0.00199475
I0217 13:41:02.581795  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:41:02.581795  8728 solver.cpp:244]     Train net output #1: loss = 0.00199474 (* 1 = 0.00199474 loss)
I0217 13:41:02.581795  8728 sgd_solver.cpp:106] Iteration 233600, lr = 0.001
I0217 13:41:20.525995  8728 solver.cpp:228] Iteration 233700, loss = 0.00479836
I0217 13:41:20.525995  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:41:20.525995  8728 solver.cpp:244]     Train net output #1: loss = 0.00479836 (* 1 = 0.00479836 loss)
I0217 13:41:20.525995  8728 sgd_solver.cpp:106] Iteration 233700, lr = 0.001
I0217 13:41:38.468067  8728 solver.cpp:228] Iteration 233800, loss = 0.00324214
I0217 13:41:38.468067  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:41:38.468067  8728 solver.cpp:244]     Train net output #1: loss = 0.00324214 (* 1 = 0.00324214 loss)
I0217 13:41:38.468067  8728 sgd_solver.cpp:106] Iteration 233800, lr = 0.001
I0217 13:41:56.401268  8728 solver.cpp:228] Iteration 233900, loss = 0.00532581
I0217 13:41:56.401268  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:41:56.401268  8728 solver.cpp:244]     Train net output #1: loss = 0.00532581 (* 1 = 0.00532581 loss)
I0217 13:41:56.401268  8728 sgd_solver.cpp:106] Iteration 233900, lr = 0.001
I0217 13:42:14.258631  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_234000.caffemodel
I0217 13:42:14.398146  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_234000.solverstate
I0217 13:42:14.467633  8728 solver.cpp:337] Iteration 234000, Testing net (#0)
I0217 13:42:14.467633  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:42:20.571620  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 13:42:20.571620  8728 solver.cpp:404]     Test net output #1: loss = 0.179569 (* 1 = 0.179569 loss)
I0217 13:42:20.644119  8728 solver.cpp:228] Iteration 234000, loss = 0.00272609
I0217 13:42:20.644119  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:42:20.644119  8728 solver.cpp:244]     Train net output #1: loss = 0.00272609 (* 1 = 0.00272609 loss)
I0217 13:42:20.644119  8728 sgd_solver.cpp:106] Iteration 234000, lr = 0.001
I0217 13:42:38.582103  8728 solver.cpp:228] Iteration 234100, loss = 0.00862056
I0217 13:42:38.582103  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:42:38.582103  8728 solver.cpp:244]     Train net output #1: loss = 0.00862056 (* 1 = 0.00862056 loss)
I0217 13:42:38.582103  8728 sgd_solver.cpp:106] Iteration 234100, lr = 0.001
I0217 13:42:56.525132  8728 solver.cpp:228] Iteration 234200, loss = 0.00529175
I0217 13:42:56.525622  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:42:56.525622  8728 solver.cpp:244]     Train net output #1: loss = 0.00529174 (* 1 = 0.00529174 loss)
I0217 13:42:56.525622  8728 sgd_solver.cpp:106] Iteration 234200, lr = 0.001
I0217 13:43:14.462836  8728 solver.cpp:228] Iteration 234300, loss = 0.00179764
I0217 13:43:14.462836  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:43:14.462836  8728 solver.cpp:244]     Train net output #1: loss = 0.00179763 (* 1 = 0.00179763 loss)
I0217 13:43:14.463307  8728 sgd_solver.cpp:106] Iteration 234300, lr = 0.001
I0217 13:43:32.401443  8728 solver.cpp:228] Iteration 234400, loss = 0.00585573
I0217 13:43:32.401443  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:43:32.401443  8728 solver.cpp:244]     Train net output #1: loss = 0.00585572 (* 1 = 0.00585572 loss)
I0217 13:43:32.401443  8728 sgd_solver.cpp:106] Iteration 234400, lr = 0.001
I0217 13:43:50.262797  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_234500.caffemodel
I0217 13:43:50.403301  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_234500.solverstate
I0217 13:43:50.471299  8728 solver.cpp:337] Iteration 234500, Testing net (#0)
I0217 13:43:50.471299  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:43:56.548805  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9445
I0217 13:43:56.548805  8728 solver.cpp:404]     Test net output #1: loss = 0.182091 (* 1 = 0.182091 loss)
I0217 13:43:56.621320  8728 solver.cpp:228] Iteration 234500, loss = 0.0048842
I0217 13:43:56.621320  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:43:56.621320  8728 solver.cpp:244]     Train net output #1: loss = 0.00488419 (* 1 = 0.00488419 loss)
I0217 13:43:56.621320  8728 sgd_solver.cpp:106] Iteration 234500, lr = 0.001
I0217 13:44:14.507024  8728 solver.cpp:228] Iteration 234600, loss = 0.00540132
I0217 13:44:14.507024  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:44:14.507024  8728 solver.cpp:244]     Train net output #1: loss = 0.0054013 (* 1 = 0.0054013 loss)
I0217 13:44:14.507024  8728 sgd_solver.cpp:106] Iteration 234600, lr = 0.001
I0217 13:44:32.386369  8728 solver.cpp:228] Iteration 234700, loss = 0.00366949
I0217 13:44:32.386369  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:44:32.386369  8728 solver.cpp:244]     Train net output #1: loss = 0.00366948 (* 1 = 0.00366948 loss)
I0217 13:44:32.386369  8728 sgd_solver.cpp:106] Iteration 234700, lr = 0.001
I0217 13:44:50.322047  8728 solver.cpp:228] Iteration 234800, loss = 0.00317855
I0217 13:44:50.322047  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:44:50.322047  8728 solver.cpp:244]     Train net output #1: loss = 0.00317854 (* 1 = 0.00317854 loss)
I0217 13:44:50.322047  8728 sgd_solver.cpp:106] Iteration 234800, lr = 0.001
I0217 13:45:08.269596  8728 solver.cpp:228] Iteration 234900, loss = 0.0206257
I0217 13:45:08.269596  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 13:45:08.269596  8728 solver.cpp:244]     Train net output #1: loss = 0.0206257 (* 1 = 0.0206257 loss)
I0217 13:45:08.269596  8728 sgd_solver.cpp:106] Iteration 234900, lr = 0.001
I0217 13:45:26.124902  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_235000.caffemodel
I0217 13:45:26.274889  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_235000.solverstate
I0217 13:45:26.343113  8728 solver.cpp:337] Iteration 235000, Testing net (#0)
I0217 13:45:26.343612  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:45:32.449100  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9441
I0217 13:45:32.449599  8728 solver.cpp:404]     Test net output #1: loss = 0.181489 (* 1 = 0.181489 loss)
I0217 13:45:32.525614  8728 solver.cpp:228] Iteration 235000, loss = 0.00347829
I0217 13:45:32.525614  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:45:32.525614  8728 solver.cpp:244]     Train net output #1: loss = 0.00347828 (* 1 = 0.00347828 loss)
I0217 13:45:32.525614  8728 sgd_solver.cpp:106] Iteration 235000, lr = 0.001
I0217 13:45:50.464826  8728 solver.cpp:228] Iteration 235100, loss = 0.00372126
I0217 13:45:50.464826  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:45:50.464826  8728 solver.cpp:244]     Train net output #1: loss = 0.00372125 (* 1 = 0.00372125 loss)
I0217 13:45:50.464826  8728 sgd_solver.cpp:106] Iteration 235100, lr = 0.001
I0217 13:46:08.404541  8728 solver.cpp:228] Iteration 235200, loss = 0.00201941
I0217 13:46:08.404541  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:46:08.404541  8728 solver.cpp:244]     Train net output #1: loss = 0.0020194 (* 1 = 0.0020194 loss)
I0217 13:46:08.404541  8728 sgd_solver.cpp:106] Iteration 235200, lr = 0.001
I0217 13:46:26.368304  8728 solver.cpp:228] Iteration 235300, loss = 0.00683223
I0217 13:46:26.368304  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:46:26.368304  8728 solver.cpp:244]     Train net output #1: loss = 0.00683222 (* 1 = 0.00683222 loss)
I0217 13:46:26.368304  8728 sgd_solver.cpp:106] Iteration 235300, lr = 0.001
I0217 13:46:44.311098  8728 solver.cpp:228] Iteration 235400, loss = 0.00322715
I0217 13:46:44.311098  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:46:44.311098  8728 solver.cpp:244]     Train net output #1: loss = 0.00322714 (* 1 = 0.00322714 loss)
I0217 13:46:44.311098  8728 sgd_solver.cpp:106] Iteration 235400, lr = 0.001
I0217 13:47:02.192203  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_235500.caffemodel
I0217 13:47:02.342721  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_235500.solverstate
I0217 13:47:02.411219  8728 solver.cpp:337] Iteration 235500, Testing net (#0)
I0217 13:47:02.411219  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:47:08.529705  8728 solver.cpp:404]     Test net output #0: accuracy = 0.943801
I0217 13:47:08.529705  8728 solver.cpp:404]     Test net output #1: loss = 0.1824 (* 1 = 0.1824 loss)
I0217 13:47:08.601233  8728 solver.cpp:228] Iteration 235500, loss = 0.00517033
I0217 13:47:08.601233  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:47:08.601233  8728 solver.cpp:244]     Train net output #1: loss = 0.00517032 (* 1 = 0.00517032 loss)
I0217 13:47:08.601233  8728 sgd_solver.cpp:106] Iteration 235500, lr = 0.001
I0217 13:47:26.564815  8728 solver.cpp:228] Iteration 235600, loss = 0.00677372
I0217 13:47:26.564815  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:47:26.564815  8728 solver.cpp:244]     Train net output #1: loss = 0.00677371 (* 1 = 0.00677371 loss)
I0217 13:47:26.564815  8728 sgd_solver.cpp:106] Iteration 235600, lr = 0.001
I0217 13:47:44.520547  8728 solver.cpp:228] Iteration 235700, loss = 0.00234292
I0217 13:47:44.520547  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:47:44.520547  8728 solver.cpp:244]     Train net output #1: loss = 0.00234291 (* 1 = 0.00234291 loss)
I0217 13:47:44.520547  8728 sgd_solver.cpp:106] Iteration 235700, lr = 0.001
I0217 13:48:02.504446  8728 solver.cpp:228] Iteration 235800, loss = 0.0022455
I0217 13:48:02.504446  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:48:02.504446  8728 solver.cpp:244]     Train net output #1: loss = 0.00224549 (* 1 = 0.00224549 loss)
I0217 13:48:02.504446  8728 sgd_solver.cpp:106] Iteration 235800, lr = 0.001
I0217 13:48:20.431757  8728 solver.cpp:228] Iteration 235900, loss = 0.00489262
I0217 13:48:20.431757  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:48:20.431757  8728 solver.cpp:244]     Train net output #1: loss = 0.00489261 (* 1 = 0.00489261 loss)
I0217 13:48:20.431757  8728 sgd_solver.cpp:106] Iteration 235900, lr = 0.001
I0217 13:48:38.287374  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_236000.caffemodel
I0217 13:48:38.426877  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_236000.solverstate
I0217 13:48:38.512876  8728 solver.cpp:337] Iteration 236000, Testing net (#0)
I0217 13:48:38.512876  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:48:44.589375  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9451
I0217 13:48:44.589875  8728 solver.cpp:404]     Test net output #1: loss = 0.180973 (* 1 = 0.180973 loss)
I0217 13:48:44.665889  8728 solver.cpp:228] Iteration 236000, loss = 0.00463938
I0217 13:48:44.665889  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:48:44.665889  8728 solver.cpp:244]     Train net output #1: loss = 0.00463937 (* 1 = 0.00463937 loss)
I0217 13:48:44.665889  8728 sgd_solver.cpp:106] Iteration 236000, lr = 0.001
I0217 13:49:02.577255  8728 solver.cpp:228] Iteration 236100, loss = 0.00412457
I0217 13:49:02.577255  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:49:02.577255  8728 solver.cpp:244]     Train net output #1: loss = 0.00412456 (* 1 = 0.00412456 loss)
I0217 13:49:02.577255  8728 sgd_solver.cpp:106] Iteration 236100, lr = 0.001
I0217 13:49:20.541743  8728 solver.cpp:228] Iteration 236200, loss = 0.00257571
I0217 13:49:20.542243  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:49:20.542243  8728 solver.cpp:244]     Train net output #1: loss = 0.0025757 (* 1 = 0.0025757 loss)
I0217 13:49:20.542243  8728 sgd_solver.cpp:106] Iteration 236200, lr = 0.001
I0217 13:49:38.541088  8728 solver.cpp:228] Iteration 236300, loss = 0.0036255
I0217 13:49:38.541088  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:49:38.541088  8728 solver.cpp:244]     Train net output #1: loss = 0.0036255 (* 1 = 0.0036255 loss)
I0217 13:49:38.541088  8728 sgd_solver.cpp:106] Iteration 236300, lr = 0.001
I0217 13:49:56.482305  8728 solver.cpp:228] Iteration 236400, loss = 0.00446687
I0217 13:49:56.482800  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:49:56.482800  8728 solver.cpp:244]     Train net output #1: loss = 0.00446686 (* 1 = 0.00446686 loss)
I0217 13:49:56.482800  8728 sgd_solver.cpp:106] Iteration 236400, lr = 0.001
I0217 13:50:14.360234  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_236500.caffemodel
I0217 13:50:14.500735  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_236500.solverstate
I0217 13:50:14.631418  8728 solver.cpp:337] Iteration 236500, Testing net (#0)
I0217 13:50:14.631418  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:50:20.735831  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9447
I0217 13:50:20.735831  8728 solver.cpp:404]     Test net output #1: loss = 0.183857 (* 1 = 0.183857 loss)
I0217 13:50:20.807838  8728 solver.cpp:228] Iteration 236500, loss = 0.00576053
I0217 13:50:20.808311  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:50:20.808311  8728 solver.cpp:244]     Train net output #1: loss = 0.00576052 (* 1 = 0.00576052 loss)
I0217 13:50:20.808311  8728 sgd_solver.cpp:106] Iteration 236500, lr = 0.001
I0217 13:50:38.736585  8728 solver.cpp:228] Iteration 236600, loss = 0.00817013
I0217 13:50:38.736585  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:50:38.736585  8728 solver.cpp:244]     Train net output #1: loss = 0.00817011 (* 1 = 0.00817011 loss)
I0217 13:50:38.736585  8728 sgd_solver.cpp:106] Iteration 236600, lr = 0.001
I0217 13:50:56.656667  8728 solver.cpp:228] Iteration 236700, loss = 0.00199732
I0217 13:50:56.656667  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:50:56.656667  8728 solver.cpp:244]     Train net output #1: loss = 0.00199731 (* 1 = 0.00199731 loss)
I0217 13:50:56.656667  8728 sgd_solver.cpp:106] Iteration 236700, lr = 0.001
I0217 13:51:14.584075  8728 solver.cpp:228] Iteration 236800, loss = 0.00363466
I0217 13:51:14.584075  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:51:14.584075  8728 solver.cpp:244]     Train net output #1: loss = 0.00363464 (* 1 = 0.00363464 loss)
I0217 13:51:14.584075  8728 sgd_solver.cpp:106] Iteration 236800, lr = 0.001
I0217 13:51:32.511168  8728 solver.cpp:228] Iteration 236900, loss = 0.0013208
I0217 13:51:32.511168  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:51:32.511168  8728 solver.cpp:244]     Train net output #1: loss = 0.00132079 (* 1 = 0.00132079 loss)
I0217 13:51:32.511168  8728 sgd_solver.cpp:106] Iteration 236900, lr = 0.001
I0217 13:51:50.375084  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_237000.caffemodel
I0217 13:51:50.518077  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_237000.solverstate
I0217 13:51:50.583575  8728 solver.cpp:337] Iteration 237000, Testing net (#0)
I0217 13:51:50.583575  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:51:56.699574  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945101
I0217 13:51:56.699574  8728 solver.cpp:404]     Test net output #1: loss = 0.180456 (* 1 = 0.180456 loss)
I0217 13:51:56.772089  8728 solver.cpp:228] Iteration 237000, loss = 0.00203515
I0217 13:51:56.772089  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:51:56.772089  8728 solver.cpp:244]     Train net output #1: loss = 0.00203514 (* 1 = 0.00203514 loss)
I0217 13:51:56.772089  8728 sgd_solver.cpp:106] Iteration 237000, lr = 0.001
I0217 13:52:14.699993  8728 solver.cpp:228] Iteration 237100, loss = 0.00345597
I0217 13:52:14.699993  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:52:14.699993  8728 solver.cpp:244]     Train net output #1: loss = 0.00345595 (* 1 = 0.00345595 loss)
I0217 13:52:14.699993  8728 sgd_solver.cpp:106] Iteration 237100, lr = 0.001
I0217 13:52:32.625844  8728 solver.cpp:228] Iteration 237200, loss = 0.0101681
I0217 13:52:32.625844  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:52:32.625844  8728 solver.cpp:244]     Train net output #1: loss = 0.0101681 (* 1 = 0.0101681 loss)
I0217 13:52:32.625844  8728 sgd_solver.cpp:106] Iteration 237200, lr = 0.001
I0217 13:52:50.549690  8728 solver.cpp:228] Iteration 237300, loss = 0.00251108
I0217 13:52:50.549690  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:52:50.549690  8728 solver.cpp:244]     Train net output #1: loss = 0.00251106 (* 1 = 0.00251106 loss)
I0217 13:52:50.549690  8728 sgd_solver.cpp:106] Iteration 237300, lr = 0.001
I0217 13:53:08.475366  8728 solver.cpp:228] Iteration 237400, loss = 0.00395207
I0217 13:53:08.475366  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:53:08.475366  8728 solver.cpp:244]     Train net output #1: loss = 0.00395206 (* 1 = 0.00395206 loss)
I0217 13:53:08.475366  8728 sgd_solver.cpp:106] Iteration 237400, lr = 0.001
I0217 13:53:26.331270  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_237500.caffemodel
I0217 13:53:26.472772  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_237500.solverstate
I0217 13:53:26.539772  8728 solver.cpp:337] Iteration 237500, Testing net (#0)
I0217 13:53:26.540271  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:53:32.604771  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9427
I0217 13:53:32.604771  8728 solver.cpp:404]     Test net output #1: loss = 0.187236 (* 1 = 0.187236 loss)
I0217 13:53:32.676782  8728 solver.cpp:228] Iteration 237500, loss = 0.00317647
I0217 13:53:32.676782  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:53:32.676782  8728 solver.cpp:244]     Train net output #1: loss = 0.00317646 (* 1 = 0.00317646 loss)
I0217 13:53:32.676782  8728 sgd_solver.cpp:106] Iteration 237500, lr = 0.001
I0217 13:53:50.586272  8728 solver.cpp:228] Iteration 237600, loss = 0.00409658
I0217 13:53:50.586272  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:53:50.586272  8728 solver.cpp:244]     Train net output #1: loss = 0.00409657 (* 1 = 0.00409657 loss)
I0217 13:53:50.586272  8728 sgd_solver.cpp:106] Iteration 237600, lr = 0.001
I0217 13:54:08.401159  8728 solver.cpp:228] Iteration 237700, loss = 0.00586607
I0217 13:54:08.401159  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:54:08.401159  8728 solver.cpp:244]     Train net output #1: loss = 0.00586606 (* 1 = 0.00586606 loss)
I0217 13:54:08.401159  8728 sgd_solver.cpp:106] Iteration 237700, lr = 0.001
I0217 13:54:26.110924  8728 solver.cpp:228] Iteration 237800, loss = 0.00179072
I0217 13:54:26.110924  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:54:26.110924  8728 solver.cpp:244]     Train net output #1: loss = 0.00179071 (* 1 = 0.00179071 loss)
I0217 13:54:26.110924  8728 sgd_solver.cpp:106] Iteration 237800, lr = 0.001
I0217 13:54:43.820085  8728 solver.cpp:228] Iteration 237900, loss = 0.00159173
I0217 13:54:43.820085  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:54:43.820085  8728 solver.cpp:244]     Train net output #1: loss = 0.00159172 (* 1 = 0.00159172 loss)
I0217 13:54:43.820085  8728 sgd_solver.cpp:106] Iteration 237900, lr = 0.001
I0217 13:55:01.446066  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_238000.caffemodel
I0217 13:55:01.587080  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_238000.solverstate
I0217 13:55:01.652585  8728 solver.cpp:337] Iteration 238000, Testing net (#0)
I0217 13:55:01.652585  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:55:07.696440  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9446
I0217 13:55:07.696440  8728 solver.cpp:404]     Test net output #1: loss = 0.185357 (* 1 = 0.185357 loss)
I0217 13:55:07.767455  8728 solver.cpp:228] Iteration 238000, loss = 0.00380179
I0217 13:55:07.767455  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:55:07.767455  8728 solver.cpp:244]     Train net output #1: loss = 0.00380179 (* 1 = 0.00380179 loss)
I0217 13:55:07.767455  8728 sgd_solver.cpp:106] Iteration 238000, lr = 0.001
I0217 13:55:25.470201  8728 solver.cpp:228] Iteration 238100, loss = 0.00576258
I0217 13:55:25.470710  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:55:25.470710  8728 solver.cpp:244]     Train net output #1: loss = 0.00576257 (* 1 = 0.00576257 loss)
I0217 13:55:25.470710  8728 sgd_solver.cpp:106] Iteration 238100, lr = 0.001
I0217 13:55:43.180486  8728 solver.cpp:228] Iteration 238200, loss = 0.00142751
I0217 13:55:43.180486  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:55:43.180486  8728 solver.cpp:244]     Train net output #1: loss = 0.00142749 (* 1 = 0.00142749 loss)
I0217 13:55:43.180486  8728 sgd_solver.cpp:106] Iteration 238200, lr = 0.001
I0217 13:56:01.119768  8728 solver.cpp:228] Iteration 238300, loss = 0.00308094
I0217 13:56:01.119768  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:56:01.119768  8728 solver.cpp:244]     Train net output #1: loss = 0.00308093 (* 1 = 0.00308093 loss)
I0217 13:56:01.119768  8728 sgd_solver.cpp:106] Iteration 238300, lr = 0.001
I0217 13:56:19.057286  8728 solver.cpp:228] Iteration 238400, loss = 0.00321413
I0217 13:56:19.057286  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:56:19.057286  8728 solver.cpp:244]     Train net output #1: loss = 0.00321412 (* 1 = 0.00321412 loss)
I0217 13:56:19.057286  8728 sgd_solver.cpp:106] Iteration 238400, lr = 0.001
I0217 13:56:36.943974  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_238500.caffemodel
I0217 13:56:37.086976  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_238500.solverstate
I0217 13:56:37.168974  8728 solver.cpp:337] Iteration 238500, Testing net (#0)
I0217 13:56:37.168974  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:56:43.227998  8728 solver.cpp:404]     Test net output #0: accuracy = 0.946801
I0217 13:56:43.227998  8728 solver.cpp:404]     Test net output #1: loss = 0.184413 (* 1 = 0.184413 loss)
I0217 13:56:43.300024  8728 solver.cpp:228] Iteration 238500, loss = 0.00212995
I0217 13:56:43.300024  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:56:43.300024  8728 solver.cpp:244]     Train net output #1: loss = 0.00212994 (* 1 = 0.00212994 loss)
I0217 13:56:43.300024  8728 sgd_solver.cpp:106] Iteration 238500, lr = 0.001
I0217 13:57:01.178382  8728 solver.cpp:228] Iteration 238600, loss = 0.00328173
I0217 13:57:01.178382  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:57:01.178382  8728 solver.cpp:244]     Train net output #1: loss = 0.00328172 (* 1 = 0.00328172 loss)
I0217 13:57:01.178382  8728 sgd_solver.cpp:106] Iteration 238600, lr = 0.001
I0217 13:57:19.126303  8728 solver.cpp:228] Iteration 238700, loss = 0.00390873
I0217 13:57:19.126791  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:57:19.126791  8728 solver.cpp:244]     Train net output #1: loss = 0.00390872 (* 1 = 0.00390872 loss)
I0217 13:57:19.126791  8728 sgd_solver.cpp:106] Iteration 238700, lr = 0.001
I0217 13:57:37.079242  8728 solver.cpp:228] Iteration 238800, loss = 0.00342122
I0217 13:57:37.079242  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:57:37.079242  8728 solver.cpp:244]     Train net output #1: loss = 0.00342121 (* 1 = 0.00342121 loss)
I0217 13:57:37.079242  8728 sgd_solver.cpp:106] Iteration 238800, lr = 0.001
I0217 13:57:55.037850  8728 solver.cpp:228] Iteration 238900, loss = 0.00253873
I0217 13:57:55.037850  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:57:55.037850  8728 solver.cpp:244]     Train net output #1: loss = 0.00253872 (* 1 = 0.00253872 loss)
I0217 13:57:55.037850  8728 sgd_solver.cpp:106] Iteration 238900, lr = 0.001
I0217 13:58:12.885915  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_239000.caffemodel
I0217 13:58:13.030410  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_239000.solverstate
I0217 13:58:13.100409  8728 solver.cpp:337] Iteration 239000, Testing net (#0)
I0217 13:58:13.100909  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:58:19.186908  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9444
I0217 13:58:19.186908  8728 solver.cpp:404]     Test net output #1: loss = 0.188619 (* 1 = 0.188619 loss)
I0217 13:58:19.258922  8728 solver.cpp:228] Iteration 239000, loss = 0.00689156
I0217 13:58:19.258922  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:58:19.258922  8728 solver.cpp:244]     Train net output #1: loss = 0.00689155 (* 1 = 0.00689155 loss)
I0217 13:58:19.258922  8728 sgd_solver.cpp:106] Iteration 239000, lr = 0.001
I0217 13:58:37.182446  8728 solver.cpp:228] Iteration 239100, loss = 0.00212389
I0217 13:58:37.182945  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:58:37.182945  8728 solver.cpp:244]     Train net output #1: loss = 0.00212388 (* 1 = 0.00212388 loss)
I0217 13:58:37.182945  8728 sgd_solver.cpp:106] Iteration 239100, lr = 0.001
I0217 13:58:55.105942  8728 solver.cpp:228] Iteration 239200, loss = 0.0116447
I0217 13:58:55.106423  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:58:55.106423  8728 solver.cpp:244]     Train net output #1: loss = 0.0116447 (* 1 = 0.0116447 loss)
I0217 13:58:55.106423  8728 sgd_solver.cpp:106] Iteration 239200, lr = 0.001
I0217 13:59:13.032486  8728 solver.cpp:228] Iteration 239300, loss = 0.0107483
I0217 13:59:13.032486  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 13:59:13.032486  8728 solver.cpp:244]     Train net output #1: loss = 0.0107483 (* 1 = 0.0107483 loss)
I0217 13:59:13.032486  8728 sgd_solver.cpp:106] Iteration 239300, lr = 0.001
I0217 13:59:30.974198  8728 solver.cpp:228] Iteration 239400, loss = 0.00371572
I0217 13:59:30.974198  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:59:30.974198  8728 solver.cpp:244]     Train net output #1: loss = 0.00371571 (* 1 = 0.00371571 loss)
I0217 13:59:30.974198  8728 sgd_solver.cpp:106] Iteration 239400, lr = 0.001
I0217 13:59:48.815426  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_239500.caffemodel
I0217 13:59:48.959445  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_239500.solverstate
I0217 13:59:49.024945  8728 solver.cpp:337] Iteration 239500, Testing net (#0)
I0217 13:59:49.024945  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 13:59:55.111446  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9455
I0217 13:59:55.111446  8728 solver.cpp:404]     Test net output #1: loss = 0.187267 (* 1 = 0.187267 loss)
I0217 13:59:55.183943  8728 solver.cpp:228] Iteration 239500, loss = 0.00274188
I0217 13:59:55.183943  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 13:59:55.183943  8728 solver.cpp:244]     Train net output #1: loss = 0.00274187 (* 1 = 0.00274187 loss)
I0217 13:59:55.183943  8728 sgd_solver.cpp:106] Iteration 239500, lr = 0.001
I0217 14:00:13.069788  8728 solver.cpp:228] Iteration 239600, loss = 0.00135409
I0217 14:00:13.069788  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:00:13.069788  8728 solver.cpp:244]     Train net output #1: loss = 0.00135407 (* 1 = 0.00135407 loss)
I0217 14:00:13.069788  8728 sgd_solver.cpp:106] Iteration 239600, lr = 0.001
I0217 14:00:30.957159  8728 solver.cpp:228] Iteration 239700, loss = 0.00190768
I0217 14:00:30.957159  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:00:30.957159  8728 solver.cpp:244]     Train net output #1: loss = 0.00190766 (* 1 = 0.00190766 loss)
I0217 14:00:30.957159  8728 sgd_solver.cpp:106] Iteration 239700, lr = 0.001
I0217 14:00:48.889772  8728 solver.cpp:228] Iteration 239800, loss = 0.00374996
I0217 14:00:48.889772  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:00:48.889772  8728 solver.cpp:244]     Train net output #1: loss = 0.00374994 (* 1 = 0.00374994 loss)
I0217 14:00:48.889772  8728 sgd_solver.cpp:106] Iteration 239800, lr = 0.001
I0217 14:01:06.819900  8728 solver.cpp:228] Iteration 239900, loss = 0.00197578
I0217 14:01:06.819900  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:01:06.819900  8728 solver.cpp:244]     Train net output #1: loss = 0.00197577 (* 1 = 0.00197577 loss)
I0217 14:01:06.819900  8728 sgd_solver.cpp:106] Iteration 239900, lr = 0.001
I0217 14:01:24.682031  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_240000.caffemodel
I0217 14:01:24.825534  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_240000.solverstate
I0217 14:01:24.890580  8728 solver.cpp:337] Iteration 240000, Testing net (#0)
I0217 14:01:24.891080  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:01:31.001755  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 14:01:31.001755  8728 solver.cpp:404]     Test net output #1: loss = 0.185495 (* 1 = 0.185495 loss)
I0217 14:01:31.073297  8728 solver.cpp:228] Iteration 240000, loss = 0.00967119
I0217 14:01:31.073297  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:01:31.073297  8728 solver.cpp:244]     Train net output #1: loss = 0.00967118 (* 1 = 0.00967118 loss)
I0217 14:01:31.073297  8728 sgd_solver.cpp:106] Iteration 240000, lr = 0.001
I0217 14:01:49.002809  8728 solver.cpp:228] Iteration 240100, loss = 0.00347018
I0217 14:01:49.002809  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:01:49.002809  8728 solver.cpp:244]     Train net output #1: loss = 0.00347017 (* 1 = 0.00347017 loss)
I0217 14:01:49.002809  8728 sgd_solver.cpp:106] Iteration 240100, lr = 0.001
I0217 14:02:06.933126  8728 solver.cpp:228] Iteration 240200, loss = 0.00259079
I0217 14:02:06.933126  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:02:06.933126  8728 solver.cpp:244]     Train net output #1: loss = 0.00259078 (* 1 = 0.00259078 loss)
I0217 14:02:06.933126  8728 sgd_solver.cpp:106] Iteration 240200, lr = 0.001
I0217 14:02:24.859221  8728 solver.cpp:228] Iteration 240300, loss = 0.00217817
I0217 14:02:24.859221  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:02:24.859221  8728 solver.cpp:244]     Train net output #1: loss = 0.00217816 (* 1 = 0.00217816 loss)
I0217 14:02:24.859221  8728 sgd_solver.cpp:106] Iteration 240300, lr = 0.001
I0217 14:02:42.850697  8728 solver.cpp:228] Iteration 240400, loss = 0.00242122
I0217 14:02:42.850697  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:02:42.850697  8728 solver.cpp:244]     Train net output #1: loss = 0.0024212 (* 1 = 0.0024212 loss)
I0217 14:02:42.850697  8728 sgd_solver.cpp:106] Iteration 240400, lr = 0.001
I0217 14:03:00.789436  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_240500.caffemodel
I0217 14:03:00.931946  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_240500.solverstate
I0217 14:03:01.001427  8728 solver.cpp:337] Iteration 240500, Testing net (#0)
I0217 14:03:01.001926  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:03:07.098433  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9459
I0217 14:03:07.098433  8728 solver.cpp:404]     Test net output #1: loss = 0.185728 (* 1 = 0.185728 loss)
I0217 14:03:07.170956  8728 solver.cpp:228] Iteration 240500, loss = 0.00297854
I0217 14:03:07.170956  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:03:07.170956  8728 solver.cpp:244]     Train net output #1: loss = 0.00297853 (* 1 = 0.00297853 loss)
I0217 14:03:07.170956  8728 sgd_solver.cpp:106] Iteration 240500, lr = 0.001
I0217 14:03:25.143419  8728 solver.cpp:228] Iteration 240600, loss = 0.0170783
I0217 14:03:25.143419  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:03:25.143419  8728 solver.cpp:244]     Train net output #1: loss = 0.0170783 (* 1 = 0.0170783 loss)
I0217 14:03:25.143419  8728 sgd_solver.cpp:106] Iteration 240600, lr = 0.001
I0217 14:03:43.138659  8728 solver.cpp:228] Iteration 240700, loss = 0.00530322
I0217 14:03:43.138659  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:03:43.138659  8728 solver.cpp:244]     Train net output #1: loss = 0.00530321 (* 1 = 0.00530321 loss)
I0217 14:03:43.138659  8728 sgd_solver.cpp:106] Iteration 240700, lr = 0.001
I0217 14:04:01.106473  8728 solver.cpp:228] Iteration 240800, loss = 0.00502411
I0217 14:04:01.106473  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:04:01.106473  8728 solver.cpp:244]     Train net output #1: loss = 0.00502409 (* 1 = 0.00502409 loss)
I0217 14:04:01.106473  8728 sgd_solver.cpp:106] Iteration 240800, lr = 0.001
I0217 14:04:19.097553  8728 solver.cpp:228] Iteration 240900, loss = 0.00371531
I0217 14:04:19.097553  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:04:19.097553  8728 solver.cpp:244]     Train net output #1: loss = 0.00371529 (* 1 = 0.00371529 loss)
I0217 14:04:19.097553  8728 sgd_solver.cpp:106] Iteration 240900, lr = 0.001
I0217 14:04:37.147248  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_241000.caffemodel
I0217 14:04:37.286247  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_241000.solverstate
I0217 14:04:37.352255  8728 solver.cpp:337] Iteration 241000, Testing net (#0)
I0217 14:04:37.352255  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:04:43.520251  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9442
I0217 14:04:43.520251  8728 solver.cpp:404]     Test net output #1: loss = 0.185445 (* 1 = 0.185445 loss)
I0217 14:04:43.593765  8728 solver.cpp:228] Iteration 241000, loss = 0.00319084
I0217 14:04:43.593765  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:04:43.593765  8728 solver.cpp:244]     Train net output #1: loss = 0.00319082 (* 1 = 0.00319082 loss)
I0217 14:04:43.593765  8728 sgd_solver.cpp:106] Iteration 241000, lr = 0.001
I0217 14:05:01.550838  8728 solver.cpp:228] Iteration 241100, loss = 0.00356231
I0217 14:05:01.550838  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:05:01.550838  8728 solver.cpp:244]     Train net output #1: loss = 0.00356229 (* 1 = 0.00356229 loss)
I0217 14:05:01.550838  8728 sgd_solver.cpp:106] Iteration 241100, lr = 0.001
I0217 14:05:19.485081  8728 solver.cpp:228] Iteration 241200, loss = 0.00404905
I0217 14:05:19.485081  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:05:19.485081  8728 solver.cpp:244]     Train net output #1: loss = 0.00404903 (* 1 = 0.00404903 loss)
I0217 14:05:19.485081  8728 sgd_solver.cpp:106] Iteration 241200, lr = 0.001
I0217 14:05:37.413941  8728 solver.cpp:228] Iteration 241300, loss = 0.00377976
I0217 14:05:37.413941  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:05:37.413941  8728 solver.cpp:244]     Train net output #1: loss = 0.00377975 (* 1 = 0.00377975 loss)
I0217 14:05:37.413941  8728 sgd_solver.cpp:106] Iteration 241300, lr = 0.001
I0217 14:05:55.352319  8728 solver.cpp:228] Iteration 241400, loss = 0.00394514
I0217 14:05:55.352319  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:05:55.352319  8728 solver.cpp:244]     Train net output #1: loss = 0.00394512 (* 1 = 0.00394512 loss)
I0217 14:05:55.352319  8728 sgd_solver.cpp:106] Iteration 241400, lr = 0.001
I0217 14:06:13.195394  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_241500.caffemodel
I0217 14:06:13.331884  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_241500.solverstate
I0217 14:06:13.397382  8728 solver.cpp:337] Iteration 241500, Testing net (#0)
I0217 14:06:13.397382  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:06:19.506392  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 14:06:19.506881  8728 solver.cpp:404]     Test net output #1: loss = 0.189079 (* 1 = 0.189079 loss)
I0217 14:06:19.583910  8728 solver.cpp:228] Iteration 241500, loss = 0.00669708
I0217 14:06:19.583910  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:06:19.583910  8728 solver.cpp:244]     Train net output #1: loss = 0.00669707 (* 1 = 0.00669707 loss)
I0217 14:06:19.583910  8728 sgd_solver.cpp:106] Iteration 241500, lr = 0.001
I0217 14:06:37.509930  8728 solver.cpp:228] Iteration 241600, loss = 0.0151051
I0217 14:06:37.509930  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:06:37.509930  8728 solver.cpp:244]     Train net output #1: loss = 0.0151051 (* 1 = 0.0151051 loss)
I0217 14:06:37.509930  8728 sgd_solver.cpp:106] Iteration 241600, lr = 0.001
I0217 14:06:55.428624  8728 solver.cpp:228] Iteration 241700, loss = 0.00948407
I0217 14:06:55.428624  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:06:55.428624  8728 solver.cpp:244]     Train net output #1: loss = 0.00948405 (* 1 = 0.00948405 loss)
I0217 14:06:55.428624  8728 sgd_solver.cpp:106] Iteration 241700, lr = 0.001
I0217 14:07:13.365787  8728 solver.cpp:228] Iteration 241800, loss = 0.00215554
I0217 14:07:13.366269  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:07:13.366269  8728 solver.cpp:244]     Train net output #1: loss = 0.00215552 (* 1 = 0.00215552 loss)
I0217 14:07:13.366269  8728 sgd_solver.cpp:106] Iteration 241800, lr = 0.001
I0217 14:07:31.295769  8728 solver.cpp:228] Iteration 241900, loss = 0.00395679
I0217 14:07:31.295769  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:07:31.295769  8728 solver.cpp:244]     Train net output #1: loss = 0.00395677 (* 1 = 0.00395677 loss)
I0217 14:07:31.295769  8728 sgd_solver.cpp:106] Iteration 241900, lr = 0.001
I0217 14:07:49.144477  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_242000.caffemodel
I0217 14:07:49.283969  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_242000.solverstate
I0217 14:07:49.349470  8728 solver.cpp:337] Iteration 242000, Testing net (#0)
I0217 14:07:49.349470  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:07:55.459971  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9443
I0217 14:07:55.459971  8728 solver.cpp:404]     Test net output #1: loss = 0.188623 (* 1 = 0.188623 loss)
I0217 14:07:55.532485  8728 solver.cpp:228] Iteration 242000, loss = 0.00610367
I0217 14:07:55.532485  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:07:55.532485  8728 solver.cpp:244]     Train net output #1: loss = 0.00610365 (* 1 = 0.00610365 loss)
I0217 14:07:55.532485  8728 sgd_solver.cpp:106] Iteration 242000, lr = 0.001
I0217 14:08:13.471294  8728 solver.cpp:228] Iteration 242100, loss = 0.00270683
I0217 14:08:13.471294  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:08:13.471294  8728 solver.cpp:244]     Train net output #1: loss = 0.00270682 (* 1 = 0.00270682 loss)
I0217 14:08:13.471294  8728 sgd_solver.cpp:106] Iteration 242100, lr = 0.001
I0217 14:08:31.403254  8728 solver.cpp:228] Iteration 242200, loss = 0.0117122
I0217 14:08:31.403254  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:08:31.403254  8728 solver.cpp:244]     Train net output #1: loss = 0.0117122 (* 1 = 0.0117122 loss)
I0217 14:08:31.403254  8728 sgd_solver.cpp:106] Iteration 242200, lr = 0.001
I0217 14:08:49.338058  8728 solver.cpp:228] Iteration 242300, loss = 0.0106533
I0217 14:08:49.338058  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:08:49.338058  8728 solver.cpp:244]     Train net output #1: loss = 0.0106533 (* 1 = 0.0106533 loss)
I0217 14:08:49.338058  8728 sgd_solver.cpp:106] Iteration 242300, lr = 0.001
I0217 14:09:07.294600  8728 solver.cpp:228] Iteration 242400, loss = 0.00279107
I0217 14:09:07.294600  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:09:07.294600  8728 solver.cpp:244]     Train net output #1: loss = 0.00279105 (* 1 = 0.00279105 loss)
I0217 14:09:07.294600  8728 sgd_solver.cpp:106] Iteration 242400, lr = 0.001
I0217 14:09:25.149130  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_242500.caffemodel
I0217 14:09:25.290634  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_242500.solverstate
I0217 14:09:25.357640  8728 solver.cpp:337] Iteration 242500, Testing net (#0)
I0217 14:09:25.358122  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:09:31.438616  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 14:09:31.438616  8728 solver.cpp:404]     Test net output #1: loss = 0.185393 (* 1 = 0.185393 loss)
I0217 14:09:31.509609  8728 solver.cpp:228] Iteration 242500, loss = 0.0050444
I0217 14:09:31.510119  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:09:31.510119  8728 solver.cpp:244]     Train net output #1: loss = 0.00504438 (* 1 = 0.00504438 loss)
I0217 14:09:31.510119  8728 sgd_solver.cpp:106] Iteration 242500, lr = 0.001
I0217 14:09:49.407690  8728 solver.cpp:228] Iteration 242600, loss = 0.00230873
I0217 14:09:49.407690  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:09:49.407690  8728 solver.cpp:244]     Train net output #1: loss = 0.00230871 (* 1 = 0.00230871 loss)
I0217 14:09:49.407690  8728 sgd_solver.cpp:106] Iteration 242600, lr = 0.001
I0217 14:10:07.309728  8728 solver.cpp:228] Iteration 242700, loss = 0.00285582
I0217 14:10:07.309728  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:10:07.309728  8728 solver.cpp:244]     Train net output #1: loss = 0.0028558 (* 1 = 0.0028558 loss)
I0217 14:10:07.309728  8728 sgd_solver.cpp:106] Iteration 242700, lr = 0.001
I0217 14:10:25.239341  8728 solver.cpp:228] Iteration 242800, loss = 0.00671453
I0217 14:10:25.239341  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:10:25.239341  8728 solver.cpp:244]     Train net output #1: loss = 0.00671451 (* 1 = 0.00671451 loss)
I0217 14:10:25.239341  8728 sgd_solver.cpp:106] Iteration 242800, lr = 0.001
I0217 14:10:43.166632  8728 solver.cpp:228] Iteration 242900, loss = 0.037985
I0217 14:10:43.166632  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0217 14:10:43.166632  8728 solver.cpp:244]     Train net output #1: loss = 0.037985 (* 1 = 0.037985 loss)
I0217 14:10:43.166632  8728 sgd_solver.cpp:106] Iteration 242900, lr = 0.001
I0217 14:11:01.030205  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_243000.caffemodel
I0217 14:11:01.175709  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_243000.solverstate
I0217 14:11:01.240222  8728 solver.cpp:337] Iteration 243000, Testing net (#0)
I0217 14:11:01.240222  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:11:07.348206  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 14:11:07.348206  8728 solver.cpp:404]     Test net output #1: loss = 0.185791 (* 1 = 0.185791 loss)
I0217 14:11:07.419721  8728 solver.cpp:228] Iteration 243000, loss = 0.00199068
I0217 14:11:07.419721  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:11:07.419721  8728 solver.cpp:244]     Train net output #1: loss = 0.00199067 (* 1 = 0.00199067 loss)
I0217 14:11:07.419721  8728 sgd_solver.cpp:106] Iteration 243000, lr = 0.001
I0217 14:11:25.365948  8728 solver.cpp:228] Iteration 243100, loss = 0.00863092
I0217 14:11:25.365948  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:11:25.365948  8728 solver.cpp:244]     Train net output #1: loss = 0.0086309 (* 1 = 0.0086309 loss)
I0217 14:11:25.365948  8728 sgd_solver.cpp:106] Iteration 243100, lr = 0.001
I0217 14:11:43.291729  8728 solver.cpp:228] Iteration 243200, loss = 0.00189545
I0217 14:11:43.292225  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:11:43.292225  8728 solver.cpp:244]     Train net output #1: loss = 0.00189543 (* 1 = 0.00189543 loss)
I0217 14:11:43.292225  8728 sgd_solver.cpp:106] Iteration 243200, lr = 0.001
I0217 14:12:01.221108  8728 solver.cpp:228] Iteration 243300, loss = 0.0118126
I0217 14:12:01.221608  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:12:01.221608  8728 solver.cpp:244]     Train net output #1: loss = 0.0118125 (* 1 = 0.0118125 loss)
I0217 14:12:01.221608  8728 sgd_solver.cpp:106] Iteration 243300, lr = 0.001
I0217 14:12:19.150605  8728 solver.cpp:228] Iteration 243400, loss = 0.0110918
I0217 14:12:19.150605  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:12:19.150605  8728 solver.cpp:244]     Train net output #1: loss = 0.0110918 (* 1 = 0.0110918 loss)
I0217 14:12:19.150605  8728 sgd_solver.cpp:106] Iteration 243400, lr = 0.001
I0217 14:12:37.016901  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_243500.caffemodel
I0217 14:12:37.157418  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_243500.solverstate
I0217 14:12:37.269462  8728 solver.cpp:337] Iteration 243500, Testing net (#0)
I0217 14:12:37.269963  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:12:43.388869  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 14:12:43.388869  8728 solver.cpp:404]     Test net output #1: loss = 0.187393 (* 1 = 0.187393 loss)
I0217 14:12:43.461890  8728 solver.cpp:228] Iteration 243500, loss = 0.000915061
I0217 14:12:43.461890  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:12:43.461890  8728 solver.cpp:244]     Train net output #1: loss = 0.000915042 (* 1 = 0.000915042 loss)
I0217 14:12:43.461890  8728 sgd_solver.cpp:106] Iteration 243500, lr = 0.001
I0217 14:13:01.397697  8728 solver.cpp:228] Iteration 243600, loss = 0.003546
I0217 14:13:01.397697  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:13:01.397697  8728 solver.cpp:244]     Train net output #1: loss = 0.00354597 (* 1 = 0.00354597 loss)
I0217 14:13:01.397697  8728 sgd_solver.cpp:106] Iteration 243600, lr = 0.001
I0217 14:13:19.330152  8728 solver.cpp:228] Iteration 243700, loss = 0.00155531
I0217 14:13:19.330624  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:13:19.330624  8728 solver.cpp:244]     Train net output #1: loss = 0.00155529 (* 1 = 0.00155529 loss)
I0217 14:13:19.330624  8728 sgd_solver.cpp:106] Iteration 243700, lr = 0.001
I0217 14:13:37.272595  8728 solver.cpp:228] Iteration 243800, loss = 0.00381622
I0217 14:13:37.272595  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:13:37.272595  8728 solver.cpp:244]     Train net output #1: loss = 0.0038162 (* 1 = 0.0038162 loss)
I0217 14:13:37.272595  8728 sgd_solver.cpp:106] Iteration 243800, lr = 0.001
I0217 14:13:55.209172  8728 solver.cpp:228] Iteration 243900, loss = 0.00221212
I0217 14:13:55.209172  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:13:55.209672  8728 solver.cpp:244]     Train net output #1: loss = 0.0022121 (* 1 = 0.0022121 loss)
I0217 14:13:55.209672  8728 sgd_solver.cpp:106] Iteration 243900, lr = 0.001
I0217 14:14:13.060458  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_244000.caffemodel
I0217 14:14:13.207962  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_244000.solverstate
I0217 14:14:13.277966  8728 solver.cpp:337] Iteration 244000, Testing net (#0)
I0217 14:14:13.277966  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:14:19.343021  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9447
I0217 14:14:19.343021  8728 solver.cpp:404]     Test net output #1: loss = 0.18764 (* 1 = 0.18764 loss)
I0217 14:14:19.416050  8728 solver.cpp:228] Iteration 244000, loss = 0.00373976
I0217 14:14:19.416050  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:14:19.416050  8728 solver.cpp:244]     Train net output #1: loss = 0.00373974 (* 1 = 0.00373974 loss)
I0217 14:14:19.416050  8728 sgd_solver.cpp:106] Iteration 244000, lr = 0.001
I0217 14:14:37.233925  8728 solver.cpp:228] Iteration 244100, loss = 0.00341691
I0217 14:14:37.233925  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:14:37.233925  8728 solver.cpp:244]     Train net output #1: loss = 0.00341689 (* 1 = 0.00341689 loss)
I0217 14:14:37.233925  8728 sgd_solver.cpp:106] Iteration 244100, lr = 0.001
I0217 14:14:54.939234  8728 solver.cpp:228] Iteration 244200, loss = 0.00404089
I0217 14:14:54.939234  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:14:54.939234  8728 solver.cpp:244]     Train net output #1: loss = 0.00404086 (* 1 = 0.00404086 loss)
I0217 14:14:54.939234  8728 sgd_solver.cpp:106] Iteration 244200, lr = 0.001
I0217 14:15:12.642433  8728 solver.cpp:228] Iteration 244300, loss = 0.00275224
I0217 14:15:12.642433  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:15:12.642433  8728 solver.cpp:244]     Train net output #1: loss = 0.00275222 (* 1 = 0.00275222 loss)
I0217 14:15:12.642433  8728 sgd_solver.cpp:106] Iteration 244300, lr = 0.001
I0217 14:15:30.348806  8728 solver.cpp:228] Iteration 244400, loss = 0.00121946
I0217 14:15:30.348806  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:15:30.348806  8728 solver.cpp:244]     Train net output #1: loss = 0.00121943 (* 1 = 0.00121943 loss)
I0217 14:15:30.348806  8728 sgd_solver.cpp:106] Iteration 244400, lr = 0.001
I0217 14:15:47.979846  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_244500.caffemodel
I0217 14:15:48.121397  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_244500.solverstate
I0217 14:15:48.187397  8728 solver.cpp:337] Iteration 244500, Testing net (#0)
I0217 14:15:48.187397  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:15:54.200538  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9447
I0217 14:15:54.200538  8728 solver.cpp:404]     Test net output #1: loss = 0.185241 (* 1 = 0.185241 loss)
I0217 14:15:54.271548  8728 solver.cpp:228] Iteration 244500, loss = 0.0017366
I0217 14:15:54.271548  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:15:54.271548  8728 solver.cpp:244]     Train net output #1: loss = 0.00173657 (* 1 = 0.00173657 loss)
I0217 14:15:54.271548  8728 sgd_solver.cpp:106] Iteration 244500, lr = 0.001
I0217 14:16:11.934303  8728 solver.cpp:228] Iteration 244600, loss = 0.00210712
I0217 14:16:11.934303  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:16:11.934303  8728 solver.cpp:244]     Train net output #1: loss = 0.00210709 (* 1 = 0.00210709 loss)
I0217 14:16:11.934303  8728 sgd_solver.cpp:106] Iteration 244600, lr = 0.001
I0217 14:16:29.644013  8728 solver.cpp:228] Iteration 244700, loss = 0.000986874
I0217 14:16:29.644013  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:16:29.644013  8728 solver.cpp:244]     Train net output #1: loss = 0.000986846 (* 1 = 0.000986846 loss)
I0217 14:16:29.644013  8728 sgd_solver.cpp:106] Iteration 244700, lr = 0.001
I0217 14:16:47.344997  8728 solver.cpp:228] Iteration 244800, loss = 0.00280936
I0217 14:16:47.344997  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:16:47.344997  8728 solver.cpp:244]     Train net output #1: loss = 0.00280933 (* 1 = 0.00280933 loss)
I0217 14:16:47.344997  8728 sgd_solver.cpp:106] Iteration 244800, lr = 0.001
I0217 14:17:05.051154  8728 solver.cpp:228] Iteration 244900, loss = 0.00305611
I0217 14:17:05.051154  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:17:05.051154  8728 solver.cpp:244]     Train net output #1: loss = 0.00305609 (* 1 = 0.00305609 loss)
I0217 14:17:05.051154  8728 sgd_solver.cpp:106] Iteration 244900, lr = 0.001
I0217 14:17:22.680114  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_245000.caffemodel
I0217 14:17:22.818141  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_245000.solverstate
I0217 14:17:22.884162  8728 solver.cpp:337] Iteration 245000, Testing net (#0)
I0217 14:17:22.884649  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:17:28.928104  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9449
I0217 14:17:28.929091  8728 solver.cpp:404]     Test net output #1: loss = 0.186759 (* 1 = 0.186759 loss)
I0217 14:17:29.000192  8728 solver.cpp:228] Iteration 245000, loss = 0.00264319
I0217 14:17:29.000192  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:17:29.000192  8728 solver.cpp:244]     Train net output #1: loss = 0.00264316 (* 1 = 0.00264316 loss)
I0217 14:17:29.000192  8728 sgd_solver.cpp:106] Iteration 245000, lr = 0.001
I0217 14:17:46.708825  8728 solver.cpp:228] Iteration 245100, loss = 0.00280268
I0217 14:17:46.708825  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:17:46.708825  8728 solver.cpp:244]     Train net output #1: loss = 0.00280266 (* 1 = 0.00280266 loss)
I0217 14:17:46.708825  8728 sgd_solver.cpp:106] Iteration 245100, lr = 0.001
I0217 14:18:04.420922  8728 solver.cpp:228] Iteration 245200, loss = 0.00960083
I0217 14:18:04.420922  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:18:04.420922  8728 solver.cpp:244]     Train net output #1: loss = 0.00960081 (* 1 = 0.00960081 loss)
I0217 14:18:04.420922  8728 sgd_solver.cpp:106] Iteration 245200, lr = 0.001
I0217 14:18:22.132366  8728 solver.cpp:228] Iteration 245300, loss = 0.00427088
I0217 14:18:22.132366  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:18:22.132366  8728 solver.cpp:244]     Train net output #1: loss = 0.00427087 (* 1 = 0.00427087 loss)
I0217 14:18:22.132366  8728 sgd_solver.cpp:106] Iteration 245300, lr = 0.001
I0217 14:18:39.876948  8728 solver.cpp:228] Iteration 245400, loss = 0.00171902
I0217 14:18:39.876948  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:18:39.876948  8728 solver.cpp:244]     Train net output #1: loss = 0.001719 (* 1 = 0.001719 loss)
I0217 14:18:39.876948  8728 sgd_solver.cpp:106] Iteration 245400, lr = 0.001
I0217 14:18:57.510354  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_245500.caffemodel
I0217 14:18:57.651854  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_245500.solverstate
I0217 14:18:57.717875  8728 solver.cpp:337] Iteration 245500, Testing net (#0)
I0217 14:18:57.718374  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:19:03.762527  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9438
I0217 14:19:03.762527  8728 solver.cpp:404]     Test net output #1: loss = 0.187492 (* 1 = 0.187492 loss)
I0217 14:19:03.833601  8728 solver.cpp:228] Iteration 245500, loss = 0.00247882
I0217 14:19:03.833601  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:19:03.833601  8728 solver.cpp:244]     Train net output #1: loss = 0.00247881 (* 1 = 0.00247881 loss)
I0217 14:19:03.833601  8728 sgd_solver.cpp:106] Iteration 245500, lr = 0.001
I0217 14:19:21.530169  8728 solver.cpp:228] Iteration 245600, loss = 0.005214
I0217 14:19:21.530169  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:19:21.530169  8728 solver.cpp:244]     Train net output #1: loss = 0.00521399 (* 1 = 0.00521399 loss)
I0217 14:19:21.530169  8728 sgd_solver.cpp:106] Iteration 245600, lr = 0.001
I0217 14:19:39.229472  8728 solver.cpp:228] Iteration 245700, loss = 0.0202755
I0217 14:19:39.229472  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:19:39.229472  8728 solver.cpp:244]     Train net output #1: loss = 0.0202754 (* 1 = 0.0202754 loss)
I0217 14:19:39.229472  8728 sgd_solver.cpp:106] Iteration 245700, lr = 0.001
I0217 14:19:56.926775  8728 solver.cpp:228] Iteration 245800, loss = 0.00157447
I0217 14:19:56.926775  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:19:56.926775  8728 solver.cpp:244]     Train net output #1: loss = 0.00157446 (* 1 = 0.00157446 loss)
I0217 14:19:56.926775  8728 sgd_solver.cpp:106] Iteration 245800, lr = 0.001
I0217 14:20:14.669016  8728 solver.cpp:228] Iteration 245900, loss = 0.002985
I0217 14:20:14.669016  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:20:14.669016  8728 solver.cpp:244]     Train net output #1: loss = 0.002985 (* 1 = 0.002985 loss)
I0217 14:20:14.669016  8728 sgd_solver.cpp:106] Iteration 245900, lr = 0.001
I0217 14:20:32.307711  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_246000.caffemodel
I0217 14:20:32.449239  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_246000.solverstate
I0217 14:20:32.513722  8728 solver.cpp:337] Iteration 246000, Testing net (#0)
I0217 14:20:32.513722  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:20:38.555229  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944201
I0217 14:20:38.556231  8728 solver.cpp:404]     Test net output #1: loss = 0.190309 (* 1 = 0.190309 loss)
I0217 14:20:38.626749  8728 solver.cpp:228] Iteration 246000, loss = 0.00154051
I0217 14:20:38.626749  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:20:38.626749  8728 solver.cpp:244]     Train net output #1: loss = 0.0015405 (* 1 = 0.0015405 loss)
I0217 14:20:38.626749  8728 sgd_solver.cpp:106] Iteration 246000, lr = 0.001
I0217 14:20:56.349835  8728 solver.cpp:228] Iteration 246100, loss = 0.00167482
I0217 14:20:56.349835  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:20:56.349835  8728 solver.cpp:244]     Train net output #1: loss = 0.00167481 (* 1 = 0.00167481 loss)
I0217 14:20:56.349835  8728 sgd_solver.cpp:106] Iteration 246100, lr = 0.001
I0217 14:21:14.073628  8728 solver.cpp:228] Iteration 246200, loss = 0.000882385
I0217 14:21:14.074100  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:21:14.074100  8728 solver.cpp:244]     Train net output #1: loss = 0.000882381 (* 1 = 0.000882381 loss)
I0217 14:21:14.074100  8728 sgd_solver.cpp:106] Iteration 246200, lr = 0.001
I0217 14:21:31.789902  8728 solver.cpp:228] Iteration 246300, loss = 0.003201
I0217 14:21:31.790376  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:21:31.790376  8728 solver.cpp:244]     Train net output #1: loss = 0.003201 (* 1 = 0.003201 loss)
I0217 14:21:31.790376  8728 sgd_solver.cpp:106] Iteration 246300, lr = 0.001
I0217 14:21:49.508641  8728 solver.cpp:228] Iteration 246400, loss = 0.00129077
I0217 14:21:49.508641  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:21:49.508641  8728 solver.cpp:244]     Train net output #1: loss = 0.00129077 (* 1 = 0.00129077 loss)
I0217 14:21:49.508641  8728 sgd_solver.cpp:106] Iteration 246400, lr = 0.001
I0217 14:22:07.146558  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_246500.caffemodel
I0217 14:22:07.288581  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_246500.solverstate
I0217 14:22:07.353582  8728 solver.cpp:337] Iteration 246500, Testing net (#0)
I0217 14:22:07.353582  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:22:13.399392  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9448
I0217 14:22:13.399392  8728 solver.cpp:404]     Test net output #1: loss = 0.189172 (* 1 = 0.189172 loss)
I0217 14:22:13.470427  8728 solver.cpp:228] Iteration 246500, loss = 0.0237073
I0217 14:22:13.470427  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:22:13.470427  8728 solver.cpp:244]     Train net output #1: loss = 0.0237073 (* 1 = 0.0237073 loss)
I0217 14:22:13.470427  8728 sgd_solver.cpp:106] Iteration 246500, lr = 0.001
I0217 14:22:31.186616  8728 solver.cpp:228] Iteration 246600, loss = 0.00223279
I0217 14:22:31.186616  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:22:31.186616  8728 solver.cpp:244]     Train net output #1: loss = 0.00223279 (* 1 = 0.00223279 loss)
I0217 14:22:31.186616  8728 sgd_solver.cpp:106] Iteration 246600, lr = 0.001
I0217 14:22:48.888422  8728 solver.cpp:228] Iteration 246700, loss = 0.00641228
I0217 14:22:48.888422  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:22:48.888422  8728 solver.cpp:244]     Train net output #1: loss = 0.00641228 (* 1 = 0.00641228 loss)
I0217 14:22:48.888422  8728 sgd_solver.cpp:106] Iteration 246700, lr = 0.001
I0217 14:23:06.633157  8728 solver.cpp:228] Iteration 246800, loss = 0.00244048
I0217 14:23:06.633157  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:23:06.633157  8728 solver.cpp:244]     Train net output #1: loss = 0.00244048 (* 1 = 0.00244048 loss)
I0217 14:23:06.633157  8728 sgd_solver.cpp:106] Iteration 246800, lr = 0.001
I0217 14:23:24.502459  8728 solver.cpp:228] Iteration 246900, loss = 0.00265019
I0217 14:23:24.502459  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:23:24.502459  8728 solver.cpp:244]     Train net output #1: loss = 0.00265019 (* 1 = 0.00265019 loss)
I0217 14:23:24.502459  8728 sgd_solver.cpp:106] Iteration 246900, lr = 0.001
I0217 14:23:42.354753  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_247000.caffemodel
I0217 14:23:42.495740  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_247000.solverstate
I0217 14:23:42.564239  8728 solver.cpp:337] Iteration 247000, Testing net (#0)
I0217 14:23:42.564239  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:23:48.691257  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9451
I0217 14:23:48.691257  8728 solver.cpp:404]     Test net output #1: loss = 0.188507 (* 1 = 0.188507 loss)
I0217 14:23:48.762747  8728 solver.cpp:228] Iteration 247000, loss = 0.0022526
I0217 14:23:48.762747  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:23:48.762747  8728 solver.cpp:244]     Train net output #1: loss = 0.0022526 (* 1 = 0.0022526 loss)
I0217 14:23:48.763252  8728 sgd_solver.cpp:106] Iteration 247000, lr = 0.001
I0217 14:24:06.704990  8728 solver.cpp:228] Iteration 247100, loss = 0.00418635
I0217 14:24:06.704990  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:24:06.704990  8728 solver.cpp:244]     Train net output #1: loss = 0.00418636 (* 1 = 0.00418636 loss)
I0217 14:24:06.704990  8728 sgd_solver.cpp:106] Iteration 247100, lr = 0.001
I0217 14:24:24.631765  8728 solver.cpp:228] Iteration 247200, loss = 0.00248549
I0217 14:24:24.631765  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:24:24.631765  8728 solver.cpp:244]     Train net output #1: loss = 0.00248549 (* 1 = 0.00248549 loss)
I0217 14:24:24.631765  8728 sgd_solver.cpp:106] Iteration 247200, lr = 0.001
I0217 14:24:42.603721  8728 solver.cpp:228] Iteration 247300, loss = 0.00142461
I0217 14:24:42.604202  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:24:42.604202  8728 solver.cpp:244]     Train net output #1: loss = 0.00142461 (* 1 = 0.00142461 loss)
I0217 14:24:42.604202  8728 sgd_solver.cpp:106] Iteration 247300, lr = 0.001
I0217 14:25:00.535383  8728 solver.cpp:228] Iteration 247400, loss = 0.00297089
I0217 14:25:00.535383  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:25:00.535383  8728 solver.cpp:244]     Train net output #1: loss = 0.00297089 (* 1 = 0.00297089 loss)
I0217 14:25:00.535383  8728 sgd_solver.cpp:106] Iteration 247400, lr = 0.001
I0217 14:25:18.479221  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_247500.caffemodel
I0217 14:25:18.622704  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_247500.solverstate
I0217 14:25:18.692203  8728 solver.cpp:337] Iteration 247500, Testing net (#0)
I0217 14:25:18.692203  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:25:24.803724  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9446
I0217 14:25:24.803724  8728 solver.cpp:404]     Test net output #1: loss = 0.191169 (* 1 = 0.191169 loss)
I0217 14:25:24.875731  8728 solver.cpp:228] Iteration 247500, loss = 0.00284524
I0217 14:25:24.875731  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:25:24.875731  8728 solver.cpp:244]     Train net output #1: loss = 0.00284524 (* 1 = 0.00284524 loss)
I0217 14:25:24.875731  8728 sgd_solver.cpp:106] Iteration 247500, lr = 0.001
I0217 14:25:42.788540  8728 solver.cpp:228] Iteration 247600, loss = 0.00310124
I0217 14:25:42.788540  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:25:42.788540  8728 solver.cpp:244]     Train net output #1: loss = 0.00310125 (* 1 = 0.00310125 loss)
I0217 14:25:42.789016  8728 sgd_solver.cpp:106] Iteration 247600, lr = 0.001
I0217 14:26:00.737921  8728 solver.cpp:228] Iteration 247700, loss = 0.000734352
I0217 14:26:00.738407  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:26:00.738407  8728 solver.cpp:244]     Train net output #1: loss = 0.000734358 (* 1 = 0.000734358 loss)
I0217 14:26:00.738407  8728 sgd_solver.cpp:106] Iteration 247700, lr = 0.001
I0217 14:26:18.710489  8728 solver.cpp:228] Iteration 247800, loss = 0.0024153
I0217 14:26:18.710489  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:26:18.710489  8728 solver.cpp:244]     Train net output #1: loss = 0.0024153 (* 1 = 0.0024153 loss)
I0217 14:26:18.710489  8728 sgd_solver.cpp:106] Iteration 247800, lr = 0.001
I0217 14:26:36.693908  8728 solver.cpp:228] Iteration 247900, loss = 0.00860296
I0217 14:26:36.693908  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:26:36.693908  8728 solver.cpp:244]     Train net output #1: loss = 0.00860296 (* 1 = 0.00860296 loss)
I0217 14:26:36.693908  8728 sgd_solver.cpp:106] Iteration 247900, lr = 0.001
I0217 14:26:54.548684  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_248000.caffemodel
I0217 14:26:54.692673  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_248000.solverstate
I0217 14:26:54.768677  8728 solver.cpp:337] Iteration 248000, Testing net (#0)
I0217 14:26:54.768677  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:27:00.881525  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9431
I0217 14:27:00.881525  8728 solver.cpp:404]     Test net output #1: loss = 0.192472 (* 1 = 0.192472 loss)
I0217 14:27:00.952529  8728 solver.cpp:228] Iteration 248000, loss = 0.0252813
I0217 14:27:00.952529  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.98
I0217 14:27:00.953027  8728 solver.cpp:244]     Train net output #1: loss = 0.0252813 (* 1 = 0.0252813 loss)
I0217 14:27:00.953027  8728 sgd_solver.cpp:106] Iteration 248000, lr = 0.001
I0217 14:27:18.892700  8728 solver.cpp:228] Iteration 248100, loss = 0.00152603
I0217 14:27:18.892700  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:27:18.892700  8728 solver.cpp:244]     Train net output #1: loss = 0.00152603 (* 1 = 0.00152603 loss)
I0217 14:27:18.892700  8728 sgd_solver.cpp:106] Iteration 248100, lr = 0.001
I0217 14:27:36.821882  8728 solver.cpp:228] Iteration 248200, loss = 0.00149395
I0217 14:27:36.822373  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:27:36.822373  8728 solver.cpp:244]     Train net output #1: loss = 0.00149395 (* 1 = 0.00149395 loss)
I0217 14:27:36.822373  8728 sgd_solver.cpp:106] Iteration 248200, lr = 0.001
I0217 14:27:54.745628  8728 solver.cpp:228] Iteration 248300, loss = 0.00467065
I0217 14:27:54.745628  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:27:54.745628  8728 solver.cpp:244]     Train net output #1: loss = 0.00467065 (* 1 = 0.00467065 loss)
I0217 14:27:54.745628  8728 sgd_solver.cpp:106] Iteration 248300, lr = 0.001
I0217 14:28:12.630831  8728 solver.cpp:228] Iteration 248400, loss = 0.00203205
I0217 14:28:12.630831  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:28:12.630831  8728 solver.cpp:244]     Train net output #1: loss = 0.00203205 (* 1 = 0.00203205 loss)
I0217 14:28:12.630831  8728 sgd_solver.cpp:106] Iteration 248400, lr = 0.001
I0217 14:28:30.262011  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_248500.caffemodel
I0217 14:28:30.402046  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_248500.solverstate
I0217 14:28:30.469563  8728 solver.cpp:337] Iteration 248500, Testing net (#0)
I0217 14:28:30.469563  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:28:36.507263  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944001
I0217 14:28:36.507263  8728 solver.cpp:404]     Test net output #1: loss = 0.189344 (* 1 = 0.189344 loss)
I0217 14:28:36.579321  8728 solver.cpp:228] Iteration 248500, loss = 0.00587959
I0217 14:28:36.579321  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:28:36.579321  8728 solver.cpp:244]     Train net output #1: loss = 0.00587959 (* 1 = 0.00587959 loss)
I0217 14:28:36.579321  8728 sgd_solver.cpp:106] Iteration 248500, lr = 0.001
I0217 14:28:54.342497  8728 solver.cpp:228] Iteration 248600, loss = 0.00217227
I0217 14:28:54.342497  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:28:54.342497  8728 solver.cpp:244]     Train net output #1: loss = 0.00217227 (* 1 = 0.00217227 loss)
I0217 14:28:54.342497  8728 sgd_solver.cpp:106] Iteration 248600, lr = 0.001
I0217 14:29:12.268399  8728 solver.cpp:228] Iteration 248700, loss = 0.000953525
I0217 14:29:12.268399  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:29:12.268399  8728 solver.cpp:244]     Train net output #1: loss = 0.000953525 (* 1 = 0.000953525 loss)
I0217 14:29:12.268399  8728 sgd_solver.cpp:106] Iteration 248700, lr = 0.001
I0217 14:29:30.190274  8728 solver.cpp:228] Iteration 248800, loss = 0.00445311
I0217 14:29:30.190274  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:29:30.190274  8728 solver.cpp:244]     Train net output #1: loss = 0.00445311 (* 1 = 0.00445311 loss)
I0217 14:29:30.190274  8728 sgd_solver.cpp:106] Iteration 248800, lr = 0.001
I0217 14:29:48.123019  8728 solver.cpp:228] Iteration 248900, loss = 0.00196443
I0217 14:29:48.123019  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:29:48.123019  8728 solver.cpp:244]     Train net output #1: loss = 0.00196444 (* 1 = 0.00196444 loss)
I0217 14:29:48.123019  8728 sgd_solver.cpp:106] Iteration 248900, lr = 0.001
I0217 14:30:06.003581  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_249000.caffemodel
I0217 14:30:06.150065  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_249000.solverstate
I0217 14:30:06.217067  8728 solver.cpp:337] Iteration 249000, Testing net (#0)
I0217 14:30:06.217067  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:30:12.333588  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944401
I0217 14:30:12.333588  8728 solver.cpp:404]     Test net output #1: loss = 0.19183 (* 1 = 0.19183 loss)
I0217 14:30:12.405588  8728 solver.cpp:228] Iteration 249000, loss = 0.00237981
I0217 14:30:12.405588  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:30:12.405588  8728 solver.cpp:244]     Train net output #1: loss = 0.00237982 (* 1 = 0.00237982 loss)
I0217 14:30:12.405588  8728 sgd_solver.cpp:106] Iteration 249000, lr = 0.001
I0217 14:30:30.298992  8728 solver.cpp:228] Iteration 249100, loss = 0.00296447
I0217 14:30:30.299464  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:30:30.299464  8728 solver.cpp:244]     Train net output #1: loss = 0.00296447 (* 1 = 0.00296447 loss)
I0217 14:30:30.299464  8728 sgd_solver.cpp:106] Iteration 249100, lr = 0.001
I0217 14:30:48.224865  8728 solver.cpp:228] Iteration 249200, loss = 0.00112843
I0217 14:30:48.224865  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:30:48.224865  8728 solver.cpp:244]     Train net output #1: loss = 0.00112844 (* 1 = 0.00112844 loss)
I0217 14:30:48.224865  8728 sgd_solver.cpp:106] Iteration 249200, lr = 0.001
I0217 14:31:06.150149  8728 solver.cpp:228] Iteration 249300, loss = 0.00234108
I0217 14:31:06.150149  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:31:06.150149  8728 solver.cpp:244]     Train net output #1: loss = 0.00234109 (* 1 = 0.00234109 loss)
I0217 14:31:06.150149  8728 sgd_solver.cpp:106] Iteration 249300, lr = 0.001
I0217 14:31:24.072645  8728 solver.cpp:228] Iteration 249400, loss = 0.00220646
I0217 14:31:24.072645  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:31:24.072645  8728 solver.cpp:244]     Train net output #1: loss = 0.00220647 (* 1 = 0.00220647 loss)
I0217 14:31:24.072645  8728 sgd_solver.cpp:106] Iteration 249400, lr = 0.001
I0217 14:31:41.928587  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_249500.caffemodel
I0217 14:31:42.072458  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_249500.solverstate
I0217 14:31:42.141439  8728 solver.cpp:337] Iteration 249500, Testing net (#0)
I0217 14:31:42.141940  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:31:48.233832  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9431
I0217 14:31:48.233832  8728 solver.cpp:404]     Test net output #1: loss = 0.191618 (* 1 = 0.191618 loss)
I0217 14:31:48.305876  8728 solver.cpp:228] Iteration 249500, loss = 0.00384146
I0217 14:31:48.305876  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:31:48.305876  8728 solver.cpp:244]     Train net output #1: loss = 0.00384147 (* 1 = 0.00384147 loss)
I0217 14:31:48.305876  8728 sgd_solver.cpp:106] Iteration 249500, lr = 0.001
I0217 14:32:06.239600  8728 solver.cpp:228] Iteration 249600, loss = 0.00275939
I0217 14:32:06.240099  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:32:06.240099  8728 solver.cpp:244]     Train net output #1: loss = 0.0027594 (* 1 = 0.0027594 loss)
I0217 14:32:06.240099  8728 sgd_solver.cpp:106] Iteration 249600, lr = 0.001
I0217 14:32:24.156766  8728 solver.cpp:228] Iteration 249700, loss = 0.00533684
I0217 14:32:24.156766  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:32:24.156766  8728 solver.cpp:244]     Train net output #1: loss = 0.00533685 (* 1 = 0.00533685 loss)
I0217 14:32:24.156766  8728 sgd_solver.cpp:106] Iteration 249700, lr = 0.001
I0217 14:32:42.082803  8728 solver.cpp:228] Iteration 249800, loss = 0.00218117
I0217 14:32:42.082803  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:32:42.082803  8728 solver.cpp:244]     Train net output #1: loss = 0.00218118 (* 1 = 0.00218118 loss)
I0217 14:32:42.082803  8728 sgd_solver.cpp:106] Iteration 249800, lr = 0.001
I0217 14:32:59.837990  8728 solver.cpp:228] Iteration 249900, loss = 0.0106624
I0217 14:32:59.837990  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:32:59.837990  8728 solver.cpp:244]     Train net output #1: loss = 0.0106624 (* 1 = 0.0106624 loss)
I0217 14:32:59.837990  8728 sgd_solver.cpp:106] Iteration 249900, lr = 0.001
I0217 14:33:17.472399  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_250000.caffemodel
I0217 14:33:17.612884  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_250000.solverstate
I0217 14:33:17.735003  8728 solver.cpp:337] Iteration 250000, Testing net (#0)
I0217 14:33:17.735003  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:33:23.770869  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9455
I0217 14:33:23.770869  8728 solver.cpp:404]     Test net output #1: loss = 0.188772 (* 1 = 0.188772 loss)
I0217 14:33:23.841931  8728 solver.cpp:228] Iteration 250000, loss = 0.00710728
I0217 14:33:23.841931  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:33:23.841931  8728 solver.cpp:244]     Train net output #1: loss = 0.00710729 (* 1 = 0.00710729 loss)
I0217 14:33:23.841931  8728 sgd_solver.cpp:106] Iteration 250000, lr = 0.001
I0217 14:33:41.544664  8728 solver.cpp:228] Iteration 250100, loss = 0.00850469
I0217 14:33:41.544664  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:33:41.544664  8728 solver.cpp:244]     Train net output #1: loss = 0.0085047 (* 1 = 0.0085047 loss)
I0217 14:33:41.544664  8728 sgd_solver.cpp:106] Iteration 250100, lr = 0.001
I0217 14:33:59.248409  8728 solver.cpp:228] Iteration 250200, loss = 0.00190999
I0217 14:33:59.248409  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:33:59.248409  8728 solver.cpp:244]     Train net output #1: loss = 0.00191 (* 1 = 0.00191 loss)
I0217 14:33:59.248409  8728 sgd_solver.cpp:106] Iteration 250200, lr = 0.001
I0217 14:34:16.960757  8728 solver.cpp:228] Iteration 250300, loss = 0.00282445
I0217 14:34:16.960757  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:34:16.960757  8728 solver.cpp:244]     Train net output #1: loss = 0.00282446 (* 1 = 0.00282446 loss)
I0217 14:34:16.960757  8728 sgd_solver.cpp:106] Iteration 250300, lr = 0.001
I0217 14:34:34.662657  8728 solver.cpp:228] Iteration 250400, loss = 0.00243903
I0217 14:34:34.662657  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:34:34.662657  8728 solver.cpp:244]     Train net output #1: loss = 0.00243904 (* 1 = 0.00243904 loss)
I0217 14:34:34.662657  8728 sgd_solver.cpp:106] Iteration 250400, lr = 0.001
I0217 14:34:52.283500  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_250500.caffemodel
I0217 14:34:52.424545  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_250500.solverstate
I0217 14:34:52.491030  8728 solver.cpp:337] Iteration 250500, Testing net (#0)
I0217 14:34:52.491030  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:34:58.529929  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9435
I0217 14:34:58.529929  8728 solver.cpp:404]     Test net output #1: loss = 0.1906 (* 1 = 0.1906 loss)
I0217 14:34:58.600965  8728 solver.cpp:228] Iteration 250500, loss = 0.00136417
I0217 14:34:58.600965  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:34:58.600965  8728 solver.cpp:244]     Train net output #1: loss = 0.00136417 (* 1 = 0.00136417 loss)
I0217 14:34:58.600965  8728 sgd_solver.cpp:106] Iteration 250500, lr = 0.001
I0217 14:35:16.297165  8728 solver.cpp:228] Iteration 250600, loss = 0.0036074
I0217 14:35:16.297165  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:35:16.297165  8728 solver.cpp:244]     Train net output #1: loss = 0.0036074 (* 1 = 0.0036074 loss)
I0217 14:35:16.297165  8728 sgd_solver.cpp:106] Iteration 250600, lr = 0.001
I0217 14:35:33.999565  8728 solver.cpp:228] Iteration 250700, loss = 0.00846473
I0217 14:35:33.999565  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:35:33.999565  8728 solver.cpp:244]     Train net output #1: loss = 0.00846473 (* 1 = 0.00846473 loss)
I0217 14:35:33.999565  8728 sgd_solver.cpp:106] Iteration 250700, lr = 0.001
I0217 14:35:51.699435  8728 solver.cpp:228] Iteration 250800, loss = 0.0016966
I0217 14:35:51.699435  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:35:51.699435  8728 solver.cpp:244]     Train net output #1: loss = 0.0016966 (* 1 = 0.0016966 loss)
I0217 14:35:51.699435  8728 sgd_solver.cpp:106] Iteration 250800, lr = 0.001
I0217 14:36:09.405299  8728 solver.cpp:228] Iteration 250900, loss = 0.000795332
I0217 14:36:09.405299  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:36:09.405299  8728 solver.cpp:244]     Train net output #1: loss = 0.000795336 (* 1 = 0.000795336 loss)
I0217 14:36:09.405299  8728 sgd_solver.cpp:106] Iteration 250900, lr = 0.001
I0217 14:36:27.034972  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_251000.caffemodel
I0217 14:36:27.179502  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_251000.solverstate
I0217 14:36:27.252552  8728 solver.cpp:337] Iteration 251000, Testing net (#0)
I0217 14:36:27.252552  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:36:33.262465  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9442
I0217 14:36:33.262465  8728 solver.cpp:404]     Test net output #1: loss = 0.189892 (* 1 = 0.189892 loss)
I0217 14:36:33.333509  8728 solver.cpp:228] Iteration 251000, loss = 0.00129434
I0217 14:36:33.333509  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:36:33.333509  8728 solver.cpp:244]     Train net output #1: loss = 0.00129435 (* 1 = 0.00129435 loss)
I0217 14:36:33.333509  8728 sgd_solver.cpp:106] Iteration 251000, lr = 0.001
I0217 14:36:51.033591  8728 solver.cpp:228] Iteration 251100, loss = 0.00497287
I0217 14:36:51.034091  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:36:51.034091  8728 solver.cpp:244]     Train net output #1: loss = 0.00497288 (* 1 = 0.00497288 loss)
I0217 14:36:51.034091  8728 sgd_solver.cpp:106] Iteration 251100, lr = 0.001
I0217 14:37:08.766508  8728 solver.cpp:228] Iteration 251200, loss = 0.00451218
I0217 14:37:08.766991  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:37:08.766991  8728 solver.cpp:244]     Train net output #1: loss = 0.00451218 (* 1 = 0.00451218 loss)
I0217 14:37:08.766991  8728 sgd_solver.cpp:106] Iteration 251200, lr = 0.001
I0217 14:37:26.467300  8728 solver.cpp:228] Iteration 251300, loss = 0.00643068
I0217 14:37:26.467300  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:37:26.467300  8728 solver.cpp:244]     Train net output #1: loss = 0.00643068 (* 1 = 0.00643068 loss)
I0217 14:37:26.467300  8728 sgd_solver.cpp:106] Iteration 251300, lr = 0.001
I0217 14:37:44.172600  8728 solver.cpp:228] Iteration 251400, loss = 0.00128876
I0217 14:37:44.172600  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:37:44.172600  8728 solver.cpp:244]     Train net output #1: loss = 0.00128877 (* 1 = 0.00128877 loss)
I0217 14:37:44.172600  8728 sgd_solver.cpp:106] Iteration 251400, lr = 0.001
I0217 14:38:01.799629  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_251500.caffemodel
I0217 14:38:01.936143  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_251500.solverstate
I0217 14:38:02.002163  8728 solver.cpp:337] Iteration 251500, Testing net (#0)
I0217 14:38:02.003147  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:38:08.039203  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9439
I0217 14:38:08.039203  8728 solver.cpp:404]     Test net output #1: loss = 0.193459 (* 1 = 0.193459 loss)
I0217 14:38:08.111232  8728 solver.cpp:228] Iteration 251500, loss = 0.00255877
I0217 14:38:08.111232  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:38:08.111232  8728 solver.cpp:244]     Train net output #1: loss = 0.00255878 (* 1 = 0.00255878 loss)
I0217 14:38:08.111232  8728 sgd_solver.cpp:106] Iteration 251500, lr = 0.001
I0217 14:38:25.816845  8728 solver.cpp:228] Iteration 251600, loss = 0.00261255
I0217 14:38:25.817344  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:38:25.817344  8728 solver.cpp:244]     Train net output #1: loss = 0.00261255 (* 1 = 0.00261255 loss)
I0217 14:38:25.817344  8728 sgd_solver.cpp:106] Iteration 251600, lr = 0.001
I0217 14:38:43.517798  8728 solver.cpp:228] Iteration 251700, loss = 0.007095
I0217 14:38:43.518286  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:38:43.518286  8728 solver.cpp:244]     Train net output #1: loss = 0.00709501 (* 1 = 0.00709501 loss)
I0217 14:38:43.518286  8728 sgd_solver.cpp:106] Iteration 251700, lr = 0.001
I0217 14:39:01.231142  8728 solver.cpp:228] Iteration 251800, loss = 0.00162104
I0217 14:39:01.231142  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:39:01.231142  8728 solver.cpp:244]     Train net output #1: loss = 0.00162104 (* 1 = 0.00162104 loss)
I0217 14:39:01.231142  8728 sgd_solver.cpp:106] Iteration 251800, lr = 0.001
I0217 14:39:18.934064  8728 solver.cpp:228] Iteration 251900, loss = 0.00553963
I0217 14:39:18.934064  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:39:18.934064  8728 solver.cpp:244]     Train net output #1: loss = 0.00553964 (* 1 = 0.00553964 loss)
I0217 14:39:18.934064  8728 sgd_solver.cpp:106] Iteration 251900, lr = 0.001
I0217 14:39:36.560681  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_252000.caffemodel
I0217 14:39:36.702697  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_252000.solverstate
I0217 14:39:36.769680  8728 solver.cpp:337] Iteration 252000, Testing net (#0)
I0217 14:39:36.769680  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:39:42.807679  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9435
I0217 14:39:42.807679  8728 solver.cpp:404]     Test net output #1: loss = 0.192826 (* 1 = 0.192826 loss)
I0217 14:39:42.878706  8728 solver.cpp:228] Iteration 252000, loss = 0.00582621
I0217 14:39:42.878706  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:39:42.879210  8728 solver.cpp:244]     Train net output #1: loss = 0.00582621 (* 1 = 0.00582621 loss)
I0217 14:39:42.879210  8728 sgd_solver.cpp:106] Iteration 252000, lr = 0.001
I0217 14:40:00.587280  8728 solver.cpp:228] Iteration 252100, loss = 0.00792219
I0217 14:40:00.587280  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:40:00.587280  8728 solver.cpp:244]     Train net output #1: loss = 0.00792219 (* 1 = 0.00792219 loss)
I0217 14:40:00.587280  8728 sgd_solver.cpp:106] Iteration 252100, lr = 0.001
I0217 14:40:18.312193  8728 solver.cpp:228] Iteration 252200, loss = 0.00107021
I0217 14:40:18.312193  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:40:18.312193  8728 solver.cpp:244]     Train net output #1: loss = 0.00107021 (* 1 = 0.00107021 loss)
I0217 14:40:18.312193  8728 sgd_solver.cpp:106] Iteration 252200, lr = 0.001
I0217 14:40:36.024014  8728 solver.cpp:228] Iteration 252300, loss = 0.00125092
I0217 14:40:36.024014  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:40:36.024014  8728 solver.cpp:244]     Train net output #1: loss = 0.00125092 (* 1 = 0.00125092 loss)
I0217 14:40:36.024014  8728 sgd_solver.cpp:106] Iteration 252300, lr = 0.001
I0217 14:40:53.727944  8728 solver.cpp:228] Iteration 252400, loss = 0.00143474
I0217 14:40:53.727944  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:40:53.727944  8728 solver.cpp:244]     Train net output #1: loss = 0.00143474 (* 1 = 0.00143474 loss)
I0217 14:40:53.727944  8728 sgd_solver.cpp:106] Iteration 252400, lr = 0.001
I0217 14:41:11.354192  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_252500.caffemodel
I0217 14:41:11.493211  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_252500.solverstate
I0217 14:41:11.561213  8728 solver.cpp:337] Iteration 252500, Testing net (#0)
I0217 14:41:11.561213  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:41:17.605192  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9442
I0217 14:41:17.605192  8728 solver.cpp:404]     Test net output #1: loss = 0.190429 (* 1 = 0.190429 loss)
I0217 14:41:17.676213  8728 solver.cpp:228] Iteration 252500, loss = 0.00261981
I0217 14:41:17.676213  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:41:17.676687  8728 solver.cpp:244]     Train net output #1: loss = 0.00261982 (* 1 = 0.00261982 loss)
I0217 14:41:17.676687  8728 sgd_solver.cpp:106] Iteration 252500, lr = 0.001
I0217 14:41:35.387895  8728 solver.cpp:228] Iteration 252600, loss = 0.0111942
I0217 14:41:35.387895  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:41:35.387895  8728 solver.cpp:244]     Train net output #1: loss = 0.0111942 (* 1 = 0.0111942 loss)
I0217 14:41:35.387895  8728 sgd_solver.cpp:106] Iteration 252600, lr = 0.001
I0217 14:41:53.090486  8728 solver.cpp:228] Iteration 252700, loss = 0.00500562
I0217 14:41:53.090486  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:41:53.090486  8728 solver.cpp:244]     Train net output #1: loss = 0.00500562 (* 1 = 0.00500562 loss)
I0217 14:41:53.090486  8728 sgd_solver.cpp:106] Iteration 252700, lr = 0.001
I0217 14:42:10.794752  8728 solver.cpp:228] Iteration 252800, loss = 0.00265607
I0217 14:42:10.794752  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:42:10.794752  8728 solver.cpp:244]     Train net output #1: loss = 0.00265608 (* 1 = 0.00265608 loss)
I0217 14:42:10.794752  8728 sgd_solver.cpp:106] Iteration 252800, lr = 0.001
I0217 14:42:28.503545  8728 solver.cpp:228] Iteration 252900, loss = 0.00387447
I0217 14:42:28.503545  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:42:28.503545  8728 solver.cpp:244]     Train net output #1: loss = 0.00387447 (* 1 = 0.00387447 loss)
I0217 14:42:28.503545  8728 sgd_solver.cpp:106] Iteration 252900, lr = 0.001
I0217 14:42:46.169625  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_253000.caffemodel
I0217 14:42:46.307158  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_253000.solverstate
I0217 14:42:46.374647  8728 solver.cpp:337] Iteration 253000, Testing net (#0)
I0217 14:42:46.375149  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:42:52.635730  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9428
I0217 14:42:52.635730  8728 solver.cpp:404]     Test net output #1: loss = 0.19279 (* 1 = 0.19279 loss)
I0217 14:42:52.706792  8728 solver.cpp:228] Iteration 253000, loss = 0.00195784
I0217 14:42:52.706792  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:42:52.706792  8728 solver.cpp:244]     Train net output #1: loss = 0.00195785 (* 1 = 0.00195785 loss)
I0217 14:42:52.706792  8728 sgd_solver.cpp:46] MultiStep Status: Iteration 253000, step = 3
I0217 14:42:52.706792  8728 sgd_solver.cpp:106] Iteration 253000, lr = 0.0001
I0217 14:43:10.518378  8728 solver.cpp:228] Iteration 253100, loss = 0.00353305
I0217 14:43:10.518378  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:43:10.518378  8728 solver.cpp:244]     Train net output #1: loss = 0.00353305 (* 1 = 0.00353305 loss)
I0217 14:43:10.518378  8728 sgd_solver.cpp:106] Iteration 253100, lr = 0.0001
I0217 14:43:28.300207  8728 solver.cpp:228] Iteration 253200, loss = 0.00141416
I0217 14:43:28.300207  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:43:28.300207  8728 solver.cpp:244]     Train net output #1: loss = 0.00141416 (* 1 = 0.00141416 loss)
I0217 14:43:28.300207  8728 sgd_solver.cpp:106] Iteration 253200, lr = 0.0001
I0217 14:43:46.021312  8728 solver.cpp:228] Iteration 253300, loss = 0.00195453
I0217 14:43:46.021312  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:43:46.021312  8728 solver.cpp:244]     Train net output #1: loss = 0.00195453 (* 1 = 0.00195453 loss)
I0217 14:43:46.021312  8728 sgd_solver.cpp:106] Iteration 253300, lr = 0.0001
I0217 14:44:03.727502  8728 solver.cpp:228] Iteration 253400, loss = 0.00147053
I0217 14:44:03.727502  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:44:03.727502  8728 solver.cpp:244]     Train net output #1: loss = 0.00147053 (* 1 = 0.00147053 loss)
I0217 14:44:03.727502  8728 sgd_solver.cpp:106] Iteration 253400, lr = 0.0001
I0217 14:44:21.357182  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_253500.caffemodel
I0217 14:44:21.494194  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_253500.solverstate
I0217 14:44:21.605702  8728 solver.cpp:337] Iteration 253500, Testing net (#0)
I0217 14:44:21.605702  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:44:27.653264  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944
I0217 14:44:27.653264  8728 solver.cpp:404]     Test net output #1: loss = 0.190722 (* 1 = 0.190722 loss)
I0217 14:44:27.724258  8728 solver.cpp:228] Iteration 253500, loss = 0.00521483
I0217 14:44:27.724258  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:44:27.724258  8728 solver.cpp:244]     Train net output #1: loss = 0.00521483 (* 1 = 0.00521483 loss)
I0217 14:44:27.724258  8728 sgd_solver.cpp:106] Iteration 253500, lr = 0.0001
I0217 14:44:45.431061  8728 solver.cpp:228] Iteration 253600, loss = 0.00270495
I0217 14:44:45.431061  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:44:45.431061  8728 solver.cpp:244]     Train net output #1: loss = 0.00270494 (* 1 = 0.00270494 loss)
I0217 14:44:45.431061  8728 sgd_solver.cpp:106] Iteration 253600, lr = 0.0001
I0217 14:45:03.126904  8728 solver.cpp:228] Iteration 253700, loss = 0.0056717
I0217 14:45:03.126904  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:45:03.126904  8728 solver.cpp:244]     Train net output #1: loss = 0.0056717 (* 1 = 0.0056717 loss)
I0217 14:45:03.126904  8728 sgd_solver.cpp:106] Iteration 253700, lr = 0.0001
I0217 14:45:20.825587  8728 solver.cpp:228] Iteration 253800, loss = 0.0104618
I0217 14:45:20.826073  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 14:45:20.826073  8728 solver.cpp:244]     Train net output #1: loss = 0.0104618 (* 1 = 0.0104618 loss)
I0217 14:45:20.826073  8728 sgd_solver.cpp:106] Iteration 253800, lr = 0.0001
I0217 14:45:38.531144  8728 solver.cpp:228] Iteration 253900, loss = 0.00472506
I0217 14:45:38.531631  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:45:38.531631  8728 solver.cpp:244]     Train net output #1: loss = 0.00472506 (* 1 = 0.00472506 loss)
I0217 14:45:38.531631  8728 sgd_solver.cpp:106] Iteration 253900, lr = 0.0001
I0217 14:45:56.166255  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_254000.caffemodel
I0217 14:45:56.305822  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_254000.solverstate
I0217 14:45:56.370331  8728 solver.cpp:337] Iteration 254000, Testing net (#0)
I0217 14:45:56.370331  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:46:02.385344  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9439
I0217 14:46:02.385344  8728 solver.cpp:404]     Test net output #1: loss = 0.188966 (* 1 = 0.188966 loss)
I0217 14:46:02.456907  8728 solver.cpp:228] Iteration 254000, loss = 0.00266473
I0217 14:46:02.456907  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:46:02.456907  8728 solver.cpp:244]     Train net output #1: loss = 0.00266473 (* 1 = 0.00266473 loss)
I0217 14:46:02.456907  8728 sgd_solver.cpp:106] Iteration 254000, lr = 0.0001
I0217 14:46:20.097020  8728 solver.cpp:228] Iteration 254100, loss = 0.00154744
I0217 14:46:20.097020  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:46:20.097020  8728 solver.cpp:244]     Train net output #1: loss = 0.00154744 (* 1 = 0.00154744 loss)
I0217 14:46:20.097020  8728 sgd_solver.cpp:106] Iteration 254100, lr = 0.0001
I0217 14:46:37.784867  8728 solver.cpp:228] Iteration 254200, loss = 0.00591231
I0217 14:46:37.784867  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:46:37.784867  8728 solver.cpp:244]     Train net output #1: loss = 0.00591231 (* 1 = 0.00591231 loss)
I0217 14:46:37.784867  8728 sgd_solver.cpp:106] Iteration 254200, lr = 0.0001
I0217 14:46:55.495041  8728 solver.cpp:228] Iteration 254300, loss = 0.00103352
I0217 14:46:55.495041  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:46:55.495041  8728 solver.cpp:244]     Train net output #1: loss = 0.00103352 (* 1 = 0.00103352 loss)
I0217 14:46:55.495041  8728 sgd_solver.cpp:106] Iteration 254300, lr = 0.0001
I0217 14:47:13.246285  8728 solver.cpp:228] Iteration 254400, loss = 0.00198495
I0217 14:47:13.246285  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:47:13.246285  8728 solver.cpp:244]     Train net output #1: loss = 0.00198495 (* 1 = 0.00198495 loss)
I0217 14:47:13.246285  8728 sgd_solver.cpp:106] Iteration 254400, lr = 0.0001
I0217 14:47:30.887964  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_254500.caffemodel
I0217 14:47:31.029492  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_254500.solverstate
I0217 14:47:31.118036  8728 solver.cpp:337] Iteration 254500, Testing net (#0)
I0217 14:47:31.118036  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:47:37.167315  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9444
I0217 14:47:37.167315  8728 solver.cpp:404]     Test net output #1: loss = 0.188334 (* 1 = 0.188334 loss)
I0217 14:47:37.237323  8728 solver.cpp:228] Iteration 254500, loss = 0.00533114
I0217 14:47:37.237805  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:47:37.237805  8728 solver.cpp:244]     Train net output #1: loss = 0.00533114 (* 1 = 0.00533114 loss)
I0217 14:47:37.237805  8728 sgd_solver.cpp:106] Iteration 254500, lr = 0.0001
I0217 14:47:54.942014  8728 solver.cpp:228] Iteration 254600, loss = 0.00111096
I0217 14:47:54.942014  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:47:54.942014  8728 solver.cpp:244]     Train net output #1: loss = 0.00111096 (* 1 = 0.00111096 loss)
I0217 14:47:54.942014  8728 sgd_solver.cpp:106] Iteration 254600, lr = 0.0001
I0217 14:48:12.651670  8728 solver.cpp:228] Iteration 254700, loss = 0.00347285
I0217 14:48:12.651670  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:48:12.651670  8728 solver.cpp:244]     Train net output #1: loss = 0.00347285 (* 1 = 0.00347285 loss)
I0217 14:48:12.651670  8728 sgd_solver.cpp:106] Iteration 254700, lr = 0.0001
I0217 14:48:30.364578  8728 solver.cpp:228] Iteration 254800, loss = 0.00173224
I0217 14:48:30.364578  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:48:30.364578  8728 solver.cpp:244]     Train net output #1: loss = 0.00173224 (* 1 = 0.00173224 loss)
I0217 14:48:30.364578  8728 sgd_solver.cpp:106] Iteration 254800, lr = 0.0001
I0217 14:48:48.065754  8728 solver.cpp:228] Iteration 254900, loss = 0.000678528
I0217 14:48:48.065754  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:48:48.065754  8728 solver.cpp:244]     Train net output #1: loss = 0.000678529 (* 1 = 0.000678529 loss)
I0217 14:48:48.065754  8728 sgd_solver.cpp:106] Iteration 254900, lr = 0.0001
I0217 14:49:05.711127  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_255000.caffemodel
I0217 14:49:05.852161  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_255000.solverstate
I0217 14:49:05.915163  8728 solver.cpp:337] Iteration 255000, Testing net (#0)
I0217 14:49:05.915163  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:49:11.957561  8728 solver.cpp:404]     Test net output #0: accuracy = 0.944
I0217 14:49:11.957561  8728 solver.cpp:404]     Test net output #1: loss = 0.188718 (* 1 = 0.188718 loss)
I0217 14:49:12.028602  8728 solver.cpp:228] Iteration 255000, loss = 0.0034711
I0217 14:49:12.028602  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:49:12.028602  8728 solver.cpp:244]     Train net output #1: loss = 0.0034711 (* 1 = 0.0034711 loss)
I0217 14:49:12.028602  8728 sgd_solver.cpp:106] Iteration 255000, lr = 0.0001
I0217 14:49:29.735649  8728 solver.cpp:228] Iteration 255100, loss = 0.00293788
I0217 14:49:29.735649  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:49:29.735649  8728 solver.cpp:244]     Train net output #1: loss = 0.00293788 (* 1 = 0.00293788 loss)
I0217 14:49:29.735649  8728 sgd_solver.cpp:106] Iteration 255100, lr = 0.0001
I0217 14:49:47.436987  8728 solver.cpp:228] Iteration 255200, loss = 0.00292036
I0217 14:49:47.436987  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:49:47.436987  8728 solver.cpp:244]     Train net output #1: loss = 0.00292035 (* 1 = 0.00292035 loss)
I0217 14:49:47.436987  8728 sgd_solver.cpp:106] Iteration 255200, lr = 0.0001
I0217 14:50:05.175989  8728 solver.cpp:228] Iteration 255300, loss = 0.00109435
I0217 14:50:05.175989  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:50:05.175989  8728 solver.cpp:244]     Train net output #1: loss = 0.00109435 (* 1 = 0.00109435 loss)
I0217 14:50:05.175989  8728 sgd_solver.cpp:106] Iteration 255300, lr = 0.0001
I0217 14:50:22.874546  8728 solver.cpp:228] Iteration 255400, loss = 0.00139075
I0217 14:50:22.874546  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:50:22.874546  8728 solver.cpp:244]     Train net output #1: loss = 0.00139075 (* 1 = 0.00139075 loss)
I0217 14:50:22.874546  8728 sgd_solver.cpp:106] Iteration 255400, lr = 0.0001
I0217 14:50:40.504901  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_255500.caffemodel
I0217 14:50:40.646401  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_255500.solverstate
I0217 14:50:40.710412  8728 solver.cpp:337] Iteration 255500, Testing net (#0)
I0217 14:50:40.710412  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:50:46.749639  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 14:50:46.749639  8728 solver.cpp:404]     Test net output #1: loss = 0.188293 (* 1 = 0.188293 loss)
I0217 14:50:46.821171  8728 solver.cpp:228] Iteration 255500, loss = 0.00111437
I0217 14:50:46.821171  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:50:46.821171  8728 solver.cpp:244]     Train net output #1: loss = 0.00111438 (* 1 = 0.00111438 loss)
I0217 14:50:46.821658  8728 sgd_solver.cpp:106] Iteration 255500, lr = 0.0001
I0217 14:51:04.520552  8728 solver.cpp:228] Iteration 255600, loss = 0.00639681
I0217 14:51:04.520552  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:51:04.520552  8728 solver.cpp:244]     Train net output #1: loss = 0.00639682 (* 1 = 0.00639682 loss)
I0217 14:51:04.520552  8728 sgd_solver.cpp:106] Iteration 255600, lr = 0.0001
I0217 14:51:22.222395  8728 solver.cpp:228] Iteration 255700, loss = 0.00594454
I0217 14:51:22.222395  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:51:22.222395  8728 solver.cpp:244]     Train net output #1: loss = 0.00594455 (* 1 = 0.00594455 loss)
I0217 14:51:22.222395  8728 sgd_solver.cpp:106] Iteration 255700, lr = 0.0001
I0217 14:51:39.928015  8728 solver.cpp:228] Iteration 255800, loss = 0.00104471
I0217 14:51:39.928015  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:51:39.928015  8728 solver.cpp:244]     Train net output #1: loss = 0.00104471 (* 1 = 0.00104471 loss)
I0217 14:51:39.928015  8728 sgd_solver.cpp:106] Iteration 255800, lr = 0.0001
I0217 14:51:57.628195  8728 solver.cpp:228] Iteration 255900, loss = 0.00185396
I0217 14:51:57.628195  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:51:57.628195  8728 solver.cpp:244]     Train net output #1: loss = 0.00185396 (* 1 = 0.00185396 loss)
I0217 14:51:57.628195  8728 sgd_solver.cpp:106] Iteration 255900, lr = 0.0001
I0217 14:52:15.304128  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_256000.caffemodel
I0217 14:52:15.444134  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_256000.solverstate
I0217 14:52:15.508635  8728 solver.cpp:337] Iteration 256000, Testing net (#0)
I0217 14:52:15.509135  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:52:21.544140  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9445
I0217 14:52:21.544140  8728 solver.cpp:404]     Test net output #1: loss = 0.187714 (* 1 = 0.187714 loss)
I0217 14:52:21.614668  8728 solver.cpp:228] Iteration 256000, loss = 0.00680167
I0217 14:52:21.614668  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:52:21.614668  8728 solver.cpp:244]     Train net output #1: loss = 0.00680166 (* 1 = 0.00680166 loss)
I0217 14:52:21.614668  8728 sgd_solver.cpp:106] Iteration 256000, lr = 0.0001
I0217 14:52:39.326067  8728 solver.cpp:228] Iteration 256100, loss = 0.00556941
I0217 14:52:39.326067  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:52:39.326067  8728 solver.cpp:244]     Train net output #1: loss = 0.0055694 (* 1 = 0.0055694 loss)
I0217 14:52:39.326067  8728 sgd_solver.cpp:106] Iteration 256100, lr = 0.0001
I0217 14:52:57.035233  8728 solver.cpp:228] Iteration 256200, loss = 0.000964529
I0217 14:52:57.035233  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:52:57.035233  8728 solver.cpp:244]     Train net output #1: loss = 0.000964523 (* 1 = 0.000964523 loss)
I0217 14:52:57.035233  8728 sgd_solver.cpp:106] Iteration 256200, lr = 0.0001
I0217 14:53:14.749337  8728 solver.cpp:228] Iteration 256300, loss = 0.0014911
I0217 14:53:14.749836  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:53:14.749836  8728 solver.cpp:244]     Train net output #1: loss = 0.0014911 (* 1 = 0.0014911 loss)
I0217 14:53:14.749836  8728 sgd_solver.cpp:106] Iteration 256300, lr = 0.0001
I0217 14:53:32.508479  8728 solver.cpp:228] Iteration 256400, loss = 0.00811873
I0217 14:53:32.508479  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:53:32.508479  8728 solver.cpp:244]     Train net output #1: loss = 0.00811872 (* 1 = 0.00811872 loss)
I0217 14:53:32.508479  8728 sgd_solver.cpp:106] Iteration 256400, lr = 0.0001
I0217 14:53:50.090998  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_256500.caffemodel
I0217 14:53:50.232547  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_256500.solverstate
I0217 14:53:50.297032  8728 solver.cpp:337] Iteration 256500, Testing net (#0)
I0217 14:53:50.297032  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:53:56.325250  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9454
I0217 14:53:56.325250  8728 solver.cpp:404]     Test net output #1: loss = 0.1878 (* 1 = 0.1878 loss)
I0217 14:53:56.396303  8728 solver.cpp:228] Iteration 256500, loss = 0.00164121
I0217 14:53:56.396303  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:53:56.396303  8728 solver.cpp:244]     Train net output #1: loss = 0.00164121 (* 1 = 0.00164121 loss)
I0217 14:53:56.396303  8728 sgd_solver.cpp:106] Iteration 256500, lr = 0.0001
I0217 14:54:14.047188  8728 solver.cpp:228] Iteration 256600, loss = 0.00513038
I0217 14:54:14.047670  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:54:14.047670  8728 solver.cpp:244]     Train net output #1: loss = 0.00513037 (* 1 = 0.00513037 loss)
I0217 14:54:14.047670  8728 sgd_solver.cpp:106] Iteration 256600, lr = 0.0001
I0217 14:54:31.696264  8728 solver.cpp:228] Iteration 256700, loss = 0.00174009
I0217 14:54:31.696264  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:54:31.696264  8728 solver.cpp:244]     Train net output #1: loss = 0.00174009 (* 1 = 0.00174009 loss)
I0217 14:54:31.696264  8728 sgd_solver.cpp:106] Iteration 256700, lr = 0.0001
I0217 14:54:49.355201  8728 solver.cpp:228] Iteration 256800, loss = 0.00277952
I0217 14:54:49.355201  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:54:49.355201  8728 solver.cpp:244]     Train net output #1: loss = 0.00277952 (* 1 = 0.00277952 loss)
I0217 14:54:49.355201  8728 sgd_solver.cpp:106] Iteration 256800, lr = 0.0001
I0217 14:55:07.013315  8728 solver.cpp:228] Iteration 256900, loss = 0.0034494
I0217 14:55:07.013315  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:55:07.013315  8728 solver.cpp:244]     Train net output #1: loss = 0.00344939 (* 1 = 0.00344939 loss)
I0217 14:55:07.013315  8728 sgd_solver.cpp:106] Iteration 256900, lr = 0.0001
I0217 14:55:24.604113  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_257000.caffemodel
I0217 14:55:24.743636  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_257000.solverstate
I0217 14:55:24.808141  8728 solver.cpp:337] Iteration 257000, Testing net (#0)
I0217 14:55:24.808642  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:55:30.807338  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9451
I0217 14:55:30.807338  8728 solver.cpp:404]     Test net output #1: loss = 0.187833 (* 1 = 0.187833 loss)
I0217 14:55:30.877354  8728 solver.cpp:228] Iteration 257000, loss = 0.0010286
I0217 14:55:30.877354  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:55:30.877354  8728 solver.cpp:244]     Train net output #1: loss = 0.00102859 (* 1 = 0.00102859 loss)
I0217 14:55:30.877354  8728 sgd_solver.cpp:106] Iteration 257000, lr = 0.0001
I0217 14:55:48.497831  8728 solver.cpp:228] Iteration 257100, loss = 0.00853499
I0217 14:55:48.497831  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:55:48.497831  8728 solver.cpp:244]     Train net output #1: loss = 0.00853499 (* 1 = 0.00853499 loss)
I0217 14:55:48.497831  8728 sgd_solver.cpp:106] Iteration 257100, lr = 0.0001
I0217 14:56:06.156795  8728 solver.cpp:228] Iteration 257200, loss = 0.00198723
I0217 14:56:06.156795  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:56:06.156795  8728 solver.cpp:244]     Train net output #1: loss = 0.00198723 (* 1 = 0.00198723 loss)
I0217 14:56:06.156795  8728 sgd_solver.cpp:106] Iteration 257200, lr = 0.0001
I0217 14:56:23.816501  8728 solver.cpp:228] Iteration 257300, loss = 0.00145177
I0217 14:56:23.816501  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:56:23.816501  8728 solver.cpp:244]     Train net output #1: loss = 0.00145176 (* 1 = 0.00145176 loss)
I0217 14:56:23.816501  8728 sgd_solver.cpp:106] Iteration 257300, lr = 0.0001
I0217 14:56:41.472254  8728 solver.cpp:228] Iteration 257400, loss = 0.00393951
I0217 14:56:41.472734  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:56:41.472734  8728 solver.cpp:244]     Train net output #1: loss = 0.00393951 (* 1 = 0.00393951 loss)
I0217 14:56:41.472734  8728 sgd_solver.cpp:106] Iteration 257400, lr = 0.0001
I0217 14:56:59.050235  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_257500.caffemodel
I0217 14:56:59.189271  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_257500.solverstate
I0217 14:56:59.254776  8728 solver.cpp:337] Iteration 257500, Testing net (#0)
I0217 14:56:59.254776  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:57:05.246062  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9444
I0217 14:57:05.246062  8728 solver.cpp:404]     Test net output #1: loss = 0.187769 (* 1 = 0.187769 loss)
I0217 14:57:05.317126  8728 solver.cpp:228] Iteration 257500, loss = 0.00125906
I0217 14:57:05.317126  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:57:05.317126  8728 solver.cpp:244]     Train net output #1: loss = 0.00125905 (* 1 = 0.00125905 loss)
I0217 14:57:05.317126  8728 sgd_solver.cpp:106] Iteration 257500, lr = 0.0001
I0217 14:57:22.934763  8728 solver.cpp:228] Iteration 257600, loss = 0.000860975
I0217 14:57:22.934763  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:57:22.934763  8728 solver.cpp:244]     Train net output #1: loss = 0.000860967 (* 1 = 0.000860967 loss)
I0217 14:57:22.934763  8728 sgd_solver.cpp:106] Iteration 257600, lr = 0.0001
I0217 14:57:40.588548  8728 solver.cpp:228] Iteration 257700, loss = 0.00248073
I0217 14:57:40.588548  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:57:40.588548  8728 solver.cpp:244]     Train net output #1: loss = 0.00248073 (* 1 = 0.00248073 loss)
I0217 14:57:40.588548  8728 sgd_solver.cpp:106] Iteration 257700, lr = 0.0001
I0217 14:57:58.239253  8728 solver.cpp:228] Iteration 257800, loss = 0.00194573
I0217 14:57:58.239253  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:57:58.239738  8728 solver.cpp:244]     Train net output #1: loss = 0.00194573 (* 1 = 0.00194573 loss)
I0217 14:57:58.239738  8728 sgd_solver.cpp:106] Iteration 257800, lr = 0.0001
I0217 14:58:15.889387  8728 solver.cpp:228] Iteration 257900, loss = 0.00186991
I0217 14:58:15.889387  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:58:15.889387  8728 solver.cpp:244]     Train net output #1: loss = 0.0018699 (* 1 = 0.0018699 loss)
I0217 14:58:15.889387  8728 sgd_solver.cpp:106] Iteration 257900, lr = 0.0001
I0217 14:58:33.462966  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_258000.caffemodel
I0217 14:58:33.603251  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_258000.solverstate
I0217 14:58:33.667256  8728 solver.cpp:337] Iteration 258000, Testing net (#0)
I0217 14:58:33.667256  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 14:58:39.659001  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0217 14:58:39.659502  8728 solver.cpp:404]     Test net output #1: loss = 0.187886 (* 1 = 0.187886 loss)
I0217 14:58:39.730017  8728 solver.cpp:228] Iteration 258000, loss = 0.00287207
I0217 14:58:39.730017  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:58:39.730017  8728 solver.cpp:244]     Train net output #1: loss = 0.00287206 (* 1 = 0.00287206 loss)
I0217 14:58:39.730017  8728 sgd_solver.cpp:106] Iteration 258000, lr = 0.0001
I0217 14:58:57.305439  8728 solver.cpp:228] Iteration 258100, loss = 0.00144332
I0217 14:58:57.305439  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:58:57.305439  8728 solver.cpp:244]     Train net output #1: loss = 0.00144331 (* 1 = 0.00144331 loss)
I0217 14:58:57.305439  8728 sgd_solver.cpp:106] Iteration 258100, lr = 0.0001
I0217 14:59:14.879310  8728 solver.cpp:228] Iteration 258200, loss = 0.00141913
I0217 14:59:14.879310  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:59:14.879310  8728 solver.cpp:244]     Train net output #1: loss = 0.00141912 (* 1 = 0.00141912 loss)
I0217 14:59:14.879310  8728 sgd_solver.cpp:106] Iteration 258200, lr = 0.0001
I0217 14:59:32.519830  8728 solver.cpp:228] Iteration 258300, loss = 0.00214926
I0217 14:59:32.519830  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:59:32.519830  8728 solver.cpp:244]     Train net output #1: loss = 0.00214925 (* 1 = 0.00214925 loss)
I0217 14:59:32.519830  8728 sgd_solver.cpp:106] Iteration 258300, lr = 0.0001
I0217 14:59:50.170114  8728 solver.cpp:228] Iteration 258400, loss = 0.00252984
I0217 14:59:50.170114  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 14:59:50.170114  8728 solver.cpp:244]     Train net output #1: loss = 0.00252984 (* 1 = 0.00252984 loss)
I0217 14:59:50.170114  8728 sgd_solver.cpp:106] Iteration 258400, lr = 0.0001
I0217 15:00:07.754256  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_258500.caffemodel
I0217 15:00:07.894248  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_258500.solverstate
I0217 15:00:07.957247  8728 solver.cpp:337] Iteration 258500, Testing net (#0)
I0217 15:00:07.957247  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:00:13.965548  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 15:00:13.966048  8728 solver.cpp:404]     Test net output #1: loss = 0.187959 (* 1 = 0.187959 loss)
I0217 15:00:14.036598  8728 solver.cpp:228] Iteration 258500, loss = 0.00134271
I0217 15:00:14.036598  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:00:14.036598  8728 solver.cpp:244]     Train net output #1: loss = 0.00134271 (* 1 = 0.00134271 loss)
I0217 15:00:14.036598  8728 sgd_solver.cpp:106] Iteration 258500, lr = 0.0001
I0217 15:00:31.696646  8728 solver.cpp:228] Iteration 258600, loss = 0.00102382
I0217 15:00:31.696646  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:00:31.696646  8728 solver.cpp:244]     Train net output #1: loss = 0.00102382 (* 1 = 0.00102382 loss)
I0217 15:00:31.696646  8728 sgd_solver.cpp:106] Iteration 258600, lr = 0.0001
I0217 15:00:49.351831  8728 solver.cpp:228] Iteration 258700, loss = 0.00323698
I0217 15:00:49.351831  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:00:49.351831  8728 solver.cpp:244]     Train net output #1: loss = 0.00323698 (* 1 = 0.00323698 loss)
I0217 15:00:49.351831  8728 sgd_solver.cpp:106] Iteration 258700, lr = 0.0001
I0217 15:01:07.014147  8728 solver.cpp:228] Iteration 258800, loss = 0.00120324
I0217 15:01:07.014147  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:01:07.014147  8728 solver.cpp:244]     Train net output #1: loss = 0.00120323 (* 1 = 0.00120323 loss)
I0217 15:01:07.014147  8728 sgd_solver.cpp:106] Iteration 258800, lr = 0.0001
I0217 15:01:24.716898  8728 solver.cpp:228] Iteration 258900, loss = 0.00336824
I0217 15:01:24.716898  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:01:24.716898  8728 solver.cpp:244]     Train net output #1: loss = 0.00336823 (* 1 = 0.00336823 loss)
I0217 15:01:24.716898  8728 sgd_solver.cpp:106] Iteration 258900, lr = 0.0001
I0217 15:01:42.298362  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_259000.caffemodel
I0217 15:01:42.438357  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_259000.solverstate
I0217 15:01:42.504374  8728 solver.cpp:337] Iteration 259000, Testing net (#0)
I0217 15:01:42.504856  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:01:48.499563  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9454
I0217 15:01:48.499563  8728 solver.cpp:404]     Test net output #1: loss = 0.187792 (* 1 = 0.187792 loss)
I0217 15:01:48.570123  8728 solver.cpp:228] Iteration 259000, loss = 0.00132193
I0217 15:01:48.570123  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:01:48.570123  8728 solver.cpp:244]     Train net output #1: loss = 0.00132192 (* 1 = 0.00132192 loss)
I0217 15:01:48.570123  8728 sgd_solver.cpp:106] Iteration 259000, lr = 0.0001
I0217 15:02:06.159986  8728 solver.cpp:228] Iteration 259100, loss = 0.00212383
I0217 15:02:06.159986  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:02:06.159986  8728 solver.cpp:244]     Train net output #1: loss = 0.00212383 (* 1 = 0.00212383 loss)
I0217 15:02:06.159986  8728 sgd_solver.cpp:106] Iteration 259100, lr = 0.0001
I0217 15:02:23.818068  8728 solver.cpp:228] Iteration 259200, loss = 0.00216392
I0217 15:02:23.818068  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:02:23.818068  8728 solver.cpp:244]     Train net output #1: loss = 0.00216392 (* 1 = 0.00216392 loss)
I0217 15:02:23.818068  8728 sgd_solver.cpp:106] Iteration 259200, lr = 0.0001
I0217 15:02:41.542176  8728 solver.cpp:228] Iteration 259300, loss = 0.00264142
I0217 15:02:41.542176  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:02:41.542176  8728 solver.cpp:244]     Train net output #1: loss = 0.00264142 (* 1 = 0.00264142 loss)
I0217 15:02:41.542176  8728 sgd_solver.cpp:106] Iteration 259300, lr = 0.0001
I0217 15:02:59.285477  8728 solver.cpp:228] Iteration 259400, loss = 0.00188657
I0217 15:02:59.285477  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:02:59.285477  8728 solver.cpp:244]     Train net output #1: loss = 0.00188657 (* 1 = 0.00188657 loss)
I0217 15:02:59.285477  8728 sgd_solver.cpp:106] Iteration 259400, lr = 0.0001
I0217 15:03:16.958356  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_259500.caffemodel
I0217 15:03:17.101858  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_259500.solverstate
I0217 15:03:17.165859  8728 solver.cpp:337] Iteration 259500, Testing net (#0)
I0217 15:03:17.166360  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:03:23.187933  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 15:03:23.187933  8728 solver.cpp:404]     Test net output #1: loss = 0.188272 (* 1 = 0.188272 loss)
I0217 15:03:23.258972  8728 solver.cpp:228] Iteration 259500, loss = 0.00445218
I0217 15:03:23.258972  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:03:23.258972  8728 solver.cpp:244]     Train net output #1: loss = 0.00445217 (* 1 = 0.00445217 loss)
I0217 15:03:23.258972  8728 sgd_solver.cpp:106] Iteration 259500, lr = 0.0001
I0217 15:03:40.993294  8728 solver.cpp:228] Iteration 259600, loss = 0.00441706
I0217 15:03:40.993793  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:03:40.993793  8728 solver.cpp:244]     Train net output #1: loss = 0.00441705 (* 1 = 0.00441705 loss)
I0217 15:03:40.993793  8728 sgd_solver.cpp:106] Iteration 259600, lr = 0.0001
I0217 15:03:58.742321  8728 solver.cpp:228] Iteration 259700, loss = 0.00091026
I0217 15:03:58.742321  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:03:58.742321  8728 solver.cpp:244]     Train net output #1: loss = 0.000910248 (* 1 = 0.000910248 loss)
I0217 15:03:58.742321  8728 sgd_solver.cpp:106] Iteration 259700, lr = 0.0001
I0217 15:04:16.474372  8728 solver.cpp:228] Iteration 259800, loss = 0.00159756
I0217 15:04:16.474372  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:04:16.474372  8728 solver.cpp:244]     Train net output #1: loss = 0.00159755 (* 1 = 0.00159755 loss)
I0217 15:04:16.474372  8728 sgd_solver.cpp:106] Iteration 259800, lr = 0.0001
I0217 15:04:34.213991  8728 solver.cpp:228] Iteration 259900, loss = 0.00237294
I0217 15:04:34.213991  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:04:34.214493  8728 solver.cpp:244]     Train net output #1: loss = 0.00237293 (* 1 = 0.00237293 loss)
I0217 15:04:34.214493  8728 sgd_solver.cpp:106] Iteration 259900, lr = 0.0001
I0217 15:04:51.864857  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_260000.caffemodel
I0217 15:04:52.000864  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_260000.solverstate
I0217 15:04:52.064851  8728 solver.cpp:337] Iteration 260000, Testing net (#0)
I0217 15:04:52.064851  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:04:58.071127  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 15:04:58.071127  8728 solver.cpp:404]     Test net output #1: loss = 0.188127 (* 1 = 0.188127 loss)
I0217 15:04:58.142652  8728 solver.cpp:228] Iteration 260000, loss = 0.00202867
I0217 15:04:58.142652  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:04:58.142652  8728 solver.cpp:244]     Train net output #1: loss = 0.00202866 (* 1 = 0.00202866 loss)
I0217 15:04:58.142652  8728 sgd_solver.cpp:106] Iteration 260000, lr = 0.0001
I0217 15:05:15.798630  8728 solver.cpp:228] Iteration 260100, loss = 0.00454786
I0217 15:05:15.798630  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:05:15.798630  8728 solver.cpp:244]     Train net output #1: loss = 0.00454785 (* 1 = 0.00454785 loss)
I0217 15:05:15.798630  8728 sgd_solver.cpp:106] Iteration 260100, lr = 0.0001
I0217 15:05:33.454839  8728 solver.cpp:228] Iteration 260200, loss = 0.00112443
I0217 15:05:33.454839  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:05:33.454839  8728 solver.cpp:244]     Train net output #1: loss = 0.00112442 (* 1 = 0.00112442 loss)
I0217 15:05:33.454839  8728 sgd_solver.cpp:106] Iteration 260200, lr = 0.0001
I0217 15:05:51.113896  8728 solver.cpp:228] Iteration 260300, loss = 0.0014869
I0217 15:05:51.113896  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:05:51.113896  8728 solver.cpp:244]     Train net output #1: loss = 0.00148689 (* 1 = 0.00148689 loss)
I0217 15:05:51.113896  8728 sgd_solver.cpp:106] Iteration 260300, lr = 0.0001
I0217 15:06:08.772931  8728 solver.cpp:228] Iteration 260400, loss = 0.00179557
I0217 15:06:08.772931  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:06:08.772931  8728 solver.cpp:244]     Train net output #1: loss = 0.00179556 (* 1 = 0.00179556 loss)
I0217 15:06:08.772931  8728 sgd_solver.cpp:106] Iteration 260400, lr = 0.0001
I0217 15:06:26.359021  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_260500.caffemodel
I0217 15:06:26.500026  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_260500.solverstate
I0217 15:06:26.564029  8728 solver.cpp:337] Iteration 260500, Testing net (#0)
I0217 15:06:26.564527  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:06:32.555910  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 15:06:32.555910  8728 solver.cpp:404]     Test net output #1: loss = 0.187903 (* 1 = 0.187903 loss)
I0217 15:06:32.626482  8728 solver.cpp:228] Iteration 260500, loss = 0.00597902
I0217 15:06:32.626482  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:06:32.626482  8728 solver.cpp:244]     Train net output #1: loss = 0.00597901 (* 1 = 0.00597901 loss)
I0217 15:06:32.626482  8728 sgd_solver.cpp:106] Iteration 260500, lr = 0.0001
I0217 15:06:50.205878  8728 solver.cpp:228] Iteration 260600, loss = 0.00117374
I0217 15:06:50.206377  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:06:50.206377  8728 solver.cpp:244]     Train net output #1: loss = 0.00117373 (* 1 = 0.00117373 loss)
I0217 15:06:50.206377  8728 sgd_solver.cpp:106] Iteration 260600, lr = 0.0001
I0217 15:07:07.910778  8728 solver.cpp:228] Iteration 260700, loss = 0.00192128
I0217 15:07:07.910778  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:07:07.910778  8728 solver.cpp:244]     Train net output #1: loss = 0.00192127 (* 1 = 0.00192127 loss)
I0217 15:07:07.910778  8728 sgd_solver.cpp:106] Iteration 260700, lr = 0.0001
I0217 15:07:25.566856  8728 solver.cpp:228] Iteration 260800, loss = 0.00256666
I0217 15:07:25.566856  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:07:25.566856  8728 solver.cpp:244]     Train net output #1: loss = 0.00256665 (* 1 = 0.00256665 loss)
I0217 15:07:25.566856  8728 sgd_solver.cpp:106] Iteration 260800, lr = 0.0001
I0217 15:07:43.222074  8728 solver.cpp:228] Iteration 260900, loss = 0.00107708
I0217 15:07:43.222074  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:07:43.222074  8728 solver.cpp:244]     Train net output #1: loss = 0.00107708 (* 1 = 0.00107708 loss)
I0217 15:07:43.222074  8728 sgd_solver.cpp:106] Iteration 260900, lr = 0.0001
I0217 15:08:00.804563  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_261000.caffemodel
I0217 15:08:00.940065  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_261000.solverstate
I0217 15:08:01.004570  8728 solver.cpp:337] Iteration 261000, Testing net (#0)
I0217 15:08:01.004570  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:08:06.990386  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0217 15:08:06.990386  8728 solver.cpp:404]     Test net output #1: loss = 0.187822 (* 1 = 0.187822 loss)
I0217 15:08:07.060930  8728 solver.cpp:228] Iteration 261000, loss = 0.00281964
I0217 15:08:07.060930  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:08:07.060930  8728 solver.cpp:244]     Train net output #1: loss = 0.00281963 (* 1 = 0.00281963 loss)
I0217 15:08:07.060930  8728 sgd_solver.cpp:106] Iteration 261000, lr = 0.0001
I0217 15:08:24.638367  8728 solver.cpp:228] Iteration 261100, loss = 0.00374953
I0217 15:08:24.638367  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:08:24.638367  8728 solver.cpp:244]     Train net output #1: loss = 0.00374952 (* 1 = 0.00374952 loss)
I0217 15:08:24.638367  8728 sgd_solver.cpp:106] Iteration 261100, lr = 0.0001
I0217 15:08:42.288097  8728 solver.cpp:228] Iteration 261200, loss = 0.00198419
I0217 15:08:42.288097  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:08:42.288097  8728 solver.cpp:244]     Train net output #1: loss = 0.00198418 (* 1 = 0.00198418 loss)
I0217 15:08:42.288097  8728 sgd_solver.cpp:106] Iteration 261200, lr = 0.0001
I0217 15:08:59.941045  8728 solver.cpp:228] Iteration 261300, loss = 0.00329226
I0217 15:08:59.941045  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:08:59.941045  8728 solver.cpp:244]     Train net output #1: loss = 0.00329226 (* 1 = 0.00329226 loss)
I0217 15:08:59.941045  8728 sgd_solver.cpp:106] Iteration 261300, lr = 0.0001
I0217 15:09:17.604902  8728 solver.cpp:228] Iteration 261400, loss = 0.00731496
I0217 15:09:17.604902  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:09:17.604902  8728 solver.cpp:244]     Train net output #1: loss = 0.00731496 (* 1 = 0.00731496 loss)
I0217 15:09:17.604902  8728 sgd_solver.cpp:106] Iteration 261400, lr = 0.0001
I0217 15:09:35.196228  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_261500.caffemodel
I0217 15:09:35.338224  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_261500.solverstate
I0217 15:09:35.402227  8728 solver.cpp:337] Iteration 261500, Testing net (#0)
I0217 15:09:35.402227  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:09:41.402189  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 15:09:41.402189  8728 solver.cpp:404]     Test net output #1: loss = 0.187586 (* 1 = 0.187586 loss)
I0217 15:09:41.472214  8728 solver.cpp:228] Iteration 261500, loss = 0.00871288
I0217 15:09:41.472214  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:09:41.472214  8728 solver.cpp:244]     Train net output #1: loss = 0.00871288 (* 1 = 0.00871288 loss)
I0217 15:09:41.472214  8728 sgd_solver.cpp:106] Iteration 261500, lr = 0.0001
I0217 15:09:59.128312  8728 solver.cpp:228] Iteration 261600, loss = 0.00534076
I0217 15:09:59.128312  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:09:59.128312  8728 solver.cpp:244]     Train net output #1: loss = 0.00534075 (* 1 = 0.00534075 loss)
I0217 15:09:59.128312  8728 sgd_solver.cpp:106] Iteration 261600, lr = 0.0001
I0217 15:10:16.791826  8728 solver.cpp:228] Iteration 261700, loss = 0.00229977
I0217 15:10:16.791826  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:10:16.791826  8728 solver.cpp:244]     Train net output #1: loss = 0.00229976 (* 1 = 0.00229976 loss)
I0217 15:10:16.791826  8728 sgd_solver.cpp:106] Iteration 261700, lr = 0.0001
I0217 15:10:34.455371  8728 solver.cpp:228] Iteration 261800, loss = 0.00312712
I0217 15:10:34.455371  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:10:34.455371  8728 solver.cpp:244]     Train net output #1: loss = 0.00312711 (* 1 = 0.00312711 loss)
I0217 15:10:34.455371  8728 sgd_solver.cpp:106] Iteration 261800, lr = 0.0001
I0217 15:10:52.108414  8728 solver.cpp:228] Iteration 261900, loss = 0.00686442
I0217 15:10:52.108901  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:10:52.108901  8728 solver.cpp:244]     Train net output #1: loss = 0.00686441 (* 1 = 0.00686441 loss)
I0217 15:10:52.108901  8728 sgd_solver.cpp:106] Iteration 261900, lr = 0.0001
I0217 15:11:09.688560  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_262000.caffemodel
I0217 15:11:09.829571  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_262000.solverstate
I0217 15:11:10.226137  8728 solver.cpp:337] Iteration 262000, Testing net (#0)
I0217 15:11:10.226137  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:11:16.248795  8728 solver.cpp:404]     Test net output #0: accuracy = 0.946
I0217 15:11:16.248795  8728 solver.cpp:404]     Test net output #1: loss = 0.187227 (* 1 = 0.187227 loss)
I0217 15:11:16.319811  8728 solver.cpp:228] Iteration 262000, loss = 0.00222308
I0217 15:11:16.319811  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:11:16.319811  8728 solver.cpp:244]     Train net output #1: loss = 0.00222307 (* 1 = 0.00222307 loss)
I0217 15:11:16.319811  8728 sgd_solver.cpp:106] Iteration 262000, lr = 0.0001
I0217 15:11:33.974956  8728 solver.cpp:228] Iteration 262100, loss = 0.00452604
I0217 15:11:33.974956  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:11:33.974956  8728 solver.cpp:244]     Train net output #1: loss = 0.00452603 (* 1 = 0.00452603 loss)
I0217 15:11:33.974956  8728 sgd_solver.cpp:106] Iteration 262100, lr = 0.0001
I0217 15:11:51.619567  8728 solver.cpp:228] Iteration 262200, loss = 0.000977089
I0217 15:11:51.620067  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:11:51.620067  8728 solver.cpp:244]     Train net output #1: loss = 0.000977081 (* 1 = 0.000977081 loss)
I0217 15:11:51.620067  8728 sgd_solver.cpp:106] Iteration 262200, lr = 0.0001
I0217 15:12:09.274194  8728 solver.cpp:228] Iteration 262300, loss = 0.0103367
I0217 15:12:09.274194  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:12:09.274194  8728 solver.cpp:244]     Train net output #1: loss = 0.0103367 (* 1 = 0.0103367 loss)
I0217 15:12:09.274194  8728 sgd_solver.cpp:106] Iteration 262300, lr = 0.0001
I0217 15:12:26.931334  8728 solver.cpp:228] Iteration 262400, loss = 0.00112119
I0217 15:12:26.931843  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:12:26.931843  8728 solver.cpp:244]     Train net output #1: loss = 0.00112118 (* 1 = 0.00112118 loss)
I0217 15:12:26.931843  8728 sgd_solver.cpp:106] Iteration 262400, lr = 0.0001
I0217 15:12:44.512063  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_262500.caffemodel
I0217 15:12:44.651064  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_262500.solverstate
I0217 15:12:44.714565  8728 solver.cpp:337] Iteration 262500, Testing net (#0)
I0217 15:12:44.714565  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:12:50.724903  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9451
I0217 15:12:50.724903  8728 solver.cpp:404]     Test net output #1: loss = 0.187266 (* 1 = 0.187266 loss)
I0217 15:12:50.795445  8728 solver.cpp:228] Iteration 262500, loss = 0.0038293
I0217 15:12:50.795445  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:12:50.795445  8728 solver.cpp:244]     Train net output #1: loss = 0.00382929 (* 1 = 0.00382929 loss)
I0217 15:12:50.795445  8728 sgd_solver.cpp:106] Iteration 262500, lr = 0.0001
I0217 15:13:08.439843  8728 solver.cpp:228] Iteration 262600, loss = 0.00117704
I0217 15:13:08.439843  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:13:08.439843  8728 solver.cpp:244]     Train net output #1: loss = 0.00117703 (* 1 = 0.00117703 loss)
I0217 15:13:08.439843  8728 sgd_solver.cpp:106] Iteration 262600, lr = 0.0001
I0217 15:13:26.084058  8728 solver.cpp:228] Iteration 262700, loss = 0.00223622
I0217 15:13:26.084555  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:13:26.084555  8728 solver.cpp:244]     Train net output #1: loss = 0.00223621 (* 1 = 0.00223621 loss)
I0217 15:13:26.084555  8728 sgd_solver.cpp:106] Iteration 262700, lr = 0.0001
I0217 15:13:43.739775  8728 solver.cpp:228] Iteration 262800, loss = 0.00290975
I0217 15:13:43.740260  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:13:43.740260  8728 solver.cpp:244]     Train net output #1: loss = 0.00290974 (* 1 = 0.00290974 loss)
I0217 15:13:43.740260  8728 sgd_solver.cpp:106] Iteration 262800, lr = 0.0001
I0217 15:14:01.391386  8728 solver.cpp:228] Iteration 262900, loss = 0.00333997
I0217 15:14:01.391386  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:14:01.391386  8728 solver.cpp:244]     Train net output #1: loss = 0.00333995 (* 1 = 0.00333995 loss)
I0217 15:14:01.391386  8728 sgd_solver.cpp:106] Iteration 262900, lr = 0.0001
I0217 15:14:18.963402  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_263000.caffemodel
I0217 15:14:19.104910  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_263000.solverstate
I0217 15:14:19.170903  8728 solver.cpp:337] Iteration 263000, Testing net (#0)
I0217 15:14:19.170903  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:14:25.184185  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9442
I0217 15:14:25.184185  8728 solver.cpp:404]     Test net output #1: loss = 0.188098 (* 1 = 0.188098 loss)
I0217 15:14:25.254228  8728 solver.cpp:228] Iteration 263000, loss = 0.0019044
I0217 15:14:25.254228  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:14:25.254228  8728 solver.cpp:244]     Train net output #1: loss = 0.00190438 (* 1 = 0.00190438 loss)
I0217 15:14:25.254228  8728 sgd_solver.cpp:106] Iteration 263000, lr = 0.0001
I0217 15:14:43.218094  8728 solver.cpp:228] Iteration 263100, loss = 0.00161224
I0217 15:14:43.218564  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:14:43.218564  8728 solver.cpp:244]     Train net output #1: loss = 0.00161223 (* 1 = 0.00161223 loss)
I0217 15:14:43.218564  8728 sgd_solver.cpp:106] Iteration 263100, lr = 0.0001
I0217 15:15:01.029541  8728 solver.cpp:228] Iteration 263200, loss = 0.0029232
I0217 15:15:01.029541  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:15:01.029541  8728 solver.cpp:244]     Train net output #1: loss = 0.00292318 (* 1 = 0.00292318 loss)
I0217 15:15:01.029541  8728 sgd_solver.cpp:106] Iteration 263200, lr = 0.0001
I0217 15:15:18.827929  8728 solver.cpp:228] Iteration 263300, loss = 0.00132334
I0217 15:15:18.828416  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:15:18.828416  8728 solver.cpp:244]     Train net output #1: loss = 0.00132333 (* 1 = 0.00132333 loss)
I0217 15:15:18.828416  8728 sgd_solver.cpp:106] Iteration 263300, lr = 0.0001
I0217 15:15:36.564788  8728 solver.cpp:228] Iteration 263400, loss = 0.00199823
I0217 15:15:36.564788  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:15:36.564788  8728 solver.cpp:244]     Train net output #1: loss = 0.00199821 (* 1 = 0.00199821 loss)
I0217 15:15:36.564788  8728 sgd_solver.cpp:106] Iteration 263400, lr = 0.0001
I0217 15:15:54.291152  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_263500.caffemodel
I0217 15:15:54.432178  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_263500.solverstate
I0217 15:15:54.498185  8728 solver.cpp:337] Iteration 263500, Testing net (#0)
I0217 15:15:54.498185  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:16:00.551565  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0217 15:16:00.551565  8728 solver.cpp:404]     Test net output #1: loss = 0.187835 (* 1 = 0.187835 loss)
I0217 15:16:00.622598  8728 solver.cpp:228] Iteration 263500, loss = 0.0118473
I0217 15:16:00.622598  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 15:16:00.622598  8728 solver.cpp:244]     Train net output #1: loss = 0.0118473 (* 1 = 0.0118473 loss)
I0217 15:16:00.622598  8728 sgd_solver.cpp:106] Iteration 263500, lr = 0.0001
I0217 15:16:18.396257  8728 solver.cpp:228] Iteration 263600, loss = 0.00530135
I0217 15:16:18.396257  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:16:18.396257  8728 solver.cpp:244]     Train net output #1: loss = 0.00530133 (* 1 = 0.00530133 loss)
I0217 15:16:18.396257  8728 sgd_solver.cpp:106] Iteration 263600, lr = 0.0001
I0217 15:16:36.210134  8728 solver.cpp:228] Iteration 263700, loss = 0.00123474
I0217 15:16:36.210134  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:16:36.210134  8728 solver.cpp:244]     Train net output #1: loss = 0.00123473 (* 1 = 0.00123473 loss)
I0217 15:16:36.210134  8728 sgd_solver.cpp:106] Iteration 263700, lr = 0.0001
I0217 15:16:54.005636  8728 solver.cpp:228] Iteration 263800, loss = 0.00151992
I0217 15:16:54.005636  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:16:54.005636  8728 solver.cpp:244]     Train net output #1: loss = 0.0015199 (* 1 = 0.0015199 loss)
I0217 15:16:54.005636  8728 sgd_solver.cpp:106] Iteration 263800, lr = 0.0001
I0217 15:17:11.804636  8728 solver.cpp:228] Iteration 263900, loss = 0.00386607
I0217 15:17:11.804636  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:17:11.804636  8728 solver.cpp:244]     Train net output #1: loss = 0.00386605 (* 1 = 0.00386605 loss)
I0217 15:17:11.804636  8728 sgd_solver.cpp:106] Iteration 263900, lr = 0.0001
I0217 15:17:29.520128  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_264000.caffemodel
I0217 15:17:29.660640  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_264000.solverstate
I0217 15:17:29.727712  8728 solver.cpp:337] Iteration 264000, Testing net (#0)
I0217 15:17:29.727712  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:17:35.792109  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 15:17:35.792109  8728 solver.cpp:404]     Test net output #1: loss = 0.187013 (* 1 = 0.187013 loss)
I0217 15:17:35.865128  8728 solver.cpp:228] Iteration 264000, loss = 0.0012852
I0217 15:17:35.865128  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:17:35.865128  8728 solver.cpp:244]     Train net output #1: loss = 0.00128518 (* 1 = 0.00128518 loss)
I0217 15:17:35.865128  8728 sgd_solver.cpp:106] Iteration 264000, lr = 0.0001
I0217 15:17:53.662004  8728 solver.cpp:228] Iteration 264100, loss = 0.00464985
I0217 15:17:53.662004  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:17:53.662004  8728 solver.cpp:244]     Train net output #1: loss = 0.00464983 (* 1 = 0.00464983 loss)
I0217 15:17:53.662004  8728 sgd_solver.cpp:106] Iteration 264100, lr = 0.0001
I0217 15:18:11.408253  8728 solver.cpp:228] Iteration 264200, loss = 0.00171697
I0217 15:18:11.408253  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:18:11.408253  8728 solver.cpp:244]     Train net output #1: loss = 0.00171695 (* 1 = 0.00171695 loss)
I0217 15:18:11.408253  8728 sgd_solver.cpp:106] Iteration 264200, lr = 0.0001
I0217 15:18:29.132814  8728 solver.cpp:228] Iteration 264300, loss = 0.00277575
I0217 15:18:29.132814  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:18:29.132814  8728 solver.cpp:244]     Train net output #1: loss = 0.00277573 (* 1 = 0.00277573 loss)
I0217 15:18:29.132814  8728 sgd_solver.cpp:106] Iteration 264300, lr = 0.0001
I0217 15:18:46.866932  8728 solver.cpp:228] Iteration 264400, loss = 0.00111452
I0217 15:18:46.866932  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:18:46.866932  8728 solver.cpp:244]     Train net output #1: loss = 0.0011145 (* 1 = 0.0011145 loss)
I0217 15:18:46.866932  8728 sgd_solver.cpp:106] Iteration 264400, lr = 0.0001
I0217 15:19:04.515477  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_264500.caffemodel
I0217 15:19:04.654522  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_264500.solverstate
I0217 15:19:04.718542  8728 solver.cpp:337] Iteration 264500, Testing net (#0)
I0217 15:19:04.719542  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:19:10.773494  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 15:19:10.773494  8728 solver.cpp:404]     Test net output #1: loss = 0.187381 (* 1 = 0.187381 loss)
I0217 15:19:10.844038  8728 solver.cpp:228] Iteration 264500, loss = 0.00189625
I0217 15:19:10.844038  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:19:10.844038  8728 solver.cpp:244]     Train net output #1: loss = 0.00189623 (* 1 = 0.00189623 loss)
I0217 15:19:10.844038  8728 sgd_solver.cpp:106] Iteration 264500, lr = 0.0001
I0217 15:19:28.577567  8728 solver.cpp:228] Iteration 264600, loss = 0.00249723
I0217 15:19:28.577567  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:19:28.577567  8728 solver.cpp:244]     Train net output #1: loss = 0.00249721 (* 1 = 0.00249721 loss)
I0217 15:19:28.577567  8728 sgd_solver.cpp:106] Iteration 264600, lr = 0.0001
I0217 15:19:46.307037  8728 solver.cpp:228] Iteration 264700, loss = 0.00649212
I0217 15:19:46.307037  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:19:46.307037  8728 solver.cpp:244]     Train net output #1: loss = 0.00649211 (* 1 = 0.00649211 loss)
I0217 15:19:46.307037  8728 sgd_solver.cpp:106] Iteration 264700, lr = 0.0001
I0217 15:20:04.066365  8728 solver.cpp:228] Iteration 264800, loss = 0.00192116
I0217 15:20:04.066365  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:20:04.066365  8728 solver.cpp:244]     Train net output #1: loss = 0.00192115 (* 1 = 0.00192115 loss)
I0217 15:20:04.066365  8728 sgd_solver.cpp:106] Iteration 264800, lr = 0.0001
I0217 15:20:21.795634  8728 solver.cpp:228] Iteration 264900, loss = 0.00174805
I0217 15:20:21.795634  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:20:21.795634  8728 solver.cpp:244]     Train net output #1: loss = 0.00174803 (* 1 = 0.00174803 loss)
I0217 15:20:21.795634  8728 sgd_solver.cpp:106] Iteration 264900, lr = 0.0001
I0217 15:20:39.451994  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_265000.caffemodel
I0217 15:20:39.593514  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_265000.solverstate
I0217 15:20:39.791309  8728 solver.cpp:337] Iteration 265000, Testing net (#0)
I0217 15:20:39.792309  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:20:45.824061  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9454
I0217 15:20:45.824061  8728 solver.cpp:404]     Test net output #1: loss = 0.187594 (* 1 = 0.187594 loss)
I0217 15:20:45.895123  8728 solver.cpp:228] Iteration 265000, loss = 0.00232143
I0217 15:20:45.895123  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:20:45.895123  8728 solver.cpp:244]     Train net output #1: loss = 0.00232142 (* 1 = 0.00232142 loss)
I0217 15:20:45.895123  8728 sgd_solver.cpp:106] Iteration 265000, lr = 0.0001
I0217 15:21:03.597627  8728 solver.cpp:228] Iteration 265100, loss = 0.0121173
I0217 15:21:03.597627  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 15:21:03.597627  8728 solver.cpp:244]     Train net output #1: loss = 0.0121173 (* 1 = 0.0121173 loss)
I0217 15:21:03.597627  8728 sgd_solver.cpp:106] Iteration 265100, lr = 0.0001
I0217 15:21:21.327860  8728 solver.cpp:228] Iteration 265200, loss = 0.000737004
I0217 15:21:21.327860  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:21:21.327860  8728 solver.cpp:244]     Train net output #1: loss = 0.000736989 (* 1 = 0.000736989 loss)
I0217 15:21:21.327860  8728 sgd_solver.cpp:106] Iteration 265200, lr = 0.0001
I0217 15:21:39.055222  8728 solver.cpp:228] Iteration 265300, loss = 0.00123513
I0217 15:21:39.055222  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:21:39.055222  8728 solver.cpp:244]     Train net output #1: loss = 0.00123512 (* 1 = 0.00123512 loss)
I0217 15:21:39.055222  8728 sgd_solver.cpp:106] Iteration 265300, lr = 0.0001
I0217 15:21:56.789381  8728 solver.cpp:228] Iteration 265400, loss = 0.0021377
I0217 15:21:56.789381  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:21:56.789381  8728 solver.cpp:244]     Train net output #1: loss = 0.00213768 (* 1 = 0.00213768 loss)
I0217 15:21:56.789381  8728 sgd_solver.cpp:106] Iteration 265400, lr = 0.0001
I0217 15:22:14.487340  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_265500.caffemodel
I0217 15:22:14.625371  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_265500.solverstate
I0217 15:22:14.689872  8728 solver.cpp:337] Iteration 265500, Testing net (#0)
I0217 15:22:14.689872  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:22:20.740669  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0217 15:22:20.740669  8728 solver.cpp:404]     Test net output #1: loss = 0.18747 (* 1 = 0.18747 loss)
I0217 15:22:20.812008  8728 solver.cpp:228] Iteration 265500, loss = 0.00582271
I0217 15:22:20.812008  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:22:20.812008  8728 solver.cpp:244]     Train net output #1: loss = 0.0058227 (* 1 = 0.0058227 loss)
I0217 15:22:20.812008  8728 sgd_solver.cpp:106] Iteration 265500, lr = 0.0001
I0217 15:22:38.542203  8728 solver.cpp:228] Iteration 265600, loss = 0.00707345
I0217 15:22:38.542203  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:22:38.542203  8728 solver.cpp:244]     Train net output #1: loss = 0.00707344 (* 1 = 0.00707344 loss)
I0217 15:22:38.542203  8728 sgd_solver.cpp:106] Iteration 265600, lr = 0.0001
I0217 15:22:56.260027  8728 solver.cpp:228] Iteration 265700, loss = 0.00204345
I0217 15:22:56.260027  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:22:56.260027  8728 solver.cpp:244]     Train net output #1: loss = 0.00204344 (* 1 = 0.00204344 loss)
I0217 15:22:56.260027  8728 sgd_solver.cpp:106] Iteration 265700, lr = 0.0001
I0217 15:23:13.990774  8728 solver.cpp:228] Iteration 265800, loss = 0.00095198
I0217 15:23:13.990774  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:23:13.990774  8728 solver.cpp:244]     Train net output #1: loss = 0.000951964 (* 1 = 0.000951964 loss)
I0217 15:23:13.990774  8728 sgd_solver.cpp:106] Iteration 265800, lr = 0.0001
I0217 15:23:31.712994  8728 solver.cpp:228] Iteration 265900, loss = 0.00515313
I0217 15:23:31.712994  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:23:31.712994  8728 solver.cpp:244]     Train net output #1: loss = 0.00515311 (* 1 = 0.00515311 loss)
I0217 15:23:31.712994  8728 sgd_solver.cpp:106] Iteration 265900, lr = 0.0001
I0217 15:23:49.362154  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_266000.caffemodel
I0217 15:23:49.503155  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_266000.solverstate
I0217 15:23:49.568156  8728 solver.cpp:337] Iteration 266000, Testing net (#0)
I0217 15:23:49.568156  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:23:55.617394  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 15:23:55.617394  8728 solver.cpp:404]     Test net output #1: loss = 0.187392 (* 1 = 0.187392 loss)
I0217 15:23:55.689427  8728 solver.cpp:228] Iteration 266000, loss = 0.00165049
I0217 15:23:55.689427  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:23:55.689427  8728 solver.cpp:244]     Train net output #1: loss = 0.00165047 (* 1 = 0.00165047 loss)
I0217 15:23:55.689427  8728 sgd_solver.cpp:106] Iteration 266000, lr = 0.0001
I0217 15:24:13.418797  8728 solver.cpp:228] Iteration 266100, loss = 0.00737385
I0217 15:24:13.418797  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:24:13.418797  8728 solver.cpp:244]     Train net output #1: loss = 0.00737384 (* 1 = 0.00737384 loss)
I0217 15:24:13.418797  8728 sgd_solver.cpp:106] Iteration 266100, lr = 0.0001
I0217 15:24:31.146203  8728 solver.cpp:228] Iteration 266200, loss = 0.00250607
I0217 15:24:31.146203  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:24:31.146203  8728 solver.cpp:244]     Train net output #1: loss = 0.00250606 (* 1 = 0.00250606 loss)
I0217 15:24:31.146203  8728 sgd_solver.cpp:106] Iteration 266200, lr = 0.0001
I0217 15:24:48.863387  8728 solver.cpp:228] Iteration 266300, loss = 0.00354897
I0217 15:24:48.863387  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:24:48.863387  8728 solver.cpp:244]     Train net output #1: loss = 0.00354896 (* 1 = 0.00354896 loss)
I0217 15:24:48.863387  8728 sgd_solver.cpp:106] Iteration 266300, lr = 0.0001
I0217 15:25:06.589610  8728 solver.cpp:228] Iteration 266400, loss = 0.00285864
I0217 15:25:06.589610  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:25:06.589610  8728 solver.cpp:244]     Train net output #1: loss = 0.00285862 (* 1 = 0.00285862 loss)
I0217 15:25:06.589610  8728 sgd_solver.cpp:106] Iteration 266400, lr = 0.0001
I0217 15:25:24.278937  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_266500.caffemodel
I0217 15:25:24.421437  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_266500.solverstate
I0217 15:25:24.573774  8728 solver.cpp:337] Iteration 266500, Testing net (#0)
I0217 15:25:24.573774  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:25:30.604205  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 15:25:30.604205  8728 solver.cpp:404]     Test net output #1: loss = 0.187728 (* 1 = 0.187728 loss)
I0217 15:25:30.676235  8728 solver.cpp:228] Iteration 266500, loss = 0.000826373
I0217 15:25:30.676235  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:25:30.676235  8728 solver.cpp:244]     Train net output #1: loss = 0.000826359 (* 1 = 0.000826359 loss)
I0217 15:25:30.676235  8728 sgd_solver.cpp:106] Iteration 266500, lr = 0.0001
I0217 15:25:48.386659  8728 solver.cpp:228] Iteration 266600, loss = 0.00371169
I0217 15:25:48.386659  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:25:48.386659  8728 solver.cpp:244]     Train net output #1: loss = 0.00371167 (* 1 = 0.00371167 loss)
I0217 15:25:48.386659  8728 sgd_solver.cpp:106] Iteration 266600, lr = 0.0001
I0217 15:26:06.096773  8728 solver.cpp:228] Iteration 266700, loss = 0.00150089
I0217 15:26:06.096773  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:26:06.096773  8728 solver.cpp:244]     Train net output #1: loss = 0.00150087 (* 1 = 0.00150087 loss)
I0217 15:26:06.096773  8728 sgd_solver.cpp:106] Iteration 266700, lr = 0.0001
I0217 15:26:23.810215  8728 solver.cpp:228] Iteration 266800, loss = 0.00361621
I0217 15:26:23.810215  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:26:23.810215  8728 solver.cpp:244]     Train net output #1: loss = 0.0036162 (* 1 = 0.0036162 loss)
I0217 15:26:23.810215  8728 sgd_solver.cpp:106] Iteration 266800, lr = 0.0001
I0217 15:26:41.527781  8728 solver.cpp:228] Iteration 266900, loss = 0.00223359
I0217 15:26:41.527781  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:26:41.527781  8728 solver.cpp:244]     Train net output #1: loss = 0.00223358 (* 1 = 0.00223358 loss)
I0217 15:26:41.527781  8728 sgd_solver.cpp:106] Iteration 266900, lr = 0.0001
I0217 15:26:59.160354  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_267000.caffemodel
I0217 15:26:59.300859  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_267000.solverstate
I0217 15:26:59.366875  8728 solver.cpp:337] Iteration 267000, Testing net (#0)
I0217 15:26:59.366875  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:27:05.409243  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9454
I0217 15:27:05.409243  8728 solver.cpp:404]     Test net output #1: loss = 0.187821 (* 1 = 0.187821 loss)
I0217 15:27:05.480245  8728 solver.cpp:228] Iteration 267000, loss = 0.00081687
I0217 15:27:05.480245  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:27:05.480245  8728 solver.cpp:244]     Train net output #1: loss = 0.000816855 (* 1 = 0.000816855 loss)
I0217 15:27:05.480245  8728 sgd_solver.cpp:106] Iteration 267000, lr = 0.0001
I0217 15:27:23.183470  8728 solver.cpp:228] Iteration 267100, loss = 0.00178473
I0217 15:27:23.183470  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:27:23.183470  8728 solver.cpp:244]     Train net output #1: loss = 0.00178472 (* 1 = 0.00178472 loss)
I0217 15:27:23.183470  8728 sgd_solver.cpp:106] Iteration 267100, lr = 0.0001
I0217 15:27:40.885550  8728 solver.cpp:228] Iteration 267200, loss = 0.00141888
I0217 15:27:40.885550  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:27:40.885550  8728 solver.cpp:244]     Train net output #1: loss = 0.00141886 (* 1 = 0.00141886 loss)
I0217 15:27:40.885550  8728 sgd_solver.cpp:106] Iteration 267200, lr = 0.0001
I0217 15:27:58.595203  8728 solver.cpp:228] Iteration 267300, loss = 0.00214928
I0217 15:27:58.595203  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:27:58.595203  8728 solver.cpp:244]     Train net output #1: loss = 0.00214927 (* 1 = 0.00214927 loss)
I0217 15:27:58.595203  8728 sgd_solver.cpp:106] Iteration 267300, lr = 0.0001
I0217 15:28:16.308990  8728 solver.cpp:228] Iteration 267400, loss = 0.000432897
I0217 15:28:16.308990  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:28:16.308990  8728 solver.cpp:244]     Train net output #1: loss = 0.000432882 (* 1 = 0.000432882 loss)
I0217 15:28:16.308990  8728 sgd_solver.cpp:106] Iteration 267400, lr = 0.0001
I0217 15:28:33.940423  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_267500.caffemodel
I0217 15:28:34.080976  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_267500.solverstate
I0217 15:28:34.149471  8728 solver.cpp:337] Iteration 267500, Testing net (#0)
I0217 15:28:34.149471  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:28:40.190979  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9455
I0217 15:28:40.190979  8728 solver.cpp:404]     Test net output #1: loss = 0.187482 (* 1 = 0.187482 loss)
I0217 15:28:40.262037  8728 solver.cpp:228] Iteration 267500, loss = 0.00521362
I0217 15:28:40.262037  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:28:40.262037  8728 solver.cpp:244]     Train net output #1: loss = 0.00521361 (* 1 = 0.00521361 loss)
I0217 15:28:40.262037  8728 sgd_solver.cpp:106] Iteration 267500, lr = 0.0001
I0217 15:28:57.964423  8728 solver.cpp:228] Iteration 267600, loss = 0.00201395
I0217 15:28:57.964423  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:28:57.964423  8728 solver.cpp:244]     Train net output #1: loss = 0.00201393 (* 1 = 0.00201393 loss)
I0217 15:28:57.964423  8728 sgd_solver.cpp:106] Iteration 267600, lr = 0.0001
I0217 15:29:15.666275  8728 solver.cpp:228] Iteration 267700, loss = 0.00270501
I0217 15:29:15.666769  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:29:15.666769  8728 solver.cpp:244]     Train net output #1: loss = 0.00270499 (* 1 = 0.00270499 loss)
I0217 15:29:15.666769  8728 sgd_solver.cpp:106] Iteration 267700, lr = 0.0001
I0217 15:29:33.373714  8728 solver.cpp:228] Iteration 267800, loss = 0.00203419
I0217 15:29:33.373714  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:29:33.373714  8728 solver.cpp:244]     Train net output #1: loss = 0.00203418 (* 1 = 0.00203418 loss)
I0217 15:29:33.373714  8728 sgd_solver.cpp:106] Iteration 267800, lr = 0.0001
I0217 15:29:51.104549  8728 solver.cpp:228] Iteration 267900, loss = 0.00105811
I0217 15:29:51.104549  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:29:51.104549  8728 solver.cpp:244]     Train net output #1: loss = 0.0010581 (* 1 = 0.0010581 loss)
I0217 15:29:51.104549  8728 sgd_solver.cpp:106] Iteration 267900, lr = 0.0001
I0217 15:30:08.781656  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_268000.caffemodel
I0217 15:30:08.924695  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_268000.solverstate
I0217 15:30:08.990684  8728 solver.cpp:337] Iteration 268000, Testing net (#0)
I0217 15:30:08.990684  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:30:15.040221  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9449
I0217 15:30:15.040221  8728 solver.cpp:404]     Test net output #1: loss = 0.187649 (* 1 = 0.187649 loss)
I0217 15:30:15.112298  8728 solver.cpp:228] Iteration 268000, loss = 0.0015562
I0217 15:30:15.112298  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:30:15.112298  8728 solver.cpp:244]     Train net output #1: loss = 0.00155619 (* 1 = 0.00155619 loss)
I0217 15:30:15.112298  8728 sgd_solver.cpp:106] Iteration 268000, lr = 0.0001
I0217 15:30:32.947969  8728 solver.cpp:228] Iteration 268100, loss = 0.006894
I0217 15:30:32.947969  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:30:32.947969  8728 solver.cpp:244]     Train net output #1: loss = 0.00689398 (* 1 = 0.00689398 loss)
I0217 15:30:32.947969  8728 sgd_solver.cpp:106] Iteration 268100, lr = 0.0001
I0217 15:30:50.728106  8728 solver.cpp:228] Iteration 268200, loss = 0.000638257
I0217 15:30:50.728106  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:30:50.728106  8728 solver.cpp:244]     Train net output #1: loss = 0.000638244 (* 1 = 0.000638244 loss)
I0217 15:30:50.728106  8728 sgd_solver.cpp:106] Iteration 268200, lr = 0.0001
I0217 15:31:08.502125  8728 solver.cpp:228] Iteration 268300, loss = 0.00190429
I0217 15:31:08.502125  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:31:08.502125  8728 solver.cpp:244]     Train net output #1: loss = 0.00190428 (* 1 = 0.00190428 loss)
I0217 15:31:08.502125  8728 sgd_solver.cpp:106] Iteration 268300, lr = 0.0001
I0217 15:31:26.318747  8728 solver.cpp:228] Iteration 268400, loss = 0.000854797
I0217 15:31:26.318747  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:31:26.318747  8728 solver.cpp:244]     Train net output #1: loss = 0.000854783 (* 1 = 0.000854783 loss)
I0217 15:31:26.318747  8728 sgd_solver.cpp:106] Iteration 268400, lr = 0.0001
I0217 15:31:44.074672  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_268500.caffemodel
I0217 15:31:44.216701  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_268500.solverstate
I0217 15:31:44.282220  8728 solver.cpp:337] Iteration 268500, Testing net (#0)
I0217 15:31:44.282220  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:31:50.320076  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 15:31:50.320076  8728 solver.cpp:404]     Test net output #1: loss = 0.186978 (* 1 = 0.186978 loss)
I0217 15:31:50.391623  8728 solver.cpp:228] Iteration 268500, loss = 0.000960902
I0217 15:31:50.391623  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:31:50.391623  8728 solver.cpp:244]     Train net output #1: loss = 0.000960886 (* 1 = 0.000960886 loss)
I0217 15:31:50.391623  8728 sgd_solver.cpp:106] Iteration 268500, lr = 0.0001
I0217 15:32:08.150212  8728 solver.cpp:228] Iteration 268600, loss = 0.00310118
I0217 15:32:08.150212  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:32:08.150212  8728 solver.cpp:244]     Train net output #1: loss = 0.00310116 (* 1 = 0.00310116 loss)
I0217 15:32:08.150212  8728 sgd_solver.cpp:106] Iteration 268600, lr = 0.0001
I0217 15:32:25.938614  8728 solver.cpp:228] Iteration 268700, loss = 0.00228432
I0217 15:32:25.939115  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:32:25.939115  8728 solver.cpp:244]     Train net output #1: loss = 0.00228431 (* 1 = 0.00228431 loss)
I0217 15:32:25.939115  8728 sgd_solver.cpp:106] Iteration 268700, lr = 0.0001
I0217 15:32:43.788763  8728 solver.cpp:228] Iteration 268800, loss = 0.00260487
I0217 15:32:43.788763  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:32:43.788763  8728 solver.cpp:244]     Train net output #1: loss = 0.00260486 (* 1 = 0.00260486 loss)
I0217 15:32:43.788763  8728 sgd_solver.cpp:106] Iteration 268800, lr = 0.0001
I0217 15:33:01.598448  8728 solver.cpp:228] Iteration 268900, loss = 0.000921651
I0217 15:33:01.598448  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:33:01.598448  8728 solver.cpp:244]     Train net output #1: loss = 0.000921635 (* 1 = 0.000921635 loss)
I0217 15:33:01.598448  8728 sgd_solver.cpp:106] Iteration 268900, lr = 0.0001
I0217 15:33:19.349490  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_269000.caffemodel
I0217 15:33:19.490546  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_269000.solverstate
I0217 15:33:19.558550  8728 solver.cpp:337] Iteration 269000, Testing net (#0)
I0217 15:33:19.558550  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:33:25.616097  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 15:33:25.616097  8728 solver.cpp:404]     Test net output #1: loss = 0.187134 (* 1 = 0.187134 loss)
I0217 15:33:25.687616  8728 solver.cpp:228] Iteration 269000, loss = 0.000570919
I0217 15:33:25.688102  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:33:25.688102  8728 solver.cpp:244]     Train net output #1: loss = 0.000570903 (* 1 = 0.000570903 loss)
I0217 15:33:25.688102  8728 sgd_solver.cpp:106] Iteration 269000, lr = 0.0001
I0217 15:33:43.531661  8728 solver.cpp:228] Iteration 269100, loss = 0.00106984
I0217 15:33:43.531661  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:33:43.531661  8728 solver.cpp:244]     Train net output #1: loss = 0.00106983 (* 1 = 0.00106983 loss)
I0217 15:33:43.531661  8728 sgd_solver.cpp:106] Iteration 269100, lr = 0.0001
I0217 15:34:01.312305  8728 solver.cpp:228] Iteration 269200, loss = 0.00174523
I0217 15:34:01.312305  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:34:01.312305  8728 solver.cpp:244]     Train net output #1: loss = 0.00174521 (* 1 = 0.00174521 loss)
I0217 15:34:01.312305  8728 sgd_solver.cpp:106] Iteration 269200, lr = 0.0001
I0217 15:34:19.088790  8728 solver.cpp:228] Iteration 269300, loss = 0.00174821
I0217 15:34:19.088790  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:34:19.088790  8728 solver.cpp:244]     Train net output #1: loss = 0.00174819 (* 1 = 0.00174819 loss)
I0217 15:34:19.088790  8728 sgd_solver.cpp:106] Iteration 269300, lr = 0.0001
I0217 15:34:36.852088  8728 solver.cpp:228] Iteration 269400, loss = 0.00157649
I0217 15:34:36.852571  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:34:36.852571  8728 solver.cpp:244]     Train net output #1: loss = 0.00157648 (* 1 = 0.00157648 loss)
I0217 15:34:36.852571  8728 sgd_solver.cpp:106] Iteration 269400, lr = 0.0001
I0217 15:34:54.562752  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_269500.caffemodel
I0217 15:34:54.707768  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_269500.solverstate
I0217 15:34:54.779785  8728 solver.cpp:337] Iteration 269500, Testing net (#0)
I0217 15:34:54.779785  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:35:00.845068  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 15:35:00.845068  8728 solver.cpp:404]     Test net output #1: loss = 0.187202 (* 1 = 0.187202 loss)
I0217 15:35:00.918088  8728 solver.cpp:228] Iteration 269500, loss = 0.000726806
I0217 15:35:00.918088  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:35:00.918088  8728 solver.cpp:244]     Train net output #1: loss = 0.000726793 (* 1 = 0.000726793 loss)
I0217 15:35:00.918088  8728 sgd_solver.cpp:106] Iteration 269500, lr = 0.0001
I0217 15:35:18.696784  8728 solver.cpp:228] Iteration 269600, loss = 0.0013312
I0217 15:35:18.696784  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:35:18.696784  8728 solver.cpp:244]     Train net output #1: loss = 0.00133119 (* 1 = 0.00133119 loss)
I0217 15:35:18.696784  8728 sgd_solver.cpp:106] Iteration 269600, lr = 0.0001
I0217 15:35:36.534318  8728 solver.cpp:228] Iteration 269700, loss = 0.0012857
I0217 15:35:36.534318  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:35:36.534318  8728 solver.cpp:244]     Train net output #1: loss = 0.00128569 (* 1 = 0.00128569 loss)
I0217 15:35:36.534318  8728 sgd_solver.cpp:106] Iteration 269700, lr = 0.0001
I0217 15:35:54.331655  8728 solver.cpp:228] Iteration 269800, loss = 0.00187463
I0217 15:35:54.331655  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:35:54.331655  8728 solver.cpp:244]     Train net output #1: loss = 0.00187461 (* 1 = 0.00187461 loss)
I0217 15:35:54.331655  8728 sgd_solver.cpp:106] Iteration 269800, lr = 0.0001
I0217 15:36:12.140863  8728 solver.cpp:228] Iteration 269900, loss = 0.00104522
I0217 15:36:12.140863  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:36:12.140863  8728 solver.cpp:244]     Train net output #1: loss = 0.00104521 (* 1 = 0.00104521 loss)
I0217 15:36:12.140863  8728 sgd_solver.cpp:106] Iteration 269900, lr = 0.0001
I0217 15:36:29.937927  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_270000.caffemodel
I0217 15:36:30.078963  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_270000.solverstate
I0217 15:36:30.147001  8728 solver.cpp:337] Iteration 270000, Testing net (#0)
I0217 15:36:30.147001  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:36:36.220389  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 15:36:36.220389  8728 solver.cpp:404]     Test net output #1: loss = 0.187175 (* 1 = 0.187175 loss)
I0217 15:36:36.291419  8728 solver.cpp:228] Iteration 270000, loss = 0.000761695
I0217 15:36:36.291419  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:36:36.291419  8728 solver.cpp:244]     Train net output #1: loss = 0.00076169 (* 1 = 0.00076169 loss)
I0217 15:36:36.291419  8728 sgd_solver.cpp:106] Iteration 270000, lr = 0.0001
I0217 15:36:54.066751  8728 solver.cpp:228] Iteration 270100, loss = 0.00844037
I0217 15:36:54.066751  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 15:36:54.066751  8728 solver.cpp:244]     Train net output #1: loss = 0.00844037 (* 1 = 0.00844037 loss)
I0217 15:36:54.066751  8728 sgd_solver.cpp:106] Iteration 270100, lr = 0.0001
I0217 15:37:11.915756  8728 solver.cpp:228] Iteration 270200, loss = 0.00199383
I0217 15:37:11.915756  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:37:11.915756  8728 solver.cpp:244]     Train net output #1: loss = 0.00199383 (* 1 = 0.00199383 loss)
I0217 15:37:11.915756  8728 sgd_solver.cpp:106] Iteration 270200, lr = 0.0001
I0217 15:37:29.640337  8728 solver.cpp:228] Iteration 270300, loss = 0.00068387
I0217 15:37:29.640337  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:37:29.640337  8728 solver.cpp:244]     Train net output #1: loss = 0.000683864 (* 1 = 0.000683864 loss)
I0217 15:37:29.640337  8728 sgd_solver.cpp:106] Iteration 270300, lr = 0.0001
I0217 15:37:47.360010  8728 solver.cpp:228] Iteration 270400, loss = 0.000497893
I0217 15:37:47.360010  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:37:47.360010  8728 solver.cpp:244]     Train net output #1: loss = 0.000497887 (* 1 = 0.000497887 loss)
I0217 15:37:47.360010  8728 sgd_solver.cpp:106] Iteration 270400, lr = 0.0001
I0217 15:38:05.039531  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_270500.caffemodel
I0217 15:38:05.197041  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_270500.solverstate
I0217 15:38:05.270037  8728 solver.cpp:337] Iteration 270500, Testing net (#0)
I0217 15:38:05.270037  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:38:11.346135  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 15:38:11.346135  8728 solver.cpp:404]     Test net output #1: loss = 0.186269 (* 1 = 0.186269 loss)
I0217 15:38:11.417173  8728 solver.cpp:228] Iteration 270500, loss = 0.00453079
I0217 15:38:11.417173  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:38:11.417173  8728 solver.cpp:244]     Train net output #1: loss = 0.00453078 (* 1 = 0.00453078 loss)
I0217 15:38:11.417173  8728 sgd_solver.cpp:106] Iteration 270500, lr = 0.0001
I0217 15:38:29.202958  8728 solver.cpp:228] Iteration 270600, loss = 0.0013424
I0217 15:38:29.202958  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:38:29.202958  8728 solver.cpp:244]     Train net output #1: loss = 0.00134239 (* 1 = 0.00134239 loss)
I0217 15:38:29.202958  8728 sgd_solver.cpp:106] Iteration 270600, lr = 0.0001
I0217 15:38:46.969329  8728 solver.cpp:228] Iteration 270700, loss = 0.00143912
I0217 15:38:46.969329  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:38:46.969329  8728 solver.cpp:244]     Train net output #1: loss = 0.00143911 (* 1 = 0.00143911 loss)
I0217 15:38:46.969329  8728 sgd_solver.cpp:106] Iteration 270700, lr = 0.0001
I0217 15:39:04.733173  8728 solver.cpp:228] Iteration 270800, loss = 0.00111162
I0217 15:39:04.733173  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:39:04.733173  8728 solver.cpp:244]     Train net output #1: loss = 0.00111162 (* 1 = 0.00111162 loss)
I0217 15:39:04.733173  8728 sgd_solver.cpp:106] Iteration 270800, lr = 0.0001
I0217 15:39:22.470404  8728 solver.cpp:228] Iteration 270900, loss = 0.000850708
I0217 15:39:22.470404  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:39:22.470404  8728 solver.cpp:244]     Train net output #1: loss = 0.0008507 (* 1 = 0.0008507 loss)
I0217 15:39:22.470404  8728 sgd_solver.cpp:106] Iteration 270900, lr = 0.0001
I0217 15:39:40.134567  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_271000.caffemodel
I0217 15:39:40.274047  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_271000.solverstate
I0217 15:39:40.341048  8728 solver.cpp:337] Iteration 271000, Testing net (#0)
I0217 15:39:40.341048  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:39:46.399175  8728 solver.cpp:404]     Test net output #0: accuracy = 0.946
I0217 15:39:46.399175  8728 solver.cpp:404]     Test net output #1: loss = 0.186906 (* 1 = 0.186906 loss)
I0217 15:39:46.469719  8728 solver.cpp:228] Iteration 271000, loss = 0.00124631
I0217 15:39:46.469719  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:39:46.469719  8728 solver.cpp:244]     Train net output #1: loss = 0.0012463 (* 1 = 0.0012463 loss)
I0217 15:39:46.469719  8728 sgd_solver.cpp:106] Iteration 271000, lr = 0.0001
I0217 15:40:04.277671  8728 solver.cpp:228] Iteration 271100, loss = 0.00136026
I0217 15:40:04.277671  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:40:04.277671  8728 solver.cpp:244]     Train net output #1: loss = 0.00136025 (* 1 = 0.00136025 loss)
I0217 15:40:04.277671  8728 sgd_solver.cpp:106] Iteration 271100, lr = 0.0001
I0217 15:40:22.080790  8728 solver.cpp:228] Iteration 271200, loss = 0.0012963
I0217 15:40:22.080790  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:40:22.080790  8728 solver.cpp:244]     Train net output #1: loss = 0.00129629 (* 1 = 0.00129629 loss)
I0217 15:40:22.080790  8728 sgd_solver.cpp:106] Iteration 271200, lr = 0.0001
I0217 15:40:39.870795  8728 solver.cpp:228] Iteration 271300, loss = 0.00263671
I0217 15:40:39.870795  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:40:39.870795  8728 solver.cpp:244]     Train net output #1: loss = 0.00263671 (* 1 = 0.00263671 loss)
I0217 15:40:39.870795  8728 sgd_solver.cpp:106] Iteration 271300, lr = 0.0001
I0217 15:40:57.613126  8728 solver.cpp:228] Iteration 271400, loss = 0.00212452
I0217 15:40:57.613612  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:40:57.613612  8728 solver.cpp:244]     Train net output #1: loss = 0.00212451 (* 1 = 0.00212451 loss)
I0217 15:40:57.613612  8728 sgd_solver.cpp:106] Iteration 271400, lr = 0.0001
I0217 15:41:15.254565  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_271500.caffemodel
I0217 15:41:15.396564  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_271500.solverstate
I0217 15:41:15.463573  8728 solver.cpp:337] Iteration 271500, Testing net (#0)
I0217 15:41:15.463573  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:41:21.510555  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9449
I0217 15:41:21.510555  8728 solver.cpp:404]     Test net output #1: loss = 0.187069 (* 1 = 0.187069 loss)
I0217 15:41:21.581564  8728 solver.cpp:228] Iteration 271500, loss = 0.0030844
I0217 15:41:21.581564  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:41:21.581564  8728 solver.cpp:244]     Train net output #1: loss = 0.00308439 (* 1 = 0.00308439 loss)
I0217 15:41:21.581564  8728 sgd_solver.cpp:106] Iteration 271500, lr = 0.0001
I0217 15:41:39.336305  8728 solver.cpp:228] Iteration 271600, loss = 0.00358321
I0217 15:41:39.336305  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:41:39.336305  8728 solver.cpp:244]     Train net output #1: loss = 0.0035832 (* 1 = 0.0035832 loss)
I0217 15:41:39.336305  8728 sgd_solver.cpp:106] Iteration 271600, lr = 0.0001
I0217 15:41:57.319473  8728 solver.cpp:228] Iteration 271700, loss = 0.00253824
I0217 15:41:57.319473  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:41:57.319473  8728 solver.cpp:244]     Train net output #1: loss = 0.00253823 (* 1 = 0.00253823 loss)
I0217 15:41:57.319473  8728 sgd_solver.cpp:106] Iteration 271700, lr = 0.0001
I0217 15:42:15.296638  8728 solver.cpp:228] Iteration 271800, loss = 0.00112076
I0217 15:42:15.296638  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:42:15.296638  8728 solver.cpp:244]     Train net output #1: loss = 0.00112076 (* 1 = 0.00112076 loss)
I0217 15:42:15.296638  8728 sgd_solver.cpp:106] Iteration 271800, lr = 0.0001
I0217 15:42:33.484814  8728 solver.cpp:228] Iteration 271900, loss = 0.0050757
I0217 15:42:33.484814  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:42:33.484814  8728 solver.cpp:244]     Train net output #1: loss = 0.00507569 (* 1 = 0.00507569 loss)
I0217 15:42:33.484814  8728 sgd_solver.cpp:106] Iteration 271900, lr = 0.0001
I0217 15:42:51.406502  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_272000.caffemodel
I0217 15:42:51.551008  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_272000.solverstate
I0217 15:42:51.621508  8728 solver.cpp:337] Iteration 272000, Testing net (#0)
I0217 15:42:51.621508  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:42:57.820410  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9448
I0217 15:42:57.820410  8728 solver.cpp:404]     Test net output #1: loss = 0.187025 (* 1 = 0.187025 loss)
I0217 15:42:57.891474  8728 solver.cpp:228] Iteration 272000, loss = 0.00120681
I0217 15:42:57.891474  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:42:57.891474  8728 solver.cpp:244]     Train net output #1: loss = 0.00120681 (* 1 = 0.00120681 loss)
I0217 15:42:57.891474  8728 sgd_solver.cpp:106] Iteration 272000, lr = 0.0001
I0217 15:43:15.691315  8728 solver.cpp:228] Iteration 272100, loss = 0.00086677
I0217 15:43:15.691315  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:43:15.691315  8728 solver.cpp:244]     Train net output #1: loss = 0.000866765 (* 1 = 0.000866765 loss)
I0217 15:43:15.691315  8728 sgd_solver.cpp:106] Iteration 272100, lr = 0.0001
I0217 15:43:33.466478  8728 solver.cpp:228] Iteration 272200, loss = 0.00327837
I0217 15:43:33.466478  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:43:33.466478  8728 solver.cpp:244]     Train net output #1: loss = 0.00327837 (* 1 = 0.00327837 loss)
I0217 15:43:33.466478  8728 sgd_solver.cpp:106] Iteration 272200, lr = 0.0001
I0217 15:43:51.216832  8728 solver.cpp:228] Iteration 272300, loss = 0.00320076
I0217 15:43:51.216832  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:43:51.216832  8728 solver.cpp:244]     Train net output #1: loss = 0.00320075 (* 1 = 0.00320075 loss)
I0217 15:43:51.216832  8728 sgd_solver.cpp:106] Iteration 272300, lr = 0.0001
I0217 15:44:08.985771  8728 solver.cpp:228] Iteration 272400, loss = 0.00242626
I0217 15:44:08.985771  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:44:08.985771  8728 solver.cpp:244]     Train net output #1: loss = 0.00242626 (* 1 = 0.00242626 loss)
I0217 15:44:08.985771  8728 sgd_solver.cpp:106] Iteration 272400, lr = 0.0001
I0217 15:44:26.664712  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_272500.caffemodel
I0217 15:44:26.807735  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_272500.solverstate
I0217 15:44:26.876768  8728 solver.cpp:337] Iteration 272500, Testing net (#0)
I0217 15:44:26.876768  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:44:32.948470  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9446
I0217 15:44:32.948470  8728 solver.cpp:404]     Test net output #1: loss = 0.187105 (* 1 = 0.187105 loss)
I0217 15:44:33.019523  8728 solver.cpp:228] Iteration 272500, loss = 0.00453169
I0217 15:44:33.019523  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:44:33.019523  8728 solver.cpp:244]     Train net output #1: loss = 0.00453169 (* 1 = 0.00453169 loss)
I0217 15:44:33.019523  8728 sgd_solver.cpp:106] Iteration 272500, lr = 0.0001
I0217 15:44:50.783757  8728 solver.cpp:228] Iteration 272600, loss = 0.00188416
I0217 15:44:50.783757  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:44:50.783757  8728 solver.cpp:244]     Train net output #1: loss = 0.00188416 (* 1 = 0.00188416 loss)
I0217 15:44:50.783757  8728 sgd_solver.cpp:106] Iteration 272600, lr = 0.0001
I0217 15:45:08.576340  8728 solver.cpp:228] Iteration 272700, loss = 0.00153364
I0217 15:45:08.576340  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:45:08.576340  8728 solver.cpp:244]     Train net output #1: loss = 0.00153364 (* 1 = 0.00153364 loss)
I0217 15:45:08.576340  8728 sgd_solver.cpp:106] Iteration 272700, lr = 0.0001
I0217 15:45:26.406261  8728 solver.cpp:228] Iteration 272800, loss = 0.0010759
I0217 15:45:26.406261  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:45:26.406261  8728 solver.cpp:244]     Train net output #1: loss = 0.00107589 (* 1 = 0.00107589 loss)
I0217 15:45:26.406261  8728 sgd_solver.cpp:106] Iteration 272800, lr = 0.0001
I0217 15:45:44.175942  8728 solver.cpp:228] Iteration 272900, loss = 0.00325522
I0217 15:45:44.175942  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:45:44.175942  8728 solver.cpp:244]     Train net output #1: loss = 0.00325522 (* 1 = 0.00325522 loss)
I0217 15:45:44.175942  8728 sgd_solver.cpp:106] Iteration 272900, lr = 0.0001
I0217 15:46:01.860972  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_273000.caffemodel
I0217 15:46:02.002477  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_273000.solverstate
I0217 15:46:02.066992  8728 solver.cpp:337] Iteration 273000, Testing net (#0)
I0217 15:46:02.067992  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:46:08.137328  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0217 15:46:08.137328  8728 solver.cpp:404]     Test net output #1: loss = 0.186865 (* 1 = 0.186865 loss)
I0217 15:46:08.208874  8728 solver.cpp:228] Iteration 273000, loss = 0.00244813
I0217 15:46:08.208874  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:46:08.208874  8728 solver.cpp:244]     Train net output #1: loss = 0.00244813 (* 1 = 0.00244813 loss)
I0217 15:46:08.208874  8728 sgd_solver.cpp:106] Iteration 273000, lr = 0.0001
I0217 15:46:25.996635  8728 solver.cpp:228] Iteration 273100, loss = 0.00204107
I0217 15:46:25.996635  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:46:25.996635  8728 solver.cpp:244]     Train net output #1: loss = 0.00204107 (* 1 = 0.00204107 loss)
I0217 15:46:25.996635  8728 sgd_solver.cpp:106] Iteration 273100, lr = 0.0001
I0217 15:46:43.780055  8728 solver.cpp:228] Iteration 273200, loss = 0.000907466
I0217 15:46:43.780055  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:46:43.780055  8728 solver.cpp:244]     Train net output #1: loss = 0.000907468 (* 1 = 0.000907468 loss)
I0217 15:46:43.780055  8728 sgd_solver.cpp:106] Iteration 273200, lr = 0.0001
I0217 15:47:01.549587  8728 solver.cpp:228] Iteration 273300, loss = 0.00234981
I0217 15:47:01.549587  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:47:01.549587  8728 solver.cpp:244]     Train net output #1: loss = 0.00234981 (* 1 = 0.00234981 loss)
I0217 15:47:01.549587  8728 sgd_solver.cpp:106] Iteration 273300, lr = 0.0001
I0217 15:47:19.407865  8728 solver.cpp:228] Iteration 273400, loss = 0.00132766
I0217 15:47:19.407865  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:47:19.407865  8728 solver.cpp:244]     Train net output #1: loss = 0.00132766 (* 1 = 0.00132766 loss)
I0217 15:47:19.407865  8728 sgd_solver.cpp:106] Iteration 273400, lr = 0.0001
I0217 15:47:37.155514  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_273500.caffemodel
I0217 15:47:37.298540  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_273500.solverstate
I0217 15:47:37.364198  8728 solver.cpp:337] Iteration 273500, Testing net (#0)
I0217 15:47:37.364198  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:47:43.480428  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0217 15:47:43.480428  8728 solver.cpp:404]     Test net output #1: loss = 0.187004 (* 1 = 0.187004 loss)
I0217 15:47:43.552498  8728 solver.cpp:228] Iteration 273500, loss = 0.000865803
I0217 15:47:43.552498  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:47:43.552498  8728 solver.cpp:244]     Train net output #1: loss = 0.000865804 (* 1 = 0.000865804 loss)
I0217 15:47:43.552498  8728 sgd_solver.cpp:106] Iteration 273500, lr = 0.0001
I0217 15:48:01.493640  8728 solver.cpp:228] Iteration 273600, loss = 0.00377611
I0217 15:48:01.493640  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:48:01.493640  8728 solver.cpp:244]     Train net output #1: loss = 0.00377611 (* 1 = 0.00377611 loss)
I0217 15:48:01.493640  8728 sgd_solver.cpp:106] Iteration 273600, lr = 0.0001
I0217 15:48:19.256279  8728 solver.cpp:228] Iteration 273700, loss = 0.0023812
I0217 15:48:19.256279  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:48:19.256279  8728 solver.cpp:244]     Train net output #1: loss = 0.0023812 (* 1 = 0.0023812 loss)
I0217 15:48:19.256279  8728 sgd_solver.cpp:106] Iteration 273700, lr = 0.0001
I0217 15:48:37.087287  8728 solver.cpp:228] Iteration 273800, loss = 0.000916986
I0217 15:48:37.087287  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:48:37.087796  8728 solver.cpp:244]     Train net output #1: loss = 0.000916988 (* 1 = 0.000916988 loss)
I0217 15:48:37.087796  8728 sgd_solver.cpp:106] Iteration 273800, lr = 0.0001
I0217 15:48:55.174705  8728 solver.cpp:228] Iteration 273900, loss = 0.00404789
I0217 15:48:55.174705  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:48:55.174705  8728 solver.cpp:244]     Train net output #1: loss = 0.00404789 (* 1 = 0.00404789 loss)
I0217 15:48:55.174705  8728 sgd_solver.cpp:106] Iteration 273900, lr = 0.0001
I0217 15:49:13.079031  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_274000.caffemodel
I0217 15:49:13.220052  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_274000.solverstate
I0217 15:49:13.286094  8728 solver.cpp:337] Iteration 274000, Testing net (#0)
I0217 15:49:13.287096  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:49:19.439155  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 15:49:19.439155  8728 solver.cpp:404]     Test net output #1: loss = 0.186787 (* 1 = 0.186787 loss)
I0217 15:49:19.511322  8728 solver.cpp:228] Iteration 274000, loss = 0.00187824
I0217 15:49:19.511322  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:49:19.511322  8728 solver.cpp:244]     Train net output #1: loss = 0.00187824 (* 1 = 0.00187824 loss)
I0217 15:49:19.511322  8728 sgd_solver.cpp:106] Iteration 274000, lr = 0.0001
I0217 15:49:37.629976  8728 solver.cpp:228] Iteration 274100, loss = 0.00218107
I0217 15:49:37.629976  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:49:37.629976  8728 solver.cpp:244]     Train net output #1: loss = 0.00218107 (* 1 = 0.00218107 loss)
I0217 15:49:37.629976  8728 sgd_solver.cpp:106] Iteration 274100, lr = 0.0001
I0217 15:49:55.735515  8728 solver.cpp:228] Iteration 274200, loss = 0.000451016
I0217 15:49:55.735515  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:49:55.735515  8728 solver.cpp:244]     Train net output #1: loss = 0.000451019 (* 1 = 0.000451019 loss)
I0217 15:49:55.735515  8728 sgd_solver.cpp:106] Iteration 274200, lr = 0.0001
I0217 15:50:13.763989  8728 solver.cpp:228] Iteration 274300, loss = 0.00133805
I0217 15:50:13.763989  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:50:13.763989  8728 solver.cpp:244]     Train net output #1: loss = 0.00133806 (* 1 = 0.00133806 loss)
I0217 15:50:13.763989  8728 sgd_solver.cpp:106] Iteration 274300, lr = 0.0001
I0217 15:50:31.750458  8728 solver.cpp:228] Iteration 274400, loss = 0.00136651
I0217 15:50:31.750458  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:50:31.750458  8728 solver.cpp:244]     Train net output #1: loss = 0.00136652 (* 1 = 0.00136652 loss)
I0217 15:50:31.750458  8728 sgd_solver.cpp:106] Iteration 274400, lr = 0.0001
I0217 15:50:49.750576  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_274500.caffemodel
I0217 15:50:49.891643  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_274500.solverstate
I0217 15:50:50.007735  8728 solver.cpp:337] Iteration 274500, Testing net (#0)
I0217 15:50:50.007735  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:50:56.283468  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9451
I0217 15:50:56.283468  8728 solver.cpp:404]     Test net output #1: loss = 0.187117 (* 1 = 0.187117 loss)
I0217 15:50:56.363667  8728 solver.cpp:228] Iteration 274500, loss = 0.00284758
I0217 15:50:56.363667  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:50:56.364164  8728 solver.cpp:244]     Train net output #1: loss = 0.00284759 (* 1 = 0.00284759 loss)
I0217 15:50:56.364164  8728 sgd_solver.cpp:106] Iteration 274500, lr = 0.0001
I0217 15:51:14.365453  8728 solver.cpp:228] Iteration 274600, loss = 0.00138786
I0217 15:51:14.365453  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:51:14.365453  8728 solver.cpp:244]     Train net output #1: loss = 0.00138787 (* 1 = 0.00138787 loss)
I0217 15:51:14.365453  8728 sgd_solver.cpp:106] Iteration 274600, lr = 0.0001
I0217 15:51:32.742818  8728 solver.cpp:228] Iteration 274700, loss = 0.00196704
I0217 15:51:32.742818  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:51:32.742818  8728 solver.cpp:244]     Train net output #1: loss = 0.00196705 (* 1 = 0.00196705 loss)
I0217 15:51:32.742818  8728 sgd_solver.cpp:106] Iteration 274700, lr = 0.0001
I0217 15:51:51.183831  8728 solver.cpp:228] Iteration 274800, loss = 0.00104171
I0217 15:51:51.183831  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:51:51.183831  8728 solver.cpp:244]     Train net output #1: loss = 0.00104172 (* 1 = 0.00104172 loss)
I0217 15:51:51.183831  8728 sgd_solver.cpp:106] Iteration 274800, lr = 0.0001
I0217 15:52:09.340945  8728 solver.cpp:228] Iteration 274900, loss = 0.000834934
I0217 15:52:09.340945  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:52:09.340945  8728 solver.cpp:244]     Train net output #1: loss = 0.00083494 (* 1 = 0.00083494 loss)
I0217 15:52:09.340945  8728 sgd_solver.cpp:106] Iteration 274900, lr = 0.0001
I0217 15:52:27.765537  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_275000.caffemodel
I0217 15:52:27.913085  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_275000.solverstate
I0217 15:52:27.984097  8728 solver.cpp:337] Iteration 275000, Testing net (#0)
I0217 15:52:27.984591  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:52:34.431048  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9449
I0217 15:52:34.431048  8728 solver.cpp:404]     Test net output #1: loss = 0.186778 (* 1 = 0.186778 loss)
I0217 15:52:34.509140  8728 solver.cpp:228] Iteration 275000, loss = 0.00300701
I0217 15:52:34.509613  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:52:34.509613  8728 solver.cpp:244]     Train net output #1: loss = 0.00300701 (* 1 = 0.00300701 loss)
I0217 15:52:34.509613  8728 sgd_solver.cpp:106] Iteration 275000, lr = 0.0001
I0217 15:52:52.730900  8728 solver.cpp:228] Iteration 275100, loss = 0.00170151
I0217 15:52:52.730900  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:52:52.730900  8728 solver.cpp:244]     Train net output #1: loss = 0.00170151 (* 1 = 0.00170151 loss)
I0217 15:52:52.730900  8728 sgd_solver.cpp:106] Iteration 275100, lr = 0.0001
I0217 15:53:11.055541  8728 solver.cpp:228] Iteration 275200, loss = 0.00206567
I0217 15:53:11.055541  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:53:11.055541  8728 solver.cpp:244]     Train net output #1: loss = 0.00206567 (* 1 = 0.00206567 loss)
I0217 15:53:11.055541  8728 sgd_solver.cpp:106] Iteration 275200, lr = 0.0001
I0217 15:53:29.513267  8728 solver.cpp:228] Iteration 275300, loss = 0.000989025
I0217 15:53:29.513267  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:53:29.513267  8728 solver.cpp:244]     Train net output #1: loss = 0.000989027 (* 1 = 0.000989027 loss)
I0217 15:53:29.513267  8728 sgd_solver.cpp:106] Iteration 275300, lr = 0.0001
I0217 15:53:47.848531  8728 solver.cpp:228] Iteration 275400, loss = 0.00536218
I0217 15:53:47.848531  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:53:47.848531  8728 solver.cpp:244]     Train net output #1: loss = 0.00536218 (* 1 = 0.00536218 loss)
I0217 15:53:47.848531  8728 sgd_solver.cpp:106] Iteration 275400, lr = 0.0001
I0217 15:54:06.067456  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_275500.caffemodel
I0217 15:54:06.210467  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_275500.solverstate
I0217 15:54:06.375895  8728 solver.cpp:337] Iteration 275500, Testing net (#0)
I0217 15:54:06.375895  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:54:12.596637  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9449
I0217 15:54:12.596637  8728 solver.cpp:404]     Test net output #1: loss = 0.186659 (* 1 = 0.186659 loss)
I0217 15:54:12.668645  8728 solver.cpp:228] Iteration 275500, loss = 0.0014456
I0217 15:54:12.668645  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:54:12.668645  8728 solver.cpp:244]     Train net output #1: loss = 0.00144561 (* 1 = 0.00144561 loss)
I0217 15:54:12.668645  8728 sgd_solver.cpp:106] Iteration 275500, lr = 0.0001
I0217 15:54:30.776034  8728 solver.cpp:228] Iteration 275600, loss = 0.0020904
I0217 15:54:30.776034  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:54:30.776034  8728 solver.cpp:244]     Train net output #1: loss = 0.0020904 (* 1 = 0.0020904 loss)
I0217 15:54:30.776034  8728 sgd_solver.cpp:106] Iteration 275600, lr = 0.0001
I0217 15:54:48.864207  8728 solver.cpp:228] Iteration 275700, loss = 0.00596819
I0217 15:54:48.864207  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:54:48.864207  8728 solver.cpp:244]     Train net output #1: loss = 0.00596819 (* 1 = 0.00596819 loss)
I0217 15:54:48.864207  8728 sgd_solver.cpp:106] Iteration 275700, lr = 0.0001
I0217 15:55:06.946979  8728 solver.cpp:228] Iteration 275800, loss = 0.000934096
I0217 15:55:06.946979  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:55:06.946979  8728 solver.cpp:244]     Train net output #1: loss = 0.000934099 (* 1 = 0.000934099 loss)
I0217 15:55:06.946979  8728 sgd_solver.cpp:106] Iteration 275800, lr = 0.0001
I0217 15:55:25.206727  8728 solver.cpp:228] Iteration 275900, loss = 0.0012741
I0217 15:55:25.206727  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:55:25.206727  8728 solver.cpp:244]     Train net output #1: loss = 0.00127411 (* 1 = 0.00127411 loss)
I0217 15:55:25.206727  8728 sgd_solver.cpp:106] Iteration 275900, lr = 0.0001
I0217 15:55:43.311503  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_276000.caffemodel
I0217 15:55:43.452055  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_276000.solverstate
I0217 15:55:43.523555  8728 solver.cpp:337] Iteration 276000, Testing net (#0)
I0217 15:55:43.523555  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:55:49.719646  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9451
I0217 15:55:49.719646  8728 solver.cpp:404]     Test net output #1: loss = 0.186908 (* 1 = 0.186908 loss)
I0217 15:55:49.792172  8728 solver.cpp:228] Iteration 276000, loss = 0.00246991
I0217 15:55:49.792172  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:55:49.792172  8728 solver.cpp:244]     Train net output #1: loss = 0.00246991 (* 1 = 0.00246991 loss)
I0217 15:55:49.792172  8728 sgd_solver.cpp:106] Iteration 276000, lr = 0.0001
I0217 15:56:07.837036  8728 solver.cpp:228] Iteration 276100, loss = 0.00386305
I0217 15:56:07.837036  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:56:07.837554  8728 solver.cpp:244]     Train net output #1: loss = 0.00386305 (* 1 = 0.00386305 loss)
I0217 15:56:07.837554  8728 sgd_solver.cpp:106] Iteration 276100, lr = 0.0001
I0217 15:56:25.867207  8728 solver.cpp:228] Iteration 276200, loss = 0.000888598
I0217 15:56:25.867207  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:56:25.867207  8728 solver.cpp:244]     Train net output #1: loss = 0.000888599 (* 1 = 0.000888599 loss)
I0217 15:56:25.867207  8728 sgd_solver.cpp:106] Iteration 276200, lr = 0.0001
I0217 15:56:43.900285  8728 solver.cpp:228] Iteration 276300, loss = 0.00147527
I0217 15:56:43.900285  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:56:43.900285  8728 solver.cpp:244]     Train net output #1: loss = 0.00147527 (* 1 = 0.00147527 loss)
I0217 15:56:43.900285  8728 sgd_solver.cpp:106] Iteration 276300, lr = 0.0001
I0217 15:57:01.941260  8728 solver.cpp:228] Iteration 276400, loss = 0.000946618
I0217 15:57:01.941260  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:57:01.941260  8728 solver.cpp:244]     Train net output #1: loss = 0.000946616 (* 1 = 0.000946616 loss)
I0217 15:57:01.941260  8728 sgd_solver.cpp:106] Iteration 276400, lr = 0.0001
I0217 15:57:19.885754  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_276500.caffemodel
I0217 15:57:20.027272  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_276500.solverstate
I0217 15:57:20.093785  8728 solver.cpp:337] Iteration 276500, Testing net (#0)
I0217 15:57:20.094784  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:57:26.278497  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9451
I0217 15:57:26.278497  8728 solver.cpp:404]     Test net output #1: loss = 0.187577 (* 1 = 0.187577 loss)
I0217 15:57:26.350569  8728 solver.cpp:228] Iteration 276500, loss = 0.00324051
I0217 15:57:26.350569  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:57:26.350569  8728 solver.cpp:244]     Train net output #1: loss = 0.00324051 (* 1 = 0.00324051 loss)
I0217 15:57:26.350569  8728 sgd_solver.cpp:106] Iteration 276500, lr = 0.0001
I0217 15:57:44.394804  8728 solver.cpp:228] Iteration 276600, loss = 0.011805
I0217 15:57:44.394804  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 15:57:44.394804  8728 solver.cpp:244]     Train net output #1: loss = 0.011805 (* 1 = 0.011805 loss)
I0217 15:57:44.394804  8728 sgd_solver.cpp:106] Iteration 276600, lr = 0.0001
I0217 15:58:02.373836  8728 solver.cpp:228] Iteration 276700, loss = 0.00336777
I0217 15:58:02.373836  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:58:02.373836  8728 solver.cpp:244]     Train net output #1: loss = 0.00336777 (* 1 = 0.00336777 loss)
I0217 15:58:02.373836  8728 sgd_solver.cpp:106] Iteration 276700, lr = 0.0001
I0217 15:58:20.398107  8728 solver.cpp:228] Iteration 276800, loss = 0.000732464
I0217 15:58:20.398107  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:58:20.398107  8728 solver.cpp:244]     Train net output #1: loss = 0.000732465 (* 1 = 0.000732465 loss)
I0217 15:58:20.398107  8728 sgd_solver.cpp:106] Iteration 276800, lr = 0.0001
I0217 15:58:38.593303  8728 solver.cpp:228] Iteration 276900, loss = 0.00184466
I0217 15:58:38.593303  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:58:38.593303  8728 solver.cpp:244]     Train net output #1: loss = 0.00184466 (* 1 = 0.00184466 loss)
I0217 15:58:38.593303  8728 sgd_solver.cpp:106] Iteration 276900, lr = 0.0001
I0217 15:58:57.002285  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_277000.caffemodel
I0217 15:58:57.153307  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_277000.solverstate
I0217 15:58:57.222348  8728 solver.cpp:337] Iteration 277000, Testing net (#0)
I0217 15:58:57.222348  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 15:59:03.621728  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9448
I0217 15:59:03.621728  8728 solver.cpp:404]     Test net output #1: loss = 0.18816 (* 1 = 0.18816 loss)
I0217 15:59:03.694479  8728 solver.cpp:228] Iteration 277000, loss = 0.00196551
I0217 15:59:03.694479  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:59:03.694479  8728 solver.cpp:244]     Train net output #1: loss = 0.00196551 (* 1 = 0.00196551 loss)
I0217 15:59:03.694479  8728 sgd_solver.cpp:106] Iteration 277000, lr = 0.0001
I0217 15:59:21.896308  8728 solver.cpp:228] Iteration 277100, loss = 0.00380795
I0217 15:59:21.896308  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:59:21.896308  8728 solver.cpp:244]     Train net output #1: loss = 0.00380795 (* 1 = 0.00380795 loss)
I0217 15:59:21.896308  8728 sgd_solver.cpp:106] Iteration 277100, lr = 0.0001
I0217 15:59:40.087110  8728 solver.cpp:228] Iteration 277200, loss = 0.000482639
I0217 15:59:40.087110  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:59:40.087110  8728 solver.cpp:244]     Train net output #1: loss = 0.000482639 (* 1 = 0.000482639 loss)
I0217 15:59:40.087110  8728 sgd_solver.cpp:106] Iteration 277200, lr = 0.0001
I0217 15:59:58.330952  8728 solver.cpp:228] Iteration 277300, loss = 0.00102646
I0217 15:59:58.330952  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 15:59:58.330952  8728 solver.cpp:244]     Train net output #1: loss = 0.00102646 (* 1 = 0.00102646 loss)
I0217 15:59:58.330952  8728 sgd_solver.cpp:106] Iteration 277300, lr = 0.0001
I0217 16:00:16.656419  8728 solver.cpp:228] Iteration 277400, loss = 0.00115698
I0217 16:00:16.656419  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:00:16.656419  8728 solver.cpp:244]     Train net output #1: loss = 0.00115699 (* 1 = 0.00115699 loss)
I0217 16:00:16.656419  8728 sgd_solver.cpp:106] Iteration 277400, lr = 0.0001
I0217 16:00:34.859877  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_277500.caffemodel
I0217 16:00:35.004376  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_277500.solverstate
I0217 16:00:35.070894  8728 solver.cpp:337] Iteration 277500, Testing net (#0)
I0217 16:00:35.071374  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:00:41.404021  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9454
I0217 16:00:41.404021  8728 solver.cpp:404]     Test net output #1: loss = 0.188167 (* 1 = 0.188167 loss)
I0217 16:00:41.475983  8728 solver.cpp:228] Iteration 277500, loss = 0.00297699
I0217 16:00:41.475983  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:00:41.475983  8728 solver.cpp:244]     Train net output #1: loss = 0.00297699 (* 1 = 0.00297699 loss)
I0217 16:00:41.475983  8728 sgd_solver.cpp:106] Iteration 277500, lr = 0.0001
I0217 16:00:59.514183  8728 solver.cpp:228] Iteration 277600, loss = 0.00189935
I0217 16:00:59.514183  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:00:59.514183  8728 solver.cpp:244]     Train net output #1: loss = 0.00189935 (* 1 = 0.00189935 loss)
I0217 16:00:59.514183  8728 sgd_solver.cpp:106] Iteration 277600, lr = 0.0001
I0217 16:01:17.817466  8728 solver.cpp:228] Iteration 277700, loss = 0.00107663
I0217 16:01:17.817466  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:01:17.817466  8728 solver.cpp:244]     Train net output #1: loss = 0.00107663 (* 1 = 0.00107663 loss)
I0217 16:01:17.817466  8728 sgd_solver.cpp:106] Iteration 277700, lr = 0.0001
I0217 16:01:36.173215  8728 solver.cpp:228] Iteration 277800, loss = 0.00505137
I0217 16:01:36.173215  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:01:36.173215  8728 solver.cpp:244]     Train net output #1: loss = 0.00505137 (* 1 = 0.00505137 loss)
I0217 16:01:36.173215  8728 sgd_solver.cpp:106] Iteration 277800, lr = 0.0001
I0217 16:01:54.537658  8728 solver.cpp:228] Iteration 277900, loss = 0.00119078
I0217 16:01:54.537658  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:01:54.537658  8728 solver.cpp:244]     Train net output #1: loss = 0.00119078 (* 1 = 0.00119078 loss)
I0217 16:01:54.537658  8728 sgd_solver.cpp:106] Iteration 277900, lr = 0.0001
I0217 16:02:12.788625  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_278000.caffemodel
I0217 16:02:12.941203  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_278000.solverstate
I0217 16:02:13.012693  8728 solver.cpp:337] Iteration 278000, Testing net (#0)
I0217 16:02:13.012693  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:02:19.642320  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 16:02:19.642320  8728 solver.cpp:404]     Test net output #1: loss = 0.187485 (* 1 = 0.187485 loss)
I0217 16:02:19.716025  8728 solver.cpp:228] Iteration 278000, loss = 0.00670934
I0217 16:02:19.716025  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:02:19.716025  8728 solver.cpp:244]     Train net output #1: loss = 0.00670934 (* 1 = 0.00670934 loss)
I0217 16:02:19.716025  8728 sgd_solver.cpp:106] Iteration 278000, lr = 0.0001
I0217 16:02:37.992832  8728 solver.cpp:228] Iteration 278100, loss = 0.00103251
I0217 16:02:37.992832  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:02:37.992832  8728 solver.cpp:244]     Train net output #1: loss = 0.00103251 (* 1 = 0.00103251 loss)
I0217 16:02:37.992832  8728 sgd_solver.cpp:106] Iteration 278100, lr = 0.0001
I0217 16:02:56.325196  8728 solver.cpp:228] Iteration 278200, loss = 0.000968044
I0217 16:02:56.325196  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:02:56.325196  8728 solver.cpp:244]     Train net output #1: loss = 0.000968045 (* 1 = 0.000968045 loss)
I0217 16:02:56.325196  8728 sgd_solver.cpp:106] Iteration 278200, lr = 0.0001
I0217 16:03:14.662252  8728 solver.cpp:228] Iteration 278300, loss = 0.00450511
I0217 16:03:14.662252  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:03:14.662252  8728 solver.cpp:244]     Train net output #1: loss = 0.00450511 (* 1 = 0.00450511 loss)
I0217 16:03:14.662252  8728 sgd_solver.cpp:106] Iteration 278300, lr = 0.0001
I0217 16:03:32.957638  8728 solver.cpp:228] Iteration 278400, loss = 0.000878879
I0217 16:03:32.957638  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:03:32.957638  8728 solver.cpp:244]     Train net output #1: loss = 0.00087888 (* 1 = 0.00087888 loss)
I0217 16:03:32.957638  8728 sgd_solver.cpp:106] Iteration 278400, lr = 0.0001
I0217 16:03:51.093577  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_278500.caffemodel
I0217 16:03:51.245097  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_278500.solverstate
I0217 16:03:51.318105  8728 solver.cpp:337] Iteration 278500, Testing net (#0)
I0217 16:03:51.318105  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:03:57.759928  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 16:03:57.759928  8728 solver.cpp:404]     Test net output #1: loss = 0.187058 (* 1 = 0.187058 loss)
I0217 16:03:57.832813  8728 solver.cpp:228] Iteration 278500, loss = 0.00144691
I0217 16:03:57.832813  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:03:57.832813  8728 solver.cpp:244]     Train net output #1: loss = 0.00144691 (* 1 = 0.00144691 loss)
I0217 16:03:57.832813  8728 sgd_solver.cpp:106] Iteration 278500, lr = 0.0001
I0217 16:04:15.863373  8728 solver.cpp:228] Iteration 278600, loss = 0.00106558
I0217 16:04:15.863373  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:04:15.863373  8728 solver.cpp:244]     Train net output #1: loss = 0.00106558 (* 1 = 0.00106558 loss)
I0217 16:04:15.863373  8728 sgd_solver.cpp:106] Iteration 278600, lr = 0.0001
I0217 16:04:34.001255  8728 solver.cpp:228] Iteration 278700, loss = 0.00049786
I0217 16:04:34.001255  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:04:34.001255  8728 solver.cpp:244]     Train net output #1: loss = 0.000497865 (* 1 = 0.000497865 loss)
I0217 16:04:34.001255  8728 sgd_solver.cpp:106] Iteration 278700, lr = 0.0001
I0217 16:04:51.853705  8728 solver.cpp:228] Iteration 278800, loss = 0.00101023
I0217 16:04:51.853705  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:04:51.853705  8728 solver.cpp:244]     Train net output #1: loss = 0.00101023 (* 1 = 0.00101023 loss)
I0217 16:04:51.853705  8728 sgd_solver.cpp:106] Iteration 278800, lr = 0.0001
I0217 16:05:09.560942  8728 solver.cpp:228] Iteration 278900, loss = 0.00385704
I0217 16:05:09.560942  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:05:09.560942  8728 solver.cpp:244]     Train net output #1: loss = 0.00385705 (* 1 = 0.00385705 loss)
I0217 16:05:09.560942  8728 sgd_solver.cpp:106] Iteration 278900, lr = 0.0001
I0217 16:05:27.193094  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_279000.caffemodel
I0217 16:05:27.329572  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_279000.solverstate
I0217 16:05:27.395572  8728 solver.cpp:337] Iteration 279000, Testing net (#0)
I0217 16:05:27.396072  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:05:33.427605  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9447
I0217 16:05:33.427605  8728 solver.cpp:404]     Test net output #1: loss = 0.187228 (* 1 = 0.187228 loss)
I0217 16:05:33.498644  8728 solver.cpp:228] Iteration 279000, loss = 0.00150879
I0217 16:05:33.498644  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:05:33.498644  8728 solver.cpp:244]     Train net output #1: loss = 0.0015088 (* 1 = 0.0015088 loss)
I0217 16:05:33.498644  8728 sgd_solver.cpp:106] Iteration 279000, lr = 0.0001
I0217 16:05:51.202261  8728 solver.cpp:228] Iteration 279100, loss = 0.0400732
I0217 16:05:51.202261  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 16:05:51.202261  8728 solver.cpp:244]     Train net output #1: loss = 0.0400732 (* 1 = 0.0400732 loss)
I0217 16:05:51.202261  8728 sgd_solver.cpp:106] Iteration 279100, lr = 0.0001
I0217 16:06:08.910048  8728 solver.cpp:228] Iteration 279200, loss = 0.000829521
I0217 16:06:08.910048  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:06:08.910048  8728 solver.cpp:244]     Train net output #1: loss = 0.000829527 (* 1 = 0.000829527 loss)
I0217 16:06:08.910048  8728 sgd_solver.cpp:106] Iteration 279200, lr = 0.0001
I0217 16:06:26.620195  8728 solver.cpp:228] Iteration 279300, loss = 0.00127526
I0217 16:06:26.620195  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:06:26.620195  8728 solver.cpp:244]     Train net output #1: loss = 0.00127527 (* 1 = 0.00127527 loss)
I0217 16:06:26.620195  8728 sgd_solver.cpp:106] Iteration 279300, lr = 0.0001
I0217 16:06:44.356397  8728 solver.cpp:228] Iteration 279400, loss = 0.00388191
I0217 16:06:44.356397  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:06:44.356397  8728 solver.cpp:244]     Train net output #1: loss = 0.00388192 (* 1 = 0.00388192 loss)
I0217 16:06:44.356397  8728 sgd_solver.cpp:106] Iteration 279400, lr = 0.0001
I0217 16:07:02.018496  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_279500.caffemodel
I0217 16:07:02.159584  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_279500.solverstate
I0217 16:07:02.225584  8728 solver.cpp:337] Iteration 279500, Testing net (#0)
I0217 16:07:02.226583  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:07:08.261086  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9447
I0217 16:07:08.261086  8728 solver.cpp:404]     Test net output #1: loss = 0.187186 (* 1 = 0.187186 loss)
I0217 16:07:08.332149  8728 solver.cpp:228] Iteration 279500, loss = 0.00262506
I0217 16:07:08.332149  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:07:08.332149  8728 solver.cpp:244]     Train net output #1: loss = 0.00262506 (* 1 = 0.00262506 loss)
I0217 16:07:08.332149  8728 sgd_solver.cpp:106] Iteration 279500, lr = 0.0001
I0217 16:07:26.053129  8728 solver.cpp:228] Iteration 279600, loss = 0.00120143
I0217 16:07:26.053129  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:07:26.053129  8728 solver.cpp:244]     Train net output #1: loss = 0.00120143 (* 1 = 0.00120143 loss)
I0217 16:07:26.053129  8728 sgd_solver.cpp:106] Iteration 279600, lr = 0.0001
I0217 16:07:43.757189  8728 solver.cpp:228] Iteration 279700, loss = 0.00383211
I0217 16:07:43.757673  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:07:43.757673  8728 solver.cpp:244]     Train net output #1: loss = 0.00383211 (* 1 = 0.00383211 loss)
I0217 16:07:43.757673  8728 sgd_solver.cpp:106] Iteration 279700, lr = 0.0001
I0217 16:08:01.464027  8728 solver.cpp:228] Iteration 279800, loss = 0.0243181
I0217 16:08:01.464498  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 16:08:01.464498  8728 solver.cpp:244]     Train net output #1: loss = 0.0243181 (* 1 = 0.0243181 loss)
I0217 16:08:01.464498  8728 sgd_solver.cpp:106] Iteration 279800, lr = 0.0001
I0217 16:08:19.172672  8728 solver.cpp:228] Iteration 279900, loss = 0.00191197
I0217 16:08:19.172672  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:08:19.172672  8728 solver.cpp:244]     Train net output #1: loss = 0.00191197 (* 1 = 0.00191197 loss)
I0217 16:08:19.172672  8728 sgd_solver.cpp:106] Iteration 279900, lr = 0.0001
I0217 16:08:36.819669  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_280000.caffemodel
I0217 16:08:36.957172  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_280000.solverstate
I0217 16:08:37.022171  8728 solver.cpp:337] Iteration 280000, Testing net (#0)
I0217 16:08:37.022672  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:08:43.088559  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 16:08:43.088559  8728 solver.cpp:404]     Test net output #1: loss = 0.187375 (* 1 = 0.187375 loss)
I0217 16:08:43.159600  8728 solver.cpp:228] Iteration 280000, loss = 0.00205968
I0217 16:08:43.160074  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:08:43.160074  8728 solver.cpp:244]     Train net output #1: loss = 0.00205968 (* 1 = 0.00205968 loss)
I0217 16:08:43.160074  8728 sgd_solver.cpp:106] Iteration 280000, lr = 0.0001
I0217 16:09:00.903406  8728 solver.cpp:228] Iteration 280100, loss = 0.0019342
I0217 16:09:00.903406  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:09:00.903406  8728 solver.cpp:244]     Train net output #1: loss = 0.0019342 (* 1 = 0.0019342 loss)
I0217 16:09:00.903406  8728 sgd_solver.cpp:106] Iteration 280100, lr = 0.0001
I0217 16:09:18.664837  8728 solver.cpp:228] Iteration 280200, loss = 0.000854745
I0217 16:09:18.665338  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:09:18.665338  8728 solver.cpp:244]     Train net output #1: loss = 0.000854744 (* 1 = 0.000854744 loss)
I0217 16:09:18.665338  8728 sgd_solver.cpp:106] Iteration 280200, lr = 0.0001
I0217 16:09:36.382380  8728 solver.cpp:228] Iteration 280300, loss = 0.00125907
I0217 16:09:36.382380  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:09:36.382380  8728 solver.cpp:244]     Train net output #1: loss = 0.00125907 (* 1 = 0.00125907 loss)
I0217 16:09:36.382380  8728 sgd_solver.cpp:106] Iteration 280300, lr = 0.0001
I0217 16:09:54.104563  8728 solver.cpp:228] Iteration 280400, loss = 0.00112399
I0217 16:09:54.104563  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:09:54.104563  8728 solver.cpp:244]     Train net output #1: loss = 0.00112399 (* 1 = 0.00112399 loss)
I0217 16:09:54.104563  8728 sgd_solver.cpp:106] Iteration 280400, lr = 0.0001
I0217 16:10:11.775096  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_280500.caffemodel
I0217 16:10:11.913135  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_280500.solverstate
I0217 16:10:11.979132  8728 solver.cpp:337] Iteration 280500, Testing net (#0)
I0217 16:10:11.979132  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:10:18.021672  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9459
I0217 16:10:18.021672  8728 solver.cpp:404]     Test net output #1: loss = 0.187256 (* 1 = 0.187256 loss)
I0217 16:10:18.092730  8728 solver.cpp:228] Iteration 280500, loss = 0.00305604
I0217 16:10:18.092730  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:10:18.092730  8728 solver.cpp:244]     Train net output #1: loss = 0.00305604 (* 1 = 0.00305604 loss)
I0217 16:10:18.092730  8728 sgd_solver.cpp:106] Iteration 280500, lr = 0.0001
I0217 16:10:35.815284  8728 solver.cpp:228] Iteration 280600, loss = 0.00199641
I0217 16:10:35.815284  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:10:35.815284  8728 solver.cpp:244]     Train net output #1: loss = 0.00199641 (* 1 = 0.00199641 loss)
I0217 16:10:35.815284  8728 sgd_solver.cpp:106] Iteration 280600, lr = 0.0001
I0217 16:10:53.538730  8728 solver.cpp:228] Iteration 280700, loss = 0.00107918
I0217 16:10:53.538730  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:10:53.538730  8728 solver.cpp:244]     Train net output #1: loss = 0.00107918 (* 1 = 0.00107918 loss)
I0217 16:10:53.538730  8728 sgd_solver.cpp:106] Iteration 280700, lr = 0.0001
I0217 16:11:11.258003  8728 solver.cpp:228] Iteration 280800, loss = 0.00490466
I0217 16:11:11.258003  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:11:11.258003  8728 solver.cpp:244]     Train net output #1: loss = 0.00490466 (* 1 = 0.00490466 loss)
I0217 16:11:11.258003  8728 sgd_solver.cpp:106] Iteration 280800, lr = 0.0001
I0217 16:11:28.980052  8728 solver.cpp:228] Iteration 280900, loss = 0.00306085
I0217 16:11:28.980052  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:11:28.980052  8728 solver.cpp:244]     Train net output #1: loss = 0.00306085 (* 1 = 0.00306085 loss)
I0217 16:11:28.980052  8728 sgd_solver.cpp:106] Iteration 280900, lr = 0.0001
I0217 16:11:46.616039  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_281000.caffemodel
I0217 16:11:46.757091  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_281000.solverstate
I0217 16:11:46.908210  8728 solver.cpp:337] Iteration 281000, Testing net (#0)
I0217 16:11:46.908210  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:11:52.918881  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 16:11:52.918881  8728 solver.cpp:404]     Test net output #1: loss = 0.18669 (* 1 = 0.18669 loss)
I0217 16:11:52.989953  8728 solver.cpp:228] Iteration 281000, loss = 0.00382275
I0217 16:11:52.989953  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:11:52.989953  8728 solver.cpp:244]     Train net output #1: loss = 0.00382276 (* 1 = 0.00382276 loss)
I0217 16:11:52.989953  8728 sgd_solver.cpp:106] Iteration 281000, lr = 0.0001
I0217 16:12:10.697345  8728 solver.cpp:228] Iteration 281100, loss = 0.000890707
I0217 16:12:10.697345  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:12:10.697345  8728 solver.cpp:244]     Train net output #1: loss = 0.00089071 (* 1 = 0.00089071 loss)
I0217 16:12:10.697345  8728 sgd_solver.cpp:106] Iteration 281100, lr = 0.0001
I0217 16:12:28.408514  8728 solver.cpp:228] Iteration 281200, loss = 0.000786543
I0217 16:12:28.408999  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:12:28.408999  8728 solver.cpp:244]     Train net output #1: loss = 0.000786544 (* 1 = 0.000786544 loss)
I0217 16:12:28.408999  8728 sgd_solver.cpp:106] Iteration 281200, lr = 0.0001
I0217 16:12:46.127729  8728 solver.cpp:228] Iteration 281300, loss = 0.000652177
I0217 16:12:46.127729  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:12:46.127729  8728 solver.cpp:244]     Train net output #1: loss = 0.000652175 (* 1 = 0.000652175 loss)
I0217 16:12:46.127729  8728 sgd_solver.cpp:106] Iteration 281300, lr = 0.0001
I0217 16:13:03.848659  8728 solver.cpp:228] Iteration 281400, loss = 0.00259759
I0217 16:13:03.848659  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:13:03.848659  8728 solver.cpp:244]     Train net output #1: loss = 0.00259759 (* 1 = 0.00259759 loss)
I0217 16:13:03.848659  8728 sgd_solver.cpp:106] Iteration 281400, lr = 0.0001
I0217 16:13:21.500422  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_281500.caffemodel
I0217 16:13:21.641430  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_281500.solverstate
I0217 16:13:21.705418  8728 solver.cpp:337] Iteration 281500, Testing net (#0)
I0217 16:13:21.705919  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:13:27.721441  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9452
I0217 16:13:27.721441  8728 solver.cpp:404]     Test net output #1: loss = 0.186887 (* 1 = 0.186887 loss)
I0217 16:13:27.792521  8728 solver.cpp:228] Iteration 281500, loss = 0.00102249
I0217 16:13:27.792521  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:13:27.792521  8728 solver.cpp:244]     Train net output #1: loss = 0.00102249 (* 1 = 0.00102249 loss)
I0217 16:13:27.792521  8728 sgd_solver.cpp:106] Iteration 281500, lr = 0.0001
I0217 16:13:45.475390  8728 solver.cpp:228] Iteration 281600, loss = 0.00254994
I0217 16:13:45.475390  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:13:45.475390  8728 solver.cpp:244]     Train net output #1: loss = 0.00254994 (* 1 = 0.00254994 loss)
I0217 16:13:45.475390  8728 sgd_solver.cpp:106] Iteration 281600, lr = 0.0001
I0217 16:14:03.200286  8728 solver.cpp:228] Iteration 281700, loss = 0.00104517
I0217 16:14:03.200286  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:14:03.200286  8728 solver.cpp:244]     Train net output #1: loss = 0.00104516 (* 1 = 0.00104516 loss)
I0217 16:14:03.200286  8728 sgd_solver.cpp:106] Iteration 281700, lr = 0.0001
I0217 16:14:20.919939  8728 solver.cpp:228] Iteration 281800, loss = 0.00616768
I0217 16:14:20.919939  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:14:20.919939  8728 solver.cpp:244]     Train net output #1: loss = 0.00616768 (* 1 = 0.00616768 loss)
I0217 16:14:20.919939  8728 sgd_solver.cpp:106] Iteration 281800, lr = 0.0001
I0217 16:14:38.699731  8728 solver.cpp:228] Iteration 281900, loss = 0.00150772
I0217 16:14:38.699731  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:14:38.699731  8728 solver.cpp:244]     Train net output #1: loss = 0.00150771 (* 1 = 0.00150771 loss)
I0217 16:14:38.700232  8728 sgd_solver.cpp:106] Iteration 281900, lr = 0.0001
I0217 16:14:56.295297  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_282000.caffemodel
I0217 16:14:56.437328  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_282000.solverstate
I0217 16:14:56.501327  8728 solver.cpp:337] Iteration 282000, Testing net (#0)
I0217 16:14:56.501327  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:15:02.505841  8728 solver.cpp:404]     Test net output #0: accuracy = 0.945
I0217 16:15:02.505841  8728 solver.cpp:404]     Test net output #1: loss = 0.186354 (* 1 = 0.186354 loss)
I0217 16:15:02.576894  8728 solver.cpp:228] Iteration 282000, loss = 0.00306213
I0217 16:15:02.576894  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:15:02.576894  8728 solver.cpp:244]     Train net output #1: loss = 0.00306213 (* 1 = 0.00306213 loss)
I0217 16:15:02.576894  8728 sgd_solver.cpp:106] Iteration 282000, lr = 0.0001
I0217 16:15:20.218814  8728 solver.cpp:228] Iteration 282100, loss = 0.00110052
I0217 16:15:20.218814  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:15:20.218814  8728 solver.cpp:244]     Train net output #1: loss = 0.00110052 (* 1 = 0.00110052 loss)
I0217 16:15:20.218814  8728 sgd_solver.cpp:106] Iteration 282100, lr = 0.0001
I0217 16:15:37.880252  8728 solver.cpp:228] Iteration 282200, loss = 0.0011067
I0217 16:15:37.880252  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:15:37.880252  8728 solver.cpp:244]     Train net output #1: loss = 0.0011067 (* 1 = 0.0011067 loss)
I0217 16:15:37.880252  8728 sgd_solver.cpp:106] Iteration 282200, lr = 0.0001
I0217 16:15:55.542650  8728 solver.cpp:228] Iteration 282300, loss = 0.00165132
I0217 16:15:55.542650  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:15:55.542650  8728 solver.cpp:244]     Train net output #1: loss = 0.00165132 (* 1 = 0.00165132 loss)
I0217 16:15:55.542650  8728 sgd_solver.cpp:106] Iteration 282300, lr = 0.0001
I0217 16:16:13.207700  8728 solver.cpp:228] Iteration 282400, loss = 0.00433428
I0217 16:16:13.207700  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:16:13.207700  8728 solver.cpp:244]     Train net output #1: loss = 0.00433428 (* 1 = 0.00433428 loss)
I0217 16:16:13.207700  8728 sgd_solver.cpp:106] Iteration 282400, lr = 0.0001
I0217 16:16:30.795014  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_282500.caffemodel
I0217 16:16:30.937021  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_282500.solverstate
I0217 16:16:31.001025  8728 solver.cpp:337] Iteration 282500, Testing net (#0)
I0217 16:16:31.001025  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:16:37.017004  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9448
I0217 16:16:37.017004  8728 solver.cpp:404]     Test net output #1: loss = 0.186804 (* 1 = 0.186804 loss)
I0217 16:16:37.087076  8728 solver.cpp:228] Iteration 282500, loss = 0.00183433
I0217 16:16:37.087076  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:16:37.087076  8728 solver.cpp:244]     Train net output #1: loss = 0.00183433 (* 1 = 0.00183433 loss)
I0217 16:16:37.087076  8728 sgd_solver.cpp:106] Iteration 282500, lr = 0.0001
I0217 16:16:54.755754  8728 solver.cpp:228] Iteration 282600, loss = 0.00291014
I0217 16:16:54.755754  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:16:54.755754  8728 solver.cpp:244]     Train net output #1: loss = 0.00291014 (* 1 = 0.00291014 loss)
I0217 16:16:54.755754  8728 sgd_solver.cpp:106] Iteration 282600, lr = 0.0001
I0217 16:17:12.419319  8728 solver.cpp:228] Iteration 282700, loss = 0.0039764
I0217 16:17:12.419319  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:17:12.419319  8728 solver.cpp:244]     Train net output #1: loss = 0.0039764 (* 1 = 0.0039764 loss)
I0217 16:17:12.419821  8728 sgd_solver.cpp:106] Iteration 282700, lr = 0.0001
I0217 16:17:30.086570  8728 solver.cpp:228] Iteration 282800, loss = 0.000518585
I0217 16:17:30.086570  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:17:30.086570  8728 solver.cpp:244]     Train net output #1: loss = 0.000518586 (* 1 = 0.000518586 loss)
I0217 16:17:30.086570  8728 sgd_solver.cpp:106] Iteration 282800, lr = 0.0001
I0217 16:17:48.060300  8728 solver.cpp:228] Iteration 282900, loss = 0.00158014
I0217 16:17:48.060300  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:17:48.060300  8728 solver.cpp:244]     Train net output #1: loss = 0.00158014 (* 1 = 0.00158014 loss)
I0217 16:17:48.060300  8728 sgd_solver.cpp:106] Iteration 282900, lr = 0.0001
I0217 16:18:05.803131  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_283000.caffemodel
I0217 16:18:05.953667  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_283000.solverstate
I0217 16:18:06.023166  8728 solver.cpp:337] Iteration 283000, Testing net (#0)
I0217 16:18:06.023166  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:18:12.059433  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 16:18:12.059433  8728 solver.cpp:404]     Test net output #1: loss = 0.187043 (* 1 = 0.187043 loss)
I0217 16:18:12.131304  8728 solver.cpp:228] Iteration 283000, loss = 0.00201405
I0217 16:18:12.131304  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:18:12.131304  8728 solver.cpp:244]     Train net output #1: loss = 0.00201405 (* 1 = 0.00201405 loss)
I0217 16:18:12.131304  8728 sgd_solver.cpp:106] Iteration 283000, lr = 0.0001
I0217 16:18:29.901510  8728 solver.cpp:228] Iteration 283100, loss = 0.000989008
I0217 16:18:29.901510  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:18:29.901510  8728 solver.cpp:244]     Train net output #1: loss = 0.000989009 (* 1 = 0.000989009 loss)
I0217 16:18:29.901510  8728 sgd_solver.cpp:106] Iteration 283100, lr = 0.0001
I0217 16:18:48.427558  8728 solver.cpp:228] Iteration 283200, loss = 0.000566516
I0217 16:18:48.427558  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:18:48.427558  8728 solver.cpp:244]     Train net output #1: loss = 0.000566517 (* 1 = 0.000566517 loss)
I0217 16:18:48.427558  8728 sgd_solver.cpp:106] Iteration 283200, lr = 0.0001
I0217 16:19:06.437098  8728 solver.cpp:228] Iteration 283300, loss = 0.0019455
I0217 16:19:06.437098  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:19:06.437098  8728 solver.cpp:244]     Train net output #1: loss = 0.0019455 (* 1 = 0.0019455 loss)
I0217 16:19:06.437098  8728 sgd_solver.cpp:106] Iteration 283300, lr = 0.0001
I0217 16:19:24.171115  8728 solver.cpp:228] Iteration 283400, loss = 0.000956724
I0217 16:19:24.171115  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:19:24.171115  8728 solver.cpp:244]     Train net output #1: loss = 0.000956724 (* 1 = 0.000956724 loss)
I0217 16:19:24.171115  8728 sgd_solver.cpp:106] Iteration 283400, lr = 0.0001
I0217 16:19:41.807132  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_283500.caffemodel
I0217 16:19:41.944123  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_283500.solverstate
I0217 16:19:42.009624  8728 solver.cpp:337] Iteration 283500, Testing net (#0)
I0217 16:19:42.009624  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:19:48.014679  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9455
I0217 16:19:48.014679  8728 solver.cpp:404]     Test net output #1: loss = 0.187005 (* 1 = 0.187005 loss)
I0217 16:19:48.085741  8728 solver.cpp:228] Iteration 283500, loss = 0.00111649
I0217 16:19:48.085741  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:19:48.085741  8728 solver.cpp:244]     Train net output #1: loss = 0.00111649 (* 1 = 0.00111649 loss)
I0217 16:19:48.085741  8728 sgd_solver.cpp:106] Iteration 283500, lr = 0.0001
I0217 16:20:05.737553  8728 solver.cpp:228] Iteration 283600, loss = 0.00151843
I0217 16:20:05.738054  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:20:05.738054  8728 solver.cpp:244]     Train net output #1: loss = 0.00151843 (* 1 = 0.00151843 loss)
I0217 16:20:05.738054  8728 sgd_solver.cpp:106] Iteration 283600, lr = 0.0001
I0217 16:20:23.457881  8728 solver.cpp:228] Iteration 283700, loss = 0.00155096
I0217 16:20:23.457881  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:20:23.457881  8728 solver.cpp:244]     Train net output #1: loss = 0.00155096 (* 1 = 0.00155096 loss)
I0217 16:20:23.457881  8728 sgd_solver.cpp:106] Iteration 283700, lr = 0.0001
I0217 16:20:41.170341  8728 solver.cpp:228] Iteration 283800, loss = 0.00213379
I0217 16:20:41.170341  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:20:41.170341  8728 solver.cpp:244]     Train net output #1: loss = 0.00213379 (* 1 = 0.00213379 loss)
I0217 16:20:41.170341  8728 sgd_solver.cpp:106] Iteration 283800, lr = 0.0001
I0217 16:20:58.880810  8728 solver.cpp:228] Iteration 283900, loss = 0.000904547
I0217 16:20:58.881309  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:20:58.881309  8728 solver.cpp:244]     Train net output #1: loss = 0.000904547 (* 1 = 0.000904547 loss)
I0217 16:20:58.881309  8728 sgd_solver.cpp:106] Iteration 283900, lr = 0.0001
I0217 16:21:16.517905  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_284000.caffemodel
I0217 16:21:16.656411  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_284000.solverstate
I0217 16:21:16.724400  8728 solver.cpp:337] Iteration 284000, Testing net (#0)
I0217 16:21:16.724400  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:21:22.756384  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 16:21:22.756384  8728 solver.cpp:404]     Test net output #1: loss = 0.187311 (* 1 = 0.187311 loss)
I0217 16:21:22.826925  8728 solver.cpp:228] Iteration 284000, loss = 0.0019514
I0217 16:21:22.826925  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:21:22.827396  8728 solver.cpp:244]     Train net output #1: loss = 0.0019514 (* 1 = 0.0019514 loss)
I0217 16:21:22.827396  8728 sgd_solver.cpp:106] Iteration 284000, lr = 0.0001
I0217 16:21:40.532513  8728 solver.cpp:228] Iteration 284100, loss = 0.00247882
I0217 16:21:40.532513  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:21:40.532513  8728 solver.cpp:244]     Train net output #1: loss = 0.00247883 (* 1 = 0.00247883 loss)
I0217 16:21:40.532513  8728 sgd_solver.cpp:106] Iteration 284100, lr = 0.0001
I0217 16:21:58.250996  8728 solver.cpp:228] Iteration 284200, loss = 0.00148603
I0217 16:21:58.250996  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:21:58.250996  8728 solver.cpp:244]     Train net output #1: loss = 0.00148603 (* 1 = 0.00148603 loss)
I0217 16:21:58.250996  8728 sgd_solver.cpp:106] Iteration 284200, lr = 0.0001
I0217 16:22:15.966606  8728 solver.cpp:228] Iteration 284300, loss = 0.00136368
I0217 16:22:15.966606  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:22:15.966606  8728 solver.cpp:244]     Train net output #1: loss = 0.00136368 (* 1 = 0.00136368 loss)
I0217 16:22:15.966606  8728 sgd_solver.cpp:106] Iteration 284300, lr = 0.0001
I0217 16:22:33.688002  8728 solver.cpp:228] Iteration 284400, loss = 0.00133487
I0217 16:22:33.688002  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:22:33.688002  8728 solver.cpp:244]     Train net output #1: loss = 0.00133487 (* 1 = 0.00133487 loss)
I0217 16:22:33.688002  8728 sgd_solver.cpp:106] Iteration 284400, lr = 0.0001
I0217 16:22:51.332154  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_284500.caffemodel
I0217 16:22:51.472170  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_284500.solverstate
I0217 16:22:51.539173  8728 solver.cpp:337] Iteration 284500, Testing net (#0)
I0217 16:22:51.539173  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:22:57.579308  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 16:22:57.579308  8728 solver.cpp:404]     Test net output #1: loss = 0.187324 (* 1 = 0.187324 loss)
I0217 16:22:57.650342  8728 solver.cpp:228] Iteration 284500, loss = 0.00105103
I0217 16:22:57.650342  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:22:57.650342  8728 solver.cpp:244]     Train net output #1: loss = 0.00105103 (* 1 = 0.00105103 loss)
I0217 16:22:57.650342  8728 sgd_solver.cpp:106] Iteration 284500, lr = 0.0001
I0217 16:23:15.366952  8728 solver.cpp:228] Iteration 284600, loss = 0.00130101
I0217 16:23:15.366952  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:23:15.366952  8728 solver.cpp:244]     Train net output #1: loss = 0.00130101 (* 1 = 0.00130101 loss)
I0217 16:23:15.366952  8728 sgd_solver.cpp:106] Iteration 284600, lr = 0.0001
I0217 16:23:33.123126  8728 solver.cpp:228] Iteration 284700, loss = 0.0119656
I0217 16:23:33.123126  8728 solver.cpp:244]     Train net output #0: accuracy_training = 0.99
I0217 16:23:33.123126  8728 solver.cpp:244]     Train net output #1: loss = 0.0119656 (* 1 = 0.0119656 loss)
I0217 16:23:33.123126  8728 sgd_solver.cpp:106] Iteration 284700, lr = 0.0001
I0217 16:23:50.827478  8728 solver.cpp:228] Iteration 284800, loss = 0.000434043
I0217 16:23:50.827478  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:23:50.827478  8728 solver.cpp:244]     Train net output #1: loss = 0.00043404 (* 1 = 0.00043404 loss)
I0217 16:23:50.827478  8728 sgd_solver.cpp:106] Iteration 284800, lr = 0.0001
I0217 16:24:08.544333  8728 solver.cpp:228] Iteration 284900, loss = 0.00112421
I0217 16:24:08.544333  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:24:08.544333  8728 solver.cpp:244]     Train net output #1: loss = 0.0011242 (* 1 = 0.0011242 loss)
I0217 16:24:08.544333  8728 sgd_solver.cpp:106] Iteration 284900, lr = 0.0001
I0217 16:24:26.188693  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_285000.caffemodel
I0217 16:24:26.327217  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_285000.solverstate
I0217 16:24:26.395200  8728 solver.cpp:337] Iteration 285000, Testing net (#0)
I0217 16:24:26.395200  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:24:32.429534  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9454
I0217 16:24:32.429534  8728 solver.cpp:404]     Test net output #1: loss = 0.187182 (* 1 = 0.187182 loss)
I0217 16:24:32.500602  8728 solver.cpp:228] Iteration 285000, loss = 0.00155998
I0217 16:24:32.500602  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:24:32.500602  8728 solver.cpp:244]     Train net output #1: loss = 0.00155998 (* 1 = 0.00155998 loss)
I0217 16:24:32.500602  8728 sgd_solver.cpp:106] Iteration 285000, lr = 0.0001
I0217 16:24:50.212788  8728 solver.cpp:228] Iteration 285100, loss = 0.00152893
I0217 16:24:50.212788  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:24:50.212788  8728 solver.cpp:244]     Train net output #1: loss = 0.00152893 (* 1 = 0.00152893 loss)
I0217 16:24:50.212788  8728 sgd_solver.cpp:106] Iteration 285100, lr = 0.0001
I0217 16:25:07.921774  8728 solver.cpp:228] Iteration 285200, loss = 0.00100312
I0217 16:25:07.921774  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:25:07.921774  8728 solver.cpp:244]     Train net output #1: loss = 0.00100311 (* 1 = 0.00100311 loss)
I0217 16:25:07.921774  8728 sgd_solver.cpp:106] Iteration 285200, lr = 0.0001
I0217 16:25:25.635385  8728 solver.cpp:228] Iteration 285300, loss = 0.000924184
I0217 16:25:25.635385  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:25:25.635385  8728 solver.cpp:244]     Train net output #1: loss = 0.00092418 (* 1 = 0.00092418 loss)
I0217 16:25:25.635385  8728 sgd_solver.cpp:106] Iteration 285300, lr = 0.0001
I0217 16:25:43.347113  8728 solver.cpp:228] Iteration 285400, loss = 0.00172601
I0217 16:25:43.347113  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:25:43.347113  8728 solver.cpp:244]     Train net output #1: loss = 0.00172601 (* 1 = 0.00172601 loss)
I0217 16:25:43.347113  8728 sgd_solver.cpp:106] Iteration 285400, lr = 0.0001
I0217 16:26:00.976871  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_285500.caffemodel
I0217 16:26:01.118865  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_285500.solverstate
I0217 16:26:01.186897  8728 solver.cpp:337] Iteration 285500, Testing net (#0)
I0217 16:26:01.187898  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:26:07.223631  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9461
I0217 16:26:07.223631  8728 solver.cpp:404]     Test net output #1: loss = 0.187111 (* 1 = 0.187111 loss)
I0217 16:26:07.294667  8728 solver.cpp:228] Iteration 285500, loss = 0.00705151
I0217 16:26:07.294667  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:26:07.294667  8728 solver.cpp:244]     Train net output #1: loss = 0.0070515 (* 1 = 0.0070515 loss)
I0217 16:26:07.294667  8728 sgd_solver.cpp:106] Iteration 285500, lr = 0.0001
I0217 16:26:25.001072  8728 solver.cpp:228] Iteration 285600, loss = 0.000601202
I0217 16:26:25.001072  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:26:25.001072  8728 solver.cpp:244]     Train net output #1: loss = 0.000601194 (* 1 = 0.000601194 loss)
I0217 16:26:25.001072  8728 sgd_solver.cpp:106] Iteration 285600, lr = 0.0001
I0217 16:26:42.707715  8728 solver.cpp:228] Iteration 285700, loss = 0.000604223
I0217 16:26:42.707715  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:26:42.707715  8728 solver.cpp:244]     Train net output #1: loss = 0.000604216 (* 1 = 0.000604216 loss)
I0217 16:26:42.707715  8728 sgd_solver.cpp:106] Iteration 285700, lr = 0.0001
I0217 16:27:00.413920  8728 solver.cpp:228] Iteration 285800, loss = 0.00204671
I0217 16:27:00.413920  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:27:00.413920  8728 solver.cpp:244]     Train net output #1: loss = 0.0020467 (* 1 = 0.0020467 loss)
I0217 16:27:00.413920  8728 sgd_solver.cpp:106] Iteration 285800, lr = 0.0001
I0217 16:27:18.117604  8728 solver.cpp:228] Iteration 285900, loss = 0.00328828
I0217 16:27:18.117604  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:27:18.117604  8728 solver.cpp:244]     Train net output #1: loss = 0.00328828 (* 1 = 0.00328828 loss)
I0217 16:27:18.117604  8728 sgd_solver.cpp:106] Iteration 285900, lr = 0.0001
I0217 16:27:35.745947  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_286000.caffemodel
I0217 16:27:35.887933  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_286000.solverstate
I0217 16:27:35.954438  8728 solver.cpp:337] Iteration 286000, Testing net (#0)
I0217 16:27:35.954438  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:27:41.997618  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 16:27:41.997618  8728 solver.cpp:404]     Test net output #1: loss = 0.187187 (* 1 = 0.187187 loss)
I0217 16:27:42.069227  8728 solver.cpp:228] Iteration 286000, loss = 0.0067015
I0217 16:27:42.069227  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:27:42.069227  8728 solver.cpp:244]     Train net output #1: loss = 0.0067015 (* 1 = 0.0067015 loss)
I0217 16:27:42.069227  8728 sgd_solver.cpp:106] Iteration 286000, lr = 0.0001
I0217 16:27:59.771023  8728 solver.cpp:228] Iteration 286100, loss = 0.0012486
I0217 16:27:59.771023  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:27:59.771023  8728 solver.cpp:244]     Train net output #1: loss = 0.00124859 (* 1 = 0.00124859 loss)
I0217 16:27:59.771023  8728 sgd_solver.cpp:106] Iteration 286100, lr = 0.0001
I0217 16:28:17.478670  8728 solver.cpp:228] Iteration 286200, loss = 0.000744581
I0217 16:28:17.478670  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:28:17.478670  8728 solver.cpp:244]     Train net output #1: loss = 0.000744572 (* 1 = 0.000744572 loss)
I0217 16:28:17.478670  8728 sgd_solver.cpp:106] Iteration 286200, lr = 0.0001
I0217 16:28:35.196959  8728 solver.cpp:228] Iteration 286300, loss = 0.00123944
I0217 16:28:35.196959  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:28:35.196959  8728 solver.cpp:244]     Train net output #1: loss = 0.00123943 (* 1 = 0.00123943 loss)
I0217 16:28:35.196959  8728 sgd_solver.cpp:106] Iteration 286300, lr = 0.0001
I0217 16:28:52.907721  8728 solver.cpp:228] Iteration 286400, loss = 0.00475864
I0217 16:28:52.907721  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:28:52.907721  8728 solver.cpp:244]     Train net output #1: loss = 0.00475863 (* 1 = 0.00475863 loss)
I0217 16:28:52.907721  8728 sgd_solver.cpp:106] Iteration 286400, lr = 0.0001
I0217 16:29:10.539805  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_286500.caffemodel
I0217 16:29:10.682304  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_286500.solverstate
I0217 16:29:10.748306  8728 solver.cpp:337] Iteration 286500, Testing net (#0)
I0217 16:29:10.748306  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:29:16.855476  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9461
I0217 16:29:16.855476  8728 solver.cpp:404]     Test net output #1: loss = 0.187058 (* 1 = 0.187058 loss)
I0217 16:29:16.926029  8728 solver.cpp:228] Iteration 286500, loss = 0.00108526
I0217 16:29:16.926029  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:29:16.926029  8728 solver.cpp:244]     Train net output #1: loss = 0.00108525 (* 1 = 0.00108525 loss)
I0217 16:29:16.926029  8728 sgd_solver.cpp:106] Iteration 286500, lr = 0.0001
I0217 16:29:34.594238  8728 solver.cpp:228] Iteration 286600, loss = 0.00200946
I0217 16:29:34.594238  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:29:34.594238  8728 solver.cpp:244]     Train net output #1: loss = 0.00200946 (* 1 = 0.00200946 loss)
I0217 16:29:34.594238  8728 sgd_solver.cpp:106] Iteration 286600, lr = 0.0001
I0217 16:29:52.257339  8728 solver.cpp:228] Iteration 286700, loss = 0.00189547
I0217 16:29:52.257339  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:29:52.257339  8728 solver.cpp:244]     Train net output #1: loss = 0.00189546 (* 1 = 0.00189546 loss)
I0217 16:29:52.257339  8728 sgd_solver.cpp:106] Iteration 286700, lr = 0.0001
I0217 16:30:09.919517  8728 solver.cpp:228] Iteration 286800, loss = 0.00148684
I0217 16:30:09.919517  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:30:09.919517  8728 solver.cpp:244]     Train net output #1: loss = 0.00148684 (* 1 = 0.00148684 loss)
I0217 16:30:09.919517  8728 sgd_solver.cpp:106] Iteration 286800, lr = 0.0001
I0217 16:30:27.573077  8728 solver.cpp:228] Iteration 286900, loss = 0.00298174
I0217 16:30:27.573077  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:30:27.573077  8728 solver.cpp:244]     Train net output #1: loss = 0.00298174 (* 1 = 0.00298174 loss)
I0217 16:30:27.573077  8728 sgd_solver.cpp:106] Iteration 286900, lr = 0.0001
I0217 16:30:45.157771  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_287000.caffemodel
I0217 16:30:45.299829  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_287000.solverstate
I0217 16:30:45.365835  8728 solver.cpp:337] Iteration 287000, Testing net (#0)
I0217 16:30:45.365835  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:30:51.381407  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9461
I0217 16:30:51.381407  8728 solver.cpp:404]     Test net output #1: loss = 0.186966 (* 1 = 0.186966 loss)
I0217 16:30:51.452468  8728 solver.cpp:228] Iteration 287000, loss = 0.000740222
I0217 16:30:51.452468  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:30:51.452468  8728 solver.cpp:244]     Train net output #1: loss = 0.000740221 (* 1 = 0.000740221 loss)
I0217 16:30:51.452468  8728 sgd_solver.cpp:106] Iteration 287000, lr = 0.0001
I0217 16:31:09.105535  8728 solver.cpp:228] Iteration 287100, loss = 0.00145893
I0217 16:31:09.105535  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:31:09.105535  8728 solver.cpp:244]     Train net output #1: loss = 0.00145893 (* 1 = 0.00145893 loss)
I0217 16:31:09.105535  8728 sgd_solver.cpp:106] Iteration 287100, lr = 0.0001
I0217 16:31:26.757058  8728 solver.cpp:228] Iteration 287200, loss = 0.00194544
I0217 16:31:26.757058  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:31:26.757058  8728 solver.cpp:244]     Train net output #1: loss = 0.00194544 (* 1 = 0.00194544 loss)
I0217 16:31:26.757058  8728 sgd_solver.cpp:106] Iteration 287200, lr = 0.0001
I0217 16:31:44.411311  8728 solver.cpp:228] Iteration 287300, loss = 0.00303404
I0217 16:31:44.411311  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:31:44.411311  8728 solver.cpp:244]     Train net output #1: loss = 0.00303404 (* 1 = 0.00303404 loss)
I0217 16:31:44.411311  8728 sgd_solver.cpp:106] Iteration 287300, lr = 0.0001
I0217 16:32:02.069557  8728 solver.cpp:228] Iteration 287400, loss = 0.000772796
I0217 16:32:02.070051  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:32:02.070051  8728 solver.cpp:244]     Train net output #1: loss = 0.000772796 (* 1 = 0.000772796 loss)
I0217 16:32:02.070051  8728 sgd_solver.cpp:106] Iteration 287400, lr = 0.0001
I0217 16:32:19.648257  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_287500.caffemodel
I0217 16:32:19.792248  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_287500.solverstate
I0217 16:32:19.859247  8728 solver.cpp:337] Iteration 287500, Testing net (#0)
I0217 16:32:19.859247  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:32:25.870779  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 16:32:25.870779  8728 solver.cpp:404]     Test net output #1: loss = 0.187089 (* 1 = 0.187089 loss)
I0217 16:32:25.941843  8728 solver.cpp:228] Iteration 287500, loss = 0.00250435
I0217 16:32:25.941843  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:32:25.941843  8728 solver.cpp:244]     Train net output #1: loss = 0.00250435 (* 1 = 0.00250435 loss)
I0217 16:32:25.941843  8728 sgd_solver.cpp:106] Iteration 287500, lr = 0.0001
I0217 16:32:43.600497  8728 solver.cpp:228] Iteration 287600, loss = 0.00203847
I0217 16:32:43.600497  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:32:43.600497  8728 solver.cpp:244]     Train net output #1: loss = 0.00203847 (* 1 = 0.00203847 loss)
I0217 16:32:43.600497  8728 sgd_solver.cpp:106] Iteration 287600, lr = 0.0001
I0217 16:33:01.257853  8728 solver.cpp:228] Iteration 287700, loss = 0.001033
I0217 16:33:01.257853  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:33:01.257853  8728 solver.cpp:244]     Train net output #1: loss = 0.001033 (* 1 = 0.001033 loss)
I0217 16:33:01.257853  8728 sgd_solver.cpp:106] Iteration 287700, lr = 0.0001
I0217 16:33:18.915547  8728 solver.cpp:228] Iteration 287800, loss = 0.00079138
I0217 16:33:18.915547  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:33:18.915547  8728 solver.cpp:244]     Train net output #1: loss = 0.000791378 (* 1 = 0.000791378 loss)
I0217 16:33:18.915547  8728 sgd_solver.cpp:106] Iteration 287800, lr = 0.0001
I0217 16:33:36.565340  8728 solver.cpp:228] Iteration 287900, loss = 0.00079187
I0217 16:33:36.565340  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:33:36.565340  8728 solver.cpp:244]     Train net output #1: loss = 0.000791868 (* 1 = 0.000791868 loss)
I0217 16:33:36.565340  8728 sgd_solver.cpp:106] Iteration 287900, lr = 0.0001
I0217 16:33:54.146059  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_288000.caffemodel
I0217 16:33:54.288056  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_288000.solverstate
I0217 16:33:54.354136  8728 solver.cpp:337] Iteration 288000, Testing net (#0)
I0217 16:33:54.354136  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:34:00.349776  8728 solver.cpp:404]     Test net output #0: accuracy = 0.946
I0217 16:34:00.349776  8728 solver.cpp:404]     Test net output #1: loss = 0.18669 (* 1 = 0.18669 loss)
I0217 16:34:00.420836  8728 solver.cpp:228] Iteration 288000, loss = 0.00774194
I0217 16:34:00.420836  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:34:00.420836  8728 solver.cpp:244]     Train net output #1: loss = 0.00774194 (* 1 = 0.00774194 loss)
I0217 16:34:00.420836  8728 sgd_solver.cpp:106] Iteration 288000, lr = 0.0001
I0217 16:34:18.032690  8728 solver.cpp:228] Iteration 288100, loss = 0.00350802
I0217 16:34:18.032690  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:34:18.032690  8728 solver.cpp:244]     Train net output #1: loss = 0.00350802 (* 1 = 0.00350802 loss)
I0217 16:34:18.032690  8728 sgd_solver.cpp:106] Iteration 288100, lr = 0.0001
I0217 16:34:35.692379  8728 solver.cpp:228] Iteration 288200, loss = 0.00136011
I0217 16:34:35.692379  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:34:35.692379  8728 solver.cpp:244]     Train net output #1: loss = 0.00136011 (* 1 = 0.00136011 loss)
I0217 16:34:35.692379  8728 sgd_solver.cpp:106] Iteration 288200, lr = 0.0001
I0217 16:34:53.352057  8728 solver.cpp:228] Iteration 288300, loss = 0.0024269
I0217 16:34:53.352057  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:34:53.352057  8728 solver.cpp:244]     Train net output #1: loss = 0.0024269 (* 1 = 0.0024269 loss)
I0217 16:34:53.352057  8728 sgd_solver.cpp:106] Iteration 288300, lr = 0.0001
I0217 16:35:11.006716  8728 solver.cpp:228] Iteration 288400, loss = 0.00107121
I0217 16:35:11.006716  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:35:11.006716  8728 solver.cpp:244]     Train net output #1: loss = 0.00107121 (* 1 = 0.00107121 loss)
I0217 16:35:11.006716  8728 sgd_solver.cpp:106] Iteration 288400, lr = 0.0001
I0217 16:35:28.588666  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_288500.caffemodel
I0217 16:35:28.727656  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_288500.solverstate
I0217 16:35:28.794657  8728 solver.cpp:337] Iteration 288500, Testing net (#0)
I0217 16:35:28.795157  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:35:34.783138  8728 solver.cpp:404]     Test net output #0: accuracy = 0.946
I0217 16:35:34.783138  8728 solver.cpp:404]     Test net output #1: loss = 0.186652 (* 1 = 0.186652 loss)
I0217 16:35:34.854184  8728 solver.cpp:228] Iteration 288500, loss = 0.00142445
I0217 16:35:34.854184  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:35:34.854184  8728 solver.cpp:244]     Train net output #1: loss = 0.00142445 (* 1 = 0.00142445 loss)
I0217 16:35:34.854184  8728 sgd_solver.cpp:106] Iteration 288500, lr = 0.0001
I0217 16:35:52.489516  8728 solver.cpp:228] Iteration 288600, loss = 0.0014573
I0217 16:35:52.489516  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:35:52.489516  8728 solver.cpp:244]     Train net output #1: loss = 0.0014573 (* 1 = 0.0014573 loss)
I0217 16:35:52.489516  8728 sgd_solver.cpp:106] Iteration 288600, lr = 0.0001
I0217 16:36:10.158264  8728 solver.cpp:228] Iteration 288700, loss = 0.00472187
I0217 16:36:10.158264  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:36:10.158264  8728 solver.cpp:244]     Train net output #1: loss = 0.00472188 (* 1 = 0.00472188 loss)
I0217 16:36:10.158264  8728 sgd_solver.cpp:106] Iteration 288700, lr = 0.0001
I0217 16:36:27.824487  8728 solver.cpp:228] Iteration 288800, loss = 0.00147072
I0217 16:36:27.824487  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:36:27.824487  8728 solver.cpp:244]     Train net output #1: loss = 0.00147072 (* 1 = 0.00147072 loss)
I0217 16:36:27.824487  8728 sgd_solver.cpp:106] Iteration 288800, lr = 0.0001
I0217 16:36:45.483849  8728 solver.cpp:228] Iteration 288900, loss = 0.00075545
I0217 16:36:45.483849  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:36:45.483849  8728 solver.cpp:244]     Train net output #1: loss = 0.000755451 (* 1 = 0.000755451 loss)
I0217 16:36:45.484347  8728 sgd_solver.cpp:106] Iteration 288900, lr = 0.0001
I0217 16:37:03.068469  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_289000.caffemodel
I0217 16:37:03.211958  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_289000.solverstate
I0217 16:37:03.277956  8728 solver.cpp:337] Iteration 289000, Testing net (#0)
I0217 16:37:03.277956  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:37:09.284014  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 16:37:09.284014  8728 solver.cpp:404]     Test net output #1: loss = 0.187095 (* 1 = 0.187095 loss)
I0217 16:37:09.355079  8728 solver.cpp:228] Iteration 289000, loss = 0.00139984
I0217 16:37:09.355079  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:37:09.355079  8728 solver.cpp:244]     Train net output #1: loss = 0.00139984 (* 1 = 0.00139984 loss)
I0217 16:37:09.355079  8728 sgd_solver.cpp:106] Iteration 289000, lr = 0.0001
I0217 16:37:27.013541  8728 solver.cpp:228] Iteration 289100, loss = 0.00160654
I0217 16:37:27.013541  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:37:27.013541  8728 solver.cpp:244]     Train net output #1: loss = 0.00160654 (* 1 = 0.00160654 loss)
I0217 16:37:27.014041  8728 sgd_solver.cpp:106] Iteration 289100, lr = 0.0001
I0217 16:37:44.665987  8728 solver.cpp:228] Iteration 289200, loss = 0.00121657
I0217 16:37:44.665987  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:37:44.665987  8728 solver.cpp:244]     Train net output #1: loss = 0.00121658 (* 1 = 0.00121658 loss)
I0217 16:37:44.665987  8728 sgd_solver.cpp:106] Iteration 289200, lr = 0.0001
I0217 16:38:02.318312  8728 solver.cpp:228] Iteration 289300, loss = 0.00150068
I0217 16:38:02.318312  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:38:02.318312  8728 solver.cpp:244]     Train net output #1: loss = 0.00150069 (* 1 = 0.00150069 loss)
I0217 16:38:02.318312  8728 sgd_solver.cpp:106] Iteration 289300, lr = 0.0001
I0217 16:38:19.974215  8728 solver.cpp:228] Iteration 289400, loss = 0.00149119
I0217 16:38:19.974215  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:38:19.974215  8728 solver.cpp:244]     Train net output #1: loss = 0.0014912 (* 1 = 0.0014912 loss)
I0217 16:38:19.974215  8728 sgd_solver.cpp:106] Iteration 289400, lr = 0.0001
I0217 16:38:37.563189  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_289500.caffemodel
I0217 16:38:37.702180  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_289500.solverstate
I0217 16:38:37.768678  8728 solver.cpp:337] Iteration 289500, Testing net (#0)
I0217 16:38:37.768678  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:38:44.032655  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9465
I0217 16:38:44.032655  8728 solver.cpp:404]     Test net output #1: loss = 0.186773 (* 1 = 0.186773 loss)
I0217 16:38:44.103682  8728 solver.cpp:228] Iteration 289500, loss = 0.00129335
I0217 16:38:44.103682  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:38:44.103682  8728 solver.cpp:244]     Train net output #1: loss = 0.00129335 (* 1 = 0.00129335 loss)
I0217 16:38:44.103682  8728 sgd_solver.cpp:106] Iteration 289500, lr = 0.0001
I0217 16:39:01.744410  8728 solver.cpp:228] Iteration 289600, loss = 0.00132579
I0217 16:39:01.744410  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:39:01.744410  8728 solver.cpp:244]     Train net output #1: loss = 0.0013258 (* 1 = 0.0013258 loss)
I0217 16:39:01.744410  8728 sgd_solver.cpp:106] Iteration 289600, lr = 0.0001
I0217 16:39:19.510741  8728 solver.cpp:228] Iteration 289700, loss = 0.000897934
I0217 16:39:19.510741  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:39:19.510741  8728 solver.cpp:244]     Train net output #1: loss = 0.000897942 (* 1 = 0.000897942 loss)
I0217 16:39:19.510741  8728 sgd_solver.cpp:106] Iteration 289700, lr = 0.0001
I0217 16:39:37.545105  8728 solver.cpp:228] Iteration 289800, loss = 0.00234579
I0217 16:39:37.545105  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:39:37.545105  8728 solver.cpp:244]     Train net output #1: loss = 0.0023458 (* 1 = 0.0023458 loss)
I0217 16:39:37.545105  8728 sgd_solver.cpp:106] Iteration 289800, lr = 0.0001
I0217 16:39:55.606499  8728 solver.cpp:228] Iteration 289900, loss = 0.00194434
I0217 16:39:55.606499  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:39:55.606499  8728 solver.cpp:244]     Train net output #1: loss = 0.00194435 (* 1 = 0.00194435 loss)
I0217 16:39:55.606499  8728 sgd_solver.cpp:106] Iteration 289900, lr = 0.0001
I0217 16:40:13.718288  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_290000.caffemodel
I0217 16:40:13.877025  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_290000.solverstate
I0217 16:40:13.942272  8728 solver.cpp:337] Iteration 290000, Testing net (#0)
I0217 16:40:13.942272  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:40:20.098188  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9462
I0217 16:40:20.098188  8728 solver.cpp:404]     Test net output #1: loss = 0.186711 (* 1 = 0.186711 loss)
I0217 16:40:20.169703  8728 solver.cpp:228] Iteration 290000, loss = 0.00213996
I0217 16:40:20.169703  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:40:20.169703  8728 solver.cpp:244]     Train net output #1: loss = 0.00213996 (* 1 = 0.00213996 loss)
I0217 16:40:20.169703  8728 sgd_solver.cpp:106] Iteration 290000, lr = 0.0001
I0217 16:40:38.158993  8728 solver.cpp:228] Iteration 290100, loss = 0.00247345
I0217 16:40:38.158993  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:40:38.158993  8728 solver.cpp:244]     Train net output #1: loss = 0.00247345 (* 1 = 0.00247345 loss)
I0217 16:40:38.158993  8728 sgd_solver.cpp:106] Iteration 290100, lr = 0.0001
I0217 16:40:56.264842  8728 solver.cpp:228] Iteration 290200, loss = 0.00375528
I0217 16:40:56.264842  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:40:56.264842  8728 solver.cpp:244]     Train net output #1: loss = 0.00375528 (* 1 = 0.00375528 loss)
I0217 16:40:56.264842  8728 sgd_solver.cpp:106] Iteration 290200, lr = 0.0001
I0217 16:41:14.299161  8728 solver.cpp:228] Iteration 290300, loss = 0.000903882
I0217 16:41:14.299161  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:41:14.299161  8728 solver.cpp:244]     Train net output #1: loss = 0.000903879 (* 1 = 0.000903879 loss)
I0217 16:41:14.299161  8728 sgd_solver.cpp:106] Iteration 290300, lr = 0.0001
I0217 16:41:32.285997  8728 solver.cpp:228] Iteration 290400, loss = 0.00514562
I0217 16:41:32.285997  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:41:32.285997  8728 solver.cpp:244]     Train net output #1: loss = 0.00514562 (* 1 = 0.00514562 loss)
I0217 16:41:32.285997  8728 sgd_solver.cpp:106] Iteration 290400, lr = 0.0001
I0217 16:41:50.284919  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_290500.caffemodel
I0217 16:41:50.435923  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_290500.solverstate
I0217 16:41:50.502439  8728 solver.cpp:337] Iteration 290500, Testing net (#0)
I0217 16:41:50.502939  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:41:56.751711  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9455
I0217 16:41:56.751711  8728 solver.cpp:404]     Test net output #1: loss = 0.187206 (* 1 = 0.187206 loss)
I0217 16:41:56.830369  8728 solver.cpp:228] Iteration 290500, loss = 0.000642956
I0217 16:41:56.830369  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:41:56.830369  8728 solver.cpp:244]     Train net output #1: loss = 0.000642955 (* 1 = 0.000642955 loss)
I0217 16:41:56.830369  8728 sgd_solver.cpp:106] Iteration 290500, lr = 0.0001
I0217 16:42:14.900960  8728 solver.cpp:228] Iteration 290600, loss = 0.00583501
I0217 16:42:14.900960  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:42:14.900960  8728 solver.cpp:244]     Train net output #1: loss = 0.00583501 (* 1 = 0.00583501 loss)
I0217 16:42:14.900960  8728 sgd_solver.cpp:106] Iteration 290600, lr = 0.0001
I0217 16:42:32.893244  8728 solver.cpp:228] Iteration 290700, loss = 0.00142871
I0217 16:42:32.893244  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:42:32.893244  8728 solver.cpp:244]     Train net output #1: loss = 0.00142871 (* 1 = 0.00142871 loss)
I0217 16:42:32.893244  8728 sgd_solver.cpp:106] Iteration 290700, lr = 0.0001
I0217 16:42:50.965643  8728 solver.cpp:228] Iteration 290800, loss = 0.000484177
I0217 16:42:50.965643  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:42:50.965643  8728 solver.cpp:244]     Train net output #1: loss = 0.000484178 (* 1 = 0.000484178 loss)
I0217 16:42:50.965643  8728 sgd_solver.cpp:106] Iteration 290800, lr = 0.0001
I0217 16:43:08.945228  8728 solver.cpp:228] Iteration 290900, loss = 0.00074936
I0217 16:43:08.945228  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:43:08.945228  8728 solver.cpp:244]     Train net output #1: loss = 0.000749357 (* 1 = 0.000749357 loss)
I0217 16:43:08.945228  8728 sgd_solver.cpp:106] Iteration 290900, lr = 0.0001
I0217 16:43:26.884470  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_291000.caffemodel
I0217 16:43:27.025075  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_291000.solverstate
I0217 16:43:27.093111  8728 solver.cpp:337] Iteration 291000, Testing net (#0)
I0217 16:43:27.093111  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:43:33.216282  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 16:43:33.216282  8728 solver.cpp:404]     Test net output #1: loss = 0.18654 (* 1 = 0.18654 loss)
I0217 16:43:33.288313  8728 solver.cpp:228] Iteration 291000, loss = 0.00170844
I0217 16:43:33.288313  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:43:33.288313  8728 solver.cpp:244]     Train net output #1: loss = 0.00170844 (* 1 = 0.00170844 loss)
I0217 16:43:33.288313  8728 sgd_solver.cpp:106] Iteration 291000, lr = 0.0001
I0217 16:43:51.258702  8728 solver.cpp:228] Iteration 291100, loss = 0.000749054
I0217 16:43:51.258702  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:43:51.258702  8728 solver.cpp:244]     Train net output #1: loss = 0.000749051 (* 1 = 0.000749051 loss)
I0217 16:43:51.258702  8728 sgd_solver.cpp:106] Iteration 291100, lr = 0.0001
I0217 16:44:09.273005  8728 solver.cpp:228] Iteration 291200, loss = 0.00398555
I0217 16:44:09.273005  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:44:09.273005  8728 solver.cpp:244]     Train net output #1: loss = 0.00398555 (* 1 = 0.00398555 loss)
I0217 16:44:09.273005  8728 sgd_solver.cpp:106] Iteration 291200, lr = 0.0001
I0217 16:44:27.243113  8728 solver.cpp:228] Iteration 291300, loss = 0.000593126
I0217 16:44:27.243113  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:44:27.243113  8728 solver.cpp:244]     Train net output #1: loss = 0.000593122 (* 1 = 0.000593122 loss)
I0217 16:44:27.243113  8728 sgd_solver.cpp:106] Iteration 291300, lr = 0.0001
I0217 16:44:45.231117  8728 solver.cpp:228] Iteration 291400, loss = 0.00213638
I0217 16:44:45.231117  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:44:45.231117  8728 solver.cpp:244]     Train net output #1: loss = 0.00213638 (* 1 = 0.00213638 loss)
I0217 16:44:45.231117  8728 sgd_solver.cpp:106] Iteration 291400, lr = 0.0001
I0217 16:45:03.232498  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_291500.caffemodel
I0217 16:45:03.391311  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_291500.solverstate
I0217 16:45:03.460922  8728 solver.cpp:337] Iteration 291500, Testing net (#0)
I0217 16:45:03.460922  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:45:09.659184  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9462
I0217 16:45:09.659184  8728 solver.cpp:404]     Test net output #1: loss = 0.186876 (* 1 = 0.186876 loss)
I0217 16:45:09.731205  8728 solver.cpp:228] Iteration 291500, loss = 0.000865188
I0217 16:45:09.731205  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:45:09.731205  8728 solver.cpp:244]     Train net output #1: loss = 0.000865185 (* 1 = 0.000865185 loss)
I0217 16:45:09.731205  8728 sgd_solver.cpp:106] Iteration 291500, lr = 0.0001
I0217 16:45:27.724159  8728 solver.cpp:228] Iteration 291600, loss = 0.00272478
I0217 16:45:27.724159  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:45:27.724159  8728 solver.cpp:244]     Train net output #1: loss = 0.00272478 (* 1 = 0.00272478 loss)
I0217 16:45:27.724159  8728 sgd_solver.cpp:106] Iteration 291600, lr = 0.0001
I0217 16:45:45.845458  8728 solver.cpp:228] Iteration 291700, loss = 0.00406888
I0217 16:45:45.845458  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:45:45.845458  8728 solver.cpp:244]     Train net output #1: loss = 0.00406887 (* 1 = 0.00406887 loss)
I0217 16:45:45.845458  8728 sgd_solver.cpp:106] Iteration 291700, lr = 0.0001
I0217 16:46:03.966682  8728 solver.cpp:228] Iteration 291800, loss = 0.000667535
I0217 16:46:03.966682  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:46:03.966682  8728 solver.cpp:244]     Train net output #1: loss = 0.000667524 (* 1 = 0.000667524 loss)
I0217 16:46:03.966682  8728 sgd_solver.cpp:106] Iteration 291800, lr = 0.0001
I0217 16:46:21.975093  8728 solver.cpp:228] Iteration 291900, loss = 0.0072733
I0217 16:46:21.975093  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:46:21.975093  8728 solver.cpp:244]     Train net output #1: loss = 0.00727329 (* 1 = 0.00727329 loss)
I0217 16:46:21.975093  8728 sgd_solver.cpp:106] Iteration 291900, lr = 0.0001
I0217 16:46:40.038074  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_292000.caffemodel
I0217 16:46:40.191715  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_292000.solverstate
I0217 16:46:40.261715  8728 solver.cpp:337] Iteration 292000, Testing net (#0)
I0217 16:46:40.261715  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:46:46.587843  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9457
I0217 16:46:46.587843  8728 solver.cpp:404]     Test net output #1: loss = 0.186828 (* 1 = 0.186828 loss)
I0217 16:46:46.659857  8728 solver.cpp:228] Iteration 292000, loss = 0.00115089
I0217 16:46:46.659857  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:46:46.659857  8728 solver.cpp:244]     Train net output #1: loss = 0.00115088 (* 1 = 0.00115088 loss)
I0217 16:46:46.659857  8728 sgd_solver.cpp:106] Iteration 292000, lr = 0.0001
I0217 16:47:04.739478  8728 solver.cpp:228] Iteration 292100, loss = 0.00487052
I0217 16:47:04.739478  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:47:04.739478  8728 solver.cpp:244]     Train net output #1: loss = 0.00487051 (* 1 = 0.00487051 loss)
I0217 16:47:04.739478  8728 sgd_solver.cpp:106] Iteration 292100, lr = 0.0001
I0217 16:47:22.824324  8728 solver.cpp:228] Iteration 292200, loss = 0.000948694
I0217 16:47:22.824324  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:47:22.824324  8728 solver.cpp:244]     Train net output #1: loss = 0.000948685 (* 1 = 0.000948685 loss)
I0217 16:47:22.824324  8728 sgd_solver.cpp:106] Iteration 292200, lr = 0.0001
I0217 16:47:40.807279  8728 solver.cpp:228] Iteration 292300, loss = 0.000838898
I0217 16:47:40.807279  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:47:40.807279  8728 solver.cpp:244]     Train net output #1: loss = 0.000838889 (* 1 = 0.000838889 loss)
I0217 16:47:40.807279  8728 sgd_solver.cpp:106] Iteration 292300, lr = 0.0001
I0217 16:47:58.780453  8728 solver.cpp:228] Iteration 292400, loss = 0.000612798
I0217 16:47:58.781453  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:47:58.781453  8728 solver.cpp:244]     Train net output #1: loss = 0.000612787 (* 1 = 0.000612787 loss)
I0217 16:47:58.781453  8728 sgd_solver.cpp:106] Iteration 292400, lr = 0.0001
I0217 16:48:16.685092  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_292500.caffemodel
I0217 16:48:16.825124  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_292500.solverstate
I0217 16:48:16.892128  8728 solver.cpp:337] Iteration 292500, Testing net (#0)
I0217 16:48:16.892128  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:48:22.989603  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 16:48:22.989603  8728 solver.cpp:404]     Test net output #1: loss = 0.187525 (* 1 = 0.187525 loss)
I0217 16:48:23.061660  8728 solver.cpp:228] Iteration 292500, loss = 0.00296507
I0217 16:48:23.061660  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:48:23.061660  8728 solver.cpp:244]     Train net output #1: loss = 0.00296506 (* 1 = 0.00296506 loss)
I0217 16:48:23.061660  8728 sgd_solver.cpp:106] Iteration 292500, lr = 0.0001
I0217 16:48:41.040701  8728 solver.cpp:228] Iteration 292600, loss = 0.00148455
I0217 16:48:41.040701  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:48:41.040701  8728 solver.cpp:244]     Train net output #1: loss = 0.00148454 (* 1 = 0.00148454 loss)
I0217 16:48:41.040701  8728 sgd_solver.cpp:106] Iteration 292600, lr = 0.0001
I0217 16:48:59.011732  8728 solver.cpp:228] Iteration 292700, loss = 0.00152015
I0217 16:48:59.011732  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:48:59.011732  8728 solver.cpp:244]     Train net output #1: loss = 0.00152014 (* 1 = 0.00152014 loss)
I0217 16:48:59.011732  8728 sgd_solver.cpp:106] Iteration 292700, lr = 0.0001
I0217 16:49:17.009793  8728 solver.cpp:228] Iteration 292800, loss = 0.00424946
I0217 16:49:17.009793  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:49:17.009793  8728 solver.cpp:244]     Train net output #1: loss = 0.00424945 (* 1 = 0.00424945 loss)
I0217 16:49:17.009793  8728 sgd_solver.cpp:106] Iteration 292800, lr = 0.0001
I0217 16:49:34.981834  8728 solver.cpp:228] Iteration 292900, loss = 0.00162163
I0217 16:49:34.981834  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:49:34.981834  8728 solver.cpp:244]     Train net output #1: loss = 0.00162161 (* 1 = 0.00162161 loss)
I0217 16:49:34.981834  8728 sgd_solver.cpp:106] Iteration 292900, lr = 0.0001
I0217 16:49:52.881654  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_293000.caffemodel
I0217 16:49:53.021667  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_293000.solverstate
I0217 16:49:53.090698  8728 solver.cpp:337] Iteration 293000, Testing net (#0)
I0217 16:49:53.091686  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:49:59.417490  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9462
I0217 16:49:59.417490  8728 solver.cpp:404]     Test net output #1: loss = 0.18737 (* 1 = 0.18737 loss)
I0217 16:49:59.494173  8728 solver.cpp:228] Iteration 293000, loss = 0.00253479
I0217 16:49:59.494173  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:49:59.494173  8728 solver.cpp:244]     Train net output #1: loss = 0.00253477 (* 1 = 0.00253477 loss)
I0217 16:49:59.494173  8728 sgd_solver.cpp:106] Iteration 293000, lr = 0.0001
I0217 16:50:17.724326  8728 solver.cpp:228] Iteration 293100, loss = 0.00231301
I0217 16:50:17.724326  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:50:17.724326  8728 solver.cpp:244]     Train net output #1: loss = 0.00231299 (* 1 = 0.00231299 loss)
I0217 16:50:17.724326  8728 sgd_solver.cpp:106] Iteration 293100, lr = 0.0001
I0217 16:50:35.853709  8728 solver.cpp:228] Iteration 293200, loss = 0.0029355
I0217 16:50:35.853709  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:50:35.853709  8728 solver.cpp:244]     Train net output #1: loss = 0.00293549 (* 1 = 0.00293549 loss)
I0217 16:50:35.853709  8728 sgd_solver.cpp:106] Iteration 293200, lr = 0.0001
I0217 16:50:53.822803  8728 solver.cpp:228] Iteration 293300, loss = 0.000875948
I0217 16:50:53.822803  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:50:53.822803  8728 solver.cpp:244]     Train net output #1: loss = 0.000875933 (* 1 = 0.000875933 loss)
I0217 16:50:53.822803  8728 sgd_solver.cpp:106] Iteration 293300, lr = 0.0001
I0217 16:51:11.664476  8728 solver.cpp:228] Iteration 293400, loss = 0.00073934
I0217 16:51:11.664476  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:51:11.664476  8728 solver.cpp:244]     Train net output #1: loss = 0.000739328 (* 1 = 0.000739328 loss)
I0217 16:51:11.664476  8728 sgd_solver.cpp:106] Iteration 293400, lr = 0.0001
I0217 16:51:29.359294  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_293500.caffemodel
I0217 16:51:29.498952  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_293500.solverstate
I0217 16:51:29.658462  8728 solver.cpp:337] Iteration 293500, Testing net (#0)
I0217 16:51:29.658462  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:51:35.722347  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9453
I0217 16:51:35.722347  8728 solver.cpp:404]     Test net output #1: loss = 0.187836 (* 1 = 0.187836 loss)
I0217 16:51:35.792369  8728 solver.cpp:228] Iteration 293500, loss = 0.00152473
I0217 16:51:35.792369  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:51:35.792369  8728 solver.cpp:244]     Train net output #1: loss = 0.00152472 (* 1 = 0.00152472 loss)
I0217 16:51:35.792369  8728 sgd_solver.cpp:106] Iteration 293500, lr = 0.0001
I0217 16:51:53.502532  8728 solver.cpp:228] Iteration 293600, loss = 0.00424763
I0217 16:51:53.502532  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:51:53.502532  8728 solver.cpp:244]     Train net output #1: loss = 0.00424762 (* 1 = 0.00424762 loss)
I0217 16:51:53.502532  8728 sgd_solver.cpp:106] Iteration 293600, lr = 0.0001
I0217 16:52:11.368666  8728 solver.cpp:228] Iteration 293700, loss = 0.000995756
I0217 16:52:11.368666  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:52:11.368666  8728 solver.cpp:244]     Train net output #1: loss = 0.000995744 (* 1 = 0.000995744 loss)
I0217 16:52:11.368666  8728 sgd_solver.cpp:106] Iteration 293700, lr = 0.0001
I0217 16:52:29.240156  8728 solver.cpp:228] Iteration 293800, loss = 0.0015019
I0217 16:52:29.240156  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:52:29.240156  8728 solver.cpp:244]     Train net output #1: loss = 0.00150189 (* 1 = 0.00150189 loss)
I0217 16:52:29.240156  8728 sgd_solver.cpp:106] Iteration 293800, lr = 0.0001
I0217 16:52:47.345305  8728 solver.cpp:228] Iteration 293900, loss = 0.00266875
I0217 16:52:47.345305  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:52:47.345305  8728 solver.cpp:244]     Train net output #1: loss = 0.00266874 (* 1 = 0.00266874 loss)
I0217 16:52:47.345305  8728 sgd_solver.cpp:106] Iteration 293900, lr = 0.0001
I0217 16:53:05.328613  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_294000.caffemodel
I0217 16:53:05.487499  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_294000.solverstate
I0217 16:53:05.558820  8728 solver.cpp:337] Iteration 294000, Testing net (#0)
I0217 16:53:05.559804  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:53:11.812886  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 16:53:11.812886  8728 solver.cpp:404]     Test net output #1: loss = 0.186749 (* 1 = 0.186749 loss)
I0217 16:53:11.885754  8728 solver.cpp:228] Iteration 294000, loss = 0.000636455
I0217 16:53:11.885754  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:53:11.885754  8728 solver.cpp:244]     Train net output #1: loss = 0.000636446 (* 1 = 0.000636446 loss)
I0217 16:53:11.885754  8728 sgd_solver.cpp:106] Iteration 294000, lr = 0.0001
I0217 16:53:29.893529  8728 solver.cpp:228] Iteration 294100, loss = 0.00291231
I0217 16:53:29.893529  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:53:29.893529  8728 solver.cpp:244]     Train net output #1: loss = 0.0029123 (* 1 = 0.0029123 loss)
I0217 16:53:29.893529  8728 sgd_solver.cpp:106] Iteration 294100, lr = 0.0001
I0217 16:53:47.729923  8728 solver.cpp:228] Iteration 294200, loss = 0.00116146
I0217 16:53:47.729923  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:53:47.729923  8728 solver.cpp:244]     Train net output #1: loss = 0.00116145 (* 1 = 0.00116145 loss)
I0217 16:53:47.729923  8728 sgd_solver.cpp:106] Iteration 294200, lr = 0.0001
I0217 16:54:05.591262  8728 solver.cpp:228] Iteration 294300, loss = 0.00194377
I0217 16:54:05.591262  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:54:05.591262  8728 solver.cpp:244]     Train net output #1: loss = 0.00194376 (* 1 = 0.00194376 loss)
I0217 16:54:05.591262  8728 sgd_solver.cpp:106] Iteration 294300, lr = 0.0001
I0217 16:54:23.420284  8728 solver.cpp:228] Iteration 294400, loss = 0.00094407
I0217 16:54:23.420284  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:54:23.420284  8728 solver.cpp:244]     Train net output #1: loss = 0.000944063 (* 1 = 0.000944063 loss)
I0217 16:54:23.420284  8728 sgd_solver.cpp:106] Iteration 294400, lr = 0.0001
I0217 16:54:41.098259  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_294500.caffemodel
I0217 16:54:41.237280  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_294500.solverstate
I0217 16:54:41.304767  8728 solver.cpp:337] Iteration 294500, Testing net (#0)
I0217 16:54:41.304767  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:54:47.377743  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 16:54:47.377743  8728 solver.cpp:404]     Test net output #1: loss = 0.187465 (* 1 = 0.187465 loss)
I0217 16:54:47.448817  8728 solver.cpp:228] Iteration 294500, loss = 0.00206012
I0217 16:54:47.448817  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:54:47.448817  8728 solver.cpp:244]     Train net output #1: loss = 0.00206011 (* 1 = 0.00206011 loss)
I0217 16:54:47.448817  8728 sgd_solver.cpp:106] Iteration 294500, lr = 0.0001
I0217 16:55:05.309947  8728 solver.cpp:228] Iteration 294600, loss = 0.00136569
I0217 16:55:05.309947  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:55:05.309947  8728 solver.cpp:244]     Train net output #1: loss = 0.00136568 (* 1 = 0.00136568 loss)
I0217 16:55:05.309947  8728 sgd_solver.cpp:106] Iteration 294600, lr = 0.0001
I0217 16:55:23.296164  8728 solver.cpp:228] Iteration 294700, loss = 0.000940243
I0217 16:55:23.296164  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:55:23.296164  8728 solver.cpp:244]     Train net output #1: loss = 0.000940236 (* 1 = 0.000940236 loss)
I0217 16:55:23.296164  8728 sgd_solver.cpp:106] Iteration 294700, lr = 0.0001
I0217 16:55:41.446380  8728 solver.cpp:228] Iteration 294800, loss = 0.00175322
I0217 16:55:41.446380  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:55:41.446380  8728 solver.cpp:244]     Train net output #1: loss = 0.00175322 (* 1 = 0.00175322 loss)
I0217 16:55:41.446380  8728 sgd_solver.cpp:106] Iteration 294800, lr = 0.0001
I0217 16:55:59.665331  8728 solver.cpp:228] Iteration 294900, loss = 0.00138348
I0217 16:55:59.665331  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:55:59.665331  8728 solver.cpp:244]     Train net output #1: loss = 0.00138347 (* 1 = 0.00138347 loss)
I0217 16:55:59.665331  8728 sgd_solver.cpp:106] Iteration 294900, lr = 0.0001
I0217 16:56:17.557694  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_295000.caffemodel
I0217 16:56:17.696192  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_295000.solverstate
I0217 16:56:17.762684  8728 solver.cpp:337] Iteration 295000, Testing net (#0)
I0217 16:56:17.762684  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:56:24.020084  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 16:56:24.020084  8728 solver.cpp:404]     Test net output #1: loss = 0.18749 (* 1 = 0.18749 loss)
I0217 16:56:24.091156  8728 solver.cpp:228] Iteration 295000, loss = 0.00170637
I0217 16:56:24.091156  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:56:24.091156  8728 solver.cpp:244]     Train net output #1: loss = 0.00170637 (* 1 = 0.00170637 loss)
I0217 16:56:24.091156  8728 sgd_solver.cpp:46] MultiStep Status: Iteration 295000, step = 4
I0217 16:56:24.091156  8728 sgd_solver.cpp:106] Iteration 295000, lr = 1e-005
I0217 16:56:41.987728  8728 solver.cpp:228] Iteration 295100, loss = 0.00149262
I0217 16:56:41.987728  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:56:41.987728  8728 solver.cpp:244]     Train net output #1: loss = 0.00149261 (* 1 = 0.00149261 loss)
I0217 16:56:41.987728  8728 sgd_solver.cpp:106] Iteration 295100, lr = 1e-005
I0217 16:56:59.659270  8728 solver.cpp:228] Iteration 295200, loss = 0.00104113
I0217 16:56:59.659270  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:56:59.659270  8728 solver.cpp:244]     Train net output #1: loss = 0.00104112 (* 1 = 0.00104112 loss)
I0217 16:56:59.659270  8728 sgd_solver.cpp:106] Iteration 295200, lr = 1e-005
I0217 16:57:17.308959  8728 solver.cpp:228] Iteration 295300, loss = 0.00372122
I0217 16:57:17.308959  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:57:17.308959  8728 solver.cpp:244]     Train net output #1: loss = 0.00372121 (* 1 = 0.00372121 loss)
I0217 16:57:17.308959  8728 sgd_solver.cpp:106] Iteration 295300, lr = 1e-005
I0217 16:57:35.031023  8728 solver.cpp:228] Iteration 295400, loss = 0.00200123
I0217 16:57:35.031522  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:57:35.031522  8728 solver.cpp:244]     Train net output #1: loss = 0.00200122 (* 1 = 0.00200122 loss)
I0217 16:57:35.031522  8728 sgd_solver.cpp:106] Iteration 295400, lr = 1e-005
I0217 16:57:52.713754  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_295500.caffemodel
I0217 16:57:52.853763  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_295500.solverstate
I0217 16:57:52.919262  8728 solver.cpp:337] Iteration 295500, Testing net (#0)
I0217 16:57:52.919764  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:57:58.988121  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 16:57:58.988121  8728 solver.cpp:404]     Test net output #1: loss = 0.187215 (* 1 = 0.187215 loss)
I0217 16:57:59.060190  8728 solver.cpp:228] Iteration 295500, loss = 0.000569821
I0217 16:57:59.060190  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:57:59.060190  8728 solver.cpp:244]     Train net output #1: loss = 0.000569811 (* 1 = 0.000569811 loss)
I0217 16:57:59.060190  8728 sgd_solver.cpp:106] Iteration 295500, lr = 1e-005
I0217 16:58:16.828366  8728 solver.cpp:228] Iteration 295600, loss = 0.00149461
I0217 16:58:16.828366  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:58:16.828366  8728 solver.cpp:244]     Train net output #1: loss = 0.0014946 (* 1 = 0.0014946 loss)
I0217 16:58:16.828366  8728 sgd_solver.cpp:106] Iteration 295600, lr = 1e-005
I0217 16:58:34.550704  8728 solver.cpp:228] Iteration 295700, loss = 0.002228
I0217 16:58:34.550704  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:58:34.550704  8728 solver.cpp:244]     Train net output #1: loss = 0.002228 (* 1 = 0.002228 loss)
I0217 16:58:34.550704  8728 sgd_solver.cpp:106] Iteration 295700, lr = 1e-005
I0217 16:58:52.261945  8728 solver.cpp:228] Iteration 295800, loss = 0.00085081
I0217 16:58:52.261945  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:58:52.261945  8728 solver.cpp:244]     Train net output #1: loss = 0.000850802 (* 1 = 0.000850802 loss)
I0217 16:58:52.261945  8728 sgd_solver.cpp:106] Iteration 295800, lr = 1e-005
I0217 16:59:09.969265  8728 solver.cpp:228] Iteration 295900, loss = 0.00155221
I0217 16:59:09.969265  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:59:09.969265  8728 solver.cpp:244]     Train net output #1: loss = 0.0015522 (* 1 = 0.0015522 loss)
I0217 16:59:09.969265  8728 sgd_solver.cpp:106] Iteration 295900, lr = 1e-005
I0217 16:59:27.653113  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_296000.caffemodel
I0217 16:59:27.793654  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_296000.solverstate
I0217 16:59:27.861158  8728 solver.cpp:337] Iteration 296000, Testing net (#0)
I0217 16:59:27.861158  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 16:59:33.908074  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9458
I0217 16:59:33.908074  8728 solver.cpp:404]     Test net output #1: loss = 0.187284 (* 1 = 0.187284 loss)
I0217 16:59:33.979142  8728 solver.cpp:228] Iteration 296000, loss = 0.00286378
I0217 16:59:33.979142  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:59:33.979142  8728 solver.cpp:244]     Train net output #1: loss = 0.00286377 (* 1 = 0.00286377 loss)
I0217 16:59:33.979142  8728 sgd_solver.cpp:106] Iteration 296000, lr = 1e-005
I0217 16:59:51.898074  8728 solver.cpp:228] Iteration 296100, loss = 0.00169356
I0217 16:59:51.898074  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 16:59:51.898074  8728 solver.cpp:244]     Train net output #1: loss = 0.00169355 (* 1 = 0.00169355 loss)
I0217 16:59:51.898074  8728 sgd_solver.cpp:106] Iteration 296100, lr = 1e-005
I0217 17:00:09.944308  8728 solver.cpp:228] Iteration 296200, loss = 0.00138177
I0217 17:00:09.944308  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 17:00:09.944308  8728 solver.cpp:244]     Train net output #1: loss = 0.00138176 (* 1 = 0.00138176 loss)
I0217 17:00:09.944308  8728 sgd_solver.cpp:106] Iteration 296200, lr = 1e-005
I0217 17:00:28.101841  8728 solver.cpp:228] Iteration 296300, loss = 0.00244786
I0217 17:00:28.101841  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 17:00:28.101841  8728 solver.cpp:244]     Train net output #1: loss = 0.00244785 (* 1 = 0.00244785 loss)
I0217 17:00:28.101841  8728 sgd_solver.cpp:106] Iteration 296300, lr = 1e-005
I0217 17:00:45.944823  8728 solver.cpp:228] Iteration 296400, loss = 0.000753382
I0217 17:00:45.944823  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 17:00:45.944823  8728 solver.cpp:244]     Train net output #1: loss = 0.000753376 (* 1 = 0.000753376 loss)
I0217 17:00:45.944823  8728 sgd_solver.cpp:106] Iteration 296400, lr = 1e-005
I0217 17:01:03.664849  8728 solver.cpp:454] Snapshotting to binary proto file examples/cifar10_full_relu_bn_iter_296500.caffemodel
I0217 17:01:03.803930  8728 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar10_full_relu_bn_iter_296500.solverstate
I0217 17:01:03.871918  8728 solver.cpp:337] Iteration 296500, Testing net (#0)
I0217 17:01:03.871918  8728 net.cpp:693] Ignoring source layer accuracy_training
I0217 17:01:09.902935  8728 solver.cpp:404]     Test net output #0: accuracy = 0.9456
I0217 17:01:09.902935  8728 solver.cpp:404]     Test net output #1: loss = 0.187298 (* 1 = 0.187298 loss)
I0217 17:01:09.974936  8728 solver.cpp:228] Iteration 296500, loss = 0.00216415
I0217 17:01:09.974936  8728 solver.cpp:244]     Train net output #0: accuracy_training = 1
I0217 17:01:09.974936  872