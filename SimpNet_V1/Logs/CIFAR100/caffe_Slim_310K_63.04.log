I0312 15:03:14.867051  1600 caffe.cpp:218] Using GPUs 0
I0312 15:03:15.037070  1600 caffe.cpp:223] GPU 0: GeForce GTX 980
I0312 15:03:15.698113  1600 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0312 15:03:15.698113  1600 solver.cpp:48] Initializing solver from parameters: 
test_iter: 200
test_interval: 800
base_lr: 0.1
display: 100
max_iter: 400000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 800
snapshot_prefix: "examples/cifar100/snaps/cifar100"
solver_mode: GPU
device_id: 0
random_seed: 1705
net: "examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt"
train_state {
  level: 0
  stage: ""
}
delta: 0.001
stepvalue: 50000
stepvalue: 95000
stepvalue: 220000
stepvalue: 295000
stepvalue: 320000
stepvalue: 270000
type: "AdaDelta"
I0312 15:03:15.698611  1600 solver.cpp:91] Creating training net from net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0312 15:03:15.699612  1600 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0312 15:03:15.699612  1600 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn1_0
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_1
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn2_2
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn3
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_1
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_2
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer bn4_0
I0312 15:03:15.699612  1600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I0312 15:03:15.700111  1600 net.cpp:58] Initializing net from parameters: 
name: "CIFAR100_full"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_train_leveldb_padding"
    batch_size: 64
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TRAIN
  }
  batch_norm_param {
    use_global_stats: false
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy_training"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy_training"
  include {
    phase: TRAIN
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0312 15:03:15.700611  1600 layer_factory.cpp:58] Creating layer cifar
I0312 15:03:15.701612  1600 net.cpp:100] Creating Layer cifar
I0312 15:03:15.701612  1600 net.cpp:408] cifar -> data
I0312 15:03:15.701612  1600 net.cpp:408] cifar -> label
I0312 15:03:15.702611 12704 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0312 15:03:15.708612 12704 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_train_leveldb_padding
I0312 15:03:15.803611  1600 data_layer.cpp:41] output data size: 64,3,32,32
I0312 15:03:15.815111  1600 net.cpp:150] Setting up cifar
I0312 15:03:15.815111  1600 net.cpp:157] Top shape: 64 3 32 32 (196608)
I0312 15:03:15.815111  1600 net.cpp:157] Top shape: 64 (64)
I0312 15:03:15.815111  1600 net.cpp:165] Memory required for data: 786688
I0312 15:03:15.815613  1600 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0312 15:03:15.815613  1600 net.cpp:100] Creating Layer label_cifar_1_split
I0312 15:03:15.815613  1600 net.cpp:434] label_cifar_1_split <- label
I0312 15:03:15.815613  1600 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0312 15:03:15.815613  1600 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0312 15:03:15.815613  1600 net.cpp:150] Setting up label_cifar_1_split
I0312 15:03:15.815613  1600 net.cpp:157] Top shape: 64 (64)
I0312 15:03:15.815613  1600 net.cpp:157] Top shape: 64 (64)
I0312 15:03:15.815613  1600 net.cpp:165] Memory required for data: 787200
I0312 15:03:15.815613  1600 layer_factory.cpp:58] Creating layer conv1
I0312 15:03:15.815613  1600 net.cpp:100] Creating Layer conv1
I0312 15:03:15.815613  1600 net.cpp:434] conv1 <- data
I0312 15:03:15.815613  1600 net.cpp:408] conv1 -> conv1
I0312 15:03:15.816625 11876 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0312 15:03:16.505159  1600 net.cpp:150] Setting up conv1
I0312 15:03:16.505159  1600 net.cpp:157] Top shape: 64 64 32 32 (4194304)
I0312 15:03:16.505159  1600 net.cpp:165] Memory required for data: 17564416
I0312 15:03:16.505159  1600 layer_factory.cpp:58] Creating layer bn1
I0312 15:03:16.505159  1600 net.cpp:100] Creating Layer bn1
I0312 15:03:16.505159  1600 net.cpp:434] bn1 <- conv1
I0312 15:03:16.505159  1600 net.cpp:408] bn1 -> bn1
I0312 15:03:16.505658  1600 net.cpp:150] Setting up bn1
I0312 15:03:16.505658  1600 net.cpp:157] Top shape: 64 64 32 32 (4194304)
I0312 15:03:16.505658  1600 net.cpp:165] Memory required for data: 34341632
I0312 15:03:16.505658  1600 layer_factory.cpp:58] Creating layer scale1
I0312 15:03:16.505658  1600 net.cpp:100] Creating Layer scale1
I0312 15:03:16.505658  1600 net.cpp:434] scale1 <- bn1
I0312 15:03:16.505658  1600 net.cpp:408] scale1 -> scale1
I0312 15:03:16.505658  1600 layer_factory.cpp:58] Creating layer scale1
I0312 15:03:16.505658  1600 net.cpp:150] Setting up scale1
I0312 15:03:16.505658  1600 net.cpp:157] Top shape: 64 64 32 32 (4194304)
I0312 15:03:16.505658  1600 net.cpp:165] Memory required for data: 51118848
I0312 15:03:16.505658  1600 layer_factory.cpp:58] Creating layer relu1
I0312 15:03:16.505658  1600 net.cpp:100] Creating Layer relu1
I0312 15:03:16.505658  1600 net.cpp:434] relu1 <- scale1
I0312 15:03:16.505658  1600 net.cpp:408] relu1 -> relu1
I0312 15:03:16.506659  1600 net.cpp:150] Setting up relu1
I0312 15:03:16.506659  1600 net.cpp:157] Top shape: 64 64 32 32 (4194304)
I0312 15:03:16.506659  1600 net.cpp:165] Memory required for data: 67896064
I0312 15:03:16.506659  1600 layer_factory.cpp:58] Creating layer conv1_0
I0312 15:03:16.506659  1600 net.cpp:100] Creating Layer conv1_0
I0312 15:03:16.506659  1600 net.cpp:434] conv1_0 <- relu1
I0312 15:03:16.506659  1600 net.cpp:408] conv1_0 -> conv1_0
I0312 15:03:16.509660  1600 net.cpp:150] Setting up conv1_0
I0312 15:03:16.509660  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.509660  1600 net.cpp:165] Memory required for data: 76284672
I0312 15:03:16.509660  1600 layer_factory.cpp:58] Creating layer bn1_0
I0312 15:03:16.509660  1600 net.cpp:100] Creating Layer bn1_0
I0312 15:03:16.509660  1600 net.cpp:434] bn1_0 <- conv1_0
I0312 15:03:16.509660  1600 net.cpp:408] bn1_0 -> bn1_0
I0312 15:03:16.510159  1600 net.cpp:150] Setting up bn1_0
I0312 15:03:16.510159  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.510159  1600 net.cpp:165] Memory required for data: 84673280
I0312 15:03:16.510159  1600 layer_factory.cpp:58] Creating layer scale1_0
I0312 15:03:16.510159  1600 net.cpp:100] Creating Layer scale1_0
I0312 15:03:16.510159  1600 net.cpp:434] scale1_0 <- bn1_0
I0312 15:03:16.510159  1600 net.cpp:408] scale1_0 -> scale1_0
I0312 15:03:16.510159  1600 layer_factory.cpp:58] Creating layer scale1_0
I0312 15:03:16.510659  1600 net.cpp:150] Setting up scale1_0
I0312 15:03:16.510659  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.510659  1600 net.cpp:165] Memory required for data: 93061888
I0312 15:03:16.510659  1600 layer_factory.cpp:58] Creating layer relu1_0
I0312 15:03:16.510659  1600 net.cpp:100] Creating Layer relu1_0
I0312 15:03:16.510659  1600 net.cpp:434] relu1_0 <- scale1_0
I0312 15:03:16.510659  1600 net.cpp:408] relu1_0 -> relu1_0
I0312 15:03:16.511159  1600 net.cpp:150] Setting up relu1_0
I0312 15:03:16.511159  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.511159  1600 net.cpp:165] Memory required for data: 101450496
I0312 15:03:16.511159  1600 layer_factory.cpp:58] Creating layer conv2
I0312 15:03:16.511159  1600 net.cpp:100] Creating Layer conv2
I0312 15:03:16.511159  1600 net.cpp:434] conv2 <- relu1_0
I0312 15:03:16.511159  1600 net.cpp:408] conv2 -> conv2
I0312 15:03:16.515159  1600 net.cpp:150] Setting up conv2
I0312 15:03:16.515159  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.515159  1600 net.cpp:165] Memory required for data: 109839104
I0312 15:03:16.515666  1600 layer_factory.cpp:58] Creating layer bn2
I0312 15:03:16.515666  1600 net.cpp:100] Creating Layer bn2
I0312 15:03:16.515666  1600 net.cpp:434] bn2 <- conv2
I0312 15:03:16.515666  1600 net.cpp:408] bn2 -> bn2
I0312 15:03:16.515666  1600 net.cpp:150] Setting up bn2
I0312 15:03:16.515666  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.515666  1600 net.cpp:165] Memory required for data: 118227712
I0312 15:03:16.515666  1600 layer_factory.cpp:58] Creating layer scale2
I0312 15:03:16.515666  1600 net.cpp:100] Creating Layer scale2
I0312 15:03:16.515666  1600 net.cpp:434] scale2 <- bn2
I0312 15:03:16.515666  1600 net.cpp:408] scale2 -> scale2
I0312 15:03:16.516160  1600 layer_factory.cpp:58] Creating layer scale2
I0312 15:03:16.516160  1600 net.cpp:150] Setting up scale2
I0312 15:03:16.516160  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.516160  1600 net.cpp:165] Memory required for data: 126616320
I0312 15:03:16.516160  1600 layer_factory.cpp:58] Creating layer relu2
I0312 15:03:16.516160  1600 net.cpp:100] Creating Layer relu2
I0312 15:03:16.516160  1600 net.cpp:434] relu2 <- scale2
I0312 15:03:16.516160  1600 net.cpp:408] relu2 -> relu2
I0312 15:03:16.517659  1600 net.cpp:150] Setting up relu2
I0312 15:03:16.517659  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.517659  1600 net.cpp:165] Memory required for data: 135004928
I0312 15:03:16.517659  1600 layer_factory.cpp:58] Creating layer conv2_1
I0312 15:03:16.517659  1600 net.cpp:100] Creating Layer conv2_1
I0312 15:03:16.517659  1600 net.cpp:434] conv2_1 <- relu2
I0312 15:03:16.517659  1600 net.cpp:408] conv2_1 -> conv2_1
I0312 15:03:16.522158  1600 net.cpp:150] Setting up conv2_1
I0312 15:03:16.522158  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.522158  1600 net.cpp:165] Memory required for data: 143393536
I0312 15:03:16.522158  1600 layer_factory.cpp:58] Creating layer bn2_1
I0312 15:03:16.522158  1600 net.cpp:100] Creating Layer bn2_1
I0312 15:03:16.522158  1600 net.cpp:434] bn2_1 <- conv2_1
I0312 15:03:16.522158  1600 net.cpp:408] bn2_1 -> bn2_1
I0312 15:03:16.522660  1600 net.cpp:150] Setting up bn2_1
I0312 15:03:16.522660  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.522660  1600 net.cpp:165] Memory required for data: 151782144
I0312 15:03:16.522660  1600 layer_factory.cpp:58] Creating layer scale2_1
I0312 15:03:16.522660  1600 net.cpp:100] Creating Layer scale2_1
I0312 15:03:16.522660  1600 net.cpp:434] scale2_1 <- bn2_1
I0312 15:03:16.522660  1600 net.cpp:408] scale2_1 -> scale2_1
I0312 15:03:16.522660  1600 layer_factory.cpp:58] Creating layer scale2_1
I0312 15:03:16.522660  1600 net.cpp:150] Setting up scale2_1
I0312 15:03:16.522660  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.522660  1600 net.cpp:165] Memory required for data: 160170752
I0312 15:03:16.522660  1600 layer_factory.cpp:58] Creating layer relu2_1
I0312 15:03:16.522660  1600 net.cpp:100] Creating Layer relu2_1
I0312 15:03:16.522660  1600 net.cpp:434] relu2_1 <- scale2_1
I0312 15:03:16.522660  1600 net.cpp:408] relu2_1 -> relu2_1
I0312 15:03:16.524657  1600 net.cpp:150] Setting up relu2_1
I0312 15:03:16.524657  1600 net.cpp:157] Top shape: 64 32 32 32 (2097152)
I0312 15:03:16.524657  1600 net.cpp:165] Memory required for data: 168559360
I0312 15:03:16.524657  1600 layer_factory.cpp:58] Creating layer pool2_1
I0312 15:03:16.524657  1600 net.cpp:100] Creating Layer pool2_1
I0312 15:03:16.524657  1600 net.cpp:434] pool2_1 <- relu2_1
I0312 15:03:16.524657  1600 net.cpp:408] pool2_1 -> pool2_1
I0312 15:03:16.524657  1600 net.cpp:150] Setting up pool2_1
I0312 15:03:16.524657  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.524657  1600 net.cpp:165] Memory required for data: 170656512
I0312 15:03:16.524657  1600 layer_factory.cpp:58] Creating layer conv2_2
I0312 15:03:16.524657  1600 net.cpp:100] Creating Layer conv2_2
I0312 15:03:16.524657  1600 net.cpp:434] conv2_2 <- pool2_1
I0312 15:03:16.524657  1600 net.cpp:408] conv2_2 -> conv2_2
I0312 15:03:16.531658  1600 net.cpp:150] Setting up conv2_2
I0312 15:03:16.531658  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.531658  1600 net.cpp:165] Memory required for data: 172753664
I0312 15:03:16.531658  1600 layer_factory.cpp:58] Creating layer bn2_2
I0312 15:03:16.531658  1600 net.cpp:100] Creating Layer bn2_2
I0312 15:03:16.531658  1600 net.cpp:434] bn2_2 <- conv2_2
I0312 15:03:16.531658  1600 net.cpp:408] bn2_2 -> bn2_2
I0312 15:03:16.532158  1600 net.cpp:150] Setting up bn2_2
I0312 15:03:16.532158  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.532158  1600 net.cpp:165] Memory required for data: 174850816
I0312 15:03:16.532158  1600 layer_factory.cpp:58] Creating layer scale2_2
I0312 15:03:16.532158  1600 net.cpp:100] Creating Layer scale2_2
I0312 15:03:16.532158  1600 net.cpp:434] scale2_2 <- bn2_2
I0312 15:03:16.532158  1600 net.cpp:408] scale2_2 -> scale2_2
I0312 15:03:16.532158  1600 layer_factory.cpp:58] Creating layer scale2_2
I0312 15:03:16.532667  1600 net.cpp:150] Setting up scale2_2
I0312 15:03:16.532667  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.532667  1600 net.cpp:165] Memory required for data: 176947968
I0312 15:03:16.532667  1600 layer_factory.cpp:58] Creating layer relu2_2
I0312 15:03:16.532667  1600 net.cpp:100] Creating Layer relu2_2
I0312 15:03:16.532667  1600 net.cpp:434] relu2_2 <- scale2_2
I0312 15:03:16.532667  1600 net.cpp:408] relu2_2 -> relu2_2
I0312 15:03:16.536159  1600 net.cpp:150] Setting up relu2_2
I0312 15:03:16.536159  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.536159  1600 net.cpp:165] Memory required for data: 179045120
I0312 15:03:16.536159  1600 layer_factory.cpp:58] Creating layer conv3
I0312 15:03:16.536159  1600 net.cpp:100] Creating Layer conv3
I0312 15:03:16.536159  1600 net.cpp:434] conv3 <- relu2_2
I0312 15:03:16.536159  1600 net.cpp:408] conv3 -> conv3
I0312 15:03:16.544658  1600 net.cpp:150] Setting up conv3
I0312 15:03:16.544658  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.544658  1600 net.cpp:165] Memory required for data: 181142272
I0312 15:03:16.544658  1600 layer_factory.cpp:58] Creating layer bn3
I0312 15:03:16.544658  1600 net.cpp:100] Creating Layer bn3
I0312 15:03:16.544658  1600 net.cpp:434] bn3 <- conv3
I0312 15:03:16.544658  1600 net.cpp:408] bn3 -> bn3
I0312 15:03:16.544658  1600 net.cpp:150] Setting up bn3
I0312 15:03:16.544658  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.545158  1600 net.cpp:165] Memory required for data: 183239424
I0312 15:03:16.545158  1600 layer_factory.cpp:58] Creating layer scale3
I0312 15:03:16.545158  1600 net.cpp:100] Creating Layer scale3
I0312 15:03:16.545158  1600 net.cpp:434] scale3 <- bn3
I0312 15:03:16.545158  1600 net.cpp:408] scale3 -> scale3
I0312 15:03:16.545158  1600 layer_factory.cpp:58] Creating layer scale3
I0312 15:03:16.545158  1600 net.cpp:150] Setting up scale3
I0312 15:03:16.545158  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.545158  1600 net.cpp:165] Memory required for data: 185336576
I0312 15:03:16.545158  1600 layer_factory.cpp:58] Creating layer relu3
I0312 15:03:16.545158  1600 net.cpp:100] Creating Layer relu3
I0312 15:03:16.545158  1600 net.cpp:434] relu3 <- scale3
I0312 15:03:16.545158  1600 net.cpp:408] relu3 -> relu3
I0312 15:03:16.549657  1600 net.cpp:150] Setting up relu3
I0312 15:03:16.549657  1600 net.cpp:157] Top shape: 64 32 16 16 (524288)
I0312 15:03:16.549657  1600 net.cpp:165] Memory required for data: 187433728
I0312 15:03:16.549657  1600 layer_factory.cpp:58] Creating layer conv4
I0312 15:03:16.549657  1600 net.cpp:100] Creating Layer conv4
I0312 15:03:16.549657  1600 net.cpp:434] conv4 <- relu3
I0312 15:03:16.549657  1600 net.cpp:408] conv4 -> conv4
I0312 15:03:16.551658  1600 net.cpp:150] Setting up conv4
I0312 15:03:16.551658  1600 net.cpp:157] Top shape: 64 64 16 16 (1048576)
I0312 15:03:16.551658  1600 net.cpp:165] Memory required for data: 191628032
I0312 15:03:16.552158  1600 layer_factory.cpp:58] Creating layer pool4
I0312 15:03:16.552158  1600 net.cpp:100] Creating Layer pool4
I0312 15:03:16.552158  1600 net.cpp:434] pool4 <- conv4
I0312 15:03:16.552158  1600 net.cpp:408] pool4 -> pool4
I0312 15:03:16.552158  1600 net.cpp:150] Setting up pool4
I0312 15:03:16.552158  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.552158  1600 net.cpp:165] Memory required for data: 192676608
I0312 15:03:16.552158  1600 layer_factory.cpp:58] Creating layer bn4
I0312 15:03:16.552158  1600 net.cpp:100] Creating Layer bn4
I0312 15:03:16.552158  1600 net.cpp:434] bn4 <- pool4
I0312 15:03:16.552158  1600 net.cpp:408] bn4 -> bn4
I0312 15:03:16.552158  1600 net.cpp:150] Setting up bn4
I0312 15:03:16.552158  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.552158  1600 net.cpp:165] Memory required for data: 193725184
I0312 15:03:16.552158  1600 layer_factory.cpp:58] Creating layer scale4
I0312 15:03:16.552158  1600 net.cpp:100] Creating Layer scale4
I0312 15:03:16.552158  1600 net.cpp:434] scale4 <- bn4
I0312 15:03:16.552158  1600 net.cpp:408] scale4 -> scale4
I0312 15:03:16.552659  1600 layer_factory.cpp:58] Creating layer scale4
I0312 15:03:16.552659  1600 net.cpp:150] Setting up scale4
I0312 15:03:16.552659  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.552659  1600 net.cpp:165] Memory required for data: 194773760
I0312 15:03:16.552659  1600 layer_factory.cpp:58] Creating layer relu4
I0312 15:03:16.552659  1600 net.cpp:100] Creating Layer relu4
I0312 15:03:16.552659  1600 net.cpp:434] relu4 <- scale4
I0312 15:03:16.552659  1600 net.cpp:408] relu4 -> relu4
I0312 15:03:16.553158  1600 net.cpp:150] Setting up relu4
I0312 15:03:16.553158  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.553158  1600 net.cpp:165] Memory required for data: 195822336
I0312 15:03:16.553158  1600 layer_factory.cpp:58] Creating layer conv4_1
I0312 15:03:16.553158  1600 net.cpp:100] Creating Layer conv4_1
I0312 15:03:16.553158  1600 net.cpp:434] conv4_1 <- relu4
I0312 15:03:16.553158  1600 net.cpp:408] conv4_1 -> conv4_1
I0312 15:03:16.562160  1600 net.cpp:150] Setting up conv4_1
I0312 15:03:16.562160  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.562160  1600 net.cpp:165] Memory required for data: 196870912
I0312 15:03:16.562160  1600 layer_factory.cpp:58] Creating layer bn4_1
I0312 15:03:16.562160  1600 net.cpp:100] Creating Layer bn4_1
I0312 15:03:16.562160  1600 net.cpp:434] bn4_1 <- conv4_1
I0312 15:03:16.562160  1600 net.cpp:408] bn4_1 -> bn4_1
I0312 15:03:16.562659  1600 net.cpp:150] Setting up bn4_1
I0312 15:03:16.562659  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.562659  1600 net.cpp:165] Memory required for data: 197919488
I0312 15:03:16.562659  1600 layer_factory.cpp:58] Creating layer scale4_1
I0312 15:03:16.562659  1600 net.cpp:100] Creating Layer scale4_1
I0312 15:03:16.562659  1600 net.cpp:434] scale4_1 <- bn4_1
I0312 15:03:16.562659  1600 net.cpp:408] scale4_1 -> scale4_1
I0312 15:03:16.562659  1600 layer_factory.cpp:58] Creating layer scale4_1
I0312 15:03:16.562659  1600 net.cpp:150] Setting up scale4_1
I0312 15:03:16.562659  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.562659  1600 net.cpp:165] Memory required for data: 198968064
I0312 15:03:16.562659  1600 layer_factory.cpp:58] Creating layer relu4_1
I0312 15:03:16.562659  1600 net.cpp:100] Creating Layer relu4_1
I0312 15:03:16.562659  1600 net.cpp:434] relu4_1 <- scale4_1
I0312 15:03:16.562659  1600 net.cpp:408] relu4_1 -> relu4_1
I0312 15:03:16.564157  1600 net.cpp:150] Setting up relu4_1
I0312 15:03:16.564157  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.564157  1600 net.cpp:165] Memory required for data: 200016640
I0312 15:03:16.564157  1600 layer_factory.cpp:58] Creating layer conv4_2
I0312 15:03:16.564157  1600 net.cpp:100] Creating Layer conv4_2
I0312 15:03:16.564157  1600 net.cpp:434] conv4_2 <- relu4_1
I0312 15:03:16.564157  1600 net.cpp:408] conv4_2 -> conv4_2
I0312 15:03:16.568158  1600 net.cpp:150] Setting up conv4_2
I0312 15:03:16.568158  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.568158  1600 net.cpp:165] Memory required for data: 201065216
I0312 15:03:16.568158  1600 layer_factory.cpp:58] Creating layer bn4_2
I0312 15:03:16.568158  1600 net.cpp:100] Creating Layer bn4_2
I0312 15:03:16.568158  1600 net.cpp:434] bn4_2 <- conv4_2
I0312 15:03:16.568158  1600 net.cpp:408] bn4_2 -> bn4_2
I0312 15:03:16.568658  1600 net.cpp:150] Setting up bn4_2
I0312 15:03:16.568658  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.568658  1600 net.cpp:165] Memory required for data: 202113792
I0312 15:03:16.568658  1600 layer_factory.cpp:58] Creating layer scale4_2
I0312 15:03:16.568658  1600 net.cpp:100] Creating Layer scale4_2
I0312 15:03:16.568658  1600 net.cpp:434] scale4_2 <- bn4_2
I0312 15:03:16.568658  1600 net.cpp:408] scale4_2 -> scale4_2
I0312 15:03:16.568658  1600 layer_factory.cpp:58] Creating layer scale4_2
I0312 15:03:16.568658  1600 net.cpp:150] Setting up scale4_2
I0312 15:03:16.568658  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.568658  1600 net.cpp:165] Memory required for data: 203162368
I0312 15:03:16.568658  1600 layer_factory.cpp:58] Creating layer relu4_2
I0312 15:03:16.568658  1600 net.cpp:100] Creating Layer relu4_2
I0312 15:03:16.568658  1600 net.cpp:434] relu4_2 <- scale4_2
I0312 15:03:16.568658  1600 net.cpp:408] relu4_2 -> relu4_2
I0312 15:03:16.569159  1600 net.cpp:150] Setting up relu4_2
I0312 15:03:16.569159  1600 net.cpp:157] Top shape: 64 64 8 8 (262144)
I0312 15:03:16.569159  1600 net.cpp:165] Memory required for data: 204210944
I0312 15:03:16.569159  1600 layer_factory.cpp:58] Creating layer pool4_2
I0312 15:03:16.569159  1600 net.cpp:100] Creating Layer pool4_2
I0312 15:03:16.569159  1600 net.cpp:434] pool4_2 <- relu4_2
I0312 15:03:16.569159  1600 net.cpp:408] pool4_2 -> pool4_2
I0312 15:03:16.569159  1600 net.cpp:150] Setting up pool4_2
I0312 15:03:16.569660  1600 net.cpp:157] Top shape: 64 64 4 4 (65536)
I0312 15:03:16.569660  1600 net.cpp:165] Memory required for data: 204473088
I0312 15:03:16.569660  1600 layer_factory.cpp:58] Creating layer conv4_0
I0312 15:03:16.569660  1600 net.cpp:100] Creating Layer conv4_0
I0312 15:03:16.569660  1600 net.cpp:434] conv4_0 <- pool4_2
I0312 15:03:16.569660  1600 net.cpp:408] conv4_0 -> conv4_0
I0312 15:03:16.577658  1600 net.cpp:150] Setting up conv4_0
I0312 15:03:16.577658  1600 net.cpp:157] Top shape: 64 128 4 4 (131072)
I0312 15:03:16.577658  1600 net.cpp:165] Memory required for data: 204997376
I0312 15:03:16.578158  1600 layer_factory.cpp:58] Creating layer bn4_0
I0312 15:03:16.578158  1600 net.cpp:100] Creating Layer bn4_0
I0312 15:03:16.578158  1600 net.cpp:434] bn4_0 <- conv4_0
I0312 15:03:16.578158  1600 net.cpp:408] bn4_0 -> bn4_0
I0312 15:03:16.578158  1600 net.cpp:150] Setting up bn4_0
I0312 15:03:16.578158  1600 net.cpp:157] Top shape: 64 128 4 4 (131072)
I0312 15:03:16.578158  1600 net.cpp:165] Memory required for data: 205521664
I0312 15:03:16.578158  1600 layer_factory.cpp:58] Creating layer scale4_0
I0312 15:03:16.578158  1600 net.cpp:100] Creating Layer scale4_0
I0312 15:03:16.578158  1600 net.cpp:434] scale4_0 <- bn4_0
I0312 15:03:16.578158  1600 net.cpp:408] scale4_0 -> scale4_0
I0312 15:03:16.578158  1600 layer_factory.cpp:58] Creating layer scale4_0
I0312 15:03:16.578660  1600 net.cpp:150] Setting up scale4_0
I0312 15:03:16.578660  1600 net.cpp:157] Top shape: 64 128 4 4 (131072)
I0312 15:03:16.578660  1600 net.cpp:165] Memory required for data: 206045952
I0312 15:03:16.578660  1600 layer_factory.cpp:58] Creating layer relu4_0
I0312 15:03:16.578660  1600 net.cpp:100] Creating Layer relu4_0
I0312 15:03:16.578660  1600 net.cpp:434] relu4_0 <- scale4_0
I0312 15:03:16.578660  1600 net.cpp:408] relu4_0 -> relu4_0
I0312 15:03:16.579160  1600 net.cpp:150] Setting up relu4_0
I0312 15:03:16.579160  1600 net.cpp:157] Top shape: 64 128 4 4 (131072)
I0312 15:03:16.579160  1600 net.cpp:165] Memory required for data: 206570240
I0312 15:03:16.579160  1600 layer_factory.cpp:58] Creating layer cccp4
I0312 15:03:16.579160  1600 net.cpp:100] Creating Layer cccp4
I0312 15:03:16.579658  1600 net.cpp:434] cccp4 <- relu4_0
I0312 15:03:16.579658  1600 net.cpp:408] cccp4 -> cccp4
I0312 15:03:16.584658  1600 net.cpp:150] Setting up cccp4
I0312 15:03:16.584658  1600 net.cpp:157] Top shape: 64 256 4 4 (262144)
I0312 15:03:16.584658  1600 net.cpp:165] Memory required for data: 207618816
I0312 15:03:16.584658  1600 layer_factory.cpp:58] Creating layer relu_cccp4
I0312 15:03:16.584658  1600 net.cpp:100] Creating Layer relu_cccp4
I0312 15:03:16.584658  1600 net.cpp:434] relu_cccp4 <- cccp4
I0312 15:03:16.584658  1600 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0312 15:03:16.586158  1600 net.cpp:150] Setting up relu_cccp4
I0312 15:03:16.586158  1600 net.cpp:157] Top shape: 64 256 4 4 (262144)
I0312 15:03:16.586158  1600 net.cpp:165] Memory required for data: 208667392
I0312 15:03:16.586158  1600 layer_factory.cpp:58] Creating layer cccp5
I0312 15:03:16.586158  1600 net.cpp:100] Creating Layer cccp5
I0312 15:03:16.586158  1600 net.cpp:434] cccp5 <- cccp4
I0312 15:03:16.586158  1600 net.cpp:408] cccp5 -> cccp5
I0312 15:03:16.595659  1600 net.cpp:150] Setting up cccp5
I0312 15:03:16.595659  1600 net.cpp:157] Top shape: 64 64 4 4 (65536)
I0312 15:03:16.595659  1600 net.cpp:165] Memory required for data: 208929536
I0312 15:03:16.595659  1600 layer_factory.cpp:58] Creating layer relu_cccp5
I0312 15:03:16.595659  1600 net.cpp:100] Creating Layer relu_cccp5
I0312 15:03:16.595659  1600 net.cpp:434] relu_cccp5 <- cccp5
I0312 15:03:16.595659  1600 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0312 15:03:16.596160  1600 net.cpp:150] Setting up relu_cccp5
I0312 15:03:16.596160  1600 net.cpp:157] Top shape: 64 64 4 4 (65536)
I0312 15:03:16.596160  1600 net.cpp:165] Memory required for data: 209191680
I0312 15:03:16.596160  1600 layer_factory.cpp:58] Creating layer poolcp5
I0312 15:03:16.596160  1600 net.cpp:100] Creating Layer poolcp5
I0312 15:03:16.596160  1600 net.cpp:434] poolcp5 <- cccp5
I0312 15:03:16.596160  1600 net.cpp:408] poolcp5 -> poolcp5
I0312 15:03:16.596160  1600 net.cpp:150] Setting up poolcp5
I0312 15:03:16.596160  1600 net.cpp:157] Top shape: 64 64 2 2 (16384)
I0312 15:03:16.596660  1600 net.cpp:165] Memory required for data: 209257216
I0312 15:03:16.596660  1600 layer_factory.cpp:58] Creating layer cccp6
I0312 15:03:16.596660  1600 net.cpp:100] Creating Layer cccp6
I0312 15:03:16.596660  1600 net.cpp:434] cccp6 <- poolcp5
I0312 15:03:16.596660  1600 net.cpp:408] cccp6 -> cccp6
I0312 15:03:16.609659  1600 net.cpp:150] Setting up cccp6
I0312 15:03:16.609659  1600 net.cpp:157] Top shape: 64 64 2 2 (16384)
I0312 15:03:16.609659  1600 net.cpp:165] Memory required for data: 209322752
I0312 15:03:16.609659  1600 layer_factory.cpp:58] Creating layer relu_cccp6
I0312 15:03:16.609659  1600 net.cpp:100] Creating Layer relu_cccp6
I0312 15:03:16.609659  1600 net.cpp:434] relu_cccp6 <- cccp6
I0312 15:03:16.609659  1600 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0312 15:03:16.610158  1600 net.cpp:150] Setting up relu_cccp6
I0312 15:03:16.610158  1600 net.cpp:157] Top shape: 64 64 2 2 (16384)
I0312 15:03:16.610158  1600 net.cpp:165] Memory required for data: 209388288
I0312 15:03:16.610158  1600 layer_factory.cpp:58] Creating layer poolcp6
I0312 15:03:16.610158  1600 net.cpp:100] Creating Layer poolcp6
I0312 15:03:16.610158  1600 net.cpp:434] poolcp6 <- cccp6
I0312 15:03:16.610158  1600 net.cpp:408] poolcp6 -> poolcp6
I0312 15:03:16.610158  1600 net.cpp:150] Setting up poolcp6
I0312 15:03:16.610158  1600 net.cpp:157] Top shape: 64 64 1 1 (4096)
I0312 15:03:16.610158  1600 net.cpp:165] Memory required for data: 209404672
I0312 15:03:16.610158  1600 layer_factory.cpp:58] Creating layer ip1
I0312 15:03:16.610158  1600 net.cpp:100] Creating Layer ip1
I0312 15:03:16.610158  1600 net.cpp:434] ip1 <- poolcp6
I0312 15:03:16.610158  1600 net.cpp:408] ip1 -> ip1
I0312 15:03:16.610658  1600 net.cpp:150] Setting up ip1
I0312 15:03:16.610658  1600 net.cpp:157] Top shape: 64 100 (6400)
I0312 15:03:16.610658  1600 net.cpp:165] Memory required for data: 209430272
I0312 15:03:16.610658  1600 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0312 15:03:16.610658  1600 net.cpp:100] Creating Layer ip1_ip1_0_split
I0312 15:03:16.610658  1600 net.cpp:434] ip1_ip1_0_split <- ip1
I0312 15:03:16.610658  1600 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0312 15:03:16.610658  1600 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0312 15:03:16.610658  1600 net.cpp:150] Setting up ip1_ip1_0_split
I0312 15:03:16.610658  1600 net.cpp:157] Top shape: 64 100 (6400)
I0312 15:03:16.610658  1600 net.cpp:157] Top shape: 64 100 (6400)
I0312 15:03:16.610658  1600 net.cpp:165] Memory required for data: 209481472
I0312 15:03:16.610658  1600 layer_factory.cpp:58] Creating layer accuracy_training
I0312 15:03:16.610658  1600 net.cpp:100] Creating Layer accuracy_training
I0312 15:03:16.610658  1600 net.cpp:434] accuracy_training <- ip1_ip1_0_split_0
I0312 15:03:16.610658  1600 net.cpp:434] accuracy_training <- label_cifar_1_split_0
I0312 15:03:16.610658  1600 net.cpp:408] accuracy_training -> accuracy_training
I0312 15:03:16.610658  1600 net.cpp:150] Setting up accuracy_training
I0312 15:03:16.610658  1600 net.cpp:157] Top shape: (1)
I0312 15:03:16.610658  1600 net.cpp:165] Memory required for data: 209481476
I0312 15:03:16.610658  1600 layer_factory.cpp:58] Creating layer loss
I0312 15:03:16.610658  1600 net.cpp:100] Creating Layer loss
I0312 15:03:16.610658  1600 net.cpp:434] loss <- ip1_ip1_0_split_1
I0312 15:03:16.610658  1600 net.cpp:434] loss <- label_cifar_1_split_1
I0312 15:03:16.610658  1600 net.cpp:408] loss -> loss
I0312 15:03:16.610658  1600 layer_factory.cpp:58] Creating layer loss
I0312 15:03:16.611160  1600 net.cpp:150] Setting up loss
I0312 15:03:16.611160  1600 net.cpp:157] Top shape: (1)
I0312 15:03:16.611160  1600 net.cpp:160]     with loss weight 1
I0312 15:03:16.611160  1600 net.cpp:165] Memory required for data: 209481480
I0312 15:03:16.611160  1600 net.cpp:226] loss needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:228] accuracy_training does not need backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] ip1 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] poolcp6 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] relu_cccp6 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] cccp6 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] poolcp5 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] relu_cccp5 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] cccp5 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] relu_cccp4 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] cccp4 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] relu4_0 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] scale4_0 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] bn4_0 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] conv4_0 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] pool4_2 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] relu4_2 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] scale4_2 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] bn4_2 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] conv4_2 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] relu4_1 needs backward computation.
I0312 15:03:16.611160  1600 net.cpp:226] scale4_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn4_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv4_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] relu4 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] scale4 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn4 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] pool4 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv4 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] relu3 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] scale3 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn3 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv3 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] relu2_2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] scale2_2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn2_2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv2_2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] pool2_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] relu2_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] scale2_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn2_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv2_1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] relu2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] scale2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv2 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] relu1_0 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] scale1_0 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn1_0 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv1_0 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] relu1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] scale1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] bn1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:226] conv1 needs backward computation.
I0312 15:03:16.611659  1600 net.cpp:228] label_cifar_1_split does not need backward computation.
I0312 15:03:16.611659  1600 net.cpp:228] cifar does not need backward computation.
I0312 15:03:16.611659  1600 net.cpp:270] This network produces output accuracy_training
I0312 15:03:16.611659  1600 net.cpp:270] This network produces output loss
I0312 15:03:16.611659  1600 net.cpp:283] Network initialization done.
I0312 15:03:16.612658  1600 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0312 15:03:16.612658  1600 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I0312 15:03:16.612658  1600 solver.cpp:181] Creating test net (#0) specified by net file: examples/cifar100/fcifar100_full_relu_train_test_bn.prototxt
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn1_0
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_1
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn2_2
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn3
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_1
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_2
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer bn4_0
I0312 15:03:16.612658  1600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer accuracy_training
I0312 15:03:16.613160  1600 net.cpp:58] Initializing net from parameters: 
name: "CIFAR100_full"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    crop_size: 32
  }
  data_param {
    source: "examples/cifar100/cifar100_test_leveldb_padding"
    batch_size: 50
    backend: LEVELDB
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1"
  type: "Scale"
  bottom: "bn1"
  top: "scale1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "scale1"
  top: "relu1"
}
layer {
  name: "conv1_0"
  type: "Convolution"
  bottom: "relu1"
  top: "conv1_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn1_0"
  type: "BatchNorm"
  bottom: "conv1_0"
  top: "bn1_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale1_0"
  type: "Scale"
  bottom: "bn1_0"
  top: "scale1_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu1_0"
  type: "ReLU"
  bottom: "scale1_0"
  top: "relu1_0"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "relu1_0"
  top: "conv2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2"
  type: "BatchNorm"
  bottom: "conv2"
  top: "bn2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2"
  type: "Scale"
  bottom: "bn2"
  top: "scale2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "scale2"
  top: "relu2"
}
layer {
  name: "conv2_1"
  type: "Convolution"
  bottom: "relu2"
  top: "conv2_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_1"
  type: "BatchNorm"
  bottom: "conv2_1"
  top: "bn2_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_1"
  type: "Scale"
  bottom: "bn2_1"
  top: "scale2_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_1"
  type: "ReLU"
  bottom: "scale2_1"
  top: "relu2_1"
}
layer {
  name: "pool2_1"
  type: "Pooling"
  bottom: "relu2_1"
  top: "pool2_1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv2_2"
  type: "Convolution"
  bottom: "pool2_1"
  top: "conv2_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
  }
}
layer {
  name: "bn2_2"
  type: "BatchNorm"
  bottom: "conv2_2"
  top: "bn2_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale2_2"
  type: "Scale"
  bottom: "bn2_2"
  top: "scale2_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu2_2"
  type: "ReLU"
  bottom: "scale2_2"
  top: "relu2_2"
}
layer {
  name: "conv3"
  type: "Convolution"
  bottom: "relu2_2"
  top: "conv3"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn3"
  type: "BatchNorm"
  bottom: "conv3"
  top: "bn3"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale3"
  type: "Scale"
  bottom: "bn3"
  top: "scale3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu3"
  type: "ReLU"
  bottom: "scale3"
  top: "relu3"
}
layer {
  name: "conv4"
  type: "Convolution"
  bottom: "relu3"
  top: "conv4"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "bn4"
  type: "BatchNorm"
  bottom: "pool4"
  top: "bn4"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4"
  type: "Scale"
  bottom: "bn4"
  top: "scale4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4"
  type: "ReLU"
  bottom: "scale4"
  top: "relu4"
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "relu4"
  top: "conv4_1"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_1"
  type: "BatchNorm"
  bottom: "conv4_1"
  top: "bn4_1"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_1"
  type: "Scale"
  bottom: "bn4_1"
  top: "scale4_1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_1"
  type: "ReLU"
  bottom: "scale4_1"
  top: "relu4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "relu4_1"
  top: "conv4_2"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_2"
  type: "BatchNorm"
  bottom: "conv4_2"
  top: "bn4_2"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_2"
  type: "Scale"
  bottom: "bn4_2"
  top: "scale4_2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_2"
  type: "ReLU"
  bottom: "scale4_2"
  top: "relu4_2"
}
layer {
  name: "pool4_2"
  type: "Pooling"
  bottom: "relu4_2"
  top: "pool4_2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "conv4_0"
  type: "Convolution"
  bottom: "pool4_2"
  top: "conv4_0"
  param {
    lr_mult: 1
  }
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "xavier"
    }
  }
}
layer {
  name: "bn4_0"
  type: "BatchNorm"
  bottom: "conv4_0"
  top: "bn4_0"
  include {
    phase: TEST
  }
  batch_norm_param {
    use_global_stats: true
    moving_average_fraction: 0.95
  }
}
layer {
  name: "scale4_0"
  type: "Scale"
  bottom: "bn4_0"
  top: "scale4_0"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "relu4_0"
  type: "ReLU"
  bottom: "scale4_0"
  top: "relu4_0"
}
layer {
  name: "cccp4"
  type: "Convolution"
  bottom: "relu4_0"
  top: "cccp4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp4"
  type: "ReLU"
  bottom: "cccp4"
  top: "cccp4"
}
layer {
  name: "cccp5"
  type: "Convolution"
  bottom: "cccp4"
  top: "cccp5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 1
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp5"
  type: "ReLU"
  bottom: "cccp5"
  top: "cccp5"
}
layer {
  name: "poolcp5"
  type: "Pooling"
  bottom: "cccp5"
  top: "poolcp5"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "cccp6"
  type: "Convolution"
  bottom: "poolcp5"
  top: "cccp6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    group: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu_cccp6"
  type: "ReLU"
  bottom: "cccp6"
  top: "cccp6"
}
layer {
  name: "poolcp6"
  type: "Pooling"
  bottom: "cccp6"
  top: "poolcp6"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "ip1"
  type: "InnerProduct"
  bottom: "poolcp6"
  top: "ip1"
  param {
    lr_mult: 1
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 100
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
    }
  }
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "ip1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
layer {
  name: "loss"
  type: "SoftmaxWithLoss"
  bottom: "ip1"
  bottom: "label"
  top: "loss"
}
I0312 15:03:16.613160  1600 layer_factory.cpp:58] Creating layer cifar
I0312 15:03:16.614161  1600 net.cpp:100] Creating Layer cifar
I0312 15:03:16.614161  1600 net.cpp:408] cifar -> data
I0312 15:03:16.614161  1600 net.cpp:408] cifar -> label
I0312 15:03:16.615658 11028 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0312 15:03:16.618659 11028 db_leveldb.cpp:18] Opened leveldb examples/cifar100/cifar100_test_leveldb_padding
I0312 15:03:16.619159  1600 data_layer.cpp:41] output data size: 50,3,32,32
I0312 15:03:16.628163  1600 net.cpp:150] Setting up cifar
I0312 15:03:16.628163  1600 net.cpp:157] Top shape: 50 3 32 32 (153600)
I0312 15:03:16.628163  1600 net.cpp:157] Top shape: 50 (50)
I0312 15:03:16.628163  1600 net.cpp:165] Memory required for data: 614600
I0312 15:03:16.628163  1600 layer_factory.cpp:58] Creating layer label_cifar_1_split
I0312 15:03:16.628163  1600 net.cpp:100] Creating Layer label_cifar_1_split
I0312 15:03:16.628163  1600 net.cpp:434] label_cifar_1_split <- label
I0312 15:03:16.628163  1600 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_0
I0312 15:03:16.628163  1600 net.cpp:408] label_cifar_1_split -> label_cifar_1_split_1
I0312 15:03:16.628659  1600 net.cpp:150] Setting up label_cifar_1_split
I0312 15:03:16.628659  1600 net.cpp:157] Top shape: 50 (50)
I0312 15:03:16.628659  1600 net.cpp:157] Top shape: 50 (50)
I0312 15:03:16.628659  1600 net.cpp:165] Memory required for data: 615000
I0312 15:03:16.628659  1600 layer_factory.cpp:58] Creating layer conv1
I0312 15:03:16.628659  1600 net.cpp:100] Creating Layer conv1
I0312 15:03:16.628659  1600 net.cpp:434] conv1 <- data
I0312 15:03:16.628659  1600 net.cpp:408] conv1 -> conv1
I0312 15:03:16.629658 13932 common.cpp:36] System entropy source not available, using fallback algorithm to generate seed instead.
I0312 15:03:16.632159  1600 net.cpp:150] Setting up conv1
I0312 15:03:16.632159  1600 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0312 15:03:16.632159  1600 net.cpp:165] Memory required for data: 13722200
I0312 15:03:16.632659  1600 layer_factory.cpp:58] Creating layer bn1
I0312 15:03:16.632659  1600 net.cpp:100] Creating Layer bn1
I0312 15:03:16.632659  1600 net.cpp:434] bn1 <- conv1
I0312 15:03:16.632659  1600 net.cpp:408] bn1 -> bn1
I0312 15:03:16.632659  1600 net.cpp:150] Setting up bn1
I0312 15:03:16.632659  1600 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0312 15:03:16.632659  1600 net.cpp:165] Memory required for data: 26829400
I0312 15:03:16.632659  1600 layer_factory.cpp:58] Creating layer scale1
I0312 15:03:16.632659  1600 net.cpp:100] Creating Layer scale1
I0312 15:03:16.632659  1600 net.cpp:434] scale1 <- bn1
I0312 15:03:16.632659  1600 net.cpp:408] scale1 -> scale1
I0312 15:03:16.632659  1600 layer_factory.cpp:58] Creating layer scale1
I0312 15:03:16.633158  1600 net.cpp:150] Setting up scale1
I0312 15:03:16.633158  1600 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0312 15:03:16.633158  1600 net.cpp:165] Memory required for data: 39936600
I0312 15:03:16.633158  1600 layer_factory.cpp:58] Creating layer relu1
I0312 15:03:16.633158  1600 net.cpp:100] Creating Layer relu1
I0312 15:03:16.633158  1600 net.cpp:434] relu1 <- scale1
I0312 15:03:16.633158  1600 net.cpp:408] relu1 -> relu1
I0312 15:03:16.634658  1600 net.cpp:150] Setting up relu1
I0312 15:03:16.634658  1600 net.cpp:157] Top shape: 50 64 32 32 (3276800)
I0312 15:03:16.634658  1600 net.cpp:165] Memory required for data: 53043800
I0312 15:03:16.634658  1600 layer_factory.cpp:58] Creating layer conv1_0
I0312 15:03:16.634658  1600 net.cpp:100] Creating Layer conv1_0
I0312 15:03:16.634658  1600 net.cpp:434] conv1_0 <- relu1
I0312 15:03:16.634658  1600 net.cpp:408] conv1_0 -> conv1_0
I0312 15:03:16.638659  1600 net.cpp:150] Setting up conv1_0
I0312 15:03:16.638659  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.638659  1600 net.cpp:165] Memory required for data: 59597400
I0312 15:03:16.638659  1600 layer_factory.cpp:58] Creating layer bn1_0
I0312 15:03:16.638659  1600 net.cpp:100] Creating Layer bn1_0
I0312 15:03:16.638659  1600 net.cpp:434] bn1_0 <- conv1_0
I0312 15:03:16.638659  1600 net.cpp:408] bn1_0 -> bn1_0
I0312 15:03:16.639158  1600 net.cpp:150] Setting up bn1_0
I0312 15:03:16.639158  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.639158  1600 net.cpp:165] Memory required for data: 66151000
I0312 15:03:16.639158  1600 layer_factory.cpp:58] Creating layer scale1_0
I0312 15:03:16.639158  1600 net.cpp:100] Creating Layer scale1_0
I0312 15:03:16.639158  1600 net.cpp:434] scale1_0 <- bn1_0
I0312 15:03:16.639158  1600 net.cpp:408] scale1_0 -> scale1_0
I0312 15:03:16.639158  1600 layer_factory.cpp:58] Creating layer scale1_0
I0312 15:03:16.639657  1600 net.cpp:150] Setting up scale1_0
I0312 15:03:16.639657  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.639657  1600 net.cpp:165] Memory required for data: 72704600
I0312 15:03:16.639657  1600 layer_factory.cpp:58] Creating layer relu1_0
I0312 15:03:16.639657  1600 net.cpp:100] Creating Layer relu1_0
I0312 15:03:16.639657  1600 net.cpp:434] relu1_0 <- scale1_0
I0312 15:03:16.639657  1600 net.cpp:408] relu1_0 -> relu1_0
I0312 15:03:16.640657  1600 net.cpp:150] Setting up relu1_0
I0312 15:03:16.640657  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.640657  1600 net.cpp:165] Memory required for data: 79258200
I0312 15:03:16.640657  1600 layer_factory.cpp:58] Creating layer conv2
I0312 15:03:16.640657  1600 net.cpp:100] Creating Layer conv2
I0312 15:03:16.640657  1600 net.cpp:434] conv2 <- relu1_0
I0312 15:03:16.640657  1600 net.cpp:408] conv2 -> conv2
I0312 15:03:16.646158  1600 net.cpp:150] Setting up conv2
I0312 15:03:16.646158  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.646158  1600 net.cpp:165] Memory required for data: 85811800
I0312 15:03:16.646158  1600 layer_factory.cpp:58] Creating layer bn2
I0312 15:03:16.646158  1600 net.cpp:100] Creating Layer bn2
I0312 15:03:16.646158  1600 net.cpp:434] bn2 <- conv2
I0312 15:03:16.646158  1600 net.cpp:408] bn2 -> bn2
I0312 15:03:16.646659  1600 net.cpp:150] Setting up bn2
I0312 15:03:16.646659  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.646659  1600 net.cpp:165] Memory required for data: 92365400
I0312 15:03:16.646659  1600 layer_factory.cpp:58] Creating layer scale2
I0312 15:03:16.646659  1600 net.cpp:100] Creating Layer scale2
I0312 15:03:16.646659  1600 net.cpp:434] scale2 <- bn2
I0312 15:03:16.646659  1600 net.cpp:408] scale2 -> scale2
I0312 15:03:16.646659  1600 layer_factory.cpp:58] Creating layer scale2
I0312 15:03:16.646659  1600 net.cpp:150] Setting up scale2
I0312 15:03:16.646659  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.646659  1600 net.cpp:165] Memory required for data: 98919000
I0312 15:03:16.646659  1600 layer_factory.cpp:58] Creating layer relu2
I0312 15:03:16.646659  1600 net.cpp:100] Creating Layer relu2
I0312 15:03:16.646659  1600 net.cpp:434] relu2 <- scale2
I0312 15:03:16.646659  1600 net.cpp:408] relu2 -> relu2
I0312 15:03:16.651160  1600 net.cpp:150] Setting up relu2
I0312 15:03:16.651160  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.651160  1600 net.cpp:165] Memory required for data: 105472600
I0312 15:03:16.651160  1600 layer_factory.cpp:58] Creating layer conv2_1
I0312 15:03:16.651160  1600 net.cpp:100] Creating Layer conv2_1
I0312 15:03:16.651160  1600 net.cpp:434] conv2_1 <- relu2
I0312 15:03:16.651160  1600 net.cpp:408] conv2_1 -> conv2_1
I0312 15:03:16.658159  1600 net.cpp:150] Setting up conv2_1
I0312 15:03:16.658159  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.658159  1600 net.cpp:165] Memory required for data: 112026200
I0312 15:03:16.658159  1600 layer_factory.cpp:58] Creating layer bn2_1
I0312 15:03:16.658159  1600 net.cpp:100] Creating Layer bn2_1
I0312 15:03:16.658159  1600 net.cpp:434] bn2_1 <- conv2_1
I0312 15:03:16.658159  1600 net.cpp:408] bn2_1 -> bn2_1
I0312 15:03:16.658159  1600 net.cpp:150] Setting up bn2_1
I0312 15:03:16.658159  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.658159  1600 net.cpp:165] Memory required for data: 118579800
I0312 15:03:16.658159  1600 layer_factory.cpp:58] Creating layer scale2_1
I0312 15:03:16.658159  1600 net.cpp:100] Creating Layer scale2_1
I0312 15:03:16.658159  1600 net.cpp:434] scale2_1 <- bn2_1
I0312 15:03:16.658159  1600 net.cpp:408] scale2_1 -> scale2_1
I0312 15:03:16.658659  1600 layer_factory.cpp:58] Creating layer scale2_1
I0312 15:03:16.658659  1600 net.cpp:150] Setting up scale2_1
I0312 15:03:16.658659  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.658659  1600 net.cpp:165] Memory required for data: 125133400
I0312 15:03:16.658659  1600 layer_factory.cpp:58] Creating layer relu2_1
I0312 15:03:16.658659  1600 net.cpp:100] Creating Layer relu2_1
I0312 15:03:16.658659  1600 net.cpp:434] relu2_1 <- scale2_1
I0312 15:03:16.658659  1600 net.cpp:408] relu2_1 -> relu2_1
I0312 15:03:16.663658  1600 net.cpp:150] Setting up relu2_1
I0312 15:03:16.663658  1600 net.cpp:157] Top shape: 50 32 32 32 (1638400)
I0312 15:03:16.663658  1600 net.cpp:165] Memory required for data: 131687000
I0312 15:03:16.663658  1600 layer_factory.cpp:58] Creating layer pool2_1
I0312 15:03:16.663658  1600 net.cpp:100] Creating Layer pool2_1
I0312 15:03:16.663658  1600 net.cpp:434] pool2_1 <- relu2_1
I0312 15:03:16.663658  1600 net.cpp:408] pool2_1 -> pool2_1
I0312 15:03:16.663658  1600 net.cpp:150] Setting up pool2_1
I0312 15:03:16.663658  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.663658  1600 net.cpp:165] Memory required for data: 133325400
I0312 15:03:16.663658  1600 layer_factory.cpp:58] Creating layer conv2_2
I0312 15:03:16.663658  1600 net.cpp:100] Creating Layer conv2_2
I0312 15:03:16.663658  1600 net.cpp:434] conv2_2 <- pool2_1
I0312 15:03:16.663658  1600 net.cpp:408] conv2_2 -> conv2_2
I0312 15:03:16.670658  1600 net.cpp:150] Setting up conv2_2
I0312 15:03:16.670658  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.670658  1600 net.cpp:165] Memory required for data: 134963800
I0312 15:03:16.670658  1600 layer_factory.cpp:58] Creating layer bn2_2
I0312 15:03:16.670658  1600 net.cpp:100] Creating Layer bn2_2
I0312 15:03:16.670658  1600 net.cpp:434] bn2_2 <- conv2_2
I0312 15:03:16.670658  1600 net.cpp:408] bn2_2 -> bn2_2
I0312 15:03:16.670658  1600 net.cpp:150] Setting up bn2_2
I0312 15:03:16.670658  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.670658  1600 net.cpp:165] Memory required for data: 136602200
I0312 15:03:16.670658  1600 layer_factory.cpp:58] Creating layer scale2_2
I0312 15:03:16.670658  1600 net.cpp:100] Creating Layer scale2_2
I0312 15:03:16.670658  1600 net.cpp:434] scale2_2 <- bn2_2
I0312 15:03:16.670658  1600 net.cpp:408] scale2_2 -> scale2_2
I0312 15:03:16.670658  1600 layer_factory.cpp:58] Creating layer scale2_2
I0312 15:03:16.671159  1600 net.cpp:150] Setting up scale2_2
I0312 15:03:16.671159  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.671159  1600 net.cpp:165] Memory required for data: 138240600
I0312 15:03:16.671159  1600 layer_factory.cpp:58] Creating layer relu2_2
I0312 15:03:16.671159  1600 net.cpp:100] Creating Layer relu2_2
I0312 15:03:16.671159  1600 net.cpp:434] relu2_2 <- scale2_2
I0312 15:03:16.671159  1600 net.cpp:408] relu2_2 -> relu2_2
I0312 15:03:16.671659  1600 net.cpp:150] Setting up relu2_2
I0312 15:03:16.671659  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.671659  1600 net.cpp:165] Memory required for data: 139879000
I0312 15:03:16.671659  1600 layer_factory.cpp:58] Creating layer conv3
I0312 15:03:16.671659  1600 net.cpp:100] Creating Layer conv3
I0312 15:03:16.671659  1600 net.cpp:434] conv3 <- relu2_2
I0312 15:03:16.671659  1600 net.cpp:408] conv3 -> conv3
I0312 15:03:16.673158  1600 net.cpp:150] Setting up conv3
I0312 15:03:16.673158  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.673658  1600 net.cpp:165] Memory required for data: 141517400
I0312 15:03:16.673658  1600 layer_factory.cpp:58] Creating layer bn3
I0312 15:03:16.673658  1600 net.cpp:100] Creating Layer bn3
I0312 15:03:16.673658  1600 net.cpp:434] bn3 <- conv3
I0312 15:03:16.673658  1600 net.cpp:408] bn3 -> bn3
I0312 15:03:16.673658  1600 net.cpp:150] Setting up bn3
I0312 15:03:16.673658  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.673658  1600 net.cpp:165] Memory required for data: 143155800
I0312 15:03:16.673658  1600 layer_factory.cpp:58] Creating layer scale3
I0312 15:03:16.673658  1600 net.cpp:100] Creating Layer scale3
I0312 15:03:16.673658  1600 net.cpp:434] scale3 <- bn3
I0312 15:03:16.673658  1600 net.cpp:408] scale3 -> scale3
I0312 15:03:16.674160  1600 layer_factory.cpp:58] Creating layer scale3
I0312 15:03:16.674160  1600 net.cpp:150] Setting up scale3
I0312 15:03:16.674160  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.674160  1600 net.cpp:165] Memory required for data: 144794200
I0312 15:03:16.674160  1600 layer_factory.cpp:58] Creating layer relu3
I0312 15:03:16.674160  1600 net.cpp:100] Creating Layer relu3
I0312 15:03:16.674160  1600 net.cpp:434] relu3 <- scale3
I0312 15:03:16.674160  1600 net.cpp:408] relu3 -> relu3
I0312 15:03:16.676159  1600 net.cpp:150] Setting up relu3
I0312 15:03:16.676159  1600 net.cpp:157] Top shape: 50 32 16 16 (409600)
I0312 15:03:16.676159  1600 net.cpp:165] Memory required for data: 146432600
I0312 15:03:16.676159  1600 layer_factory.cpp:58] Creating layer conv4
I0312 15:03:16.676159  1600 net.cpp:100] Creating Layer conv4
I0312 15:03:16.676159  1600 net.cpp:434] conv4 <- relu3
I0312 15:03:16.676159  1600 net.cpp:408] conv4 -> conv4
I0312 15:03:16.685158  1600 net.cpp:150] Setting up conv4
I0312 15:03:16.685158  1600 net.cpp:157] Top shape: 50 64 16 16 (819200)
I0312 15:03:16.685158  1600 net.cpp:165] Memory required for data: 149709400
I0312 15:03:16.685158  1600 layer_factory.cpp:58] Creating layer pool4
I0312 15:03:16.685158  1600 net.cpp:100] Creating Layer pool4
I0312 15:03:16.685158  1600 net.cpp:434] pool4 <- conv4
I0312 15:03:16.685158  1600 net.cpp:408] pool4 -> pool4
I0312 15:03:16.685158  1600 net.cpp:150] Setting up pool4
I0312 15:03:16.685158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.685158  1600 net.cpp:165] Memory required for data: 150528600
I0312 15:03:16.685158  1600 layer_factory.cpp:58] Creating layer bn4
I0312 15:03:16.685158  1600 net.cpp:100] Creating Layer bn4
I0312 15:03:16.685158  1600 net.cpp:434] bn4 <- pool4
I0312 15:03:16.685158  1600 net.cpp:408] bn4 -> bn4
I0312 15:03:16.685659  1600 net.cpp:150] Setting up bn4
I0312 15:03:16.685659  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.685659  1600 net.cpp:165] Memory required for data: 151347800
I0312 15:03:16.685659  1600 layer_factory.cpp:58] Creating layer scale4
I0312 15:03:16.685659  1600 net.cpp:100] Creating Layer scale4
I0312 15:03:16.685659  1600 net.cpp:434] scale4 <- bn4
I0312 15:03:16.685659  1600 net.cpp:408] scale4 -> scale4
I0312 15:03:16.685659  1600 layer_factory.cpp:58] Creating layer scale4
I0312 15:03:16.685659  1600 net.cpp:150] Setting up scale4
I0312 15:03:16.685659  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.685659  1600 net.cpp:165] Memory required for data: 152167000
I0312 15:03:16.685659  1600 layer_factory.cpp:58] Creating layer relu4
I0312 15:03:16.685659  1600 net.cpp:100] Creating Layer relu4
I0312 15:03:16.685659  1600 net.cpp:434] relu4 <- scale4
I0312 15:03:16.685659  1600 net.cpp:408] relu4 -> relu4
I0312 15:03:16.686158  1600 net.cpp:150] Setting up relu4
I0312 15:03:16.686158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.686158  1600 net.cpp:165] Memory required for data: 152986200
I0312 15:03:16.686658  1600 layer_factory.cpp:58] Creating layer conv4_1
I0312 15:03:16.686658  1600 net.cpp:100] Creating Layer conv4_1
I0312 15:03:16.686658  1600 net.cpp:434] conv4_1 <- relu4
I0312 15:03:16.686658  1600 net.cpp:408] conv4_1 -> conv4_1
I0312 15:03:16.689158  1600 net.cpp:150] Setting up conv4_1
I0312 15:03:16.689158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.689158  1600 net.cpp:165] Memory required for data: 153805400
I0312 15:03:16.689659  1600 layer_factory.cpp:58] Creating layer bn4_1
I0312 15:03:16.689659  1600 net.cpp:100] Creating Layer bn4_1
I0312 15:03:16.689659  1600 net.cpp:434] bn4_1 <- conv4_1
I0312 15:03:16.689659  1600 net.cpp:408] bn4_1 -> bn4_1
I0312 15:03:16.689659  1600 net.cpp:150] Setting up bn4_1
I0312 15:03:16.689659  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.689659  1600 net.cpp:165] Memory required for data: 154624600
I0312 15:03:16.689659  1600 layer_factory.cpp:58] Creating layer scale4_1
I0312 15:03:16.689659  1600 net.cpp:100] Creating Layer scale4_1
I0312 15:03:16.689659  1600 net.cpp:434] scale4_1 <- bn4_1
I0312 15:03:16.689659  1600 net.cpp:408] scale4_1 -> scale4_1
I0312 15:03:16.689659  1600 layer_factory.cpp:58] Creating layer scale4_1
I0312 15:03:16.690158  1600 net.cpp:150] Setting up scale4_1
I0312 15:03:16.690158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.690158  1600 net.cpp:165] Memory required for data: 155443800
I0312 15:03:16.690158  1600 layer_factory.cpp:58] Creating layer relu4_1
I0312 15:03:16.690158  1600 net.cpp:100] Creating Layer relu4_1
I0312 15:03:16.690158  1600 net.cpp:434] relu4_1 <- scale4_1
I0312 15:03:16.690158  1600 net.cpp:408] relu4_1 -> relu4_1
I0312 15:03:16.690659  1600 net.cpp:150] Setting up relu4_1
I0312 15:03:16.690659  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.690659  1600 net.cpp:165] Memory required for data: 156263000
I0312 15:03:16.690659  1600 layer_factory.cpp:58] Creating layer conv4_2
I0312 15:03:16.690659  1600 net.cpp:100] Creating Layer conv4_2
I0312 15:03:16.690659  1600 net.cpp:434] conv4_2 <- relu4_1
I0312 15:03:16.690659  1600 net.cpp:408] conv4_2 -> conv4_2
I0312 15:03:16.695158  1600 net.cpp:150] Setting up conv4_2
I0312 15:03:16.695158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.695158  1600 net.cpp:165] Memory required for data: 157082200
I0312 15:03:16.695158  1600 layer_factory.cpp:58] Creating layer bn4_2
I0312 15:03:16.695158  1600 net.cpp:100] Creating Layer bn4_2
I0312 15:03:16.695158  1600 net.cpp:434] bn4_2 <- conv4_2
I0312 15:03:16.695158  1600 net.cpp:408] bn4_2 -> bn4_2
I0312 15:03:16.695158  1600 net.cpp:150] Setting up bn4_2
I0312 15:03:16.695158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.695158  1600 net.cpp:165] Memory required for data: 157901400
I0312 15:03:16.695158  1600 layer_factory.cpp:58] Creating layer scale4_2
I0312 15:03:16.695158  1600 net.cpp:100] Creating Layer scale4_2
I0312 15:03:16.695158  1600 net.cpp:434] scale4_2 <- bn4_2
I0312 15:03:16.695158  1600 net.cpp:408] scale4_2 -> scale4_2
I0312 15:03:16.695158  1600 layer_factory.cpp:58] Creating layer scale4_2
I0312 15:03:16.695158  1600 net.cpp:150] Setting up scale4_2
I0312 15:03:16.695158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.695158  1600 net.cpp:165] Memory required for data: 158720600
I0312 15:03:16.695657  1600 layer_factory.cpp:58] Creating layer relu4_2
I0312 15:03:16.695657  1600 net.cpp:100] Creating Layer relu4_2
I0312 15:03:16.695657  1600 net.cpp:434] relu4_2 <- scale4_2
I0312 15:03:16.695657  1600 net.cpp:408] relu4_2 -> relu4_2
I0312 15:03:16.696158  1600 net.cpp:150] Setting up relu4_2
I0312 15:03:16.696158  1600 net.cpp:157] Top shape: 50 64 8 8 (204800)
I0312 15:03:16.696158  1600 net.cpp:165] Memory required for data: 159539800
I0312 15:03:16.696158  1600 layer_factory.cpp:58] Creating layer pool4_2
I0312 15:03:16.696158  1600 net.cpp:100] Creating Layer pool4_2
I0312 15:03:16.696158  1600 net.cpp:434] pool4_2 <- relu4_2
I0312 15:03:16.696158  1600 net.cpp:408] pool4_2 -> pool4_2
I0312 15:03:16.696158  1600 net.cpp:150] Setting up pool4_2
I0312 15:03:16.696158  1600 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0312 15:03:16.696158  1600 net.cpp:165] Memory required for data: 159744600
I0312 15:03:16.696158  1600 layer_factory.cpp:58] Creating layer conv4_0
I0312 15:03:16.696158  1600 net.cpp:100] Creating Layer conv4_0
I0312 15:03:16.696158  1600 net.cpp:434] conv4_0 <- pool4_2
I0312 15:03:16.696158  1600 net.cpp:408] conv4_0 -> conv4_0
I0312 15:03:16.705657  1600 net.cpp:150] Setting up conv4_0
I0312 15:03:16.705657  1600 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0312 15:03:16.705657  1600 net.cpp:165] Memory required for data: 160154200
I0312 15:03:16.705657  1600 layer_factory.cpp:58] Creating layer bn4_0
I0312 15:03:16.705657  1600 net.cpp:100] Creating Layer bn4_0
I0312 15:03:16.706158  1600 net.cpp:434] bn4_0 <- conv4_0
I0312 15:03:16.706158  1600 net.cpp:408] bn4_0 -> bn4_0
I0312 15:03:16.706158  1600 net.cpp:150] Setting up bn4_0
I0312 15:03:16.706158  1600 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0312 15:03:16.706158  1600 net.cpp:165] Memory required for data: 160563800
I0312 15:03:16.706158  1600 layer_factory.cpp:58] Creating layer scale4_0
I0312 15:03:16.706158  1600 net.cpp:100] Creating Layer scale4_0
I0312 15:03:16.706158  1600 net.cpp:434] scale4_0 <- bn4_0
I0312 15:03:16.706158  1600 net.cpp:408] scale4_0 -> scale4_0
I0312 15:03:16.706158  1600 layer_factory.cpp:58] Creating layer scale4_0
I0312 15:03:16.706158  1600 net.cpp:150] Setting up scale4_0
I0312 15:03:16.706657  1600 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0312 15:03:16.706657  1600 net.cpp:165] Memory required for data: 160973400
I0312 15:03:16.706657  1600 layer_factory.cpp:58] Creating layer relu4_0
I0312 15:03:16.706657  1600 net.cpp:100] Creating Layer relu4_0
I0312 15:03:16.706657  1600 net.cpp:434] relu4_0 <- scale4_0
I0312 15:03:16.706657  1600 net.cpp:408] relu4_0 -> relu4_0
I0312 15:03:16.710157  1600 net.cpp:150] Setting up relu4_0
I0312 15:03:16.710157  1600 net.cpp:157] Top shape: 50 128 4 4 (102400)
I0312 15:03:16.710157  1600 net.cpp:165] Memory required for data: 161383000
I0312 15:03:16.710157  1600 layer_factory.cpp:58] Creating layer cccp4
I0312 15:03:16.710157  1600 net.cpp:100] Creating Layer cccp4
I0312 15:03:16.710157  1600 net.cpp:434] cccp4 <- relu4_0
I0312 15:03:16.710157  1600 net.cpp:408] cccp4 -> cccp4
I0312 15:03:16.716657  1600 net.cpp:150] Setting up cccp4
I0312 15:03:16.716657  1600 net.cpp:157] Top shape: 50 256 4 4 (204800)
I0312 15:03:16.716657  1600 net.cpp:165] Memory required for data: 162202200
I0312 15:03:16.716657  1600 layer_factory.cpp:58] Creating layer relu_cccp4
I0312 15:03:16.716657  1600 net.cpp:100] Creating Layer relu_cccp4
I0312 15:03:16.716657  1600 net.cpp:434] relu_cccp4 <- cccp4
I0312 15:03:16.716657  1600 net.cpp:395] relu_cccp4 -> cccp4 (in-place)
I0312 15:03:16.719657  1600 net.cpp:150] Setting up relu_cccp4
I0312 15:03:16.719657  1600 net.cpp:157] Top shape: 50 256 4 4 (204800)
I0312 15:03:16.719657  1600 net.cpp:165] Memory required for data: 163021400
I0312 15:03:16.719657  1600 layer_factory.cpp:58] Creating layer cccp5
I0312 15:03:16.719657  1600 net.cpp:100] Creating Layer cccp5
I0312 15:03:16.719657  1600 net.cpp:434] cccp5 <- cccp4
I0312 15:03:16.719657  1600 net.cpp:408] cccp5 -> cccp5
I0312 15:03:16.729157  1600 net.cpp:150] Setting up cccp5
I0312 15:03:16.729157  1600 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0312 15:03:16.729157  1600 net.cpp:165] Memory required for data: 163226200
I0312 15:03:16.729157  1600 layer_factory.cpp:58] Creating layer relu_cccp5
I0312 15:03:16.729157  1600 net.cpp:100] Creating Layer relu_cccp5
I0312 15:03:16.729157  1600 net.cpp:434] relu_cccp5 <- cccp5
I0312 15:03:16.729157  1600 net.cpp:395] relu_cccp5 -> cccp5 (in-place)
I0312 15:03:16.729658  1600 net.cpp:150] Setting up relu_cccp5
I0312 15:03:16.729658  1600 net.cpp:157] Top shape: 50 64 4 4 (51200)
I0312 15:03:16.729658  1600 net.cpp:165] Memory required for data: 163431000
I0312 15:03:16.729658  1600 layer_factory.cpp:58] Creating layer poolcp5
I0312 15:03:16.729658  1600 net.cpp:100] Creating Layer poolcp5
I0312 15:03:16.729658  1600 net.cpp:434] poolcp5 <- cccp5
I0312 15:03:16.729658  1600 net.cpp:408] poolcp5 -> poolcp5
I0312 15:03:16.729658  1600 net.cpp:150] Setting up poolcp5
I0312 15:03:16.729658  1600 net.cpp:157] Top shape: 50 64 2 2 (12800)
I0312 15:03:16.729658  1600 net.cpp:165] Memory required for data: 163482200
I0312 15:03:16.729658  1600 layer_factory.cpp:58] Creating layer cccp6
I0312 15:03:16.729658  1600 net.cpp:100] Creating Layer cccp6
I0312 15:03:16.729658  1600 net.cpp:434] cccp6 <- poolcp5
I0312 15:03:16.729658  1600 net.cpp:408] cccp6 -> cccp6
I0312 15:03:16.731657  1600 net.cpp:150] Setting up cccp6
I0312 15:03:16.731657  1600 net.cpp:157] Top shape: 50 64 2 2 (12800)
I0312 15:03:16.731657  1600 net.cpp:165] Memory required for data: 163533400
I0312 15:03:16.731657  1600 layer_factory.cpp:58] Creating layer relu_cccp6
I0312 15:03:16.731657  1600 net.cpp:100] Creating Layer relu_cccp6
I0312 15:03:16.731657  1600 net.cpp:434] relu_cccp6 <- cccp6
I0312 15:03:16.731657  1600 net.cpp:395] relu_cccp6 -> cccp6 (in-place)
I0312 15:03:16.732657  1600 net.cpp:150] Setting up relu_cccp6
I0312 15:03:16.732657  1600 net.cpp:157] Top shape: 50 64 2 2 (12800)
I0312 15:03:16.732657  1600 net.cpp:165] Memory required for data: 163584600
I0312 15:03:16.732657  1600 layer_factory.cpp:58] Creating layer poolcp6
I0312 15:03:16.732657  1600 net.cpp:100] Creating Layer poolcp6
I0312 15:03:16.732657  1600 net.cpp:434] poolcp6 <- cccp6
I0312 15:03:16.732657  1600 net.cpp:408] poolcp6 -> poolcp6
I0312 15:03:16.732657  1600 net.cpp:150] Setting up poolcp6
I0312 15:03:16.732657  1600 net.cpp:157] Top shape: 50 64 1 1 (3200)
I0312 15:03:16.732657  1600 net.cpp:165] Memory required for data: 163597400
I0312 15:03:16.732657  1600 layer_factory.cpp:58] Creating layer ip1
I0312 15:03:16.732657  1600 net.cpp:100] Creating Layer ip1
I0312 15:03:16.732657  1600 net.cpp:434] ip1 <- poolcp6
I0312 15:03:16.732657  1600 net.cpp:408] ip1 -> ip1
I0312 15:03:16.732657  1600 net.cpp:150] Setting up ip1
I0312 15:03:16.732657  1600 net.cpp:157] Top shape: 50 100 (5000)
I0312 15:03:16.732657  1600 net.cpp:165] Memory required for data: 163617400
I0312 15:03:16.732657  1600 layer_factory.cpp:58] Creating layer ip1_ip1_0_split
I0312 15:03:16.732657  1600 net.cpp:100] Creating Layer ip1_ip1_0_split
I0312 15:03:16.732657  1600 net.cpp:434] ip1_ip1_0_split <- ip1
I0312 15:03:16.732657  1600 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_0
I0312 15:03:16.732657  1600 net.cpp:408] ip1_ip1_0_split -> ip1_ip1_0_split_1
I0312 15:03:16.732657  1600 net.cpp:150] Setting up ip1_ip1_0_split
I0312 15:03:16.732657  1600 net.cpp:157] Top shape: 50 100 (5000)
I0312 15:03:16.732657  1600 net.cpp:157] Top shape: 50 100 (5000)
I0312 15:03:16.732657  1600 net.cpp:165] Memory required for data: 163657400
I0312 15:03:16.732657  1600 layer_factory.cpp:58] Creating layer accuracy
I0312 15:03:16.732657  1600 net.cpp:100] Creating Layer accuracy
I0312 15:03:16.732657  1600 net.cpp:434] accuracy <- ip1_ip1_0_split_0
I0312 15:03:16.732657  1600 net.cpp:434] accuracy <- label_cifar_1_split_0
I0312 15:03:16.732657  1600 net.cpp:408] accuracy -> accuracy
I0312 15:03:16.732657  1600 net.cpp:150] Setting up accuracy
I0312 15:03:16.732657  1600 net.cpp:157] Top shape: (1)
I0312 15:03:16.732657  1600 net.cpp:165] Memory required for data: 163657404
I0312 15:03:16.732657  1600 layer_factory.cpp:58] Creating layer loss
I0312 15:03:16.732657  1600 net.cpp:100] Creating Layer loss
I0312 15:03:16.732657  1600 net.cpp:434] loss <- ip1_ip1_0_split_1
I0312 15:03:16.733158  1600 net.cpp:434] loss <- label_cifar_1_split_1
I0312 15:03:16.733158  1600 net.cpp:408] loss -> loss
I0312 15:03:16.733158  1600 layer_factory.cpp:58] Creating layer loss
I0312 15:03:16.735157  1600 net.cpp:150] Setting up loss
I0312 15:03:16.735157  1600 net.cpp:157] Top shape: (1)
I0312 15:03:16.735157  1600 net.cpp:160]     with loss weight 1
I0312 15:03:16.735157  1600 net.cpp:165] Memory required for data: 163657408
I0312 15:03:16.735157  1600 net.cpp:226] loss needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:228] accuracy does not need backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] ip1_ip1_0_split needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] ip1 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] poolcp6 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] relu_cccp6 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] cccp6 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] poolcp5 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] relu_cccp5 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] cccp5 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] relu_cccp4 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] cccp4 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] relu4_0 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] scale4_0 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] bn4_0 needs backward computation.
I0312 15:03:16.735157  1600 net.cpp:226] conv4_0 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] pool4_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu4_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale4_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn4_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv4_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu4_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale4_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn4_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv4_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu4 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale4 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn4 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] pool4 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv4 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu3 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale3 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn3 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv3 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu2_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale2_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn2_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv2_2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] pool2_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu2_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale2_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn2_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv2_1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv2 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu1_0 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale1_0 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn1_0 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv1_0 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] relu1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] scale1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] bn1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:226] conv1 needs backward computation.
I0312 15:03:16.735657  1600 net.cpp:228] label_cifar_1_split does not need backward computation.
I0312 15:03:16.735657  1600 net.cpp:228] cifar does not need backward computation.
I0312 15:03:16.735657  1600 net.cpp:270] This network produces output accuracy
I0312 15:03:16.735657  1600 net.cpp:270] This network produces output loss
I0312 15:03:16.735657  1600 net.cpp:283] Network initialization done.
I0312 15:03:16.735657  1600 solver.cpp:60] Solver scaffolding done.
I0312 15:03:16.739657  1600 caffe.cpp:252] Starting Optimization
I0312 15:03:16.739657  1600 solver.cpp:279] Solving CIFAR100_full
I0312 15:03:16.739657  1600 solver.cpp:280] Learning Rate Policy: multistep
I0312 15:03:16.741158  1600 solver.cpp:337] Iteration 0, Testing net (#0)
I0312 15:03:16.744164  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:03:20.620673  1600 solver.cpp:404]     Test net output #0: accuracy = 0.00999999
I0312 15:03:20.620673  1600 solver.cpp:404]     Test net output #1: loss = 86.4632 (* 1 = 86.4632 loss)
I0312 15:03:20.850677  1600 solver.cpp:228] Iteration 0, loss = 4.71214
I0312 15:03:20.850677  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.015625
I0312 15:03:20.850677  1600 solver.cpp:244]     Train net output #1: loss = 4.71214 (* 1 = 4.71214 loss)
I0312 15:03:20.850677  1600 sgd_solver.cpp:106] Iteration 0, lr = 0.1
I0312 15:03:29.901767  1600 solver.cpp:228] Iteration 100, loss = 4.47985
I0312 15:03:29.901767  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0
I0312 15:03:29.901767  1600 solver.cpp:244]     Train net output #1: loss = 4.47985 (* 1 = 4.47985 loss)
I0312 15:03:29.901767  1600 sgd_solver.cpp:106] Iteration 100, lr = 0.1
I0312 15:03:39.084494  1600 solver.cpp:228] Iteration 200, loss = 4.31747
I0312 15:03:39.084494  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.03125
I0312 15:03:39.084494  1600 solver.cpp:244]     Train net output #1: loss = 4.31747 (* 1 = 4.31747 loss)
I0312 15:03:39.084494  1600 sgd_solver.cpp:106] Iteration 200, lr = 0.1
I0312 15:03:48.184217  1600 solver.cpp:228] Iteration 300, loss = 4.05484
I0312 15:03:48.184717  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.09375
I0312 15:03:48.184717  1600 solver.cpp:244]     Train net output #1: loss = 4.05484 (* 1 = 4.05484 loss)
I0312 15:03:48.184717  1600 sgd_solver.cpp:106] Iteration 300, lr = 0.1
I0312 15:03:57.407093  1600 solver.cpp:228] Iteration 400, loss = 4.10314
I0312 15:03:57.407093  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.0625
I0312 15:03:57.407093  1600 solver.cpp:244]     Train net output #1: loss = 4.10314 (* 1 = 4.10314 loss)
I0312 15:03:57.407093  1600 sgd_solver.cpp:106] Iteration 400, lr = 0.1
I0312 15:04:06.603335  1600 solver.cpp:228] Iteration 500, loss = 3.90591
I0312 15:04:06.603335  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.09375
I0312 15:04:06.603335  1600 solver.cpp:244]     Train net output #1: loss = 3.90591 (* 1 = 3.90591 loss)
I0312 15:04:06.603335  1600 sgd_solver.cpp:106] Iteration 500, lr = 0.1
I0312 15:04:15.741472  1600 solver.cpp:228] Iteration 600, loss = 3.92038
I0312 15:04:15.741472  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.0625
I0312 15:04:15.741472  1600 solver.cpp:244]     Train net output #1: loss = 3.92038 (* 1 = 3.92038 loss)
I0312 15:04:15.741472  1600 sgd_solver.cpp:106] Iteration 600, lr = 0.1
I0312 15:04:24.797755  1600 solver.cpp:228] Iteration 700, loss = 3.99666
I0312 15:04:24.797755  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.0625
I0312 15:04:24.798254  1600 solver.cpp:244]     Train net output #1: loss = 3.99666 (* 1 = 3.99666 loss)
I0312 15:04:24.798254  1600 sgd_solver.cpp:106] Iteration 700, lr = 0.1
I0312 15:04:33.880483  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_800.caffemodel
I0312 15:04:33.903983  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_800.solverstate
I0312 15:04:33.908483  1600 solver.cpp:337] Iteration 800, Testing net (#0)
I0312 15:04:33.908483  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:04:37.658012  1600 solver.cpp:404]     Test net output #0: accuracy = 0.1011
I0312 15:04:37.658012  1600 solver.cpp:404]     Test net output #1: loss = 3.79289 (* 1 = 3.79289 loss)
I0312 15:04:37.688066  1600 solver.cpp:228] Iteration 800, loss = 3.83386
I0312 15:04:37.688066  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.125
I0312 15:04:37.688066  1600 solver.cpp:244]     Train net output #1: loss = 3.83386 (* 1 = 3.83386 loss)
I0312 15:04:37.688066  1600 sgd_solver.cpp:106] Iteration 800, lr = 0.1
I0312 15:04:46.946544  1600 solver.cpp:228] Iteration 900, loss = 4.09626
I0312 15:04:46.946544  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.109375
I0312 15:04:46.946544  1600 solver.cpp:244]     Train net output #1: loss = 4.09626 (* 1 = 4.09626 loss)
I0312 15:04:46.946544  1600 sgd_solver.cpp:106] Iteration 900, lr = 0.1
I0312 15:04:55.911090  1600 solver.cpp:228] Iteration 1000, loss = 3.54034
I0312 15:04:55.911090  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.171875
I0312 15:04:55.911090  1600 solver.cpp:244]     Train net output #1: loss = 3.54034 (* 1 = 3.54034 loss)
I0312 15:04:55.911090  1600 sgd_solver.cpp:106] Iteration 1000, lr = 0.1
I0312 15:05:04.873798  1600 solver.cpp:228] Iteration 1100, loss = 3.84062
I0312 15:05:04.873798  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.140625
I0312 15:05:04.873798  1600 solver.cpp:244]     Train net output #1: loss = 3.84062 (* 1 = 3.84062 loss)
I0312 15:05:04.873798  1600 sgd_solver.cpp:106] Iteration 1100, lr = 0.1
I0312 15:05:13.266508  1600 solver.cpp:228] Iteration 1200, loss = 3.74551
I0312 15:05:13.266508  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.09375
I0312 15:05:13.266508  1600 solver.cpp:244]     Train net output #1: loss = 3.74551 (* 1 = 3.74551 loss)
I0312 15:05:13.266508  1600 sgd_solver.cpp:106] Iteration 1200, lr = 0.1
I0312 15:05:19.133615  1600 solver.cpp:228] Iteration 1300, loss = 3.44896
I0312 15:05:19.133615  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.1875
I0312 15:05:19.133615  1600 solver.cpp:244]     Train net output #1: loss = 3.44896 (* 1 = 3.44896 loss)
I0312 15:05:19.133615  1600 sgd_solver.cpp:106] Iteration 1300, lr = 0.1
I0312 15:05:24.940026  1600 solver.cpp:228] Iteration 1400, loss = 3.32248
I0312 15:05:24.940026  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.140625
I0312 15:05:24.940026  1600 solver.cpp:244]     Train net output #1: loss = 3.32248 (* 1 = 3.32248 loss)
I0312 15:05:24.940026  1600 sgd_solver.cpp:106] Iteration 1400, lr = 0.1
I0312 15:05:31.519062  1600 solver.cpp:228] Iteration 1500, loss = 3.28566
I0312 15:05:31.519062  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.21875
I0312 15:05:31.519062  1600 solver.cpp:244]     Train net output #1: loss = 3.28566 (* 1 = 3.28566 loss)
I0312 15:05:31.519062  1600 sgd_solver.cpp:106] Iteration 1500, lr = 0.1
I0312 15:05:40.546756  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_1600.caffemodel
I0312 15:05:40.561755  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_1600.solverstate
I0312 15:05:40.567255  1600 solver.cpp:337] Iteration 1600, Testing net (#0)
I0312 15:05:40.567255  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:05:44.220428  1600 solver.cpp:404]     Test net output #0: accuracy = 0.1787
I0312 15:05:44.220428  1600 solver.cpp:404]     Test net output #1: loss = 3.37223 (* 1 = 3.37223 loss)
I0312 15:05:44.239518  1600 solver.cpp:228] Iteration 1600, loss = 3.69536
I0312 15:05:44.239518  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.109375
I0312 15:05:44.239518  1600 solver.cpp:244]     Train net output #1: loss = 3.69536 (* 1 = 3.69536 loss)
I0312 15:05:44.239518  1600 sgd_solver.cpp:106] Iteration 1600, lr = 0.1
I0312 15:05:53.282251  1600 solver.cpp:228] Iteration 1700, loss = 3.61738
I0312 15:05:53.282251  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.140625
I0312 15:05:53.282251  1600 solver.cpp:244]     Train net output #1: loss = 3.61738 (* 1 = 3.61738 loss)
I0312 15:05:53.282251  1600 sgd_solver.cpp:106] Iteration 1700, lr = 0.1
I0312 15:06:02.360903  1600 solver.cpp:228] Iteration 1800, loss = 3.35748
I0312 15:06:02.360903  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.234375
I0312 15:06:02.360903  1600 solver.cpp:244]     Train net output #1: loss = 3.35748 (* 1 = 3.35748 loss)
I0312 15:06:02.360903  1600 sgd_solver.cpp:106] Iteration 1800, lr = 0.1
I0312 15:06:11.567586  1600 solver.cpp:228] Iteration 1900, loss = 3.32968
I0312 15:06:11.567586  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.171875
I0312 15:06:11.567586  1600 solver.cpp:244]     Train net output #1: loss = 3.32968 (* 1 = 3.32968 loss)
I0312 15:06:11.567586  1600 sgd_solver.cpp:106] Iteration 1900, lr = 0.1
I0312 15:06:20.686741  1600 solver.cpp:228] Iteration 2000, loss = 2.92509
I0312 15:06:20.686741  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.21875
I0312 15:06:20.686741  1600 solver.cpp:244]     Train net output #1: loss = 2.92509 (* 1 = 2.92509 loss)
I0312 15:06:20.686741  1600 sgd_solver.cpp:106] Iteration 2000, lr = 0.1
I0312 15:06:29.787174  1600 solver.cpp:228] Iteration 2100, loss = 2.84101
I0312 15:06:29.787174  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.171875
I0312 15:06:29.787174  1600 solver.cpp:244]     Train net output #1: loss = 2.84101 (* 1 = 2.84101 loss)
I0312 15:06:29.787174  1600 sgd_solver.cpp:106] Iteration 2100, lr = 0.1
I0312 15:06:38.845896  1600 solver.cpp:228] Iteration 2200, loss = 2.94016
I0312 15:06:38.846396  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.25
I0312 15:06:38.846396  1600 solver.cpp:244]     Train net output #1: loss = 2.94016 (* 1 = 2.94016 loss)
I0312 15:06:38.846396  1600 sgd_solver.cpp:106] Iteration 2200, lr = 0.1
I0312 15:06:47.973448  1600 solver.cpp:228] Iteration 2300, loss = 2.87641
I0312 15:06:47.973448  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.21875
I0312 15:06:47.973448  1600 solver.cpp:244]     Train net output #1: loss = 2.87641 (* 1 = 2.87641 loss)
I0312 15:06:47.973448  1600 sgd_solver.cpp:106] Iteration 2300, lr = 0.1
I0312 15:06:56.910598  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_2400.caffemodel
I0312 15:06:56.926599  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_2400.solverstate
I0312 15:06:56.931601  1600 solver.cpp:337] Iteration 2400, Testing net (#0)
I0312 15:06:56.931601  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:07:00.646881  1600 solver.cpp:404]     Test net output #0: accuracy = 0.1963
I0312 15:07:00.646881  1600 solver.cpp:404]     Test net output #1: loss = 3.37481 (* 1 = 3.37481 loss)
I0312 15:07:00.676882  1600 solver.cpp:228] Iteration 2400, loss = 3.56919
I0312 15:07:00.676882  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.15625
I0312 15:07:00.676882  1600 solver.cpp:244]     Train net output #1: loss = 3.56919 (* 1 = 3.56919 loss)
I0312 15:07:00.676882  1600 sgd_solver.cpp:106] Iteration 2400, lr = 0.1
I0312 15:07:09.843181  1600 solver.cpp:228] Iteration 2500, loss = 2.92127
I0312 15:07:09.843680  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.234375
I0312 15:07:09.843680  1600 solver.cpp:244]     Train net output #1: loss = 2.92127 (* 1 = 2.92127 loss)
I0312 15:07:09.843680  1600 sgd_solver.cpp:106] Iteration 2500, lr = 0.1
I0312 15:07:19.206001  1600 solver.cpp:228] Iteration 2600, loss = 2.89184
I0312 15:07:19.206001  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.203125
I0312 15:07:19.206001  1600 solver.cpp:244]     Train net output #1: loss = 2.89184 (* 1 = 2.89184 loss)
I0312 15:07:19.206001  1600 sgd_solver.cpp:106] Iteration 2600, lr = 0.1
I0312 15:07:28.355244  1600 solver.cpp:228] Iteration 2700, loss = 2.94799
I0312 15:07:28.355244  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.265625
I0312 15:07:28.355244  1600 solver.cpp:244]     Train net output #1: loss = 2.94799 (* 1 = 2.94799 loss)
I0312 15:07:28.355244  1600 sgd_solver.cpp:106] Iteration 2700, lr = 0.1
I0312 15:07:37.460569  1600 solver.cpp:228] Iteration 2800, loss = 2.84239
I0312 15:07:37.460569  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.21875
I0312 15:07:37.460569  1600 solver.cpp:244]     Train net output #1: loss = 2.84239 (* 1 = 2.84239 loss)
I0312 15:07:37.460569  1600 sgd_solver.cpp:106] Iteration 2800, lr = 0.1
I0312 15:07:46.635604  1600 solver.cpp:228] Iteration 2900, loss = 2.97149
I0312 15:07:46.635604  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.234375
I0312 15:07:46.636104  1600 solver.cpp:244]     Train net output #1: loss = 2.97149 (* 1 = 2.97149 loss)
I0312 15:07:46.636104  1600 sgd_solver.cpp:106] Iteration 2900, lr = 0.1
I0312 15:07:55.715853  1600 solver.cpp:228] Iteration 3000, loss = 2.92564
I0312 15:07:55.716353  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.265625
I0312 15:07:55.716353  1600 solver.cpp:244]     Train net output #1: loss = 2.92564 (* 1 = 2.92564 loss)
I0312 15:07:55.716353  1600 sgd_solver.cpp:106] Iteration 3000, lr = 0.1
I0312 15:08:04.674813  1600 solver.cpp:228] Iteration 3100, loss = 2.83504
I0312 15:08:04.674813  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.265625
I0312 15:08:04.674813  1600 solver.cpp:244]     Train net output #1: loss = 2.83504 (* 1 = 2.83504 loss)
I0312 15:08:04.674813  1600 sgd_solver.cpp:106] Iteration 3100, lr = 0.1
I0312 15:08:13.828390  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_3200.caffemodel
I0312 15:08:13.847406  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_3200.solverstate
I0312 15:08:13.852406  1600 solver.cpp:337] Iteration 3200, Testing net (#0)
I0312 15:08:13.852406  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:08:17.566213  1600 solver.cpp:404]     Test net output #0: accuracy = 0.2679
I0312 15:08:17.566712  1600 solver.cpp:404]     Test net output #1: loss = 2.91197 (* 1 = 2.91197 loss)
I0312 15:08:17.575213  1600 solver.cpp:228] Iteration 3200, loss = 3.116
I0312 15:08:17.575213  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.21875
I0312 15:08:17.575213  1600 solver.cpp:244]     Train net output #1: loss = 3.116 (* 1 = 3.116 loss)
I0312 15:08:17.575213  1600 sgd_solver.cpp:106] Iteration 3200, lr = 0.1
I0312 15:08:26.569320  1600 solver.cpp:228] Iteration 3300, loss = 2.65314
I0312 15:08:26.569820  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.234375
I0312 15:08:26.569820  1600 solver.cpp:244]     Train net output #1: loss = 2.65314 (* 1 = 2.65314 loss)
I0312 15:08:26.569820  1600 sgd_solver.cpp:106] Iteration 3300, lr = 0.1
I0312 15:08:35.868325  1600 solver.cpp:228] Iteration 3400, loss = 2.54195
I0312 15:08:35.868325  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.3125
I0312 15:08:35.868325  1600 solver.cpp:244]     Train net output #1: loss = 2.54195 (* 1 = 2.54195 loss)
I0312 15:08:35.868325  1600 sgd_solver.cpp:106] Iteration 3400, lr = 0.1
I0312 15:08:44.865156  1600 solver.cpp:228] Iteration 3500, loss = 2.99306
I0312 15:08:44.865156  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.296875
I0312 15:08:44.865156  1600 solver.cpp:244]     Train net output #1: loss = 2.99306 (* 1 = 2.99306 loss)
I0312 15:08:44.865156  1600 sgd_solver.cpp:106] Iteration 3500, lr = 0.1
I0312 15:08:53.758210  1600 solver.cpp:228] Iteration 3600, loss = 2.67669
I0312 15:08:53.758210  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.359375
I0312 15:08:53.758210  1600 solver.cpp:244]     Train net output #1: loss = 2.67669 (* 1 = 2.67669 loss)
I0312 15:08:53.758210  1600 sgd_solver.cpp:106] Iteration 3600, lr = 0.1
I0312 15:09:02.895488  1600 solver.cpp:228] Iteration 3700, loss = 2.39613
I0312 15:09:02.895488  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.359375
I0312 15:09:02.895488  1600 solver.cpp:244]     Train net output #1: loss = 2.39613 (* 1 = 2.39613 loss)
I0312 15:09:02.895488  1600 sgd_solver.cpp:106] Iteration 3700, lr = 0.1
I0312 15:09:12.062690  1600 solver.cpp:228] Iteration 3800, loss = 2.84979
I0312 15:09:12.062690  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.234375
I0312 15:09:12.062690  1600 solver.cpp:244]     Train net output #1: loss = 2.84979 (* 1 = 2.84979 loss)
I0312 15:09:12.062690  1600 sgd_solver.cpp:106] Iteration 3800, lr = 0.1
I0312 15:09:21.217000  1600 solver.cpp:228] Iteration 3900, loss = 2.70487
I0312 15:09:21.217500  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:09:21.217500  1600 solver.cpp:244]     Train net output #1: loss = 2.70487 (* 1 = 2.70487 loss)
I0312 15:09:21.217500  1600 sgd_solver.cpp:106] Iteration 3900, lr = 0.1
I0312 15:09:30.212668  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_4000.caffemodel
I0312 15:09:30.228168  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_4000.solverstate
I0312 15:09:30.233667  1600 solver.cpp:337] Iteration 4000, Testing net (#0)
I0312 15:09:30.233667  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:09:33.977926  1600 solver.cpp:404]     Test net output #0: accuracy = 0.33
I0312 15:09:33.977926  1600 solver.cpp:404]     Test net output #1: loss = 2.56597 (* 1 = 2.56597 loss)
I0312 15:09:33.997944  1600 solver.cpp:228] Iteration 4000, loss = 2.94781
I0312 15:09:33.997944  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.265625
I0312 15:09:33.997944  1600 solver.cpp:244]     Train net output #1: loss = 2.94781 (* 1 = 2.94781 loss)
I0312 15:09:33.997944  1600 sgd_solver.cpp:106] Iteration 4000, lr = 0.1
I0312 15:09:43.217142  1600 solver.cpp:228] Iteration 4100, loss = 2.98094
I0312 15:09:43.217142  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.25
I0312 15:09:43.217142  1600 solver.cpp:244]     Train net output #1: loss = 2.98094 (* 1 = 2.98094 loss)
I0312 15:09:43.217142  1600 sgd_solver.cpp:106] Iteration 4100, lr = 0.1
I0312 15:09:52.450757  1600 solver.cpp:228] Iteration 4200, loss = 2.79771
I0312 15:09:52.450757  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.265625
I0312 15:09:52.450757  1600 solver.cpp:244]     Train net output #1: loss = 2.79771 (* 1 = 2.79771 loss)
I0312 15:09:52.450757  1600 sgd_solver.cpp:106] Iteration 4200, lr = 0.1
I0312 15:10:01.621832  1600 solver.cpp:228] Iteration 4300, loss = 2.18966
I0312 15:10:01.621832  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:10:01.621832  1600 solver.cpp:244]     Train net output #1: loss = 2.18966 (* 1 = 2.18966 loss)
I0312 15:10:01.621832  1600 sgd_solver.cpp:106] Iteration 4300, lr = 0.1
I0312 15:10:10.811491  1600 solver.cpp:228] Iteration 4400, loss = 2.50826
I0312 15:10:10.811491  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:10:10.811491  1600 solver.cpp:244]     Train net output #1: loss = 2.50826 (* 1 = 2.50826 loss)
I0312 15:10:10.811491  1600 sgd_solver.cpp:106] Iteration 4400, lr = 0.1
I0312 15:10:18.944653  1600 solver.cpp:228] Iteration 4500, loss = 2.34912
I0312 15:10:18.944653  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:10:18.944653  1600 solver.cpp:244]     Train net output #1: loss = 2.34912 (* 1 = 2.34912 loss)
I0312 15:10:18.944653  1600 sgd_solver.cpp:106] Iteration 4500, lr = 0.1
I0312 15:10:24.758934  1600 solver.cpp:228] Iteration 4600, loss = 2.48768
I0312 15:10:24.758934  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.375
I0312 15:10:24.758934  1600 solver.cpp:244]     Train net output #1: loss = 2.48768 (* 1 = 2.48768 loss)
I0312 15:10:24.758934  1600 sgd_solver.cpp:106] Iteration 4600, lr = 0.1
I0312 15:10:30.583549  1600 solver.cpp:228] Iteration 4700, loss = 2.56578
I0312 15:10:30.583549  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:10:30.583549  1600 solver.cpp:244]     Train net output #1: loss = 2.56578 (* 1 = 2.56578 loss)
I0312 15:10:30.583549  1600 sgd_solver.cpp:106] Iteration 4700, lr = 0.1
I0312 15:10:37.301456  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_4800.caffemodel
I0312 15:10:37.318958  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_4800.solverstate
I0312 15:10:37.324457  1600 solver.cpp:337] Iteration 4800, Testing net (#0)
I0312 15:10:37.324957  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:10:40.991431  1600 solver.cpp:404]     Test net output #0: accuracy = 0.341
I0312 15:10:40.991431  1600 solver.cpp:404]     Test net output #1: loss = 2.54785 (* 1 = 2.54785 loss)
I0312 15:10:41.009932  1600 solver.cpp:228] Iteration 4800, loss = 2.21284
I0312 15:10:41.009932  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:10:41.009932  1600 solver.cpp:244]     Train net output #1: loss = 2.21284 (* 1 = 2.21284 loss)
I0312 15:10:41.009932  1600 sgd_solver.cpp:106] Iteration 4800, lr = 0.1
I0312 15:10:50.312826  1600 solver.cpp:228] Iteration 4900, loss = 2.40413
I0312 15:10:50.312826  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.359375
I0312 15:10:50.312826  1600 solver.cpp:244]     Train net output #1: loss = 2.40413 (* 1 = 2.40413 loss)
I0312 15:10:50.312826  1600 sgd_solver.cpp:106] Iteration 4900, lr = 0.1
I0312 15:10:59.434759  1600 solver.cpp:228] Iteration 5000, loss = 2.3414
I0312 15:10:59.434759  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.328125
I0312 15:10:59.434759  1600 solver.cpp:244]     Train net output #1: loss = 2.3414 (* 1 = 2.3414 loss)
I0312 15:10:59.434759  1600 sgd_solver.cpp:106] Iteration 5000, lr = 0.1
I0312 15:11:08.520912  1600 solver.cpp:228] Iteration 5100, loss = 2.43634
I0312 15:11:08.520912  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:11:08.520912  1600 solver.cpp:244]     Train net output #1: loss = 2.43634 (* 1 = 2.43634 loss)
I0312 15:11:08.520912  1600 sgd_solver.cpp:106] Iteration 5100, lr = 0.1
I0312 15:11:17.541545  1600 solver.cpp:228] Iteration 5200, loss = 2.16245
I0312 15:11:17.542044  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:11:17.542044  1600 solver.cpp:244]     Train net output #1: loss = 2.16245 (* 1 = 2.16245 loss)
I0312 15:11:17.542044  1600 sgd_solver.cpp:106] Iteration 5200, lr = 0.1
I0312 15:11:26.462424  1600 solver.cpp:228] Iteration 5300, loss = 2.02462
I0312 15:11:26.462424  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:11:26.462424  1600 solver.cpp:244]     Train net output #1: loss = 2.02462 (* 1 = 2.02462 loss)
I0312 15:11:26.462424  1600 sgd_solver.cpp:106] Iteration 5300, lr = 0.1
I0312 15:11:35.504720  1600 solver.cpp:228] Iteration 5400, loss = 2.29935
I0312 15:11:35.504720  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.375
I0312 15:11:35.504720  1600 solver.cpp:244]     Train net output #1: loss = 2.29935 (* 1 = 2.29935 loss)
I0312 15:11:35.504720  1600 sgd_solver.cpp:106] Iteration 5400, lr = 0.1
I0312 15:11:44.474692  1600 solver.cpp:228] Iteration 5500, loss = 2.01356
I0312 15:11:44.474692  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.421875
I0312 15:11:44.474692  1600 solver.cpp:244]     Train net output #1: loss = 2.01356 (* 1 = 2.01356 loss)
I0312 15:11:44.474692  1600 sgd_solver.cpp:106] Iteration 5500, lr = 0.1
I0312 15:11:53.579000  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_5600.caffemodel
I0312 15:11:53.633500  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_5600.solverstate
I0312 15:11:53.639000  1600 solver.cpp:337] Iteration 5600, Testing net (#0)
I0312 15:11:53.639000  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:11:57.419906  1600 solver.cpp:404]     Test net output #0: accuracy = 0.3836
I0312 15:11:57.419906  1600 solver.cpp:404]     Test net output #1: loss = 2.33915 (* 1 = 2.33915 loss)
I0312 15:11:57.436906  1600 solver.cpp:228] Iteration 5600, loss = 2.41447
I0312 15:11:57.436906  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:11:57.436906  1600 solver.cpp:244]     Train net output #1: loss = 2.41447 (* 1 = 2.41447 loss)
I0312 15:11:57.436906  1600 sgd_solver.cpp:106] Iteration 5600, lr = 0.1
I0312 15:12:06.342846  1600 solver.cpp:228] Iteration 5700, loss = 2.10368
I0312 15:12:06.342846  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:12:06.342846  1600 solver.cpp:244]     Train net output #1: loss = 2.10368 (* 1 = 2.10368 loss)
I0312 15:12:06.342846  1600 sgd_solver.cpp:106] Iteration 5700, lr = 0.1
I0312 15:12:15.670344  1600 solver.cpp:228] Iteration 5800, loss = 2.37917
I0312 15:12:15.670344  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.375
I0312 15:12:15.670344  1600 solver.cpp:244]     Train net output #1: loss = 2.37917 (* 1 = 2.37917 loss)
I0312 15:12:15.670344  1600 sgd_solver.cpp:106] Iteration 5800, lr = 0.1
I0312 15:12:24.944557  1600 solver.cpp:228] Iteration 5900, loss = 2.17533
I0312 15:12:24.945057  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:12:24.945057  1600 solver.cpp:244]     Train net output #1: loss = 2.17533 (* 1 = 2.17533 loss)
I0312 15:12:24.945057  1600 sgd_solver.cpp:106] Iteration 5900, lr = 0.1
I0312 15:12:34.033599  1600 solver.cpp:228] Iteration 6000, loss = 2.42344
I0312 15:12:34.033599  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:12:34.033599  1600 solver.cpp:244]     Train net output #1: loss = 2.42344 (* 1 = 2.42344 loss)
I0312 15:12:34.033599  1600 sgd_solver.cpp:106] Iteration 6000, lr = 0.1
I0312 15:12:43.109319  1600 solver.cpp:228] Iteration 6100, loss = 2.58917
I0312 15:12:43.109319  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.296875
I0312 15:12:43.109319  1600 solver.cpp:244]     Train net output #1: loss = 2.58917 (* 1 = 2.58917 loss)
I0312 15:12:43.109319  1600 sgd_solver.cpp:106] Iteration 6100, lr = 0.1
I0312 15:12:52.300374  1600 solver.cpp:228] Iteration 6200, loss = 2.54179
I0312 15:12:52.300374  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.375
I0312 15:12:52.300374  1600 solver.cpp:244]     Train net output #1: loss = 2.54179 (* 1 = 2.54179 loss)
I0312 15:12:52.300374  1600 sgd_solver.cpp:106] Iteration 6200, lr = 0.1
I0312 15:13:01.523413  1600 solver.cpp:228] Iteration 6300, loss = 2.27627
I0312 15:13:01.523413  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:13:01.523413  1600 solver.cpp:244]     Train net output #1: loss = 2.27627 (* 1 = 2.27627 loss)
I0312 15:13:01.523413  1600 sgd_solver.cpp:106] Iteration 6300, lr = 0.1
I0312 15:13:10.593787  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_6400.caffemodel
I0312 15:13:10.610302  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_6400.solverstate
I0312 15:13:10.616322  1600 solver.cpp:337] Iteration 6400, Testing net (#0)
I0312 15:13:10.616823  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:13:14.273907  1600 solver.cpp:404]     Test net output #0: accuracy = 0.3437
I0312 15:13:14.273907  1600 solver.cpp:404]     Test net output #1: loss = 2.64325 (* 1 = 2.64325 loss)
I0312 15:13:14.293901  1600 solver.cpp:228] Iteration 6400, loss = 2.44346
I0312 15:13:14.293901  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:13:14.293901  1600 solver.cpp:244]     Train net output #1: loss = 2.44346 (* 1 = 2.44346 loss)
I0312 15:13:14.293901  1600 sgd_solver.cpp:106] Iteration 6400, lr = 0.1
I0312 15:13:23.199230  1600 solver.cpp:228] Iteration 6500, loss = 2.2461
I0312 15:13:23.199230  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:13:23.199230  1600 solver.cpp:244]     Train net output #1: loss = 2.2461 (* 1 = 2.2461 loss)
I0312 15:13:23.199731  1600 sgd_solver.cpp:106] Iteration 6500, lr = 0.1
I0312 15:13:32.225083  1600 solver.cpp:228] Iteration 6600, loss = 2.06648
I0312 15:13:32.225584  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:13:32.225584  1600 solver.cpp:244]     Train net output #1: loss = 2.06648 (* 1 = 2.06648 loss)
I0312 15:13:32.225584  1600 sgd_solver.cpp:106] Iteration 6600, lr = 0.1
I0312 15:13:41.370123  1600 solver.cpp:228] Iteration 6700, loss = 1.8776
I0312 15:13:41.370123  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:13:41.370123  1600 solver.cpp:244]     Train net output #1: loss = 1.8776 (* 1 = 1.8776 loss)
I0312 15:13:41.370123  1600 sgd_solver.cpp:106] Iteration 6700, lr = 0.1
I0312 15:13:50.275394  1600 solver.cpp:228] Iteration 6800, loss = 2.10011
I0312 15:13:50.275394  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:13:50.275394  1600 solver.cpp:244]     Train net output #1: loss = 2.10011 (* 1 = 2.10011 loss)
I0312 15:13:50.275394  1600 sgd_solver.cpp:106] Iteration 6800, lr = 0.1
I0312 15:13:59.463094  1600 solver.cpp:228] Iteration 6900, loss = 2.19768
I0312 15:13:59.463610  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:13:59.463610  1600 solver.cpp:244]     Train net output #1: loss = 2.19768 (* 1 = 2.19768 loss)
I0312 15:13:59.463610  1600 sgd_solver.cpp:106] Iteration 6900, lr = 0.1
I0312 15:14:08.464918  1600 solver.cpp:228] Iteration 7000, loss = 2.22608
I0312 15:14:08.464918  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:14:08.464918  1600 solver.cpp:244]     Train net output #1: loss = 2.22608 (* 1 = 2.22608 loss)
I0312 15:14:08.464918  1600 sgd_solver.cpp:106] Iteration 7000, lr = 0.1
I0312 15:14:17.545018  1600 solver.cpp:228] Iteration 7100, loss = 2.08984
I0312 15:14:17.545018  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.375
I0312 15:14:17.545018  1600 solver.cpp:244]     Train net output #1: loss = 2.08984 (* 1 = 2.08984 loss)
I0312 15:14:17.545018  1600 sgd_solver.cpp:106] Iteration 7100, lr = 0.1
I0312 15:14:26.662524  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_7200.caffemodel
I0312 15:14:26.682526  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_7200.solverstate
I0312 15:14:26.687525  1600 solver.cpp:337] Iteration 7200, Testing net (#0)
I0312 15:14:26.688025  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:14:30.351649  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4048
I0312 15:14:30.351649  1600 solver.cpp:404]     Test net output #1: loss = 2.29212 (* 1 = 2.29212 loss)
I0312 15:14:30.381649  1600 solver.cpp:228] Iteration 7200, loss = 2.01706
I0312 15:14:30.381649  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.375
I0312 15:14:30.381649  1600 solver.cpp:244]     Train net output #1: loss = 2.01706 (* 1 = 2.01706 loss)
I0312 15:14:30.381649  1600 sgd_solver.cpp:106] Iteration 7200, lr = 0.1
I0312 15:14:39.514174  1600 solver.cpp:228] Iteration 7300, loss = 2.37545
I0312 15:14:39.514174  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:14:39.514174  1600 solver.cpp:244]     Train net output #1: loss = 2.37545 (* 1 = 2.37545 loss)
I0312 15:14:39.514174  1600 sgd_solver.cpp:106] Iteration 7300, lr = 0.1
I0312 15:14:48.595616  1600 solver.cpp:228] Iteration 7400, loss = 2.10612
I0312 15:14:48.595616  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:14:48.595616  1600 solver.cpp:244]     Train net output #1: loss = 2.10612 (* 1 = 2.10612 loss)
I0312 15:14:48.595616  1600 sgd_solver.cpp:106] Iteration 7400, lr = 0.1
I0312 15:14:57.824990  1600 solver.cpp:228] Iteration 7500, loss = 2.02557
I0312 15:14:57.824990  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.421875
I0312 15:14:57.824990  1600 solver.cpp:244]     Train net output #1: loss = 2.02557 (* 1 = 2.02557 loss)
I0312 15:14:57.824990  1600 sgd_solver.cpp:106] Iteration 7500, lr = 0.1
I0312 15:15:06.794538  1600 solver.cpp:228] Iteration 7600, loss = 2.34027
I0312 15:15:06.794538  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.421875
I0312 15:15:06.794538  1600 solver.cpp:244]     Train net output #1: loss = 2.34027 (* 1 = 2.34027 loss)
I0312 15:15:06.794538  1600 sgd_solver.cpp:106] Iteration 7600, lr = 0.1
I0312 15:15:15.898906  1600 solver.cpp:228] Iteration 7700, loss = 2.30056
I0312 15:15:15.898906  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.34375
I0312 15:15:15.898906  1600 solver.cpp:244]     Train net output #1: loss = 2.30056 (* 1 = 2.30056 loss)
I0312 15:15:15.898906  1600 sgd_solver.cpp:106] Iteration 7700, lr = 0.1
I0312 15:15:24.087414  1600 solver.cpp:228] Iteration 7800, loss = 2.06798
I0312 15:15:24.087414  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.359375
I0312 15:15:24.087414  1600 solver.cpp:244]     Train net output #1: loss = 2.06798 (* 1 = 2.06798 loss)
I0312 15:15:24.087414  1600 sgd_solver.cpp:106] Iteration 7800, lr = 0.1
I0312 15:15:29.895092  1600 solver.cpp:228] Iteration 7900, loss = 2.07057
I0312 15:15:29.895092  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:15:29.895092  1600 solver.cpp:244]     Train net output #1: loss = 2.07057 (* 1 = 2.07057 loss)
I0312 15:15:29.895092  1600 sgd_solver.cpp:106] Iteration 7900, lr = 0.1
I0312 15:15:35.666440  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_8000.caffemodel
I0312 15:15:35.676441  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_8000.solverstate
I0312 15:15:35.689447  1600 solver.cpp:337] Iteration 8000, Testing net (#0)
I0312 15:15:35.689447  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:15:38.164929  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4297
I0312 15:15:38.164929  1600 solver.cpp:404]     Test net output #1: loss = 2.13059 (* 1 = 2.13059 loss)
I0312 15:15:38.193434  1600 solver.cpp:228] Iteration 8000, loss = 2.06294
I0312 15:15:38.193434  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.421875
I0312 15:15:38.193434  1600 solver.cpp:244]     Train net output #1: loss = 2.06294 (* 1 = 2.06294 loss)
I0312 15:15:38.193434  1600 sgd_solver.cpp:106] Iteration 8000, lr = 0.1
I0312 15:15:46.229562  1600 solver.cpp:228] Iteration 8100, loss = 1.95704
I0312 15:15:46.229562  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:15:46.229562  1600 solver.cpp:244]     Train net output #1: loss = 1.95704 (* 1 = 1.95704 loss)
I0312 15:15:46.229562  1600 sgd_solver.cpp:106] Iteration 8100, lr = 0.1
I0312 15:15:55.352138  1600 solver.cpp:228] Iteration 8200, loss = 2.12673
I0312 15:15:55.352138  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.3125
I0312 15:15:55.352138  1600 solver.cpp:244]     Train net output #1: loss = 2.12673 (* 1 = 2.12673 loss)
I0312 15:15:55.352138  1600 sgd_solver.cpp:106] Iteration 8200, lr = 0.1
I0312 15:16:04.691073  1600 solver.cpp:228] Iteration 8300, loss = 2.20529
I0312 15:16:04.691073  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.359375
I0312 15:16:04.691073  1600 solver.cpp:244]     Train net output #1: loss = 2.20529 (* 1 = 2.20529 loss)
I0312 15:16:04.691073  1600 sgd_solver.cpp:106] Iteration 8300, lr = 0.1
I0312 15:16:13.843667  1600 solver.cpp:228] Iteration 8400, loss = 1.91538
I0312 15:16:13.843667  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:16:13.843667  1600 solver.cpp:244]     Train net output #1: loss = 1.91538 (* 1 = 1.91538 loss)
I0312 15:16:13.843667  1600 sgd_solver.cpp:106] Iteration 8400, lr = 0.1
I0312 15:16:22.908340  1600 solver.cpp:228] Iteration 8500, loss = 2.06065
I0312 15:16:22.908340  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.390625
I0312 15:16:22.908340  1600 solver.cpp:244]     Train net output #1: loss = 2.06065 (* 1 = 2.06065 loss)
I0312 15:16:22.908340  1600 sgd_solver.cpp:106] Iteration 8500, lr = 0.1
I0312 15:16:31.941836  1600 solver.cpp:228] Iteration 8600, loss = 2.1415
I0312 15:16:31.941836  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:16:31.941836  1600 solver.cpp:244]     Train net output #1: loss = 2.1415 (* 1 = 2.1415 loss)
I0312 15:16:31.941836  1600 sgd_solver.cpp:106] Iteration 8600, lr = 0.1
I0312 15:16:41.217734  1600 solver.cpp:228] Iteration 8700, loss = 1.5771
I0312 15:16:41.217734  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:16:41.217734  1600 solver.cpp:244]     Train net output #1: loss = 1.5771 (* 1 = 1.5771 loss)
I0312 15:16:41.217734  1600 sgd_solver.cpp:106] Iteration 8700, lr = 0.1
I0312 15:16:50.323375  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_8800.caffemodel
I0312 15:16:50.353376  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_8800.solverstate
I0312 15:16:50.353376  1600 solver.cpp:337] Iteration 8800, Testing net (#0)
I0312 15:16:50.353376  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:16:54.135987  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4448
I0312 15:16:54.135987  1600 solver.cpp:404]     Test net output #1: loss = 2.08678 (* 1 = 2.08678 loss)
I0312 15:16:54.159494  1600 solver.cpp:228] Iteration 8800, loss = 1.6301
I0312 15:16:54.159494  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:16:54.159494  1600 solver.cpp:244]     Train net output #1: loss = 1.6301 (* 1 = 1.6301 loss)
I0312 15:16:54.159494  1600 sgd_solver.cpp:106] Iteration 8800, lr = 0.1
I0312 15:17:03.287955  1600 solver.cpp:228] Iteration 8900, loss = 1.72236
I0312 15:17:03.287955  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:17:03.287955  1600 solver.cpp:244]     Train net output #1: loss = 1.72236 (* 1 = 1.72236 loss)
I0312 15:17:03.287955  1600 sgd_solver.cpp:106] Iteration 8900, lr = 0.1
I0312 15:17:12.364316  1600 solver.cpp:228] Iteration 9000, loss = 1.91379
I0312 15:17:12.364316  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:17:12.364316  1600 solver.cpp:244]     Train net output #1: loss = 1.91379 (* 1 = 1.91379 loss)
I0312 15:17:12.364316  1600 sgd_solver.cpp:106] Iteration 9000, lr = 0.1
I0312 15:17:21.416755  1600 solver.cpp:228] Iteration 9100, loss = 1.77872
I0312 15:17:21.416755  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:17:21.416755  1600 solver.cpp:244]     Train net output #1: loss = 1.77872 (* 1 = 1.77872 loss)
I0312 15:17:21.416755  1600 sgd_solver.cpp:106] Iteration 9100, lr = 0.1
I0312 15:17:30.496520  1600 solver.cpp:228] Iteration 9200, loss = 1.84648
I0312 15:17:30.496520  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:17:30.496520  1600 solver.cpp:244]     Train net output #1: loss = 1.84648 (* 1 = 1.84648 loss)
I0312 15:17:30.496520  1600 sgd_solver.cpp:106] Iteration 9200, lr = 0.1
I0312 15:17:39.604758  1600 solver.cpp:228] Iteration 9300, loss = 1.96155
I0312 15:17:39.604758  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:17:39.604758  1600 solver.cpp:244]     Train net output #1: loss = 1.96155 (* 1 = 1.96155 loss)
I0312 15:17:39.604758  1600 sgd_solver.cpp:106] Iteration 9300, lr = 0.1
I0312 15:17:48.921725  1600 solver.cpp:228] Iteration 9400, loss = 1.91504
I0312 15:17:48.921725  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:17:48.922226  1600 solver.cpp:244]     Train net output #1: loss = 1.91504 (* 1 = 1.91504 loss)
I0312 15:17:48.922226  1600 sgd_solver.cpp:106] Iteration 9400, lr = 0.1
I0312 15:17:58.010738  1600 solver.cpp:228] Iteration 9500, loss = 1.64646
I0312 15:17:58.010738  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:17:58.010738  1600 solver.cpp:244]     Train net output #1: loss = 1.64646 (* 1 = 1.64646 loss)
I0312 15:17:58.010738  1600 sgd_solver.cpp:106] Iteration 9500, lr = 0.1
I0312 15:18:07.096010  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_9600.caffemodel
I0312 15:18:07.130010  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_9600.solverstate
I0312 15:18:07.135511  1600 solver.cpp:337] Iteration 9600, Testing net (#0)
I0312 15:18:07.135511  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:18:10.834774  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4427
I0312 15:18:10.834774  1600 solver.cpp:404]     Test net output #1: loss = 2.10193 (* 1 = 2.10193 loss)
I0312 15:18:10.856274  1600 solver.cpp:228] Iteration 9600, loss = 1.9796
I0312 15:18:10.856274  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:18:10.856274  1600 solver.cpp:244]     Train net output #1: loss = 1.9796 (* 1 = 1.9796 loss)
I0312 15:18:10.856274  1600 sgd_solver.cpp:106] Iteration 9600, lr = 0.1
I0312 15:18:19.865770  1600 solver.cpp:228] Iteration 9700, loss = 1.7934
I0312 15:18:19.865770  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:18:19.866271  1600 solver.cpp:244]     Train net output #1: loss = 1.7934 (* 1 = 1.7934 loss)
I0312 15:18:19.866271  1600 sgd_solver.cpp:106] Iteration 9700, lr = 0.1
I0312 15:18:28.868635  1600 solver.cpp:228] Iteration 9800, loss = 1.95894
I0312 15:18:28.868635  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:18:28.868635  1600 solver.cpp:244]     Train net output #1: loss = 1.95894 (* 1 = 1.95894 loss)
I0312 15:18:28.868635  1600 sgd_solver.cpp:106] Iteration 9800, lr = 0.1
I0312 15:18:37.954486  1600 solver.cpp:228] Iteration 9900, loss = 2.0392
I0312 15:18:37.954486  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:18:37.954486  1600 solver.cpp:244]     Train net output #1: loss = 2.0392 (* 1 = 2.0392 loss)
I0312 15:18:37.954486  1600 sgd_solver.cpp:106] Iteration 9900, lr = 0.1
I0312 15:18:47.125967  1600 solver.cpp:228] Iteration 10000, loss = 2.10299
I0312 15:18:47.126466  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.40625
I0312 15:18:47.126466  1600 solver.cpp:244]     Train net output #1: loss = 2.10299 (* 1 = 2.10299 loss)
I0312 15:18:47.126466  1600 sgd_solver.cpp:106] Iteration 10000, lr = 0.1
I0312 15:18:56.283977  1600 solver.cpp:228] Iteration 10100, loss = 1.88704
I0312 15:18:56.283977  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:18:56.283977  1600 solver.cpp:244]     Train net output #1: loss = 1.88704 (* 1 = 1.88704 loss)
I0312 15:18:56.283977  1600 sgd_solver.cpp:106] Iteration 10100, lr = 0.1
I0312 15:19:05.349732  1600 solver.cpp:228] Iteration 10200, loss = 2.05745
I0312 15:19:05.349732  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:19:05.349732  1600 solver.cpp:244]     Train net output #1: loss = 2.05745 (* 1 = 2.05745 loss)
I0312 15:19:05.349732  1600 sgd_solver.cpp:106] Iteration 10200, lr = 0.1
I0312 15:19:14.331622  1600 solver.cpp:228] Iteration 10300, loss = 1.86682
I0312 15:19:14.331622  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:19:14.331622  1600 solver.cpp:244]     Train net output #1: loss = 1.86682 (* 1 = 1.86682 loss)
I0312 15:19:14.331622  1600 sgd_solver.cpp:106] Iteration 10300, lr = 0.1
I0312 15:19:23.384634  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_10400.caffemodel
I0312 15:19:23.398627  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_10400.solverstate
I0312 15:19:23.403635  1600 solver.cpp:337] Iteration 10400, Testing net (#0)
I0312 15:19:23.403635  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:19:27.143854  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4676
I0312 15:19:27.143854  1600 solver.cpp:404]     Test net output #1: loss = 2.00633 (* 1 = 2.00633 loss)
I0312 15:19:27.163877  1600 solver.cpp:228] Iteration 10400, loss = 1.7052
I0312 15:19:27.163877  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:19:27.163877  1600 solver.cpp:244]     Train net output #1: loss = 1.7052 (* 1 = 1.7052 loss)
I0312 15:19:27.163877  1600 sgd_solver.cpp:106] Iteration 10400, lr = 0.1
I0312 15:19:36.145799  1600 solver.cpp:228] Iteration 10500, loss = 2.10873
I0312 15:19:36.146299  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:19:36.146299  1600 solver.cpp:244]     Train net output #1: loss = 2.10873 (* 1 = 2.10873 loss)
I0312 15:19:36.146299  1600 sgd_solver.cpp:106] Iteration 10500, lr = 0.1
I0312 15:19:45.126150  1600 solver.cpp:228] Iteration 10600, loss = 1.79951
I0312 15:19:45.126150  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:19:45.126150  1600 solver.cpp:244]     Train net output #1: loss = 1.79951 (* 1 = 1.79951 loss)
I0312 15:19:45.126150  1600 sgd_solver.cpp:106] Iteration 10600, lr = 0.1
I0312 15:19:54.260851  1600 solver.cpp:228] Iteration 10700, loss = 1.54053
I0312 15:19:54.260851  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:19:54.260851  1600 solver.cpp:244]     Train net output #1: loss = 1.54053 (* 1 = 1.54053 loss)
I0312 15:19:54.260851  1600 sgd_solver.cpp:106] Iteration 10700, lr = 0.1
I0312 15:20:03.454300  1600 solver.cpp:228] Iteration 10800, loss = 1.6742
I0312 15:20:03.454300  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:20:03.454300  1600 solver.cpp:244]     Train net output #1: loss = 1.6742 (* 1 = 1.6742 loss)
I0312 15:20:03.454300  1600 sgd_solver.cpp:106] Iteration 10800, lr = 0.1
I0312 15:20:12.390943  1600 solver.cpp:228] Iteration 10900, loss = 1.6794
I0312 15:20:12.391443  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:20:12.391443  1600 solver.cpp:244]     Train net output #1: loss = 1.6794 (* 1 = 1.6794 loss)
I0312 15:20:12.391443  1600 sgd_solver.cpp:106] Iteration 10900, lr = 0.1
I0312 15:20:21.508905  1600 solver.cpp:228] Iteration 11000, loss = 1.65649
I0312 15:20:21.508905  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:20:21.508905  1600 solver.cpp:244]     Train net output #1: loss = 1.65649 (* 1 = 1.65649 loss)
I0312 15:20:21.508905  1600 sgd_solver.cpp:106] Iteration 11000, lr = 0.1
I0312 15:20:29.388398  1600 solver.cpp:228] Iteration 11100, loss = 1.87042
I0312 15:20:29.388398  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:20:29.388398  1600 solver.cpp:244]     Train net output #1: loss = 1.87042 (* 1 = 1.87042 loss)
I0312 15:20:29.388398  1600 sgd_solver.cpp:106] Iteration 11100, lr = 0.1
I0312 15:20:35.197574  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_11200.caffemodel
I0312 15:20:35.217567  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_11200.solverstate
I0312 15:20:35.217567  1600 solver.cpp:337] Iteration 11200, Testing net (#0)
I0312 15:20:35.217567  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:20:37.703650  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4634
I0312 15:20:37.703650  1600 solver.cpp:404]     Test net output #1: loss = 2.05304 (* 1 = 2.05304 loss)
I0312 15:20:37.723649  1600 solver.cpp:228] Iteration 11200, loss = 1.5569
I0312 15:20:37.723649  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:20:37.723649  1600 solver.cpp:244]     Train net output #1: loss = 1.5569 (* 1 = 1.5569 loss)
I0312 15:20:37.723649  1600 sgd_solver.cpp:106] Iteration 11200, lr = 0.1
I0312 15:20:43.586130  1600 solver.cpp:228] Iteration 11300, loss = 1.88236
I0312 15:20:43.586130  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:20:43.586130  1600 solver.cpp:244]     Train net output #1: loss = 1.88236 (* 1 = 1.88236 loss)
I0312 15:20:43.586130  1600 sgd_solver.cpp:106] Iteration 11300, lr = 0.1
I0312 15:20:52.207476  1600 solver.cpp:228] Iteration 11400, loss = 1.65395
I0312 15:20:52.207476  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:20:52.207476  1600 solver.cpp:244]     Train net output #1: loss = 1.65395 (* 1 = 1.65395 loss)
I0312 15:20:52.207476  1600 sgd_solver.cpp:106] Iteration 11400, lr = 0.1
I0312 15:21:01.229153  1600 solver.cpp:228] Iteration 11500, loss = 1.76891
I0312 15:21:01.229153  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:21:01.229153  1600 solver.cpp:244]     Train net output #1: loss = 1.76891 (* 1 = 1.76891 loss)
I0312 15:21:01.229153  1600 sgd_solver.cpp:106] Iteration 11500, lr = 0.1
I0312 15:21:10.391743  1600 solver.cpp:228] Iteration 11600, loss = 1.95241
I0312 15:21:10.391743  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.390625
I0312 15:21:10.391743  1600 solver.cpp:244]     Train net output #1: loss = 1.95241 (* 1 = 1.95241 loss)
I0312 15:21:10.391743  1600 sgd_solver.cpp:106] Iteration 11600, lr = 0.1
I0312 15:21:19.568049  1600 solver.cpp:228] Iteration 11700, loss = 1.69443
I0312 15:21:19.568549  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.421875
I0312 15:21:19.568549  1600 solver.cpp:244]     Train net output #1: loss = 1.69443 (* 1 = 1.69443 loss)
I0312 15:21:19.568549  1600 sgd_solver.cpp:106] Iteration 11700, lr = 0.1
I0312 15:21:28.833377  1600 solver.cpp:228] Iteration 11800, loss = 1.81437
I0312 15:21:28.833878  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:21:28.833878  1600 solver.cpp:244]     Train net output #1: loss = 1.81437 (* 1 = 1.81437 loss)
I0312 15:21:28.833878  1600 sgd_solver.cpp:106] Iteration 11800, lr = 0.1
I0312 15:21:37.864928  1600 solver.cpp:228] Iteration 11900, loss = 1.55535
I0312 15:21:37.864928  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:21:37.864928  1600 solver.cpp:244]     Train net output #1: loss = 1.55535 (* 1 = 1.55535 loss)
I0312 15:21:37.864928  1600 sgd_solver.cpp:106] Iteration 11900, lr = 0.1
I0312 15:21:47.075572  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_12000.caffemodel
I0312 15:21:47.100072  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_12000.solverstate
I0312 15:21:47.104593  1600 solver.cpp:337] Iteration 12000, Testing net (#0)
I0312 15:21:47.104593  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:21:50.773607  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4752
I0312 15:21:50.773607  1600 solver.cpp:404]     Test net output #1: loss = 1.95822 (* 1 = 1.95822 loss)
I0312 15:21:50.803607  1600 solver.cpp:228] Iteration 12000, loss = 1.9599
I0312 15:21:50.803607  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:21:50.803607  1600 solver.cpp:244]     Train net output #1: loss = 1.9599 (* 1 = 1.9599 loss)
I0312 15:21:50.803607  1600 sgd_solver.cpp:106] Iteration 12000, lr = 0.1
I0312 15:21:59.797103  1600 solver.cpp:228] Iteration 12100, loss = 1.83788
I0312 15:21:59.797603  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:21:59.797603  1600 solver.cpp:244]     Train net output #1: loss = 1.83788 (* 1 = 1.83788 loss)
I0312 15:21:59.797603  1600 sgd_solver.cpp:106] Iteration 12100, lr = 0.1
I0312 15:22:08.913390  1600 solver.cpp:228] Iteration 12200, loss = 1.76889
I0312 15:22:08.913390  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:22:08.913390  1600 solver.cpp:244]     Train net output #1: loss = 1.76889 (* 1 = 1.76889 loss)
I0312 15:22:08.913390  1600 sgd_solver.cpp:106] Iteration 12200, lr = 0.1
I0312 15:22:17.996171  1600 solver.cpp:228] Iteration 12300, loss = 1.91717
I0312 15:22:17.996171  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:22:17.996171  1600 solver.cpp:244]     Train net output #1: loss = 1.91717 (* 1 = 1.91717 loss)
I0312 15:22:17.996171  1600 sgd_solver.cpp:106] Iteration 12300, lr = 0.1
I0312 15:22:26.905656  1600 solver.cpp:228] Iteration 12400, loss = 1.7962
I0312 15:22:26.905656  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:22:26.905656  1600 solver.cpp:244]     Train net output #1: loss = 1.7962 (* 1 = 1.7962 loss)
I0312 15:22:26.905656  1600 sgd_solver.cpp:106] Iteration 12400, lr = 0.1
I0312 15:22:35.966871  1600 solver.cpp:228] Iteration 12500, loss = 1.93206
I0312 15:22:35.966871  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.390625
I0312 15:22:35.967370  1600 solver.cpp:244]     Train net output #1: loss = 1.93206 (* 1 = 1.93206 loss)
I0312 15:22:35.967370  1600 sgd_solver.cpp:106] Iteration 12500, lr = 0.1
I0312 15:22:44.890307  1600 solver.cpp:228] Iteration 12600, loss = 1.74509
I0312 15:22:44.890307  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:22:44.890307  1600 solver.cpp:244]     Train net output #1: loss = 1.74509 (* 1 = 1.74509 loss)
I0312 15:22:44.890307  1600 sgd_solver.cpp:106] Iteration 12600, lr = 0.1
I0312 15:22:53.917413  1600 solver.cpp:228] Iteration 12700, loss = 1.33556
I0312 15:22:53.917413  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:22:53.917413  1600 solver.cpp:244]     Train net output #1: loss = 1.33556 (* 1 = 1.33556 loss)
I0312 15:22:53.917413  1600 sgd_solver.cpp:106] Iteration 12700, lr = 0.1
I0312 15:23:02.817054  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_12800.caffemodel
I0312 15:23:02.833055  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_12800.solverstate
I0312 15:23:02.838053  1600 solver.cpp:337] Iteration 12800, Testing net (#0)
I0312 15:23:02.838053  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:23:06.579290  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4551
I0312 15:23:06.579290  1600 solver.cpp:404]     Test net output #1: loss = 2.07422 (* 1 = 2.07422 loss)
I0312 15:23:06.595783  1600 solver.cpp:228] Iteration 12800, loss = 1.51724
I0312 15:23:06.595783  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:23:06.595783  1600 solver.cpp:244]     Train net output #1: loss = 1.51724 (* 1 = 1.51724 loss)
I0312 15:23:06.595783  1600 sgd_solver.cpp:106] Iteration 12800, lr = 0.1
I0312 15:23:15.825626  1600 solver.cpp:228] Iteration 12900, loss = 1.50203
I0312 15:23:15.825626  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:23:15.825626  1600 solver.cpp:244]     Train net output #1: loss = 1.50203 (* 1 = 1.50203 loss)
I0312 15:23:15.825626  1600 sgd_solver.cpp:106] Iteration 12900, lr = 0.1
I0312 15:23:24.874721  1600 solver.cpp:228] Iteration 13000, loss = 1.51877
I0312 15:23:24.874721  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:23:24.874721  1600 solver.cpp:244]     Train net output #1: loss = 1.51877 (* 1 = 1.51877 loss)
I0312 15:23:24.874721  1600 sgd_solver.cpp:106] Iteration 13000, lr = 0.1
I0312 15:23:34.087941  1600 solver.cpp:228] Iteration 13100, loss = 1.56911
I0312 15:23:34.088441  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:23:34.088441  1600 solver.cpp:244]     Train net output #1: loss = 1.56911 (* 1 = 1.56911 loss)
I0312 15:23:34.088441  1600 sgd_solver.cpp:106] Iteration 13100, lr = 0.1
I0312 15:23:42.998366  1600 solver.cpp:228] Iteration 13200, loss = 1.57735
I0312 15:23:42.998366  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:23:42.998366  1600 solver.cpp:244]     Train net output #1: loss = 1.57735 (* 1 = 1.57735 loss)
I0312 15:23:42.998366  1600 sgd_solver.cpp:106] Iteration 13200, lr = 0.1
I0312 15:23:52.066792  1600 solver.cpp:228] Iteration 13300, loss = 1.67353
I0312 15:23:52.066792  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:23:52.066792  1600 solver.cpp:244]     Train net output #1: loss = 1.67353 (* 1 = 1.67353 loss)
I0312 15:23:52.066792  1600 sgd_solver.cpp:106] Iteration 13300, lr = 0.1
I0312 15:24:00.975076  1600 solver.cpp:228] Iteration 13400, loss = 2.08102
I0312 15:24:00.975076  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:24:00.975076  1600 solver.cpp:244]     Train net output #1: loss = 2.08102 (* 1 = 2.08102 loss)
I0312 15:24:00.975076  1600 sgd_solver.cpp:106] Iteration 13400, lr = 0.1
I0312 15:24:10.213654  1600 solver.cpp:228] Iteration 13500, loss = 1.7835
I0312 15:24:10.214157  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:24:10.214157  1600 solver.cpp:244]     Train net output #1: loss = 1.7835 (* 1 = 1.7835 loss)
I0312 15:24:10.214157  1600 sgd_solver.cpp:106] Iteration 13500, lr = 0.1
I0312 15:24:19.374567  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_13600.caffemodel
I0312 15:24:19.385680  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_13600.solverstate
I0312 15:24:19.385680  1600 solver.cpp:337] Iteration 13600, Testing net (#0)
I0312 15:24:19.385680  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:24:23.120275  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4731
I0312 15:24:23.120275  1600 solver.cpp:404]     Test net output #1: loss = 1.9955 (* 1 = 1.9955 loss)
I0312 15:24:23.137758  1600 solver.cpp:228] Iteration 13600, loss = 1.87647
I0312 15:24:23.137758  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:24:23.137758  1600 solver.cpp:244]     Train net output #1: loss = 1.87647 (* 1 = 1.87647 loss)
I0312 15:24:23.137758  1600 sgd_solver.cpp:106] Iteration 13600, lr = 0.1
I0312 15:24:32.413002  1600 solver.cpp:228] Iteration 13700, loss = 1.6375
I0312 15:24:32.413002  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:24:32.413002  1600 solver.cpp:244]     Train net output #1: loss = 1.6375 (* 1 = 1.6375 loss)
I0312 15:24:32.413002  1600 sgd_solver.cpp:106] Iteration 13700, lr = 0.1
I0312 15:24:41.577816  1600 solver.cpp:228] Iteration 13800, loss = 1.32646
I0312 15:24:41.577816  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:24:41.577816  1600 solver.cpp:244]     Train net output #1: loss = 1.32646 (* 1 = 1.32646 loss)
I0312 15:24:41.577816  1600 sgd_solver.cpp:106] Iteration 13800, lr = 0.1
I0312 15:24:50.717176  1600 solver.cpp:228] Iteration 13900, loss = 1.45843
I0312 15:24:50.717176  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:24:50.717176  1600 solver.cpp:244]     Train net output #1: loss = 1.45843 (* 1 = 1.45843 loss)
I0312 15:24:50.717176  1600 sgd_solver.cpp:106] Iteration 13900, lr = 0.1
I0312 15:24:59.717594  1600 solver.cpp:228] Iteration 14000, loss = 1.48245
I0312 15:24:59.717594  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:24:59.717594  1600 solver.cpp:244]     Train net output #1: loss = 1.48245 (* 1 = 1.48245 loss)
I0312 15:24:59.717594  1600 sgd_solver.cpp:106] Iteration 14000, lr = 0.1
I0312 15:25:08.697947  1600 solver.cpp:228] Iteration 14100, loss = 1.75639
I0312 15:25:08.697947  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:25:08.697947  1600 solver.cpp:244]     Train net output #1: loss = 1.75639 (* 1 = 1.75639 loss)
I0312 15:25:08.697947  1600 sgd_solver.cpp:106] Iteration 14100, lr = 0.1
I0312 15:25:17.598559  1600 solver.cpp:228] Iteration 14200, loss = 2.0315
I0312 15:25:17.598559  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:25:17.598559  1600 solver.cpp:244]     Train net output #1: loss = 2.0315 (* 1 = 2.0315 loss)
I0312 15:25:17.598559  1600 sgd_solver.cpp:106] Iteration 14200, lr = 0.1
I0312 15:25:26.837623  1600 solver.cpp:228] Iteration 14300, loss = 1.45511
I0312 15:25:26.837623  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:25:26.837623  1600 solver.cpp:244]     Train net output #1: loss = 1.45511 (* 1 = 1.45511 loss)
I0312 15:25:26.837623  1600 sgd_solver.cpp:106] Iteration 14300, lr = 0.1
I0312 15:25:34.586491  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_14400.caffemodel
I0312 15:25:34.606492  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_14400.solverstate
I0312 15:25:34.616492  1600 solver.cpp:337] Iteration 14400, Testing net (#0)
I0312 15:25:34.616492  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:25:37.117722  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4812
I0312 15:25:37.117722  1600 solver.cpp:404]     Test net output #1: loss = 1.95767 (* 1 = 1.95767 loss)
I0312 15:25:37.137720  1600 solver.cpp:228] Iteration 14400, loss = 1.53262
I0312 15:25:37.137720  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:25:37.137720  1600 solver.cpp:244]     Train net output #1: loss = 1.53262 (* 1 = 1.53262 loss)
I0312 15:25:37.137720  1600 sgd_solver.cpp:106] Iteration 14400, lr = 0.1
I0312 15:25:42.979079  1600 solver.cpp:228] Iteration 14500, loss = 1.40153
I0312 15:25:42.979079  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:25:42.979079  1600 solver.cpp:244]     Train net output #1: loss = 1.40153 (* 1 = 1.40153 loss)
I0312 15:25:42.979079  1600 sgd_solver.cpp:106] Iteration 14500, lr = 0.1
I0312 15:25:48.831995  1600 solver.cpp:228] Iteration 14600, loss = 1.56762
I0312 15:25:48.831995  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:25:48.831995  1600 solver.cpp:244]     Train net output #1: loss = 1.56762 (* 1 = 1.56762 loss)
I0312 15:25:48.831995  1600 sgd_solver.cpp:106] Iteration 14600, lr = 0.1
I0312 15:25:57.582001  1600 solver.cpp:228] Iteration 14700, loss = 1.57255
I0312 15:25:57.582001  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:25:57.582001  1600 solver.cpp:244]     Train net output #1: loss = 1.57255 (* 1 = 1.57255 loss)
I0312 15:25:57.582001  1600 sgd_solver.cpp:106] Iteration 14700, lr = 0.1
I0312 15:26:06.554210  1600 solver.cpp:228] Iteration 14800, loss = 1.41823
I0312 15:26:06.554210  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:26:06.554210  1600 solver.cpp:244]     Train net output #1: loss = 1.41823 (* 1 = 1.41823 loss)
I0312 15:26:06.554210  1600 sgd_solver.cpp:106] Iteration 14800, lr = 0.1
I0312 15:26:15.759035  1600 solver.cpp:228] Iteration 14900, loss = 1.73185
I0312 15:26:15.759035  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:26:15.759035  1600 solver.cpp:244]     Train net output #1: loss = 1.73185 (* 1 = 1.73185 loss)
I0312 15:26:15.759035  1600 sgd_solver.cpp:106] Iteration 14900, lr = 0.1
I0312 15:26:24.796612  1600 solver.cpp:228] Iteration 15000, loss = 1.38976
I0312 15:26:24.796612  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:26:24.796612  1600 solver.cpp:244]     Train net output #1: loss = 1.38976 (* 1 = 1.38976 loss)
I0312 15:26:24.796612  1600 sgd_solver.cpp:106] Iteration 15000, lr = 0.1
I0312 15:26:33.807011  1600 solver.cpp:228] Iteration 15100, loss = 1.54093
I0312 15:26:33.807011  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:26:33.807011  1600 solver.cpp:244]     Train net output #1: loss = 1.54093 (* 1 = 1.54093 loss)
I0312 15:26:33.807011  1600 sgd_solver.cpp:106] Iteration 15100, lr = 0.1
I0312 15:26:42.837549  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_15200.caffemodel
I0312 15:26:42.855550  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_15200.solverstate
I0312 15:26:42.860548  1600 solver.cpp:337] Iteration 15200, Testing net (#0)
I0312 15:26:42.860548  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:26:46.559922  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4888
I0312 15:26:46.559922  1600 solver.cpp:404]     Test net output #1: loss = 1.92875 (* 1 = 1.92875 loss)
I0312 15:26:46.616936  1600 solver.cpp:228] Iteration 15200, loss = 1.50989
I0312 15:26:46.616936  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:26:46.616936  1600 solver.cpp:244]     Train net output #1: loss = 1.50989 (* 1 = 1.50989 loss)
I0312 15:26:46.616936  1600 sgd_solver.cpp:106] Iteration 15200, lr = 0.1
I0312 15:26:55.661633  1600 solver.cpp:228] Iteration 15300, loss = 1.65394
I0312 15:26:55.661633  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:26:55.661633  1600 solver.cpp:244]     Train net output #1: loss = 1.65394 (* 1 = 1.65394 loss)
I0312 15:26:55.661633  1600 sgd_solver.cpp:106] Iteration 15300, lr = 0.1
I0312 15:27:04.521559  1600 solver.cpp:228] Iteration 15400, loss = 1.59635
I0312 15:27:04.521559  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:27:04.521559  1600 solver.cpp:244]     Train net output #1: loss = 1.59635 (* 1 = 1.59635 loss)
I0312 15:27:04.521559  1600 sgd_solver.cpp:106] Iteration 15400, lr = 0.1
I0312 15:27:13.583197  1600 solver.cpp:228] Iteration 15500, loss = 1.39104
I0312 15:27:13.583197  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:27:13.583197  1600 solver.cpp:244]     Train net output #1: loss = 1.39104 (* 1 = 1.39104 loss)
I0312 15:27:13.583197  1600 sgd_solver.cpp:106] Iteration 15500, lr = 0.1
I0312 15:27:22.389703  1600 solver.cpp:228] Iteration 15600, loss = 1.49175
I0312 15:27:22.389703  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:27:22.389703  1600 solver.cpp:244]     Train net output #1: loss = 1.49175 (* 1 = 1.49175 loss)
I0312 15:27:22.389703  1600 sgd_solver.cpp:106] Iteration 15600, lr = 0.1
I0312 15:27:31.506610  1600 solver.cpp:228] Iteration 15700, loss = 1.89748
I0312 15:27:31.506610  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:27:31.506610  1600 solver.cpp:244]     Train net output #1: loss = 1.89748 (* 1 = 1.89748 loss)
I0312 15:27:31.506610  1600 sgd_solver.cpp:106] Iteration 15700, lr = 0.1
I0312 15:27:40.599954  1600 solver.cpp:228] Iteration 15800, loss = 1.4776
I0312 15:27:40.599954  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:27:40.599954  1600 solver.cpp:244]     Train net output #1: loss = 1.4776 (* 1 = 1.4776 loss)
I0312 15:27:40.599954  1600 sgd_solver.cpp:106] Iteration 15800, lr = 0.1
I0312 15:27:49.692724  1600 solver.cpp:228] Iteration 15900, loss = 1.51252
I0312 15:27:49.692724  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:27:49.692724  1600 solver.cpp:244]     Train net output #1: loss = 1.51252 (* 1 = 1.51252 loss)
I0312 15:27:49.692724  1600 sgd_solver.cpp:106] Iteration 15900, lr = 0.1
I0312 15:27:58.623394  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_16000.caffemodel
I0312 15:27:58.638878  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_16000.solverstate
I0312 15:27:58.644378  1600 solver.cpp:337] Iteration 16000, Testing net (#0)
I0312 15:27:58.644378  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:28:02.345629  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4878
I0312 15:28:02.345629  1600 solver.cpp:404]     Test net output #1: loss = 1.9528 (* 1 = 1.9528 loss)
I0312 15:28:02.371635  1600 solver.cpp:228] Iteration 16000, loss = 1.47928
I0312 15:28:02.371635  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:28:02.371635  1600 solver.cpp:244]     Train net output #1: loss = 1.47928 (* 1 = 1.47928 loss)
I0312 15:28:02.371635  1600 sgd_solver.cpp:106] Iteration 16000, lr = 0.1
I0312 15:28:11.411679  1600 solver.cpp:228] Iteration 16100, loss = 1.53388
I0312 15:28:11.411679  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:28:11.411679  1600 solver.cpp:244]     Train net output #1: loss = 1.53388 (* 1 = 1.53388 loss)
I0312 15:28:11.411679  1600 sgd_solver.cpp:106] Iteration 16100, lr = 0.1
I0312 15:28:20.468628  1600 solver.cpp:228] Iteration 16200, loss = 1.6049
I0312 15:28:20.468628  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:28:20.468628  1600 solver.cpp:244]     Train net output #1: loss = 1.6049 (* 1 = 1.6049 loss)
I0312 15:28:20.468628  1600 sgd_solver.cpp:106] Iteration 16200, lr = 0.1
I0312 15:28:29.718530  1600 solver.cpp:228] Iteration 16300, loss = 1.70901
I0312 15:28:29.718530  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:28:29.718530  1600 solver.cpp:244]     Train net output #1: loss = 1.70901 (* 1 = 1.70901 loss)
I0312 15:28:29.718530  1600 sgd_solver.cpp:106] Iteration 16300, lr = 0.1
I0312 15:28:38.871942  1600 solver.cpp:228] Iteration 16400, loss = 1.69791
I0312 15:28:38.871942  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:28:38.871942  1600 solver.cpp:244]     Train net output #1: loss = 1.69791 (* 1 = 1.69791 loss)
I0312 15:28:38.871942  1600 sgd_solver.cpp:106] Iteration 16400, lr = 0.1
I0312 15:28:48.046774  1600 solver.cpp:228] Iteration 16500, loss = 1.90983
I0312 15:28:48.046774  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:28:48.046774  1600 solver.cpp:244]     Train net output #1: loss = 1.90983 (* 1 = 1.90983 loss)
I0312 15:28:48.046774  1600 sgd_solver.cpp:106] Iteration 16500, lr = 0.1
I0312 15:28:57.152174  1600 solver.cpp:228] Iteration 16600, loss = 1.74316
I0312 15:28:57.152174  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:28:57.152174  1600 solver.cpp:244]     Train net output #1: loss = 1.74316 (* 1 = 1.74316 loss)
I0312 15:28:57.152174  1600 sgd_solver.cpp:106] Iteration 16600, lr = 0.1
I0312 15:29:06.365381  1600 solver.cpp:228] Iteration 16700, loss = 1.51032
I0312 15:29:06.365381  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:29:06.365381  1600 solver.cpp:244]     Train net output #1: loss = 1.51032 (* 1 = 1.51032 loss)
I0312 15:29:06.365381  1600 sgd_solver.cpp:106] Iteration 16700, lr = 0.1
I0312 15:29:15.374528  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_16800.caffemodel
I0312 15:29:15.403028  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_16800.solverstate
I0312 15:29:15.408527  1600 solver.cpp:337] Iteration 16800, Testing net (#0)
I0312 15:29:15.408527  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:29:19.081099  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4918
I0312 15:29:19.081599  1600 solver.cpp:404]     Test net output #1: loss = 1.91297 (* 1 = 1.91297 loss)
I0312 15:29:19.101599  1600 solver.cpp:228] Iteration 16800, loss = 1.46511
I0312 15:29:19.101599  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:29:19.101599  1600 solver.cpp:244]     Train net output #1: loss = 1.46511 (* 1 = 1.46511 loss)
I0312 15:29:19.101599  1600 sgd_solver.cpp:106] Iteration 16800, lr = 0.1
I0312 15:29:28.099179  1600 solver.cpp:228] Iteration 16900, loss = 1.27861
I0312 15:29:28.099179  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:29:28.099179  1600 solver.cpp:244]     Train net output #1: loss = 1.27861 (* 1 = 1.27861 loss)
I0312 15:29:28.099179  1600 sgd_solver.cpp:106] Iteration 16900, lr = 0.1
I0312 15:29:37.153244  1600 solver.cpp:228] Iteration 17000, loss = 1.53603
I0312 15:29:37.153244  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:29:37.153244  1600 solver.cpp:244]     Train net output #1: loss = 1.53603 (* 1 = 1.53603 loss)
I0312 15:29:37.153244  1600 sgd_solver.cpp:106] Iteration 17000, lr = 0.1
I0312 15:29:46.249887  1600 solver.cpp:228] Iteration 17100, loss = 1.90247
I0312 15:29:46.249887  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:29:46.249887  1600 solver.cpp:244]     Train net output #1: loss = 1.90247 (* 1 = 1.90247 loss)
I0312 15:29:46.249887  1600 sgd_solver.cpp:106] Iteration 17100, lr = 0.1
I0312 15:29:55.569103  1600 solver.cpp:228] Iteration 17200, loss = 1.64796
I0312 15:29:55.569103  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:29:55.569103  1600 solver.cpp:244]     Train net output #1: loss = 1.64796 (* 1 = 1.64796 loss)
I0312 15:29:55.569103  1600 sgd_solver.cpp:106] Iteration 17200, lr = 0.1
I0312 15:30:04.690788  1600 solver.cpp:228] Iteration 17300, loss = 1.51862
I0312 15:30:04.690788  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:30:04.690788  1600 solver.cpp:244]     Train net output #1: loss = 1.51862 (* 1 = 1.51862 loss)
I0312 15:30:04.690788  1600 sgd_solver.cpp:106] Iteration 17300, lr = 0.1
I0312 15:30:13.930533  1600 solver.cpp:228] Iteration 17400, loss = 1.41288
I0312 15:30:13.930533  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:30:13.930533  1600 solver.cpp:244]     Train net output #1: loss = 1.41288 (* 1 = 1.41288 loss)
I0312 15:30:13.930533  1600 sgd_solver.cpp:106] Iteration 17400, lr = 0.1
I0312 15:30:23.189501  1600 solver.cpp:228] Iteration 17500, loss = 1.56026
I0312 15:30:23.190001  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:30:23.190001  1600 solver.cpp:244]     Train net output #1: loss = 1.56026 (* 1 = 1.56026 loss)
I0312 15:30:23.190001  1600 sgd_solver.cpp:106] Iteration 17500, lr = 0.1
I0312 15:30:32.088933  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_17600.caffemodel
I0312 15:30:32.119946  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_17600.solverstate
I0312 15:30:32.124945  1600 solver.cpp:337] Iteration 17600, Testing net (#0)
I0312 15:30:32.124945  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:30:35.906332  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5004
I0312 15:30:35.906332  1600 solver.cpp:404]     Test net output #1: loss = 1.88012 (* 1 = 1.88012 loss)
I0312 15:30:35.926333  1600 solver.cpp:228] Iteration 17600, loss = 1.55558
I0312 15:30:35.926333  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:30:35.926333  1600 solver.cpp:244]     Train net output #1: loss = 1.55558 (* 1 = 1.55558 loss)
I0312 15:30:35.926333  1600 sgd_solver.cpp:106] Iteration 17600, lr = 0.1
I0312 15:30:42.346067  1600 solver.cpp:228] Iteration 17700, loss = 1.47192
I0312 15:30:42.346067  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:30:42.346067  1600 solver.cpp:244]     Train net output #1: loss = 1.47192 (* 1 = 1.47192 loss)
I0312 15:30:42.346067  1600 sgd_solver.cpp:106] Iteration 17700, lr = 0.1
I0312 15:30:48.215234  1600 solver.cpp:228] Iteration 17800, loss = 1.37072
I0312 15:30:48.215234  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:30:48.215234  1600 solver.cpp:244]     Train net output #1: loss = 1.37072 (* 1 = 1.37072 loss)
I0312 15:30:48.215234  1600 sgd_solver.cpp:106] Iteration 17800, lr = 0.1
I0312 15:30:54.001286  1600 solver.cpp:228] Iteration 17900, loss = 1.6225
I0312 15:30:54.001286  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:30:54.001286  1600 solver.cpp:244]     Train net output #1: loss = 1.6225 (* 1 = 1.6225 loss)
I0312 15:30:54.001286  1600 sgd_solver.cpp:106] Iteration 17900, lr = 0.1
I0312 15:31:02.588564  1600 solver.cpp:228] Iteration 18000, loss = 1.21532
I0312 15:31:02.588564  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:31:02.588564  1600 solver.cpp:244]     Train net output #1: loss = 1.21532 (* 1 = 1.21532 loss)
I0312 15:31:02.588564  1600 sgd_solver.cpp:106] Iteration 18000, lr = 0.1
I0312 15:31:11.594326  1600 solver.cpp:228] Iteration 18100, loss = 1.59864
I0312 15:31:11.594326  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:31:11.594326  1600 solver.cpp:244]     Train net output #1: loss = 1.59864 (* 1 = 1.59864 loss)
I0312 15:31:11.594326  1600 sgd_solver.cpp:106] Iteration 18100, lr = 0.1
I0312 15:31:20.544739  1600 solver.cpp:228] Iteration 18200, loss = 1.26819
I0312 15:31:20.544739  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:31:20.544739  1600 solver.cpp:244]     Train net output #1: loss = 1.26819 (* 1 = 1.26819 loss)
I0312 15:31:20.544739  1600 sgd_solver.cpp:106] Iteration 18200, lr = 0.1
I0312 15:31:29.620854  1600 solver.cpp:228] Iteration 18300, loss = 1.29275
I0312 15:31:29.621372  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:31:29.621372  1600 solver.cpp:244]     Train net output #1: loss = 1.29275 (* 1 = 1.29275 loss)
I0312 15:31:29.621372  1600 sgd_solver.cpp:106] Iteration 18300, lr = 0.1
I0312 15:31:38.845924  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_18400.caffemodel
I0312 15:31:38.862424  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_18400.solverstate
I0312 15:31:38.867424  1600 solver.cpp:337] Iteration 18400, Testing net (#0)
I0312 15:31:38.867924  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:31:42.576300  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5091
I0312 15:31:42.576300  1600 solver.cpp:404]     Test net output #1: loss = 1.80948 (* 1 = 1.80948 loss)
I0312 15:31:42.616801  1600 solver.cpp:228] Iteration 18400, loss = 1.24266
I0312 15:31:42.616801  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:31:42.616801  1600 solver.cpp:244]     Train net output #1: loss = 1.24266 (* 1 = 1.24266 loss)
I0312 15:31:42.616801  1600 sgd_solver.cpp:106] Iteration 18400, lr = 0.1
I0312 15:31:51.820828  1600 solver.cpp:228] Iteration 18500, loss = 1.61934
I0312 15:31:51.820828  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:31:51.820828  1600 solver.cpp:244]     Train net output #1: loss = 1.61934 (* 1 = 1.61934 loss)
I0312 15:31:51.820828  1600 sgd_solver.cpp:106] Iteration 18500, lr = 0.1
I0312 15:32:01.029345  1600 solver.cpp:228] Iteration 18600, loss = 1.80213
I0312 15:32:01.029345  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:32:01.029345  1600 solver.cpp:244]     Train net output #1: loss = 1.80213 (* 1 = 1.80213 loss)
I0312 15:32:01.029345  1600 sgd_solver.cpp:106] Iteration 18600, lr = 0.1
I0312 15:32:10.232134  1600 solver.cpp:228] Iteration 18700, loss = 1.62121
I0312 15:32:10.232134  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:32:10.232134  1600 solver.cpp:244]     Train net output #1: loss = 1.62121 (* 1 = 1.62121 loss)
I0312 15:32:10.232134  1600 sgd_solver.cpp:106] Iteration 18700, lr = 0.1
I0312 15:32:19.399648  1600 solver.cpp:228] Iteration 18800, loss = 1.72734
I0312 15:32:19.399648  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:32:19.399648  1600 solver.cpp:244]     Train net output #1: loss = 1.72734 (* 1 = 1.72734 loss)
I0312 15:32:19.399648  1600 sgd_solver.cpp:106] Iteration 18800, lr = 0.1
I0312 15:32:28.350159  1600 solver.cpp:228] Iteration 18900, loss = 1.74812
I0312 15:32:28.350159  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:32:28.350159  1600 solver.cpp:244]     Train net output #1: loss = 1.74812 (* 1 = 1.74812 loss)
I0312 15:32:28.350159  1600 sgd_solver.cpp:106] Iteration 18900, lr = 0.1
I0312 15:32:37.503146  1600 solver.cpp:228] Iteration 19000, loss = 1.4023
I0312 15:32:37.503146  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:32:37.503146  1600 solver.cpp:244]     Train net output #1: loss = 1.4023 (* 1 = 1.4023 loss)
I0312 15:32:37.503146  1600 sgd_solver.cpp:106] Iteration 19000, lr = 0.1
I0312 15:32:46.530761  1600 solver.cpp:228] Iteration 19100, loss = 1.093
I0312 15:32:46.530761  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:32:46.530761  1600 solver.cpp:244]     Train net output #1: loss = 1.093 (* 1 = 1.093 loss)
I0312 15:32:46.530761  1600 sgd_solver.cpp:106] Iteration 19100, lr = 0.1
I0312 15:32:55.733113  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_19200.caffemodel
I0312 15:32:55.761112  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_19200.solverstate
I0312 15:32:55.766613  1600 solver.cpp:337] Iteration 19200, Testing net (#0)
I0312 15:32:55.766613  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:32:59.427867  1600 solver.cpp:404]     Test net output #0: accuracy = 0.51
I0312 15:32:59.427867  1600 solver.cpp:404]     Test net output #1: loss = 1.85023 (* 1 = 1.85023 loss)
I0312 15:32:59.447248  1600 solver.cpp:228] Iteration 19200, loss = 1.55241
I0312 15:32:59.447248  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:32:59.447248  1600 solver.cpp:244]     Train net output #1: loss = 1.55241 (* 1 = 1.55241 loss)
I0312 15:32:59.447248  1600 sgd_solver.cpp:106] Iteration 19200, lr = 0.1
I0312 15:33:08.585309  1600 solver.cpp:228] Iteration 19300, loss = 1.5148
I0312 15:33:08.585808  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:33:08.585808  1600 solver.cpp:244]     Train net output #1: loss = 1.5148 (* 1 = 1.5148 loss)
I0312 15:33:08.585808  1600 sgd_solver.cpp:106] Iteration 19300, lr = 0.1
I0312 15:33:17.688611  1600 solver.cpp:228] Iteration 19400, loss = 1.55308
I0312 15:33:17.688611  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:33:17.688611  1600 solver.cpp:244]     Train net output #1: loss = 1.55308 (* 1 = 1.55308 loss)
I0312 15:33:17.688611  1600 sgd_solver.cpp:106] Iteration 19400, lr = 0.1
I0312 15:33:26.793864  1600 solver.cpp:228] Iteration 19500, loss = 1.44344
I0312 15:33:26.793864  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:33:26.793864  1600 solver.cpp:244]     Train net output #1: loss = 1.44344 (* 1 = 1.44344 loss)
I0312 15:33:26.793864  1600 sgd_solver.cpp:106] Iteration 19500, lr = 0.1
I0312 15:33:35.733856  1600 solver.cpp:228] Iteration 19600, loss = 1.53539
I0312 15:33:35.733856  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:33:35.733856  1600 solver.cpp:244]     Train net output #1: loss = 1.53539 (* 1 = 1.53539 loss)
I0312 15:33:35.733856  1600 sgd_solver.cpp:106] Iteration 19600, lr = 0.1
I0312 15:33:44.819622  1600 solver.cpp:228] Iteration 19700, loss = 1.47081
I0312 15:33:44.820121  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:33:44.820121  1600 solver.cpp:244]     Train net output #1: loss = 1.47081 (* 1 = 1.47081 loss)
I0312 15:33:44.820121  1600 sgd_solver.cpp:106] Iteration 19700, lr = 0.1
I0312 15:33:53.836802  1600 solver.cpp:228] Iteration 19800, loss = 1.32732
I0312 15:33:53.836802  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:33:53.836802  1600 solver.cpp:244]     Train net output #1: loss = 1.32732 (* 1 = 1.32732 loss)
I0312 15:33:53.836802  1600 sgd_solver.cpp:106] Iteration 19800, lr = 0.1
I0312 15:34:02.774888  1600 solver.cpp:228] Iteration 19900, loss = 1.63053
I0312 15:34:02.774888  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:34:02.774888  1600 solver.cpp:244]     Train net output #1: loss = 1.63053 (* 1 = 1.63053 loss)
I0312 15:34:02.774888  1600 sgd_solver.cpp:106] Iteration 19900, lr = 0.1
I0312 15:34:11.743410  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_20000.caffemodel
I0312 15:34:11.771411  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_20000.solverstate
I0312 15:34:11.776410  1600 solver.cpp:337] Iteration 20000, Testing net (#0)
I0312 15:34:11.776410  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:34:15.447036  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5029
I0312 15:34:15.447520  1600 solver.cpp:404]     Test net output #1: loss = 1.88633 (* 1 = 1.88633 loss)
I0312 15:34:15.469519  1600 solver.cpp:228] Iteration 20000, loss = 1.53732
I0312 15:34:15.469519  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:34:15.469519  1600 solver.cpp:244]     Train net output #1: loss = 1.53732 (* 1 = 1.53732 loss)
I0312 15:34:15.469519  1600 sgd_solver.cpp:106] Iteration 20000, lr = 0.1
I0312 15:34:24.602663  1600 solver.cpp:228] Iteration 20100, loss = 1.89145
I0312 15:34:24.602663  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:34:24.602663  1600 solver.cpp:244]     Train net output #1: loss = 1.89145 (* 1 = 1.89145 loss)
I0312 15:34:24.602663  1600 sgd_solver.cpp:106] Iteration 20100, lr = 0.1
I0312 15:34:33.706533  1600 solver.cpp:228] Iteration 20200, loss = 1.56714
I0312 15:34:33.706533  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:34:33.706533  1600 solver.cpp:244]     Train net output #1: loss = 1.56714 (* 1 = 1.56714 loss)
I0312 15:34:33.706533  1600 sgd_solver.cpp:106] Iteration 20200, lr = 0.1
I0312 15:34:42.756188  1600 solver.cpp:228] Iteration 20300, loss = 1.98015
I0312 15:34:42.756188  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.4375
I0312 15:34:42.756188  1600 solver.cpp:244]     Train net output #1: loss = 1.98015 (* 1 = 1.98015 loss)
I0312 15:34:42.756188  1600 sgd_solver.cpp:106] Iteration 20300, lr = 0.1
I0312 15:34:51.789140  1600 solver.cpp:228] Iteration 20400, loss = 1.52587
I0312 15:34:51.789140  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:34:51.789140  1600 solver.cpp:244]     Train net output #1: loss = 1.52587 (* 1 = 1.52587 loss)
I0312 15:34:51.789140  1600 sgd_solver.cpp:106] Iteration 20400, lr = 0.1
I0312 15:35:00.943189  1600 solver.cpp:228] Iteration 20500, loss = 1.57852
I0312 15:35:00.943688  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:35:00.943688  1600 solver.cpp:244]     Train net output #1: loss = 1.57852 (* 1 = 1.57852 loss)
I0312 15:35:00.943688  1600 sgd_solver.cpp:106] Iteration 20500, lr = 0.1
I0312 15:35:09.955958  1600 solver.cpp:228] Iteration 20600, loss = 1.56339
I0312 15:35:09.956457  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:35:09.956457  1600 solver.cpp:244]     Train net output #1: loss = 1.56339 (* 1 = 1.56339 loss)
I0312 15:35:09.956457  1600 sgd_solver.cpp:106] Iteration 20600, lr = 0.1
I0312 15:35:18.888803  1600 solver.cpp:228] Iteration 20700, loss = 1.45952
I0312 15:35:18.888803  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:35:18.888803  1600 solver.cpp:244]     Train net output #1: loss = 1.45952 (* 1 = 1.45952 loss)
I0312 15:35:18.888803  1600 sgd_solver.cpp:106] Iteration 20700, lr = 0.1
I0312 15:35:27.996598  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_20800.caffemodel
I0312 15:35:28.026582  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_20800.solverstate
I0312 15:35:28.036582  1600 solver.cpp:337] Iteration 20800, Testing net (#0)
I0312 15:35:28.036582  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:35:31.764467  1600 solver.cpp:404]     Test net output #0: accuracy = 0.518
I0312 15:35:31.764467  1600 solver.cpp:404]     Test net output #1: loss = 1.8053 (* 1 = 1.8053 loss)
I0312 15:35:31.820955  1600 solver.cpp:228] Iteration 20800, loss = 1.73194
I0312 15:35:31.820955  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:35:31.820955  1600 solver.cpp:244]     Train net output #1: loss = 1.73194 (* 1 = 1.73194 loss)
I0312 15:35:31.820955  1600 sgd_solver.cpp:106] Iteration 20800, lr = 0.1
I0312 15:35:41.008327  1600 solver.cpp:228] Iteration 20900, loss = 1.49517
I0312 15:35:41.008327  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:35:41.008816  1600 solver.cpp:244]     Train net output #1: loss = 1.49517 (* 1 = 1.49517 loss)
I0312 15:35:41.008816  1600 sgd_solver.cpp:106] Iteration 20900, lr = 0.1
I0312 15:35:47.729065  1600 solver.cpp:228] Iteration 21000, loss = 1.35442
I0312 15:35:47.729065  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:35:47.729065  1600 solver.cpp:244]     Train net output #1: loss = 1.35442 (* 1 = 1.35442 loss)
I0312 15:35:47.729065  1600 sgd_solver.cpp:106] Iteration 21000, lr = 0.1
I0312 15:35:53.531689  1600 solver.cpp:228] Iteration 21100, loss = 1.30717
I0312 15:35:53.531689  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:35:53.531689  1600 solver.cpp:244]     Train net output #1: loss = 1.30717 (* 1 = 1.30717 loss)
I0312 15:35:53.531689  1600 sgd_solver.cpp:106] Iteration 21100, lr = 0.1
I0312 15:35:59.377804  1600 solver.cpp:228] Iteration 21200, loss = 1.24818
I0312 15:35:59.377804  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:35:59.377804  1600 solver.cpp:244]     Train net output #1: loss = 1.24818 (* 1 = 1.24818 loss)
I0312 15:35:59.377804  1600 sgd_solver.cpp:106] Iteration 21200, lr = 0.1
I0312 15:36:07.689582  1600 solver.cpp:228] Iteration 21300, loss = 0.92851
I0312 15:36:07.689582  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:36:07.689582  1600 solver.cpp:244]     Train net output #1: loss = 0.92851 (* 1 = 0.92851 loss)
I0312 15:36:07.689582  1600 sgd_solver.cpp:106] Iteration 21300, lr = 0.1
I0312 15:36:16.906971  1600 solver.cpp:228] Iteration 21400, loss = 1.27877
I0312 15:36:16.906971  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:36:16.906971  1600 solver.cpp:244]     Train net output #1: loss = 1.27877 (* 1 = 1.27877 loss)
I0312 15:36:16.906971  1600 sgd_solver.cpp:106] Iteration 21400, lr = 0.1
I0312 15:36:25.998214  1600 solver.cpp:228] Iteration 21500, loss = 1.46856
I0312 15:36:25.998214  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:36:25.998214  1600 solver.cpp:244]     Train net output #1: loss = 1.46856 (* 1 = 1.46856 loss)
I0312 15:36:25.998214  1600 sgd_solver.cpp:106] Iteration 21500, lr = 0.1
I0312 15:36:35.093281  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_21600.caffemodel
I0312 15:36:35.109781  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_21600.solverstate
I0312 15:36:35.114780  1600 solver.cpp:337] Iteration 21600, Testing net (#0)
I0312 15:36:35.114780  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:36:38.782146  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5313
I0312 15:36:38.782146  1600 solver.cpp:404]     Test net output #1: loss = 1.75191 (* 1 = 1.75191 loss)
I0312 15:36:38.799131  1600 solver.cpp:228] Iteration 21600, loss = 1.30559
I0312 15:36:38.799131  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:36:38.799131  1600 solver.cpp:244]     Train net output #1: loss = 1.30559 (* 1 = 1.30559 loss)
I0312 15:36:38.799131  1600 sgd_solver.cpp:106] Iteration 21600, lr = 0.1
I0312 15:36:48.006085  1600 solver.cpp:228] Iteration 21700, loss = 1.28731
I0312 15:36:48.006085  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:36:48.006085  1600 solver.cpp:244]     Train net output #1: loss = 1.28731 (* 1 = 1.28731 loss)
I0312 15:36:48.006085  1600 sgd_solver.cpp:106] Iteration 21700, lr = 0.1
I0312 15:36:56.994280  1600 solver.cpp:228] Iteration 21800, loss = 1.59063
I0312 15:36:56.994280  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:36:56.994280  1600 solver.cpp:244]     Train net output #1: loss = 1.59063 (* 1 = 1.59063 loss)
I0312 15:36:56.994280  1600 sgd_solver.cpp:106] Iteration 21800, lr = 0.1
I0312 15:37:06.071754  1600 solver.cpp:228] Iteration 21900, loss = 1.52049
I0312 15:37:06.071754  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:37:06.071754  1600 solver.cpp:244]     Train net output #1: loss = 1.52049 (* 1 = 1.52049 loss)
I0312 15:37:06.071754  1600 sgd_solver.cpp:106] Iteration 21900, lr = 0.1
I0312 15:37:15.064266  1600 solver.cpp:228] Iteration 22000, loss = 1.12678
I0312 15:37:15.064266  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:37:15.064266  1600 solver.cpp:244]     Train net output #1: loss = 1.12678 (* 1 = 1.12678 loss)
I0312 15:37:15.064266  1600 sgd_solver.cpp:106] Iteration 22000, lr = 0.1
I0312 15:37:24.235652  1600 solver.cpp:228] Iteration 22100, loss = 1.27767
I0312 15:37:24.235652  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:37:24.235652  1600 solver.cpp:244]     Train net output #1: loss = 1.27767 (* 1 = 1.27767 loss)
I0312 15:37:24.235652  1600 sgd_solver.cpp:106] Iteration 22100, lr = 0.1
I0312 15:37:33.235251  1600 solver.cpp:228] Iteration 22200, loss = 1.25009
I0312 15:37:33.235251  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:37:33.235251  1600 solver.cpp:244]     Train net output #1: loss = 1.25009 (* 1 = 1.25009 loss)
I0312 15:37:33.235251  1600 sgd_solver.cpp:106] Iteration 22200, lr = 0.1
I0312 15:37:42.382414  1600 solver.cpp:228] Iteration 22300, loss = 1.50925
I0312 15:37:42.382915  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:37:42.382915  1600 solver.cpp:244]     Train net output #1: loss = 1.50925 (* 1 = 1.50925 loss)
I0312 15:37:42.382915  1600 sgd_solver.cpp:106] Iteration 22300, lr = 0.1
I0312 15:37:51.267179  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_22400.caffemodel
I0312 15:37:51.282680  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_22400.solverstate
I0312 15:37:51.287679  1600 solver.cpp:337] Iteration 22400, Testing net (#0)
I0312 15:37:51.288188  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:37:54.961859  1600 solver.cpp:404]     Test net output #0: accuracy = 0.527
I0312 15:37:54.961859  1600 solver.cpp:404]     Test net output #1: loss = 1.77584 (* 1 = 1.77584 loss)
I0312 15:37:54.981844  1600 solver.cpp:228] Iteration 22400, loss = 1.60965
I0312 15:37:54.981844  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:37:54.981844  1600 solver.cpp:244]     Train net output #1: loss = 1.60965 (* 1 = 1.60965 loss)
I0312 15:37:54.981844  1600 sgd_solver.cpp:106] Iteration 22400, lr = 0.1
I0312 15:38:04.016614  1600 solver.cpp:228] Iteration 22500, loss = 1.68969
I0312 15:38:04.016614  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:38:04.016614  1600 solver.cpp:244]     Train net output #1: loss = 1.68969 (* 1 = 1.68969 loss)
I0312 15:38:04.016614  1600 sgd_solver.cpp:106] Iteration 22500, lr = 0.1
I0312 15:38:13.129931  1600 solver.cpp:228] Iteration 22600, loss = 1.78083
I0312 15:38:13.129931  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:38:13.129931  1600 solver.cpp:244]     Train net output #1: loss = 1.78083 (* 1 = 1.78083 loss)
I0312 15:38:13.129931  1600 sgd_solver.cpp:106] Iteration 22600, lr = 0.1
I0312 15:38:22.108959  1600 solver.cpp:228] Iteration 22700, loss = 1.65035
I0312 15:38:22.108959  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:38:22.108959  1600 solver.cpp:244]     Train net output #1: loss = 1.65035 (* 1 = 1.65035 loss)
I0312 15:38:22.108959  1600 sgd_solver.cpp:106] Iteration 22700, lr = 0.1
I0312 15:38:31.255568  1600 solver.cpp:228] Iteration 22800, loss = 1.35253
I0312 15:38:31.255568  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:38:31.255568  1600 solver.cpp:244]     Train net output #1: loss = 1.35253 (* 1 = 1.35253 loss)
I0312 15:38:31.255568  1600 sgd_solver.cpp:106] Iteration 22800, lr = 0.1
I0312 15:38:40.356377  1600 solver.cpp:228] Iteration 22900, loss = 1.22856
I0312 15:38:40.356377  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:38:40.356377  1600 solver.cpp:244]     Train net output #1: loss = 1.22856 (* 1 = 1.22856 loss)
I0312 15:38:40.356377  1600 sgd_solver.cpp:106] Iteration 22900, lr = 0.1
I0312 15:38:49.427012  1600 solver.cpp:228] Iteration 23000, loss = 1.73762
I0312 15:38:49.427012  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:38:49.427012  1600 solver.cpp:244]     Train net output #1: loss = 1.73762 (* 1 = 1.73762 loss)
I0312 15:38:49.427012  1600 sgd_solver.cpp:106] Iteration 23000, lr = 0.1
I0312 15:38:58.571108  1600 solver.cpp:228] Iteration 23100, loss = 1.17492
I0312 15:38:58.571108  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:38:58.571108  1600 solver.cpp:244]     Train net output #1: loss = 1.17492 (* 1 = 1.17492 loss)
I0312 15:38:58.571108  1600 sgd_solver.cpp:106] Iteration 23100, lr = 0.1
I0312 15:39:07.466969  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_23200.caffemodel
I0312 15:39:07.488469  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_23200.solverstate
I0312 15:39:07.493969  1600 solver.cpp:337] Iteration 23200, Testing net (#0)
I0312 15:39:07.493969  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:39:11.266770  1600 solver.cpp:404]     Test net output #0: accuracy = 0.4963
I0312 15:39:11.266770  1600 solver.cpp:404]     Test net output #1: loss = 1.94572 (* 1 = 1.94572 loss)
I0312 15:39:11.288260  1600 solver.cpp:228] Iteration 23200, loss = 1.34381
I0312 15:39:11.288260  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:39:11.288260  1600 solver.cpp:244]     Train net output #1: loss = 1.34381 (* 1 = 1.34381 loss)
I0312 15:39:11.288260  1600 sgd_solver.cpp:106] Iteration 23200, lr = 0.1
I0312 15:39:20.437763  1600 solver.cpp:228] Iteration 23300, loss = 1.26275
I0312 15:39:20.437763  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:39:20.437763  1600 solver.cpp:244]     Train net output #1: loss = 1.26275 (* 1 = 1.26275 loss)
I0312 15:39:20.437763  1600 sgd_solver.cpp:106] Iteration 23300, lr = 0.1
I0312 15:39:29.585993  1600 solver.cpp:228] Iteration 23400, loss = 1.16765
I0312 15:39:29.585993  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:39:29.585993  1600 solver.cpp:244]     Train net output #1: loss = 1.16765 (* 1 = 1.16765 loss)
I0312 15:39:29.585993  1600 sgd_solver.cpp:106] Iteration 23400, lr = 0.1
I0312 15:39:38.852444  1600 solver.cpp:228] Iteration 23500, loss = 1.25268
I0312 15:39:38.852444  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:39:38.852444  1600 solver.cpp:244]     Train net output #1: loss = 1.25268 (* 1 = 1.25268 loss)
I0312 15:39:38.852444  1600 sgd_solver.cpp:106] Iteration 23500, lr = 0.1
I0312 15:39:47.927464  1600 solver.cpp:228] Iteration 23600, loss = 1.54148
I0312 15:39:47.927464  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:39:47.927464  1600 solver.cpp:244]     Train net output #1: loss = 1.54148 (* 1 = 1.54148 loss)
I0312 15:39:47.927464  1600 sgd_solver.cpp:106] Iteration 23600, lr = 0.1
I0312 15:39:57.042701  1600 solver.cpp:228] Iteration 23700, loss = 1.16924
I0312 15:39:57.042701  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:39:57.042701  1600 solver.cpp:244]     Train net output #1: loss = 1.16924 (* 1 = 1.16924 loss)
I0312 15:39:57.042701  1600 sgd_solver.cpp:106] Iteration 23700, lr = 0.1
I0312 15:40:05.935150  1600 solver.cpp:228] Iteration 23800, loss = 1.5134
I0312 15:40:05.935150  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:40:05.935150  1600 solver.cpp:244]     Train net output #1: loss = 1.5134 (* 1 = 1.5134 loss)
I0312 15:40:05.935150  1600 sgd_solver.cpp:106] Iteration 23800, lr = 0.1
I0312 15:40:15.008321  1600 solver.cpp:228] Iteration 23900, loss = 1.39052
I0312 15:40:15.008321  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:40:15.008821  1600 solver.cpp:244]     Train net output #1: loss = 1.39052 (* 1 = 1.39052 loss)
I0312 15:40:15.008821  1600 sgd_solver.cpp:106] Iteration 23900, lr = 0.1
I0312 15:40:23.924422  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_24000.caffemodel
I0312 15:40:23.942422  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_24000.solverstate
I0312 15:40:23.947422  1600 solver.cpp:337] Iteration 24000, Testing net (#0)
I0312 15:40:23.947926  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:40:27.577025  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5065
I0312 15:40:27.577025  1600 solver.cpp:404]     Test net output #1: loss = 1.8756 (* 1 = 1.8756 loss)
I0312 15:40:27.610525  1600 solver.cpp:228] Iteration 24000, loss = 1.32315
I0312 15:40:27.610525  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:40:27.610525  1600 solver.cpp:244]     Train net output #1: loss = 1.32315 (* 1 = 1.32315 loss)
I0312 15:40:27.610525  1600 sgd_solver.cpp:106] Iteration 24000, lr = 0.1
I0312 15:40:36.566838  1600 solver.cpp:228] Iteration 24100, loss = 1.56754
I0312 15:40:36.566838  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:40:36.566838  1600 solver.cpp:244]     Train net output #1: loss = 1.56754 (* 1 = 1.56754 loss)
I0312 15:40:36.566838  1600 sgd_solver.cpp:106] Iteration 24100, lr = 0.1
I0312 15:40:45.645009  1600 solver.cpp:228] Iteration 24200, loss = 1.33362
I0312 15:40:45.645009  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:40:45.645009  1600 solver.cpp:244]     Train net output #1: loss = 1.33362 (* 1 = 1.33362 loss)
I0312 15:40:45.645009  1600 sgd_solver.cpp:106] Iteration 24200, lr = 0.1
I0312 15:40:52.486244  1600 solver.cpp:228] Iteration 24300, loss = 1.21814
I0312 15:40:52.486745  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:40:52.486745  1600 solver.cpp:244]     Train net output #1: loss = 1.21814 (* 1 = 1.21814 loss)
I0312 15:40:52.486745  1600 sgd_solver.cpp:106] Iteration 24300, lr = 0.1
I0312 15:40:58.303709  1600 solver.cpp:228] Iteration 24400, loss = 1.02295
I0312 15:40:58.303709  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:40:58.303709  1600 solver.cpp:244]     Train net output #1: loss = 1.02295 (* 1 = 1.02295 loss)
I0312 15:40:58.303709  1600 sgd_solver.cpp:106] Iteration 24400, lr = 0.1
I0312 15:41:04.090153  1600 solver.cpp:228] Iteration 24500, loss = 1.57281
I0312 15:41:04.090153  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:41:04.090153  1600 solver.cpp:244]     Train net output #1: loss = 1.57281 (* 1 = 1.57281 loss)
I0312 15:41:04.090153  1600 sgd_solver.cpp:106] Iteration 24500, lr = 0.1
I0312 15:41:12.229988  1600 solver.cpp:228] Iteration 24600, loss = 1.19391
I0312 15:41:12.229988  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:41:12.229988  1600 solver.cpp:244]     Train net output #1: loss = 1.19391 (* 1 = 1.19391 loss)
I0312 15:41:12.229988  1600 sgd_solver.cpp:106] Iteration 24600, lr = 0.1
I0312 15:41:21.337357  1600 solver.cpp:228] Iteration 24700, loss = 1.46839
I0312 15:41:21.337357  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:41:21.337357  1600 solver.cpp:244]     Train net output #1: loss = 1.46839 (* 1 = 1.46839 loss)
I0312 15:41:21.337357  1600 sgd_solver.cpp:106] Iteration 24700, lr = 0.1
I0312 15:41:30.461397  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_24800.caffemodel
I0312 15:41:30.476898  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_24800.solverstate
I0312 15:41:30.481398  1600 solver.cpp:337] Iteration 24800, Testing net (#0)
I0312 15:41:30.481398  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:41:34.202323  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5018
I0312 15:41:34.202323  1600 solver.cpp:404]     Test net output #1: loss = 1.89244 (* 1 = 1.89244 loss)
I0312 15:41:34.232331  1600 solver.cpp:228] Iteration 24800, loss = 1.68539
I0312 15:41:34.232331  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:41:34.232331  1600 solver.cpp:244]     Train net output #1: loss = 1.68539 (* 1 = 1.68539 loss)
I0312 15:41:34.232331  1600 sgd_solver.cpp:106] Iteration 24800, lr = 0.1
I0312 15:41:43.260891  1600 solver.cpp:228] Iteration 24900, loss = 1.27163
I0312 15:41:43.260891  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:41:43.260891  1600 solver.cpp:244]     Train net output #1: loss = 1.27163 (* 1 = 1.27163 loss)
I0312 15:41:43.260891  1600 sgd_solver.cpp:106] Iteration 24900, lr = 0.1
I0312 15:41:52.303094  1600 solver.cpp:228] Iteration 25000, loss = 1.51759
I0312 15:41:52.303094  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:41:52.303094  1600 solver.cpp:244]     Train net output #1: loss = 1.51759 (* 1 = 1.51759 loss)
I0312 15:41:52.303094  1600 sgd_solver.cpp:106] Iteration 25000, lr = 0.1
I0312 15:42:01.361845  1600 solver.cpp:228] Iteration 25100, loss = 1.52535
I0312 15:42:01.361845  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:42:01.361845  1600 solver.cpp:244]     Train net output #1: loss = 1.52535 (* 1 = 1.52535 loss)
I0312 15:42:01.361845  1600 sgd_solver.cpp:106] Iteration 25100, lr = 0.1
I0312 15:42:10.425717  1600 solver.cpp:228] Iteration 25200, loss = 0.844452
I0312 15:42:10.425717  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 15:42:10.425717  1600 solver.cpp:244]     Train net output #1: loss = 0.844452 (* 1 = 0.844452 loss)
I0312 15:42:10.425717  1600 sgd_solver.cpp:106] Iteration 25200, lr = 0.1
I0312 15:42:19.455652  1600 solver.cpp:228] Iteration 25300, loss = 1.18197
I0312 15:42:19.455652  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:42:19.455652  1600 solver.cpp:244]     Train net output #1: loss = 1.18197 (* 1 = 1.18197 loss)
I0312 15:42:19.455652  1600 sgd_solver.cpp:106] Iteration 25300, lr = 0.1
I0312 15:42:28.394743  1600 solver.cpp:228] Iteration 25400, loss = 1.22698
I0312 15:42:28.394743  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:42:28.394743  1600 solver.cpp:244]     Train net output #1: loss = 1.22698 (* 1 = 1.22698 loss)
I0312 15:42:28.394743  1600 sgd_solver.cpp:106] Iteration 25400, lr = 0.1
I0312 15:42:37.346365  1600 solver.cpp:228] Iteration 25500, loss = 1.52948
I0312 15:42:37.346365  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:42:37.346865  1600 solver.cpp:244]     Train net output #1: loss = 1.52948 (* 1 = 1.52948 loss)
I0312 15:42:37.346865  1600 sgd_solver.cpp:106] Iteration 25500, lr = 0.1
I0312 15:42:46.462231  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_25600.caffemodel
I0312 15:42:46.480731  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_25600.solverstate
I0312 15:42:46.485239  1600 solver.cpp:337] Iteration 25600, Testing net (#0)
I0312 15:42:46.485239  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:42:50.208770  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5218
I0312 15:42:50.208770  1600 solver.cpp:404]     Test net output #1: loss = 1.85832 (* 1 = 1.85832 loss)
I0312 15:42:50.253269  1600 solver.cpp:228] Iteration 25600, loss = 1.15564
I0312 15:42:50.253269  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:42:50.253269  1600 solver.cpp:244]     Train net output #1: loss = 1.15564 (* 1 = 1.15564 loss)
I0312 15:42:50.253269  1600 sgd_solver.cpp:106] Iteration 25600, lr = 0.1
I0312 15:42:59.199411  1600 solver.cpp:228] Iteration 25700, loss = 1.27014
I0312 15:42:59.199411  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:42:59.199911  1600 solver.cpp:244]     Train net output #1: loss = 1.27014 (* 1 = 1.27014 loss)
I0312 15:42:59.199911  1600 sgd_solver.cpp:106] Iteration 25700, lr = 0.1
I0312 15:43:08.370833  1600 solver.cpp:228] Iteration 25800, loss = 1.34277
I0312 15:43:08.371333  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:43:08.371333  1600 solver.cpp:244]     Train net output #1: loss = 1.34277 (* 1 = 1.34277 loss)
I0312 15:43:08.371333  1600 sgd_solver.cpp:106] Iteration 25800, lr = 0.1
I0312 15:43:17.533442  1600 solver.cpp:228] Iteration 25900, loss = 1.61657
I0312 15:43:17.533442  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:43:17.533442  1600 solver.cpp:244]     Train net output #1: loss = 1.61657 (* 1 = 1.61657 loss)
I0312 15:43:17.533442  1600 sgd_solver.cpp:106] Iteration 25900, lr = 0.1
I0312 15:43:26.396793  1600 solver.cpp:228] Iteration 26000, loss = 1.3044
I0312 15:43:26.396793  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:43:26.396793  1600 solver.cpp:244]     Train net output #1: loss = 1.3044 (* 1 = 1.3044 loss)
I0312 15:43:26.396793  1600 sgd_solver.cpp:106] Iteration 26000, lr = 0.1
I0312 15:43:35.604018  1600 solver.cpp:228] Iteration 26100, loss = 1.33556
I0312 15:43:35.604018  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:43:35.604018  1600 solver.cpp:244]     Train net output #1: loss = 1.33556 (* 1 = 1.33556 loss)
I0312 15:43:35.604018  1600 sgd_solver.cpp:106] Iteration 26100, lr = 0.1
I0312 15:43:44.673223  1600 solver.cpp:228] Iteration 26200, loss = 1.30693
I0312 15:43:44.673223  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:43:44.673223  1600 solver.cpp:244]     Train net output #1: loss = 1.30693 (* 1 = 1.30693 loss)
I0312 15:43:44.673223  1600 sgd_solver.cpp:106] Iteration 26200, lr = 0.1
I0312 15:43:53.872539  1600 solver.cpp:228] Iteration 26300, loss = 1.07816
I0312 15:43:53.872539  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 15:43:53.872539  1600 solver.cpp:244]     Train net output #1: loss = 1.07816 (* 1 = 1.07816 loss)
I0312 15:43:53.872539  1600 sgd_solver.cpp:106] Iteration 26300, lr = 0.1
I0312 15:44:03.043118  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_26400.caffemodel
I0312 15:44:03.058117  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_26400.solverstate
I0312 15:44:03.063117  1600 solver.cpp:337] Iteration 26400, Testing net (#0)
I0312 15:44:03.063117  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:44:06.773244  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5087
I0312 15:44:06.773244  1600 solver.cpp:404]     Test net output #1: loss = 1.91592 (* 1 = 1.91592 loss)
I0312 15:44:06.793251  1600 solver.cpp:228] Iteration 26400, loss = 1.24069
I0312 15:44:06.793251  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:44:06.793251  1600 solver.cpp:244]     Train net output #1: loss = 1.24069 (* 1 = 1.24069 loss)
I0312 15:44:06.793251  1600 sgd_solver.cpp:106] Iteration 26400, lr = 0.1
I0312 15:44:15.809993  1600 solver.cpp:228] Iteration 26500, loss = 1.15467
I0312 15:44:15.809993  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:44:15.809993  1600 solver.cpp:244]     Train net output #1: loss = 1.15467 (* 1 = 1.15467 loss)
I0312 15:44:15.809993  1600 sgd_solver.cpp:106] Iteration 26500, lr = 0.1
I0312 15:44:25.142406  1600 solver.cpp:228] Iteration 26600, loss = 1.79251
I0312 15:44:25.142406  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:44:25.142406  1600 solver.cpp:244]     Train net output #1: loss = 1.79251 (* 1 = 1.79251 loss)
I0312 15:44:25.142906  1600 sgd_solver.cpp:106] Iteration 26600, lr = 0.1
I0312 15:44:34.313206  1600 solver.cpp:228] Iteration 26700, loss = 1.5776
I0312 15:44:34.313709  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.484375
I0312 15:44:34.313709  1600 solver.cpp:244]     Train net output #1: loss = 1.5776 (* 1 = 1.5776 loss)
I0312 15:44:34.313709  1600 sgd_solver.cpp:106] Iteration 26700, lr = 0.1
I0312 15:44:43.260222  1600 solver.cpp:228] Iteration 26800, loss = 1.21532
I0312 15:44:43.260222  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:44:43.260222  1600 solver.cpp:244]     Train net output #1: loss = 1.21532 (* 1 = 1.21532 loss)
I0312 15:44:43.260222  1600 sgd_solver.cpp:106] Iteration 26800, lr = 0.1
I0312 15:44:52.106307  1600 solver.cpp:228] Iteration 26900, loss = 1.33921
I0312 15:44:52.106307  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:44:52.106307  1600 solver.cpp:244]     Train net output #1: loss = 1.33921 (* 1 = 1.33921 loss)
I0312 15:44:52.106307  1600 sgd_solver.cpp:106] Iteration 26900, lr = 0.1
I0312 15:45:01.242288  1600 solver.cpp:228] Iteration 27000, loss = 1.33998
I0312 15:45:01.242288  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 15:45:01.242288  1600 solver.cpp:244]     Train net output #1: loss = 1.33998 (* 1 = 1.33998 loss)
I0312 15:45:01.242288  1600 sgd_solver.cpp:106] Iteration 27000, lr = 0.1
I0312 15:45:10.468530  1600 solver.cpp:228] Iteration 27100, loss = 1.29467
I0312 15:45:10.468530  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:45:10.468530  1600 solver.cpp:244]     Train net output #1: loss = 1.29467 (* 1 = 1.29467 loss)
I0312 15:45:10.468530  1600 sgd_solver.cpp:106] Iteration 27100, lr = 0.1
I0312 15:45:19.431509  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_27200.caffemodel
I0312 15:45:19.463009  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_27200.solverstate
I0312 15:45:19.467010  1600 solver.cpp:337] Iteration 27200, Testing net (#0)
I0312 15:45:19.467010  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:45:23.240985  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5223
I0312 15:45:23.240985  1600 solver.cpp:404]     Test net output #1: loss = 1.82957 (* 1 = 1.82957 loss)
I0312 15:45:23.260985  1600 solver.cpp:228] Iteration 27200, loss = 1.24508
I0312 15:45:23.260985  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:45:23.260985  1600 solver.cpp:244]     Train net output #1: loss = 1.24508 (* 1 = 1.24508 loss)
I0312 15:45:23.260985  1600 sgd_solver.cpp:106] Iteration 27200, lr = 0.1
I0312 15:45:32.413619  1600 solver.cpp:228] Iteration 27300, loss = 1.18111
I0312 15:45:32.413619  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:45:32.414119  1600 solver.cpp:244]     Train net output #1: loss = 1.18111 (* 1 = 1.18111 loss)
I0312 15:45:32.414119  1600 sgd_solver.cpp:106] Iteration 27300, lr = 0.1
I0312 15:45:41.531419  1600 solver.cpp:228] Iteration 27400, loss = 1.36975
I0312 15:45:41.531419  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:45:41.531419  1600 solver.cpp:244]     Train net output #1: loss = 1.36975 (* 1 = 1.36975 loss)
I0312 15:45:41.531419  1600 sgd_solver.cpp:106] Iteration 27400, lr = 0.1
I0312 15:45:50.643776  1600 solver.cpp:228] Iteration 27500, loss = 1.11449
I0312 15:45:50.643776  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 15:45:50.643776  1600 solver.cpp:244]     Train net output #1: loss = 1.11449 (* 1 = 1.11449 loss)
I0312 15:45:50.643776  1600 sgd_solver.cpp:106] Iteration 27500, lr = 0.1
I0312 15:45:57.485179  1600 solver.cpp:228] Iteration 27600, loss = 1.19491
I0312 15:45:57.485179  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:45:57.485179  1600 solver.cpp:244]     Train net output #1: loss = 1.19491 (* 1 = 1.19491 loss)
I0312 15:45:57.485179  1600 sgd_solver.cpp:106] Iteration 27600, lr = 0.1
I0312 15:46:03.295930  1600 solver.cpp:228] Iteration 27700, loss = 1.29611
I0312 15:46:03.295930  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:46:03.295930  1600 solver.cpp:244]     Train net output #1: loss = 1.29611 (* 1 = 1.29611 loss)
I0312 15:46:03.295930  1600 sgd_solver.cpp:106] Iteration 27700, lr = 0.1
I0312 15:46:09.087678  1600 solver.cpp:228] Iteration 27800, loss = 1.27128
I0312 15:46:09.087678  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:46:09.087678  1600 solver.cpp:244]     Train net output #1: loss = 1.27128 (* 1 = 1.27128 loss)
I0312 15:46:09.087678  1600 sgd_solver.cpp:106] Iteration 27800, lr = 0.1
I0312 15:46:17.172771  1600 solver.cpp:228] Iteration 27900, loss = 1.28288
I0312 15:46:17.172771  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:46:17.172771  1600 solver.cpp:244]     Train net output #1: loss = 1.28288 (* 1 = 1.28288 loss)
I0312 15:46:17.172771  1600 sgd_solver.cpp:106] Iteration 27900, lr = 0.1
I0312 15:46:26.245694  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_28000.caffemodel
I0312 15:46:26.274195  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_28000.solverstate
I0312 15:46:26.279196  1600 solver.cpp:337] Iteration 28000, Testing net (#0)
I0312 15:46:26.279196  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:46:29.974365  1600 solver.cpp:404]     Test net output #0: accuracy = 0.534
I0312 15:46:29.974365  1600 solver.cpp:404]     Test net output #1: loss = 1.76652 (* 1 = 1.76652 loss)
I0312 15:46:29.997365  1600 solver.cpp:228] Iteration 28000, loss = 1.11947
I0312 15:46:29.997365  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 15:46:29.997365  1600 solver.cpp:244]     Train net output #1: loss = 1.11947 (* 1 = 1.11947 loss)
I0312 15:46:29.997365  1600 sgd_solver.cpp:106] Iteration 28000, lr = 0.1
I0312 15:46:39.076309  1600 solver.cpp:228] Iteration 28100, loss = 1.10405
I0312 15:46:39.076309  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:46:39.076309  1600 solver.cpp:244]     Train net output #1: loss = 1.10405 (* 1 = 1.10405 loss)
I0312 15:46:39.076309  1600 sgd_solver.cpp:106] Iteration 28100, lr = 0.1
I0312 15:46:48.234113  1600 solver.cpp:228] Iteration 28200, loss = 1.55498
I0312 15:46:48.234113  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:46:48.234113  1600 solver.cpp:244]     Train net output #1: loss = 1.55498 (* 1 = 1.55498 loss)
I0312 15:46:48.234113  1600 sgd_solver.cpp:106] Iteration 28200, lr = 0.1
I0312 15:46:57.487318  1600 solver.cpp:228] Iteration 28300, loss = 1.36247
I0312 15:46:57.487318  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:46:57.487318  1600 solver.cpp:244]     Train net output #1: loss = 1.36247 (* 1 = 1.36247 loss)
I0312 15:46:57.487318  1600 sgd_solver.cpp:106] Iteration 28300, lr = 0.1
I0312 15:47:06.520948  1600 solver.cpp:228] Iteration 28400, loss = 1.03433
I0312 15:47:06.520948  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:47:06.520948  1600 solver.cpp:244]     Train net output #1: loss = 1.03433 (* 1 = 1.03433 loss)
I0312 15:47:06.520948  1600 sgd_solver.cpp:106] Iteration 28400, lr = 0.1
I0312 15:47:15.477969  1600 solver.cpp:228] Iteration 28500, loss = 1.28183
I0312 15:47:15.477969  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:47:15.477969  1600 solver.cpp:244]     Train net output #1: loss = 1.28183 (* 1 = 1.28183 loss)
I0312 15:47:15.477969  1600 sgd_solver.cpp:106] Iteration 28500, lr = 0.1
I0312 15:47:24.711722  1600 solver.cpp:228] Iteration 28600, loss = 1.29291
I0312 15:47:24.711722  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:47:24.711722  1600 solver.cpp:244]     Train net output #1: loss = 1.29291 (* 1 = 1.29291 loss)
I0312 15:47:24.711722  1600 sgd_solver.cpp:106] Iteration 28600, lr = 0.1
I0312 15:47:33.836278  1600 solver.cpp:228] Iteration 28700, loss = 1.41241
I0312 15:47:33.836278  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:47:33.836278  1600 solver.cpp:244]     Train net output #1: loss = 1.41241 (* 1 = 1.41241 loss)
I0312 15:47:33.836278  1600 sgd_solver.cpp:106] Iteration 28700, lr = 0.1
I0312 15:47:42.876575  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_28800.caffemodel
I0312 15:47:42.899075  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_28800.solverstate
I0312 15:47:42.904074  1600 solver.cpp:337] Iteration 28800, Testing net (#0)
I0312 15:47:42.904074  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:47:46.588063  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5473
I0312 15:47:46.588063  1600 solver.cpp:404]     Test net output #1: loss = 1.71194 (* 1 = 1.71194 loss)
I0312 15:47:46.608080  1600 solver.cpp:228] Iteration 28800, loss = 1.79582
I0312 15:47:46.608080  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.46875
I0312 15:47:46.608080  1600 solver.cpp:244]     Train net output #1: loss = 1.79582 (* 1 = 1.79582 loss)
I0312 15:47:46.608080  1600 sgd_solver.cpp:106] Iteration 28800, lr = 0.1
I0312 15:47:55.625147  1600 solver.cpp:228] Iteration 28900, loss = 1.28745
I0312 15:47:55.625147  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:47:55.625147  1600 solver.cpp:244]     Train net output #1: loss = 1.28745 (* 1 = 1.28745 loss)
I0312 15:47:55.625147  1600 sgd_solver.cpp:106] Iteration 28900, lr = 0.1
I0312 15:48:04.713274  1600 solver.cpp:228] Iteration 29000, loss = 1.84265
I0312 15:48:04.713274  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:48:04.713274  1600 solver.cpp:244]     Train net output #1: loss = 1.84265 (* 1 = 1.84265 loss)
I0312 15:48:04.713274  1600 sgd_solver.cpp:106] Iteration 29000, lr = 0.1
I0312 15:48:13.825764  1600 solver.cpp:228] Iteration 29100, loss = 1.90736
I0312 15:48:13.825764  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.453125
I0312 15:48:13.825764  1600 solver.cpp:244]     Train net output #1: loss = 1.90736 (* 1 = 1.90736 loss)
I0312 15:48:13.825764  1600 sgd_solver.cpp:106] Iteration 29100, lr = 0.1
I0312 15:48:22.848552  1600 solver.cpp:228] Iteration 29200, loss = 1.329
I0312 15:48:22.849052  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:48:22.849052  1600 solver.cpp:244]     Train net output #1: loss = 1.329 (* 1 = 1.329 loss)
I0312 15:48:22.849052  1600 sgd_solver.cpp:106] Iteration 29200, lr = 0.1
I0312 15:48:31.957754  1600 solver.cpp:228] Iteration 29300, loss = 1.16178
I0312 15:48:31.957754  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 15:48:31.957754  1600 solver.cpp:244]     Train net output #1: loss = 1.16178 (* 1 = 1.16178 loss)
I0312 15:48:31.957754  1600 sgd_solver.cpp:106] Iteration 29300, lr = 0.1
I0312 15:48:41.029876  1600 solver.cpp:228] Iteration 29400, loss = 1.19325
I0312 15:48:41.029876  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:48:41.029876  1600 solver.cpp:244]     Train net output #1: loss = 1.19325 (* 1 = 1.19325 loss)
I0312 15:48:41.029876  1600 sgd_solver.cpp:106] Iteration 29400, lr = 0.1
I0312 15:48:49.979890  1600 solver.cpp:228] Iteration 29500, loss = 1.29928
I0312 15:48:49.979890  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:48:49.979890  1600 solver.cpp:244]     Train net output #1: loss = 1.29928 (* 1 = 1.29928 loss)
I0312 15:48:49.979890  1600 sgd_solver.cpp:106] Iteration 29500, lr = 0.1
I0312 15:48:59.154026  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_29600.caffemodel
I0312 15:48:59.175510  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_29600.solverstate
I0312 15:48:59.180510  1600 solver.cpp:337] Iteration 29600, Testing net (#0)
I0312 15:48:59.181010  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:49:02.887495  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5328
I0312 15:49:02.887495  1600 solver.cpp:404]     Test net output #1: loss = 1.77982 (* 1 = 1.77982 loss)
I0312 15:49:02.934016  1600 solver.cpp:228] Iteration 29600, loss = 1.29985
I0312 15:49:02.934016  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:49:02.934016  1600 solver.cpp:244]     Train net output #1: loss = 1.29985 (* 1 = 1.29985 loss)
I0312 15:49:02.934016  1600 sgd_solver.cpp:106] Iteration 29600, lr = 0.1
I0312 15:49:12.158028  1600 solver.cpp:228] Iteration 29700, loss = 1.2272
I0312 15:49:12.158028  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:49:12.158028  1600 solver.cpp:244]     Train net output #1: loss = 1.2272 (* 1 = 1.2272 loss)
I0312 15:49:12.158028  1600 sgd_solver.cpp:106] Iteration 29700, lr = 0.1
I0312 15:49:21.098282  1600 solver.cpp:228] Iteration 29800, loss = 1.09251
I0312 15:49:21.098282  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:49:21.098282  1600 solver.cpp:244]     Train net output #1: loss = 1.09251 (* 1 = 1.09251 loss)
I0312 15:49:21.098783  1600 sgd_solver.cpp:106] Iteration 29800, lr = 0.1
I0312 15:49:30.078188  1600 solver.cpp:228] Iteration 29900, loss = 1.3881
I0312 15:49:30.078688  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:49:30.078688  1600 solver.cpp:244]     Train net output #1: loss = 1.3881 (* 1 = 1.3881 loss)
I0312 15:49:30.078688  1600 sgd_solver.cpp:106] Iteration 29900, lr = 0.1
I0312 15:49:39.135311  1600 solver.cpp:228] Iteration 30000, loss = 1.25707
I0312 15:49:39.135311  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:49:39.135311  1600 solver.cpp:244]     Train net output #1: loss = 1.25707 (* 1 = 1.25707 loss)
I0312 15:49:39.135311  1600 sgd_solver.cpp:106] Iteration 30000, lr = 0.1
I0312 15:49:48.228782  1600 solver.cpp:228] Iteration 30100, loss = 1.30254
I0312 15:49:48.228782  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:49:48.228782  1600 solver.cpp:244]     Train net output #1: loss = 1.30254 (* 1 = 1.30254 loss)
I0312 15:49:48.228782  1600 sgd_solver.cpp:106] Iteration 30100, lr = 0.1
I0312 15:49:57.398962  1600 solver.cpp:228] Iteration 30200, loss = 1.22291
I0312 15:49:57.398962  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:49:57.398962  1600 solver.cpp:244]     Train net output #1: loss = 1.22291 (* 1 = 1.22291 loss)
I0312 15:49:57.398962  1600 sgd_solver.cpp:106] Iteration 30200, lr = 0.1
I0312 15:50:06.551568  1600 solver.cpp:228] Iteration 30300, loss = 0.973711
I0312 15:50:06.551568  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:50:06.551568  1600 solver.cpp:244]     Train net output #1: loss = 0.973711 (* 1 = 0.973711 loss)
I0312 15:50:06.551568  1600 sgd_solver.cpp:106] Iteration 30300, lr = 0.1
I0312 15:50:15.721350  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_30400.caffemodel
I0312 15:50:15.740350  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_30400.solverstate
I0312 15:50:15.744849  1600 solver.cpp:337] Iteration 30400, Testing net (#0)
I0312 15:50:15.744849  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:50:19.362644  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5432
I0312 15:50:19.362644  1600 solver.cpp:404]     Test net output #1: loss = 1.73316 (* 1 = 1.73316 loss)
I0312 15:50:19.402624  1600 solver.cpp:228] Iteration 30400, loss = 1.52162
I0312 15:50:19.402624  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:50:19.402624  1600 solver.cpp:244]     Train net output #1: loss = 1.52162 (* 1 = 1.52162 loss)
I0312 15:50:19.402624  1600 sgd_solver.cpp:106] Iteration 30400, lr = 0.1
I0312 15:50:28.371969  1600 solver.cpp:228] Iteration 30500, loss = 1.16165
I0312 15:50:28.371969  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:50:28.371969  1600 solver.cpp:244]     Train net output #1: loss = 1.16165 (* 1 = 1.16165 loss)
I0312 15:50:28.372470  1600 sgd_solver.cpp:106] Iteration 30500, lr = 0.1
I0312 15:50:37.616868  1600 solver.cpp:228] Iteration 30600, loss = 1.0893
I0312 15:50:37.616868  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:50:37.616868  1600 solver.cpp:244]     Train net output #1: loss = 1.0893 (* 1 = 1.0893 loss)
I0312 15:50:37.616868  1600 sgd_solver.cpp:106] Iteration 30600, lr = 0.1
I0312 15:50:46.673141  1600 solver.cpp:228] Iteration 30700, loss = 0.805323
I0312 15:50:46.673141  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 15:50:46.673141  1600 solver.cpp:244]     Train net output #1: loss = 0.805323 (* 1 = 0.805323 loss)
I0312 15:50:46.673141  1600 sgd_solver.cpp:106] Iteration 30700, lr = 0.1
I0312 15:50:55.798616  1600 solver.cpp:228] Iteration 30800, loss = 0.993716
I0312 15:50:55.798616  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:50:55.798616  1600 solver.cpp:244]     Train net output #1: loss = 0.993716 (* 1 = 0.993716 loss)
I0312 15:50:55.798616  1600 sgd_solver.cpp:106] Iteration 30800, lr = 0.1
I0312 15:51:02.493698  1600 solver.cpp:228] Iteration 30900, loss = 0.988577
I0312 15:51:02.493698  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:51:02.493698  1600 solver.cpp:244]     Train net output #1: loss = 0.988577 (* 1 = 0.988577 loss)
I0312 15:51:02.493698  1600 sgd_solver.cpp:106] Iteration 30900, lr = 0.1
I0312 15:51:08.326359  1600 solver.cpp:228] Iteration 31000, loss = 1.31012
I0312 15:51:08.326359  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:51:08.326359  1600 solver.cpp:244]     Train net output #1: loss = 1.31012 (* 1 = 1.31012 loss)
I0312 15:51:08.326359  1600 sgd_solver.cpp:106] Iteration 31000, lr = 0.1
I0312 15:51:14.178418  1600 solver.cpp:228] Iteration 31100, loss = 1.2763
I0312 15:51:14.178418  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:51:14.178418  1600 solver.cpp:244]     Train net output #1: loss = 1.2763 (* 1 = 1.2763 loss)
I0312 15:51:14.178418  1600 sgd_solver.cpp:106] Iteration 31100, lr = 0.1
I0312 15:51:22.523694  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_31200.caffemodel
I0312 15:51:22.557194  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_31200.solverstate
I0312 15:51:22.562194  1600 solver.cpp:337] Iteration 31200, Testing net (#0)
I0312 15:51:22.562194  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:51:26.271100  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5477
I0312 15:51:26.271100  1600 solver.cpp:404]     Test net output #1: loss = 1.74048 (* 1 = 1.74048 loss)
I0312 15:51:26.301100  1600 solver.cpp:228] Iteration 31200, loss = 1.39971
I0312 15:51:26.301100  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:51:26.301100  1600 solver.cpp:244]     Train net output #1: loss = 1.39971 (* 1 = 1.39971 loss)
I0312 15:51:26.301100  1600 sgd_solver.cpp:106] Iteration 31200, lr = 0.1
I0312 15:51:35.346231  1600 solver.cpp:228] Iteration 31300, loss = 1.3677
I0312 15:51:35.346231  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:51:35.346231  1600 solver.cpp:244]     Train net output #1: loss = 1.3677 (* 1 = 1.3677 loss)
I0312 15:51:35.346231  1600 sgd_solver.cpp:106] Iteration 31300, lr = 0.1
I0312 15:51:44.378298  1600 solver.cpp:228] Iteration 31400, loss = 1.34776
I0312 15:51:44.378298  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:51:44.378298  1600 solver.cpp:244]     Train net output #1: loss = 1.34776 (* 1 = 1.34776 loss)
I0312 15:51:44.378298  1600 sgd_solver.cpp:106] Iteration 31400, lr = 0.1
I0312 15:51:53.644062  1600 solver.cpp:228] Iteration 31500, loss = 1.32477
I0312 15:51:53.644062  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:51:53.644062  1600 solver.cpp:244]     Train net output #1: loss = 1.32477 (* 1 = 1.32477 loss)
I0312 15:51:53.644062  1600 sgd_solver.cpp:106] Iteration 31500, lr = 0.1
I0312 15:52:02.733294  1600 solver.cpp:228] Iteration 31600, loss = 1.2789
I0312 15:52:02.733294  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:52:02.733294  1600 solver.cpp:244]     Train net output #1: loss = 1.2789 (* 1 = 1.2789 loss)
I0312 15:52:02.733294  1600 sgd_solver.cpp:106] Iteration 31600, lr = 0.1
I0312 15:52:11.870084  1600 solver.cpp:228] Iteration 31700, loss = 1.20382
I0312 15:52:11.870585  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:52:11.870585  1600 solver.cpp:244]     Train net output #1: loss = 1.20382 (* 1 = 1.20382 loss)
I0312 15:52:11.870585  1600 sgd_solver.cpp:106] Iteration 31700, lr = 0.1
I0312 15:52:20.957993  1600 solver.cpp:228] Iteration 31800, loss = 1.2819
I0312 15:52:20.957993  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:52:20.957993  1600 solver.cpp:244]     Train net output #1: loss = 1.2819 (* 1 = 1.2819 loss)
I0312 15:52:20.957993  1600 sgd_solver.cpp:106] Iteration 31800, lr = 0.1
I0312 15:52:29.927151  1600 solver.cpp:228] Iteration 31900, loss = 1.24554
I0312 15:52:29.927151  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:52:29.927151  1600 solver.cpp:244]     Train net output #1: loss = 1.24554 (* 1 = 1.24554 loss)
I0312 15:52:29.927151  1600 sgd_solver.cpp:106] Iteration 31900, lr = 0.1
I0312 15:52:38.910225  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_32000.caffemodel
I0312 15:52:38.923724  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_32000.solverstate
I0312 15:52:38.928725  1600 solver.cpp:337] Iteration 32000, Testing net (#0)
I0312 15:52:38.929225  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:52:42.551390  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5253
I0312 15:52:42.551390  1600 solver.cpp:404]     Test net output #1: loss = 1.85123 (* 1 = 1.85123 loss)
I0312 15:52:42.571390  1600 solver.cpp:228] Iteration 32000, loss = 1.33396
I0312 15:52:42.571390  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:52:42.571390  1600 solver.cpp:244]     Train net output #1: loss = 1.33396 (* 1 = 1.33396 loss)
I0312 15:52:42.571390  1600 sgd_solver.cpp:106] Iteration 32000, lr = 0.1
I0312 15:52:51.598546  1600 solver.cpp:228] Iteration 32100, loss = 1.32836
I0312 15:52:51.598546  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:52:51.598546  1600 solver.cpp:244]     Train net output #1: loss = 1.32836 (* 1 = 1.32836 loss)
I0312 15:52:51.598546  1600 sgd_solver.cpp:106] Iteration 32100, lr = 0.1
I0312 15:53:00.566668  1600 solver.cpp:228] Iteration 32200, loss = 1.27907
I0312 15:53:00.567168  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:53:00.567168  1600 solver.cpp:244]     Train net output #1: loss = 1.27907 (* 1 = 1.27907 loss)
I0312 15:53:00.567168  1600 sgd_solver.cpp:106] Iteration 32200, lr = 0.1
I0312 15:53:09.769325  1600 solver.cpp:228] Iteration 32300, loss = 1.0426
I0312 15:53:09.769325  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:53:09.769325  1600 solver.cpp:244]     Train net output #1: loss = 1.0426 (* 1 = 1.0426 loss)
I0312 15:53:09.769325  1600 sgd_solver.cpp:106] Iteration 32300, lr = 0.1
I0312 15:53:18.773653  1600 solver.cpp:228] Iteration 32400, loss = 1.35939
I0312 15:53:18.773653  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:53:18.773653  1600 solver.cpp:244]     Train net output #1: loss = 1.35939 (* 1 = 1.35939 loss)
I0312 15:53:18.773653  1600 sgd_solver.cpp:106] Iteration 32400, lr = 0.1
I0312 15:53:27.708889  1600 solver.cpp:228] Iteration 32500, loss = 1.32672
I0312 15:53:27.708889  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:53:27.708889  1600 solver.cpp:244]     Train net output #1: loss = 1.32672 (* 1 = 1.32672 loss)
I0312 15:53:27.708889  1600 sgd_solver.cpp:106] Iteration 32500, lr = 0.1
I0312 15:53:36.750496  1600 solver.cpp:228] Iteration 32600, loss = 1.96915
I0312 15:53:36.750496  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:53:36.750496  1600 solver.cpp:244]     Train net output #1: loss = 1.96915 (* 1 = 1.96915 loss)
I0312 15:53:36.750496  1600 sgd_solver.cpp:106] Iteration 32600, lr = 0.1
I0312 15:53:45.830637  1600 solver.cpp:228] Iteration 32700, loss = 1.24852
I0312 15:53:45.830637  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:53:45.830637  1600 solver.cpp:244]     Train net output #1: loss = 1.24852 (* 1 = 1.24852 loss)
I0312 15:53:45.830637  1600 sgd_solver.cpp:106] Iteration 32700, lr = 0.1
I0312 15:53:55.025238  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_32800.caffemodel
I0312 15:53:55.046736  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_32800.solverstate
I0312 15:53:55.051738  1600 solver.cpp:337] Iteration 32800, Testing net (#0)
I0312 15:53:55.051738  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:53:58.799191  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5566
I0312 15:53:58.799191  1600 solver.cpp:404]     Test net output #1: loss = 1.71022 (* 1 = 1.71022 loss)
I0312 15:53:58.839188  1600 solver.cpp:228] Iteration 32800, loss = 1.59548
I0312 15:53:58.839188  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:53:58.839188  1600 solver.cpp:244]     Train net output #1: loss = 1.59548 (* 1 = 1.59548 loss)
I0312 15:53:58.839188  1600 sgd_solver.cpp:106] Iteration 32800, lr = 0.1
I0312 15:54:07.909698  1600 solver.cpp:228] Iteration 32900, loss = 1.25389
I0312 15:54:07.910198  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:54:07.910198  1600 solver.cpp:244]     Train net output #1: loss = 1.25389 (* 1 = 1.25389 loss)
I0312 15:54:07.910198  1600 sgd_solver.cpp:106] Iteration 32900, lr = 0.1
I0312 15:54:16.965932  1600 solver.cpp:228] Iteration 33000, loss = 1.27819
I0312 15:54:16.965932  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:54:16.965932  1600 solver.cpp:244]     Train net output #1: loss = 1.27819 (* 1 = 1.27819 loss)
I0312 15:54:16.965932  1600 sgd_solver.cpp:106] Iteration 33000, lr = 0.1
I0312 15:54:26.055408  1600 solver.cpp:228] Iteration 33100, loss = 1.53079
I0312 15:54:26.055408  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 15:54:26.055408  1600 solver.cpp:244]     Train net output #1: loss = 1.53079 (* 1 = 1.53079 loss)
I0312 15:54:26.055408  1600 sgd_solver.cpp:106] Iteration 33100, lr = 0.1
I0312 15:54:35.256602  1600 solver.cpp:228] Iteration 33200, loss = 1.34977
I0312 15:54:35.256602  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:54:35.256602  1600 solver.cpp:244]     Train net output #1: loss = 1.34977 (* 1 = 1.34977 loss)
I0312 15:54:35.256602  1600 sgd_solver.cpp:106] Iteration 33200, lr = 0.1
I0312 15:54:44.392350  1600 solver.cpp:228] Iteration 33300, loss = 1.42881
I0312 15:54:44.392350  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:54:44.392350  1600 solver.cpp:244]     Train net output #1: loss = 1.42881 (* 1 = 1.42881 loss)
I0312 15:54:44.392350  1600 sgd_solver.cpp:106] Iteration 33300, lr = 0.1
I0312 15:54:53.558706  1600 solver.cpp:228] Iteration 33400, loss = 1.16555
I0312 15:54:53.558706  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:54:53.558706  1600 solver.cpp:244]     Train net output #1: loss = 1.16555 (* 1 = 1.16555 loss)
I0312 15:54:53.558706  1600 sgd_solver.cpp:106] Iteration 33400, lr = 0.1
I0312 15:55:02.620489  1600 solver.cpp:228] Iteration 33500, loss = 1.37776
I0312 15:55:02.620990  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5
I0312 15:55:02.620990  1600 solver.cpp:244]     Train net output #1: loss = 1.37776 (* 1 = 1.37776 loss)
I0312 15:55:02.620990  1600 sgd_solver.cpp:106] Iteration 33500, lr = 0.1
I0312 15:55:11.638782  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_33600.caffemodel
I0312 15:55:11.665772  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_33600.solverstate
I0312 15:55:11.670771  1600 solver.cpp:337] Iteration 33600, Testing net (#0)
I0312 15:55:11.671272  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:55:15.378859  1600 solver.cpp:404]     Test net output #0: accuracy = 0.544
I0312 15:55:15.378859  1600 solver.cpp:404]     Test net output #1: loss = 1.71438 (* 1 = 1.71438 loss)
I0312 15:55:15.402858  1600 solver.cpp:228] Iteration 33600, loss = 1.35693
I0312 15:55:15.402858  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:55:15.402858  1600 solver.cpp:244]     Train net output #1: loss = 1.35693 (* 1 = 1.35693 loss)
I0312 15:55:15.402858  1600 sgd_solver.cpp:106] Iteration 33600, lr = 0.1
I0312 15:55:24.341835  1600 solver.cpp:228] Iteration 33700, loss = 1.30943
I0312 15:55:24.341835  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:55:24.341835  1600 solver.cpp:244]     Train net output #1: loss = 1.30943 (* 1 = 1.30943 loss)
I0312 15:55:24.341835  1600 sgd_solver.cpp:106] Iteration 33700, lr = 0.1
I0312 15:55:33.314435  1600 solver.cpp:228] Iteration 33800, loss = 0.883428
I0312 15:55:33.314435  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:55:33.314435  1600 solver.cpp:244]     Train net output #1: loss = 0.883428 (* 1 = 0.883428 loss)
I0312 15:55:33.314435  1600 sgd_solver.cpp:106] Iteration 33800, lr = 0.1
I0312 15:55:42.495774  1600 solver.cpp:228] Iteration 33900, loss = 1.02002
I0312 15:55:42.495774  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:55:42.495774  1600 solver.cpp:244]     Train net output #1: loss = 1.02002 (* 1 = 1.02002 loss)
I0312 15:55:42.495774  1600 sgd_solver.cpp:106] Iteration 33900, lr = 0.1
I0312 15:55:51.461551  1600 solver.cpp:228] Iteration 34000, loss = 1.28596
I0312 15:55:51.461551  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:55:51.462050  1600 solver.cpp:244]     Train net output #1: loss = 1.28596 (* 1 = 1.28596 loss)
I0312 15:55:51.462050  1600 sgd_solver.cpp:106] Iteration 34000, lr = 0.1
I0312 15:56:00.476893  1600 solver.cpp:228] Iteration 34100, loss = 1.32317
I0312 15:56:00.476893  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 15:56:00.476893  1600 solver.cpp:244]     Train net output #1: loss = 1.32317 (* 1 = 1.32317 loss)
I0312 15:56:00.476893  1600 sgd_solver.cpp:106] Iteration 34100, lr = 0.1
I0312 15:56:06.882784  1600 solver.cpp:228] Iteration 34200, loss = 1.10568
I0312 15:56:06.882784  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 15:56:06.882784  1600 solver.cpp:244]     Train net output #1: loss = 1.10568 (* 1 = 1.10568 loss)
I0312 15:56:06.882784  1600 sgd_solver.cpp:106] Iteration 34200, lr = 0.1
I0312 15:56:12.674055  1600 solver.cpp:228] Iteration 34300, loss = 1.16953
I0312 15:56:12.674055  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:56:12.674055  1600 solver.cpp:244]     Train net output #1: loss = 1.16953 (* 1 = 1.16953 loss)
I0312 15:56:12.674055  1600 sgd_solver.cpp:106] Iteration 34300, lr = 0.1
I0312 15:56:18.485766  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_34400.caffemodel
I0312 15:56:18.505753  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_34400.solverstate
I0312 15:56:18.515753  1600 solver.cpp:337] Iteration 34400, Testing net (#0)
I0312 15:56:18.515753  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:56:21.830775  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5452
I0312 15:56:21.830775  1600 solver.cpp:404]     Test net output #1: loss = 1.72415 (* 1 = 1.72415 loss)
I0312 15:56:21.875275  1600 solver.cpp:228] Iteration 34400, loss = 1.2535
I0312 15:56:21.875275  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:56:21.875275  1600 solver.cpp:244]     Train net output #1: loss = 1.2535 (* 1 = 1.2535 loss)
I0312 15:56:21.875275  1600 sgd_solver.cpp:106] Iteration 34400, lr = 0.1
I0312 15:56:30.813427  1600 solver.cpp:228] Iteration 34500, loss = 0.870295
I0312 15:56:30.813427  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 15:56:30.813427  1600 solver.cpp:244]     Train net output #1: loss = 0.870295 (* 1 = 0.870295 loss)
I0312 15:56:30.813427  1600 sgd_solver.cpp:106] Iteration 34500, lr = 0.1
I0312 15:56:39.951963  1600 solver.cpp:228] Iteration 34600, loss = 1.35345
I0312 15:56:39.952463  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:56:39.952463  1600 solver.cpp:244]     Train net output #1: loss = 1.35345 (* 1 = 1.35345 loss)
I0312 15:56:39.952463  1600 sgd_solver.cpp:106] Iteration 34600, lr = 0.1
I0312 15:56:49.165498  1600 solver.cpp:228] Iteration 34700, loss = 1.16057
I0312 15:56:49.165498  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:56:49.165498  1600 solver.cpp:244]     Train net output #1: loss = 1.16057 (* 1 = 1.16057 loss)
I0312 15:56:49.165498  1600 sgd_solver.cpp:106] Iteration 34700, lr = 0.1
I0312 15:56:58.177073  1600 solver.cpp:228] Iteration 34800, loss = 1.25165
I0312 15:56:58.177073  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 15:56:58.177073  1600 solver.cpp:244]     Train net output #1: loss = 1.25165 (* 1 = 1.25165 loss)
I0312 15:56:58.177073  1600 sgd_solver.cpp:106] Iteration 34800, lr = 0.1
I0312 15:57:07.461792  1600 solver.cpp:228] Iteration 34900, loss = 1.33738
I0312 15:57:07.461792  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:57:07.461792  1600 solver.cpp:244]     Train net output #1: loss = 1.33738 (* 1 = 1.33738 loss)
I0312 15:57:07.461792  1600 sgd_solver.cpp:106] Iteration 34900, lr = 0.1
I0312 15:57:16.757109  1600 solver.cpp:228] Iteration 35000, loss = 1.53788
I0312 15:57:16.757109  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:57:16.757109  1600 solver.cpp:244]     Train net output #1: loss = 1.53788 (* 1 = 1.53788 loss)
I0312 15:57:16.757109  1600 sgd_solver.cpp:106] Iteration 35000, lr = 0.1
I0312 15:57:25.893982  1600 solver.cpp:228] Iteration 35100, loss = 1.3644
I0312 15:57:25.893982  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:57:25.893982  1600 solver.cpp:244]     Train net output #1: loss = 1.3644 (* 1 = 1.3644 loss)
I0312 15:57:25.893982  1600 sgd_solver.cpp:106] Iteration 35100, lr = 0.1
I0312 15:57:34.770602  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_35200.caffemodel
I0312 15:57:34.800101  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_35200.solverstate
I0312 15:57:34.805100  1600 solver.cpp:337] Iteration 35200, Testing net (#0)
I0312 15:57:34.805600  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:57:38.526904  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5433
I0312 15:57:38.526904  1600 solver.cpp:404]     Test net output #1: loss = 1.75994 (* 1 = 1.75994 loss)
I0312 15:57:38.546905  1600 solver.cpp:228] Iteration 35200, loss = 1.40831
I0312 15:57:38.546905  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.515625
I0312 15:57:38.546905  1600 solver.cpp:244]     Train net output #1: loss = 1.40831 (* 1 = 1.40831 loss)
I0312 15:57:38.546905  1600 sgd_solver.cpp:106] Iteration 35200, lr = 0.1
I0312 15:57:47.695590  1600 solver.cpp:228] Iteration 35300, loss = 1.26015
I0312 15:57:47.695590  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:57:47.695590  1600 solver.cpp:244]     Train net output #1: loss = 1.26015 (* 1 = 1.26015 loss)
I0312 15:57:47.695590  1600 sgd_solver.cpp:106] Iteration 35300, lr = 0.1
I0312 15:57:56.604359  1600 solver.cpp:228] Iteration 35400, loss = 1.11676
I0312 15:57:56.604359  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 15:57:56.604359  1600 solver.cpp:244]     Train net output #1: loss = 1.11676 (* 1 = 1.11676 loss)
I0312 15:57:56.604359  1600 sgd_solver.cpp:106] Iteration 35400, lr = 0.1
I0312 15:58:05.725641  1600 solver.cpp:228] Iteration 35500, loss = 1.43828
I0312 15:58:05.725641  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 15:58:05.725641  1600 solver.cpp:244]     Train net output #1: loss = 1.43828 (* 1 = 1.43828 loss)
I0312 15:58:05.725641  1600 sgd_solver.cpp:106] Iteration 35500, lr = 0.1
I0312 15:58:14.868746  1600 solver.cpp:228] Iteration 35600, loss = 1.20548
I0312 15:58:14.868746  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:58:14.868746  1600 solver.cpp:244]     Train net output #1: loss = 1.20548 (* 1 = 1.20548 loss)
I0312 15:58:14.868746  1600 sgd_solver.cpp:106] Iteration 35600, lr = 0.1
I0312 15:58:23.677274  1600 solver.cpp:228] Iteration 35700, loss = 1.09627
I0312 15:58:23.677775  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:58:23.677775  1600 solver.cpp:244]     Train net output #1: loss = 1.09627 (* 1 = 1.09627 loss)
I0312 15:58:23.677775  1600 sgd_solver.cpp:106] Iteration 35700, lr = 0.1
I0312 15:58:32.867064  1600 solver.cpp:228] Iteration 35800, loss = 1.02869
I0312 15:58:32.867064  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:58:32.867064  1600 solver.cpp:244]     Train net output #1: loss = 1.02869 (* 1 = 1.02869 loss)
I0312 15:58:32.867064  1600 sgd_solver.cpp:106] Iteration 35800, lr = 0.1
I0312 15:58:42.221596  1600 solver.cpp:228] Iteration 35900, loss = 1.08841
I0312 15:58:42.221596  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 15:58:42.221596  1600 solver.cpp:244]     Train net output #1: loss = 1.08841 (* 1 = 1.08841 loss)
I0312 15:58:42.221596  1600 sgd_solver.cpp:106] Iteration 35900, lr = 0.1
I0312 15:58:51.017954  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_36000.caffemodel
I0312 15:58:51.033951  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_36000.solverstate
I0312 15:58:51.038950  1600 solver.cpp:337] Iteration 36000, Testing net (#0)
I0312 15:58:51.038950  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 15:58:54.855547  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5443
I0312 15:58:54.855547  1600 solver.cpp:404]     Test net output #1: loss = 1.75607 (* 1 = 1.75607 loss)
I0312 15:58:54.906554  1600 solver.cpp:228] Iteration 36000, loss = 1.10638
I0312 15:58:54.906554  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 15:58:54.906554  1600 solver.cpp:244]     Train net output #1: loss = 1.10638 (* 1 = 1.10638 loss)
I0312 15:58:54.906554  1600 sgd_solver.cpp:106] Iteration 36000, lr = 0.1
I0312 15:59:03.862753  1600 solver.cpp:228] Iteration 36100, loss = 1.29741
I0312 15:59:03.862753  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 15:59:03.862753  1600 solver.cpp:244]     Train net output #1: loss = 1.29741 (* 1 = 1.29741 loss)
I0312 15:59:03.862753  1600 sgd_solver.cpp:106] Iteration 36100, lr = 0.1
I0312 15:59:12.591686  1600 solver.cpp:228] Iteration 36200, loss = 0.989582
I0312 15:59:12.591686  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 15:59:12.591686  1600 solver.cpp:244]     Train net output #1: loss = 0.989582 (* 1 = 0.989582 loss)
I0312 15:59:12.591686  1600 sgd_solver.cpp:106] Iteration 36200, lr = 0.1
I0312 15:59:21.474284  1600 solver.cpp:228] Iteration 36300, loss = 1.22266
I0312 15:59:21.474284  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:59:21.474284  1600 solver.cpp:244]     Train net output #1: loss = 1.22266 (* 1 = 1.22266 loss)
I0312 15:59:21.474284  1600 sgd_solver.cpp:106] Iteration 36300, lr = 0.1
I0312 15:59:30.560091  1600 solver.cpp:228] Iteration 36400, loss = 0.934494
I0312 15:59:30.560091  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 15:59:30.560091  1600 solver.cpp:244]     Train net output #1: loss = 0.934494 (* 1 = 0.934494 loss)
I0312 15:59:30.560091  1600 sgd_solver.cpp:106] Iteration 36400, lr = 0.1
I0312 15:59:39.776559  1600 solver.cpp:228] Iteration 36500, loss = 1.12359
I0312 15:59:39.776559  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 15:59:39.776559  1600 solver.cpp:244]     Train net output #1: loss = 1.12359 (* 1 = 1.12359 loss)
I0312 15:59:39.776559  1600 sgd_solver.cpp:106] Iteration 36500, lr = 0.1
I0312 15:59:48.946172  1600 solver.cpp:228] Iteration 36600, loss = 1.30245
I0312 15:59:48.946172  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 15:59:48.946172  1600 solver.cpp:244]     Train net output #1: loss = 1.30245 (* 1 = 1.30245 loss)
I0312 15:59:48.946172  1600 sgd_solver.cpp:106] Iteration 36600, lr = 0.1
I0312 15:59:58.044149  1600 solver.cpp:228] Iteration 36700, loss = 1.25867
I0312 15:59:58.044149  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 15:59:58.044149  1600 solver.cpp:244]     Train net output #1: loss = 1.25867 (* 1 = 1.25867 loss)
I0312 15:59:58.044149  1600 sgd_solver.cpp:106] Iteration 36700, lr = 0.1
I0312 16:00:07.172647  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_36800.caffemodel
I0312 16:00:07.189648  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_36800.solverstate
I0312 16:00:07.195649  1600 solver.cpp:337] Iteration 36800, Testing net (#0)
I0312 16:00:07.195649  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:00:10.942050  1600 solver.cpp:404]     Test net output #0: accuracy = 0.544
I0312 16:00:10.942050  1600 solver.cpp:404]     Test net output #1: loss = 1.75043 (* 1 = 1.75043 loss)
I0312 16:00:10.984047  1600 solver.cpp:228] Iteration 36800, loss = 1.21206
I0312 16:00:10.984047  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:00:10.984047  1600 solver.cpp:244]     Train net output #1: loss = 1.21206 (* 1 = 1.21206 loss)
I0312 16:00:10.984047  1600 sgd_solver.cpp:106] Iteration 36800, lr = 0.1
I0312 16:00:20.249912  1600 solver.cpp:228] Iteration 36900, loss = 0.982825
I0312 16:00:20.249912  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:00:20.249912  1600 solver.cpp:244]     Train net output #1: loss = 0.982825 (* 1 = 0.982825 loss)
I0312 16:00:20.249912  1600 sgd_solver.cpp:106] Iteration 36900, lr = 0.1
I0312 16:00:29.490334  1600 solver.cpp:228] Iteration 37000, loss = 1.26874
I0312 16:00:29.490334  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:00:29.490334  1600 solver.cpp:244]     Train net output #1: loss = 1.26874 (* 1 = 1.26874 loss)
I0312 16:00:29.490334  1600 sgd_solver.cpp:106] Iteration 37000, lr = 0.1
I0312 16:00:38.590246  1600 solver.cpp:228] Iteration 37100, loss = 1.19774
I0312 16:00:38.590246  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:00:38.590746  1600 solver.cpp:244]     Train net output #1: loss = 1.19774 (* 1 = 1.19774 loss)
I0312 16:00:38.590746  1600 sgd_solver.cpp:106] Iteration 37100, lr = 0.1
I0312 16:00:47.763434  1600 solver.cpp:228] Iteration 37200, loss = 1.18717
I0312 16:00:47.763434  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:00:47.763434  1600 solver.cpp:244]     Train net output #1: loss = 1.18717 (* 1 = 1.18717 loss)
I0312 16:00:47.763434  1600 sgd_solver.cpp:106] Iteration 37200, lr = 0.1
I0312 16:00:56.736570  1600 solver.cpp:228] Iteration 37300, loss = 1.59063
I0312 16:00:56.736570  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:00:56.737072  1600 solver.cpp:244]     Train net output #1: loss = 1.59063 (* 1 = 1.59063 loss)
I0312 16:00:56.737072  1600 sgd_solver.cpp:106] Iteration 37300, lr = 0.1
I0312 16:01:05.670619  1600 solver.cpp:228] Iteration 37400, loss = 1.24845
I0312 16:01:05.670619  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:01:05.670619  1600 solver.cpp:244]     Train net output #1: loss = 1.24845 (* 1 = 1.24845 loss)
I0312 16:01:05.670619  1600 sgd_solver.cpp:106] Iteration 37400, lr = 0.1
I0312 16:01:12.047880  1600 solver.cpp:228] Iteration 37500, loss = 1.30799
I0312 16:01:12.047880  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:01:12.047880  1600 solver.cpp:244]     Train net output #1: loss = 1.30799 (* 1 = 1.30799 loss)
I0312 16:01:12.047880  1600 sgd_solver.cpp:106] Iteration 37500, lr = 0.1
I0312 16:01:17.863818  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_37600.caffemodel
I0312 16:01:17.883821  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_37600.solverstate
I0312 16:01:17.883821  1600 solver.cpp:337] Iteration 37600, Testing net (#0)
I0312 16:01:17.893821  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:01:20.345331  1600 solver.cpp:404]     Test net output #0: accuracy = 0.555
I0312 16:01:20.345331  1600 solver.cpp:404]     Test net output #1: loss = 1.70548 (* 1 = 1.70548 loss)
I0312 16:01:20.365335  1600 solver.cpp:228] Iteration 37600, loss = 1.33755
I0312 16:01:20.365335  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:01:20.365335  1600 solver.cpp:244]     Train net output #1: loss = 1.33755 (* 1 = 1.33755 loss)
I0312 16:01:20.365335  1600 sgd_solver.cpp:106] Iteration 37600, lr = 0.1
I0312 16:01:26.940981  1600 solver.cpp:228] Iteration 37700, loss = 1.0616
I0312 16:01:26.940981  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:01:26.940981  1600 solver.cpp:244]     Train net output #1: loss = 1.0616 (* 1 = 1.0616 loss)
I0312 16:01:26.940981  1600 sgd_solver.cpp:106] Iteration 37700, lr = 0.1
I0312 16:01:36.125923  1600 solver.cpp:228] Iteration 37800, loss = 1.19215
I0312 16:01:36.125923  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 16:01:36.125923  1600 solver.cpp:244]     Train net output #1: loss = 1.19215 (* 1 = 1.19215 loss)
I0312 16:01:36.125923  1600 sgd_solver.cpp:106] Iteration 37800, lr = 0.1
I0312 16:01:45.174206  1600 solver.cpp:228] Iteration 37900, loss = 1.24527
I0312 16:01:45.174206  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 16:01:45.174206  1600 solver.cpp:244]     Train net output #1: loss = 1.24527 (* 1 = 1.24527 loss)
I0312 16:01:45.174206  1600 sgd_solver.cpp:106] Iteration 37900, lr = 0.1
I0312 16:01:54.297148  1600 solver.cpp:228] Iteration 38000, loss = 1.26955
I0312 16:01:54.297148  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:01:54.297148  1600 solver.cpp:244]     Train net output #1: loss = 1.26955 (* 1 = 1.26955 loss)
I0312 16:01:54.297148  1600 sgd_solver.cpp:106] Iteration 38000, lr = 0.1
I0312 16:02:03.404131  1600 solver.cpp:228] Iteration 38100, loss = 1.02058
I0312 16:02:03.404131  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:02:03.404131  1600 solver.cpp:244]     Train net output #1: loss = 1.02058 (* 1 = 1.02058 loss)
I0312 16:02:03.404131  1600 sgd_solver.cpp:106] Iteration 38100, lr = 0.1
I0312 16:02:12.646039  1600 solver.cpp:228] Iteration 38200, loss = 1.17076
I0312 16:02:12.646039  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:02:12.646039  1600 solver.cpp:244]     Train net output #1: loss = 1.17076 (* 1 = 1.17076 loss)
I0312 16:02:12.646039  1600 sgd_solver.cpp:106] Iteration 38200, lr = 0.1
I0312 16:02:21.668447  1600 solver.cpp:228] Iteration 38300, loss = 0.97694
I0312 16:02:21.668447  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:02:21.668447  1600 solver.cpp:244]     Train net output #1: loss = 0.97694 (* 1 = 0.97694 loss)
I0312 16:02:21.668447  1600 sgd_solver.cpp:106] Iteration 38300, lr = 0.1
I0312 16:02:30.597430  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_38400.caffemodel
I0312 16:02:30.615929  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_38400.solverstate
I0312 16:02:30.620929  1600 solver.cpp:337] Iteration 38400, Testing net (#0)
I0312 16:02:30.621428  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:02:34.323449  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5607
I0312 16:02:34.323449  1600 solver.cpp:404]     Test net output #1: loss = 1.70811 (* 1 = 1.70811 loss)
I0312 16:02:34.353454  1600 solver.cpp:228] Iteration 38400, loss = 1.27433
I0312 16:02:34.353454  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:02:34.353454  1600 solver.cpp:244]     Train net output #1: loss = 1.27433 (* 1 = 1.27433 loss)
I0312 16:02:34.353454  1600 sgd_solver.cpp:106] Iteration 38400, lr = 0.1
I0312 16:02:43.511317  1600 solver.cpp:228] Iteration 38500, loss = 1.18281
I0312 16:02:43.511317  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:02:43.511317  1600 solver.cpp:244]     Train net output #1: loss = 1.18281 (* 1 = 1.18281 loss)
I0312 16:02:43.511317  1600 sgd_solver.cpp:106] Iteration 38500, lr = 0.1
I0312 16:02:52.743540  1600 solver.cpp:228] Iteration 38600, loss = 1.12292
I0312 16:02:52.744040  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:02:52.744040  1600 solver.cpp:244]     Train net output #1: loss = 1.12292 (* 1 = 1.12292 loss)
I0312 16:02:52.744040  1600 sgd_solver.cpp:106] Iteration 38600, lr = 0.1
I0312 16:03:02.081676  1600 solver.cpp:228] Iteration 38700, loss = 0.990301
I0312 16:03:02.081676  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:03:02.081676  1600 solver.cpp:244]     Train net output #1: loss = 0.990301 (* 1 = 0.990301 loss)
I0312 16:03:02.081676  1600 sgd_solver.cpp:106] Iteration 38700, lr = 0.1
I0312 16:03:11.182938  1600 solver.cpp:228] Iteration 38800, loss = 1.03356
I0312 16:03:11.182938  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:03:11.182938  1600 solver.cpp:244]     Train net output #1: loss = 1.03356 (* 1 = 1.03356 loss)
I0312 16:03:11.182938  1600 sgd_solver.cpp:106] Iteration 38800, lr = 0.1
I0312 16:03:20.151741  1600 solver.cpp:228] Iteration 38900, loss = 1.2191
I0312 16:03:20.151741  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:03:20.151741  1600 solver.cpp:244]     Train net output #1: loss = 1.2191 (* 1 = 1.2191 loss)
I0312 16:03:20.151741  1600 sgd_solver.cpp:106] Iteration 38900, lr = 0.1
I0312 16:03:29.185953  1600 solver.cpp:228] Iteration 39000, loss = 1.02318
I0312 16:03:29.185953  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:03:29.185953  1600 solver.cpp:244]     Train net output #1: loss = 1.02318 (* 1 = 1.02318 loss)
I0312 16:03:29.185953  1600 sgd_solver.cpp:106] Iteration 39000, lr = 0.1
I0312 16:03:38.488816  1600 solver.cpp:228] Iteration 39100, loss = 1.45315
I0312 16:03:38.488816  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:03:38.488816  1600 solver.cpp:244]     Train net output #1: loss = 1.45315 (* 1 = 1.45315 loss)
I0312 16:03:38.488816  1600 sgd_solver.cpp:106] Iteration 39100, lr = 0.1
I0312 16:03:47.592149  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_39200.caffemodel
I0312 16:03:47.608150  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_39200.solverstate
I0312 16:03:47.613150  1600 solver.cpp:337] Iteration 39200, Testing net (#0)
I0312 16:03:47.613150  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:03:51.260231  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5487
I0312 16:03:51.260231  1600 solver.cpp:404]     Test net output #1: loss = 1.75632 (* 1 = 1.75632 loss)
I0312 16:03:51.311215  1600 solver.cpp:228] Iteration 39200, loss = 1.47161
I0312 16:03:51.311215  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 16:03:51.311215  1600 solver.cpp:244]     Train net output #1: loss = 1.47161 (* 1 = 1.47161 loss)
I0312 16:03:51.311215  1600 sgd_solver.cpp:106] Iteration 39200, lr = 0.1
I0312 16:04:00.145215  1600 solver.cpp:228] Iteration 39300, loss = 1.04681
I0312 16:04:00.145215  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:04:00.145215  1600 solver.cpp:244]     Train net output #1: loss = 1.04681 (* 1 = 1.04681 loss)
I0312 16:04:00.145215  1600 sgd_solver.cpp:106] Iteration 39300, lr = 0.1
I0312 16:04:09.492498  1600 solver.cpp:228] Iteration 39400, loss = 1.34816
I0312 16:04:09.492498  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:04:09.492498  1600 solver.cpp:244]     Train net output #1: loss = 1.34816 (* 1 = 1.34816 loss)
I0312 16:04:09.492498  1600 sgd_solver.cpp:106] Iteration 39400, lr = 0.1
I0312 16:04:18.468721  1600 solver.cpp:228] Iteration 39500, loss = 1.15572
I0312 16:04:18.468721  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:04:18.468721  1600 solver.cpp:244]     Train net output #1: loss = 1.15572 (* 1 = 1.15572 loss)
I0312 16:04:18.468721  1600 sgd_solver.cpp:106] Iteration 39500, lr = 0.1
I0312 16:04:27.618369  1600 solver.cpp:228] Iteration 39600, loss = 1.08604
I0312 16:04:27.618369  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:04:27.618369  1600 solver.cpp:244]     Train net output #1: loss = 1.08604 (* 1 = 1.08604 loss)
I0312 16:04:27.618369  1600 sgd_solver.cpp:106] Iteration 39600, lr = 0.1
I0312 16:04:36.724262  1600 solver.cpp:228] Iteration 39700, loss = 1.19163
I0312 16:04:36.724262  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:04:36.724262  1600 solver.cpp:244]     Train net output #1: loss = 1.19163 (* 1 = 1.19163 loss)
I0312 16:04:36.724262  1600 sgd_solver.cpp:106] Iteration 39700, lr = 0.1
I0312 16:04:45.616986  1600 solver.cpp:228] Iteration 39800, loss = 1.15808
I0312 16:04:45.617485  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:04:45.617485  1600 solver.cpp:244]     Train net output #1: loss = 1.15808 (* 1 = 1.15808 loss)
I0312 16:04:45.617485  1600 sgd_solver.cpp:106] Iteration 39800, lr = 0.1
I0312 16:04:54.825784  1600 solver.cpp:228] Iteration 39900, loss = 1.29582
I0312 16:04:54.825784  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:04:54.825784  1600 solver.cpp:244]     Train net output #1: loss = 1.29582 (* 1 = 1.29582 loss)
I0312 16:04:54.825784  1600 sgd_solver.cpp:106] Iteration 39900, lr = 0.1
I0312 16:05:03.901172  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_40000.caffemodel
I0312 16:05:03.916169  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_40000.solverstate
I0312 16:05:03.921169  1600 solver.cpp:337] Iteration 40000, Testing net (#0)
I0312 16:05:03.921669  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:05:07.642474  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5511
I0312 16:05:07.642474  1600 solver.cpp:404]     Test net output #1: loss = 1.75247 (* 1 = 1.75247 loss)
I0312 16:05:07.665961  1600 solver.cpp:228] Iteration 40000, loss = 1.14215
I0312 16:05:07.665961  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:05:07.665961  1600 solver.cpp:244]     Train net output #1: loss = 1.14215 (* 1 = 1.14215 loss)
I0312 16:05:07.665961  1600 sgd_solver.cpp:106] Iteration 40000, lr = 0.1
I0312 16:05:16.825354  1600 solver.cpp:228] Iteration 40100, loss = 1.1753
I0312 16:05:16.825354  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 16:05:16.825354  1600 solver.cpp:244]     Train net output #1: loss = 1.1753 (* 1 = 1.1753 loss)
I0312 16:05:16.825354  1600 sgd_solver.cpp:106] Iteration 40100, lr = 0.1
I0312 16:05:25.925220  1600 solver.cpp:228] Iteration 40200, loss = 1.12945
I0312 16:05:25.925220  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:05:25.925220  1600 solver.cpp:244]     Train net output #1: loss = 1.12945 (* 1 = 1.12945 loss)
I0312 16:05:25.925220  1600 sgd_solver.cpp:106] Iteration 40200, lr = 0.1
I0312 16:05:34.968263  1600 solver.cpp:228] Iteration 40300, loss = 1.17006
I0312 16:05:34.968263  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:05:34.968263  1600 solver.cpp:244]     Train net output #1: loss = 1.17006 (* 1 = 1.17006 loss)
I0312 16:05:34.968263  1600 sgd_solver.cpp:106] Iteration 40300, lr = 0.1
I0312 16:05:44.024405  1600 solver.cpp:228] Iteration 40400, loss = 1.24587
I0312 16:05:44.024405  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:05:44.024405  1600 solver.cpp:244]     Train net output #1: loss = 1.24587 (* 1 = 1.24587 loss)
I0312 16:05:44.024405  1600 sgd_solver.cpp:106] Iteration 40400, lr = 0.1
I0312 16:05:53.026373  1600 solver.cpp:228] Iteration 40500, loss = 0.980449
I0312 16:05:53.026373  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:05:53.026373  1600 solver.cpp:244]     Train net output #1: loss = 0.980449 (* 1 = 0.980449 loss)
I0312 16:05:53.026373  1600 sgd_solver.cpp:106] Iteration 40500, lr = 0.1
I0312 16:06:02.231959  1600 solver.cpp:228] Iteration 40600, loss = 1.08139
I0312 16:06:02.231959  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:06:02.231959  1600 solver.cpp:244]     Train net output #1: loss = 1.08139 (* 1 = 1.08139 loss)
I0312 16:06:02.231959  1600 sgd_solver.cpp:106] Iteration 40600, lr = 0.1
I0312 16:06:11.283388  1600 solver.cpp:228] Iteration 40700, loss = 1.35758
I0312 16:06:11.283388  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 16:06:11.283388  1600 solver.cpp:244]     Train net output #1: loss = 1.35758 (* 1 = 1.35758 loss)
I0312 16:06:11.283388  1600 sgd_solver.cpp:106] Iteration 40700, lr = 0.1
I0312 16:06:17.504061  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_40800.caffemodel
I0312 16:06:17.524262  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_40800.solverstate
I0312 16:06:17.524262  1600 solver.cpp:337] Iteration 40800, Testing net (#0)
I0312 16:06:17.524262  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:06:19.996320  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5502
I0312 16:06:19.996320  1600 solver.cpp:404]     Test net output #1: loss = 1.74888 (* 1 = 1.74888 loss)
I0312 16:06:20.016324  1600 solver.cpp:228] Iteration 40800, loss = 1.03388
I0312 16:06:20.016324  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:06:20.016324  1600 solver.cpp:244]     Train net output #1: loss = 1.03388 (* 1 = 1.03388 loss)
I0312 16:06:20.016324  1600 sgd_solver.cpp:106] Iteration 40800, lr = 0.1
I0312 16:06:25.836779  1600 solver.cpp:228] Iteration 40900, loss = 0.972445
I0312 16:06:25.836779  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:06:25.836779  1600 solver.cpp:244]     Train net output #1: loss = 0.972445 (* 1 = 0.972445 loss)
I0312 16:06:25.836779  1600 sgd_solver.cpp:106] Iteration 40900, lr = 0.1
I0312 16:06:32.588374  1600 solver.cpp:228] Iteration 41000, loss = 1.09656
I0312 16:06:32.588374  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:06:32.588374  1600 solver.cpp:244]     Train net output #1: loss = 1.09656 (* 1 = 1.09656 loss)
I0312 16:06:32.588374  1600 sgd_solver.cpp:106] Iteration 41000, lr = 0.1
I0312 16:06:41.738121  1600 solver.cpp:228] Iteration 41100, loss = 1.12195
I0312 16:06:41.738121  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:06:41.738121  1600 solver.cpp:244]     Train net output #1: loss = 1.12195 (* 1 = 1.12195 loss)
I0312 16:06:41.738121  1600 sgd_solver.cpp:106] Iteration 41100, lr = 0.1
I0312 16:06:50.897719  1600 solver.cpp:228] Iteration 41200, loss = 1.11873
I0312 16:06:50.897719  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:06:50.898219  1600 solver.cpp:244]     Train net output #1: loss = 1.11873 (* 1 = 1.11873 loss)
I0312 16:06:50.898219  1600 sgd_solver.cpp:106] Iteration 41200, lr = 0.1
I0312 16:06:59.998256  1600 solver.cpp:228] Iteration 41300, loss = 1.37196
I0312 16:06:59.998256  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.53125
I0312 16:06:59.998256  1600 solver.cpp:244]     Train net output #1: loss = 1.37196 (* 1 = 1.37196 loss)
I0312 16:06:59.998256  1600 sgd_solver.cpp:106] Iteration 41300, lr = 0.1
I0312 16:07:08.990875  1600 solver.cpp:228] Iteration 41400, loss = 1.14499
I0312 16:07:08.990875  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:07:08.990875  1600 solver.cpp:244]     Train net output #1: loss = 1.14499 (* 1 = 1.14499 loss)
I0312 16:07:08.990875  1600 sgd_solver.cpp:106] Iteration 41400, lr = 0.1
I0312 16:07:18.056573  1600 solver.cpp:228] Iteration 41500, loss = 1.59042
I0312 16:07:18.056573  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:07:18.056573  1600 solver.cpp:244]     Train net output #1: loss = 1.59042 (* 1 = 1.59042 loss)
I0312 16:07:18.056573  1600 sgd_solver.cpp:106] Iteration 41500, lr = 0.1
I0312 16:07:27.094645  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_41600.caffemodel
I0312 16:07:27.124143  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_41600.solverstate
I0312 16:07:27.129143  1600 solver.cpp:337] Iteration 41600, Testing net (#0)
I0312 16:07:27.129143  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:07:30.793817  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5344
I0312 16:07:30.793817  1600 solver.cpp:404]     Test net output #1: loss = 1.8436 (* 1 = 1.8436 loss)
I0312 16:07:30.851830  1600 solver.cpp:228] Iteration 41600, loss = 1.51106
I0312 16:07:30.851830  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 16:07:30.851830  1600 solver.cpp:244]     Train net output #1: loss = 1.51106 (* 1 = 1.51106 loss)
I0312 16:07:30.851830  1600 sgd_solver.cpp:106] Iteration 41600, lr = 0.1
I0312 16:07:39.897591  1600 solver.cpp:228] Iteration 41700, loss = 1.26456
I0312 16:07:39.898094  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:07:39.898094  1600 solver.cpp:244]     Train net output #1: loss = 1.26456 (* 1 = 1.26456 loss)
I0312 16:07:39.898094  1600 sgd_solver.cpp:106] Iteration 41700, lr = 0.1
I0312 16:07:49.105121  1600 solver.cpp:228] Iteration 41800, loss = 1.11996
I0312 16:07:49.105121  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:07:49.105121  1600 solver.cpp:244]     Train net output #1: loss = 1.11996 (* 1 = 1.11996 loss)
I0312 16:07:49.105121  1600 sgd_solver.cpp:106] Iteration 41800, lr = 0.1
I0312 16:07:58.088868  1600 solver.cpp:228] Iteration 41900, loss = 1.05399
I0312 16:07:58.088868  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 16:07:58.088868  1600 solver.cpp:244]     Train net output #1: loss = 1.05399 (* 1 = 1.05399 loss)
I0312 16:07:58.088868  1600 sgd_solver.cpp:106] Iteration 41900, lr = 0.1
I0312 16:08:07.127338  1600 solver.cpp:228] Iteration 42000, loss = 1.23391
I0312 16:08:07.127338  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:08:07.127338  1600 solver.cpp:244]     Train net output #1: loss = 1.23391 (* 1 = 1.23391 loss)
I0312 16:08:07.127838  1600 sgd_solver.cpp:106] Iteration 42000, lr = 0.1
I0312 16:08:16.125726  1600 solver.cpp:228] Iteration 42100, loss = 1.11718
I0312 16:08:16.125726  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:08:16.125726  1600 solver.cpp:244]     Train net output #1: loss = 1.11718 (* 1 = 1.11718 loss)
I0312 16:08:16.125726  1600 sgd_solver.cpp:106] Iteration 42100, lr = 0.1
I0312 16:08:25.043395  1600 solver.cpp:228] Iteration 42200, loss = 1.07924
I0312 16:08:25.043395  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:08:25.043395  1600 solver.cpp:244]     Train net output #1: loss = 1.07924 (* 1 = 1.07924 loss)
I0312 16:08:25.043395  1600 sgd_solver.cpp:106] Iteration 42200, lr = 0.1
I0312 16:08:34.228639  1600 solver.cpp:228] Iteration 42300, loss = 1.20531
I0312 16:08:34.228639  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:08:34.228639  1600 solver.cpp:244]     Train net output #1: loss = 1.20531 (* 1 = 1.20531 loss)
I0312 16:08:34.228639  1600 sgd_solver.cpp:106] Iteration 42300, lr = 0.1
I0312 16:08:43.387156  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_42400.caffemodel
I0312 16:08:43.406625  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_42400.solverstate
I0312 16:08:43.414162  1600 solver.cpp:337] Iteration 42400, Testing net (#0)
I0312 16:08:43.414162  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:08:47.216433  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5589
I0312 16:08:47.216907  1600 solver.cpp:404]     Test net output #1: loss = 1.67441 (* 1 = 1.67441 loss)
I0312 16:08:47.233904  1600 solver.cpp:228] Iteration 42400, loss = 1.2924
I0312 16:08:47.233904  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 16:08:47.233904  1600 solver.cpp:244]     Train net output #1: loss = 1.2924 (* 1 = 1.2924 loss)
I0312 16:08:47.233904  1600 sgd_solver.cpp:106] Iteration 42400, lr = 0.1
I0312 16:08:56.347260  1600 solver.cpp:228] Iteration 42500, loss = 0.915131
I0312 16:08:56.347260  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:08:56.347260  1600 solver.cpp:244]     Train net output #1: loss = 0.915131 (* 1 = 0.915131 loss)
I0312 16:08:56.347260  1600 sgd_solver.cpp:106] Iteration 42500, lr = 0.1
I0312 16:09:05.452285  1600 solver.cpp:228] Iteration 42600, loss = 1.48797
I0312 16:09:05.452285  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 16:09:05.452285  1600 solver.cpp:244]     Train net output #1: loss = 1.48797 (* 1 = 1.48797 loss)
I0312 16:09:05.452285  1600 sgd_solver.cpp:106] Iteration 42600, lr = 0.1
I0312 16:09:14.495853  1600 solver.cpp:228] Iteration 42700, loss = 1.18366
I0312 16:09:14.495853  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:09:14.495853  1600 solver.cpp:244]     Train net output #1: loss = 1.18366 (* 1 = 1.18366 loss)
I0312 16:09:14.495853  1600 sgd_solver.cpp:106] Iteration 42700, lr = 0.1
I0312 16:09:23.469856  1600 solver.cpp:228] Iteration 42800, loss = 1.02888
I0312 16:09:23.470355  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:09:23.470355  1600 solver.cpp:244]     Train net output #1: loss = 1.02888 (* 1 = 1.02888 loss)
I0312 16:09:23.470355  1600 sgd_solver.cpp:106] Iteration 42800, lr = 0.1
I0312 16:09:32.678134  1600 solver.cpp:228] Iteration 42900, loss = 1.36778
I0312 16:09:32.678134  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:09:32.678134  1600 solver.cpp:244]     Train net output #1: loss = 1.36778 (* 1 = 1.36778 loss)
I0312 16:09:32.678134  1600 sgd_solver.cpp:106] Iteration 42900, lr = 0.1
I0312 16:09:41.865206  1600 solver.cpp:228] Iteration 43000, loss = 0.817013
I0312 16:09:41.865206  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:09:41.865206  1600 solver.cpp:244]     Train net output #1: loss = 0.817013 (* 1 = 0.817013 loss)
I0312 16:09:41.865206  1600 sgd_solver.cpp:106] Iteration 43000, lr = 0.1
I0312 16:09:50.953894  1600 solver.cpp:228] Iteration 43100, loss = 0.887337
I0312 16:09:50.953894  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:09:50.953894  1600 solver.cpp:244]     Train net output #1: loss = 0.887337 (* 1 = 0.887337 loss)
I0312 16:09:50.953894  1600 sgd_solver.cpp:106] Iteration 43100, lr = 0.1
I0312 16:10:00.091553  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_43200.caffemodel
I0312 16:10:00.121548  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_43200.solverstate
I0312 16:10:00.126547  1600 solver.cpp:337] Iteration 43200, Testing net (#0)
I0312 16:10:00.126547  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:10:03.793270  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5592
I0312 16:10:03.793270  1600 solver.cpp:404]     Test net output #1: loss = 1.6846 (* 1 = 1.6846 loss)
I0312 16:10:03.814759  1600 solver.cpp:228] Iteration 43200, loss = 0.693089
I0312 16:10:03.814759  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:10:03.814759  1600 solver.cpp:244]     Train net output #1: loss = 0.693089 (* 1 = 0.693089 loss)
I0312 16:10:03.814759  1600 sgd_solver.cpp:106] Iteration 43200, lr = 0.1
I0312 16:10:12.991122  1600 solver.cpp:228] Iteration 43300, loss = 0.733048
I0312 16:10:12.991122  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:10:12.991122  1600 solver.cpp:244]     Train net output #1: loss = 0.733048 (* 1 = 0.733048 loss)
I0312 16:10:12.991122  1600 sgd_solver.cpp:106] Iteration 43300, lr = 0.1
I0312 16:10:21.936569  1600 solver.cpp:228] Iteration 43400, loss = 0.961073
I0312 16:10:21.936569  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:10:21.936569  1600 solver.cpp:244]     Train net output #1: loss = 0.961073 (* 1 = 0.961073 loss)
I0312 16:10:21.936569  1600 sgd_solver.cpp:106] Iteration 43400, lr = 0.1
I0312 16:10:31.135439  1600 solver.cpp:228] Iteration 43500, loss = 1.05502
I0312 16:10:31.135439  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:10:31.135439  1600 solver.cpp:244]     Train net output #1: loss = 1.05502 (* 1 = 1.05502 loss)
I0312 16:10:31.135439  1600 sgd_solver.cpp:106] Iteration 43500, lr = 0.1
I0312 16:10:39.958624  1600 solver.cpp:228] Iteration 43600, loss = 1.27301
I0312 16:10:39.958624  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:10:39.958624  1600 solver.cpp:244]     Train net output #1: loss = 1.27301 (* 1 = 1.27301 loss)
I0312 16:10:39.958624  1600 sgd_solver.cpp:106] Iteration 43600, lr = 0.1
I0312 16:10:48.891218  1600 solver.cpp:228] Iteration 43700, loss = 1.26249
I0312 16:10:48.891218  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:10:48.891218  1600 solver.cpp:244]     Train net output #1: loss = 1.26249 (* 1 = 1.26249 loss)
I0312 16:10:48.891218  1600 sgd_solver.cpp:106] Iteration 43700, lr = 0.1
I0312 16:10:57.896761  1600 solver.cpp:228] Iteration 43800, loss = 1.24074
I0312 16:10:57.896761  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:10:57.896761  1600 solver.cpp:244]     Train net output #1: loss = 1.24074 (* 1 = 1.24074 loss)
I0312 16:10:57.896761  1600 sgd_solver.cpp:106] Iteration 43800, lr = 0.1
I0312 16:11:07.105334  1600 solver.cpp:228] Iteration 43900, loss = 1.19253
I0312 16:11:07.105334  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:11:07.105334  1600 solver.cpp:244]     Train net output #1: loss = 1.19253 (* 1 = 1.19253 loss)
I0312 16:11:07.105334  1600 sgd_solver.cpp:106] Iteration 43900, lr = 0.1
I0312 16:11:16.168895  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_44000.caffemodel
I0312 16:11:16.184379  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_44000.solverstate
I0312 16:11:16.189378  1600 solver.cpp:337] Iteration 44000, Testing net (#0)
I0312 16:11:16.189878  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:11:19.082633  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5641
I0312 16:11:19.082633  1600 solver.cpp:404]     Test net output #1: loss = 1.70771 (* 1 = 1.70771 loss)
I0312 16:11:19.102620  1600 solver.cpp:228] Iteration 44000, loss = 1.03298
I0312 16:11:19.102620  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:11:19.102620  1600 solver.cpp:244]     Train net output #1: loss = 1.03298 (* 1 = 1.03298 loss)
I0312 16:11:19.102620  1600 sgd_solver.cpp:106] Iteration 44000, lr = 0.1
I0312 16:11:24.944327  1600 solver.cpp:228] Iteration 44100, loss = 1.05384
I0312 16:11:24.944327  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:11:24.944327  1600 solver.cpp:244]     Train net output #1: loss = 1.05384 (* 1 = 1.05384 loss)
I0312 16:11:24.944327  1600 sgd_solver.cpp:106] Iteration 44100, lr = 0.1
I0312 16:11:30.765337  1600 solver.cpp:228] Iteration 44200, loss = 0.91987
I0312 16:11:30.765337  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:11:30.765337  1600 solver.cpp:244]     Train net output #1: loss = 0.91987 (* 1 = 0.91987 loss)
I0312 16:11:30.765337  1600 sgd_solver.cpp:106] Iteration 44200, lr = 0.1
I0312 16:11:37.449537  1600 solver.cpp:228] Iteration 44300, loss = 1.25681
I0312 16:11:37.449537  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:11:37.449537  1600 solver.cpp:244]     Train net output #1: loss = 1.25681 (* 1 = 1.25681 loss)
I0312 16:11:37.449537  1600 sgd_solver.cpp:106] Iteration 44300, lr = 0.1
I0312 16:11:46.690809  1600 solver.cpp:228] Iteration 44400, loss = 1.06472
I0312 16:11:46.690809  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:11:46.690809  1600 solver.cpp:244]     Train net output #1: loss = 1.06472 (* 1 = 1.06472 loss)
I0312 16:11:46.690809  1600 sgd_solver.cpp:106] Iteration 44400, lr = 0.1
I0312 16:11:55.636276  1600 solver.cpp:228] Iteration 44500, loss = 1.13252
I0312 16:11:55.636775  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:11:55.636775  1600 solver.cpp:244]     Train net output #1: loss = 1.13252 (* 1 = 1.13252 loss)
I0312 16:11:55.636775  1600 sgd_solver.cpp:106] Iteration 44500, lr = 0.1
I0312 16:12:04.680979  1600 solver.cpp:228] Iteration 44600, loss = 1.25634
I0312 16:12:04.680979  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:12:04.680979  1600 solver.cpp:244]     Train net output #1: loss = 1.25634 (* 1 = 1.25634 loss)
I0312 16:12:04.680979  1600 sgd_solver.cpp:106] Iteration 44600, lr = 0.1
I0312 16:12:13.659797  1600 solver.cpp:228] Iteration 44700, loss = 1.16492
I0312 16:12:13.659797  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 16:12:13.659797  1600 solver.cpp:244]     Train net output #1: loss = 1.16492 (* 1 = 1.16492 loss)
I0312 16:12:13.659797  1600 sgd_solver.cpp:106] Iteration 44700, lr = 0.1
I0312 16:12:22.651953  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_44800.caffemodel
I0312 16:12:22.671939  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_44800.solverstate
I0312 16:12:22.677438  1600 solver.cpp:337] Iteration 44800, Testing net (#0)
I0312 16:12:22.677438  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:12:26.310410  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5554
I0312 16:12:26.310410  1600 solver.cpp:404]     Test net output #1: loss = 1.75483 (* 1 = 1.75483 loss)
I0312 16:12:26.360407  1600 solver.cpp:228] Iteration 44800, loss = 1.08753
I0312 16:12:26.360407  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:12:26.360407  1600 solver.cpp:244]     Train net output #1: loss = 1.08753 (* 1 = 1.08753 loss)
I0312 16:12:26.360407  1600 sgd_solver.cpp:106] Iteration 44800, lr = 0.1
I0312 16:12:35.344789  1600 solver.cpp:228] Iteration 44900, loss = 1.60654
I0312 16:12:35.344789  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:12:35.344789  1600 solver.cpp:244]     Train net output #1: loss = 1.60654 (* 1 = 1.60654 loss)
I0312 16:12:35.344789  1600 sgd_solver.cpp:106] Iteration 44900, lr = 0.1
I0312 16:12:44.455134  1600 solver.cpp:228] Iteration 45000, loss = 1.24145
I0312 16:12:44.455134  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:12:44.455134  1600 solver.cpp:244]     Train net output #1: loss = 1.24145 (* 1 = 1.24145 loss)
I0312 16:12:44.455134  1600 sgd_solver.cpp:106] Iteration 45000, lr = 0.1
I0312 16:12:53.503965  1600 solver.cpp:228] Iteration 45100, loss = 1.39718
I0312 16:12:53.503965  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:12:53.503965  1600 solver.cpp:244]     Train net output #1: loss = 1.39718 (* 1 = 1.39718 loss)
I0312 16:12:53.503965  1600 sgd_solver.cpp:106] Iteration 45100, lr = 0.1
I0312 16:13:02.532946  1600 solver.cpp:228] Iteration 45200, loss = 1.0596
I0312 16:13:02.532946  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:13:02.532946  1600 solver.cpp:244]     Train net output #1: loss = 1.0596 (* 1 = 1.0596 loss)
I0312 16:13:02.532946  1600 sgd_solver.cpp:106] Iteration 45200, lr = 0.1
I0312 16:13:11.542567  1600 solver.cpp:228] Iteration 45300, loss = 1.48571
I0312 16:13:11.542567  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 16:13:11.542567  1600 solver.cpp:244]     Train net output #1: loss = 1.48571 (* 1 = 1.48571 loss)
I0312 16:13:11.542567  1600 sgd_solver.cpp:106] Iteration 45300, lr = 0.1
I0312 16:13:20.738180  1600 solver.cpp:228] Iteration 45400, loss = 1.21613
I0312 16:13:20.738180  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:13:20.738680  1600 solver.cpp:244]     Train net output #1: loss = 1.21613 (* 1 = 1.21613 loss)
I0312 16:13:20.738680  1600 sgd_solver.cpp:106] Iteration 45400, lr = 0.1
I0312 16:13:30.032676  1600 solver.cpp:228] Iteration 45500, loss = 1.20787
I0312 16:13:30.032676  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:13:30.032676  1600 solver.cpp:244]     Train net output #1: loss = 1.20787 (* 1 = 1.20787 loss)
I0312 16:13:30.032676  1600 sgd_solver.cpp:106] Iteration 45500, lr = 0.1
I0312 16:13:39.091985  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_45600.caffemodel
I0312 16:13:39.110983  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_45600.solverstate
I0312 16:13:39.115983  1600 solver.cpp:337] Iteration 45600, Testing net (#0)
I0312 16:13:39.115983  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:13:42.836383  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5698
I0312 16:13:42.836383  1600 solver.cpp:404]     Test net output #1: loss = 1.72604 (* 1 = 1.72604 loss)
I0312 16:13:42.856367  1600 solver.cpp:228] Iteration 45600, loss = 1.32265
I0312 16:13:42.856367  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 16:13:42.856367  1600 solver.cpp:244]     Train net output #1: loss = 1.32265 (* 1 = 1.32265 loss)
I0312 16:13:42.856367  1600 sgd_solver.cpp:106] Iteration 45600, lr = 0.1
I0312 16:13:51.955389  1600 solver.cpp:228] Iteration 45700, loss = 1.40341
I0312 16:13:51.955389  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.59375
I0312 16:13:51.955389  1600 solver.cpp:244]     Train net output #1: loss = 1.40341 (* 1 = 1.40341 loss)
I0312 16:13:51.955389  1600 sgd_solver.cpp:106] Iteration 45700, lr = 0.1
I0312 16:14:01.218961  1600 solver.cpp:228] Iteration 45800, loss = 1.32866
I0312 16:14:01.218961  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:14:01.218961  1600 solver.cpp:244]     Train net output #1: loss = 1.32866 (* 1 = 1.32866 loss)
I0312 16:14:01.218961  1600 sgd_solver.cpp:106] Iteration 45800, lr = 0.1
I0312 16:14:10.461904  1600 solver.cpp:228] Iteration 45900, loss = 1.04527
I0312 16:14:10.461904  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:14:10.461904  1600 solver.cpp:244]     Train net output #1: loss = 1.04527 (* 1 = 1.04527 loss)
I0312 16:14:10.461904  1600 sgd_solver.cpp:106] Iteration 45900, lr = 0.1
I0312 16:14:19.553267  1600 solver.cpp:228] Iteration 46000, loss = 1.23211
I0312 16:14:19.553767  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:14:19.553767  1600 solver.cpp:244]     Train net output #1: loss = 1.23211 (* 1 = 1.23211 loss)
I0312 16:14:19.553767  1600 sgd_solver.cpp:106] Iteration 46000, lr = 0.1
I0312 16:14:28.576190  1600 solver.cpp:228] Iteration 46100, loss = 1.13032
I0312 16:14:28.576190  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:14:28.576190  1600 solver.cpp:244]     Train net output #1: loss = 1.13032 (* 1 = 1.13032 loss)
I0312 16:14:28.576190  1600 sgd_solver.cpp:106] Iteration 46100, lr = 0.1
I0312 16:14:37.703570  1600 solver.cpp:228] Iteration 46200, loss = 0.965633
I0312 16:14:37.703570  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:14:37.703570  1600 solver.cpp:244]     Train net output #1: loss = 0.965633 (* 1 = 0.965633 loss)
I0312 16:14:37.703570  1600 sgd_solver.cpp:106] Iteration 46200, lr = 0.1
I0312 16:14:46.818298  1600 solver.cpp:228] Iteration 46300, loss = 0.82641
I0312 16:14:46.818298  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:14:46.818298  1600 solver.cpp:244]     Train net output #1: loss = 0.82641 (* 1 = 0.82641 loss)
I0312 16:14:46.818298  1600 sgd_solver.cpp:106] Iteration 46300, lr = 0.1
I0312 16:14:55.922067  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_46400.caffemodel
I0312 16:14:55.946566  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_46400.solverstate
I0312 16:14:55.951588  1600 solver.cpp:337] Iteration 46400, Testing net (#0)
I0312 16:14:55.952067  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:14:59.645151  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5432
I0312 16:14:59.645151  1600 solver.cpp:404]     Test net output #1: loss = 1.88226 (* 1 = 1.88226 loss)
I0312 16:14:59.655153  1600 solver.cpp:228] Iteration 46400, loss = 1.22615
I0312 16:14:59.655153  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.609375
I0312 16:14:59.655153  1600 solver.cpp:244]     Train net output #1: loss = 1.22615 (* 1 = 1.22615 loss)
I0312 16:14:59.655153  1600 sgd_solver.cpp:106] Iteration 46400, lr = 0.1
I0312 16:15:08.799060  1600 solver.cpp:228] Iteration 46500, loss = 1.12641
I0312 16:15:08.799060  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:15:08.799060  1600 solver.cpp:244]     Train net output #1: loss = 1.12641 (* 1 = 1.12641 loss)
I0312 16:15:08.799060  1600 sgd_solver.cpp:106] Iteration 46500, lr = 0.1
I0312 16:15:17.699425  1600 solver.cpp:228] Iteration 46600, loss = 1.05011
I0312 16:15:17.699425  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:15:17.699425  1600 solver.cpp:244]     Train net output #1: loss = 1.05011 (* 1 = 1.05011 loss)
I0312 16:15:17.699425  1600 sgd_solver.cpp:106] Iteration 46600, lr = 0.1
I0312 16:15:26.969215  1600 solver.cpp:228] Iteration 46700, loss = 0.986667
I0312 16:15:26.969215  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:15:26.969215  1600 solver.cpp:244]     Train net output #1: loss = 0.986667 (* 1 = 0.986667 loss)
I0312 16:15:26.969215  1600 sgd_solver.cpp:106] Iteration 46700, lr = 0.1
I0312 16:15:36.264371  1600 solver.cpp:228] Iteration 46800, loss = 1.18929
I0312 16:15:36.264371  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:15:36.264371  1600 solver.cpp:244]     Train net output #1: loss = 1.18929 (* 1 = 1.18929 loss)
I0312 16:15:36.264371  1600 sgd_solver.cpp:106] Iteration 46800, lr = 0.1
I0312 16:15:45.473515  1600 solver.cpp:228] Iteration 46900, loss = 1.39951
I0312 16:15:45.473515  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:15:45.473515  1600 solver.cpp:244]     Train net output #1: loss = 1.39951 (* 1 = 1.39951 loss)
I0312 16:15:45.473515  1600 sgd_solver.cpp:106] Iteration 46900, lr = 0.1
I0312 16:15:54.546958  1600 solver.cpp:228] Iteration 47000, loss = 0.928677
I0312 16:15:54.546958  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:15:54.546958  1600 solver.cpp:244]     Train net output #1: loss = 0.928677 (* 1 = 0.928677 loss)
I0312 16:15:54.546958  1600 sgd_solver.cpp:106] Iteration 47000, lr = 0.1
I0312 16:16:03.533833  1600 solver.cpp:228] Iteration 47100, loss = 1.18297
I0312 16:16:03.533833  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:16:03.533833  1600 solver.cpp:244]     Train net output #1: loss = 1.18297 (* 1 = 1.18297 loss)
I0312 16:16:03.533833  1600 sgd_solver.cpp:106] Iteration 47100, lr = 0.1
I0312 16:16:12.535020  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_47200.caffemodel
I0312 16:16:12.563520  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_47200.solverstate
I0312 16:16:12.568521  1600 solver.cpp:337] Iteration 47200, Testing net (#0)
I0312 16:16:12.568521  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:16:16.270839  1600 solver.cpp:404]     Test net output #0: accuracy = 0.549
I0312 16:16:16.270839  1600 solver.cpp:404]     Test net output #1: loss = 1.82366 (* 1 = 1.82366 loss)
I0312 16:16:16.294829  1600 solver.cpp:228] Iteration 47200, loss = 0.96613
I0312 16:16:16.294829  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:16:16.294829  1600 solver.cpp:244]     Train net output #1: loss = 0.96613 (* 1 = 0.96613 loss)
I0312 16:16:16.294829  1600 sgd_solver.cpp:106] Iteration 47200, lr = 0.1
I0312 16:16:24.514019  1600 solver.cpp:228] Iteration 47300, loss = 1.36326
I0312 16:16:24.514019  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.5625
I0312 16:16:24.514019  1600 solver.cpp:244]     Train net output #1: loss = 1.36326 (* 1 = 1.36326 loss)
I0312 16:16:24.514019  1600 sgd_solver.cpp:106] Iteration 47300, lr = 0.1
I0312 16:16:30.331656  1600 solver.cpp:228] Iteration 47400, loss = 1.31388
I0312 16:16:30.331656  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:16:30.331656  1600 solver.cpp:244]     Train net output #1: loss = 1.31388 (* 1 = 1.31388 loss)
I0312 16:16:30.331656  1600 sgd_solver.cpp:106] Iteration 47400, lr = 0.1
I0312 16:16:36.143487  1600 solver.cpp:228] Iteration 47500, loss = 1.34957
I0312 16:16:36.143487  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:16:36.143487  1600 solver.cpp:244]     Train net output #1: loss = 1.34957 (* 1 = 1.34957 loss)
I0312 16:16:36.143487  1600 sgd_solver.cpp:106] Iteration 47500, lr = 0.1
I0312 16:16:42.961356  1600 solver.cpp:228] Iteration 47600, loss = 1.34876
I0312 16:16:42.961356  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:16:42.961356  1600 solver.cpp:244]     Train net output #1: loss = 1.34876 (* 1 = 1.34876 loss)
I0312 16:16:42.961356  1600 sgd_solver.cpp:106] Iteration 47600, lr = 0.1
I0312 16:16:52.027639  1600 solver.cpp:228] Iteration 47700, loss = 1.42136
I0312 16:16:52.027639  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.546875
I0312 16:16:52.027639  1600 solver.cpp:244]     Train net output #1: loss = 1.42136 (* 1 = 1.42136 loss)
I0312 16:16:52.027639  1600 sgd_solver.cpp:106] Iteration 47700, lr = 0.1
I0312 16:17:01.041333  1600 solver.cpp:228] Iteration 47800, loss = 0.895292
I0312 16:17:01.041333  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:17:01.041333  1600 solver.cpp:244]     Train net output #1: loss = 0.895292 (* 1 = 0.895292 loss)
I0312 16:17:01.041333  1600 sgd_solver.cpp:106] Iteration 47800, lr = 0.1
I0312 16:17:10.285956  1600 solver.cpp:228] Iteration 47900, loss = 1.27299
I0312 16:17:10.285956  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:17:10.285956  1600 solver.cpp:244]     Train net output #1: loss = 1.27299 (* 1 = 1.27299 loss)
I0312 16:17:10.285956  1600 sgd_solver.cpp:106] Iteration 47900, lr = 0.1
I0312 16:17:19.350884  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_48000.caffemodel
I0312 16:17:19.365386  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_48000.solverstate
I0312 16:17:19.370384  1600 solver.cpp:337] Iteration 48000, Testing net (#0)
I0312 16:17:19.370384  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:17:23.083588  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5585
I0312 16:17:23.083588  1600 solver.cpp:404]     Test net output #1: loss = 1.75057 (* 1 = 1.75057 loss)
I0312 16:17:23.114219  1600 solver.cpp:228] Iteration 48000, loss = 1.21613
I0312 16:17:23.114219  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:17:23.114219  1600 solver.cpp:244]     Train net output #1: loss = 1.21613 (* 1 = 1.21613 loss)
I0312 16:17:23.114219  1600 sgd_solver.cpp:106] Iteration 48000, lr = 0.1
I0312 16:17:32.181352  1600 solver.cpp:228] Iteration 48100, loss = 0.869592
I0312 16:17:32.181352  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:17:32.181352  1600 solver.cpp:244]     Train net output #1: loss = 0.869592 (* 1 = 0.869592 loss)
I0312 16:17:32.181352  1600 sgd_solver.cpp:106] Iteration 48100, lr = 0.1
I0312 16:17:41.287134  1600 solver.cpp:228] Iteration 48200, loss = 0.907562
I0312 16:17:41.287134  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:17:41.287134  1600 solver.cpp:244]     Train net output #1: loss = 0.907562 (* 1 = 0.907562 loss)
I0312 16:17:41.287134  1600 sgd_solver.cpp:106] Iteration 48200, lr = 0.1
I0312 16:17:50.251740  1600 solver.cpp:228] Iteration 48300, loss = 1.13621
I0312 16:17:50.251740  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:17:50.251740  1600 solver.cpp:244]     Train net output #1: loss = 1.13621 (* 1 = 1.13621 loss)
I0312 16:17:50.251740  1600 sgd_solver.cpp:106] Iteration 48300, lr = 0.1
I0312 16:17:59.258173  1600 solver.cpp:228] Iteration 48400, loss = 0.899667
I0312 16:17:59.258173  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:17:59.258173  1600 solver.cpp:244]     Train net output #1: loss = 0.899667 (* 1 = 0.899667 loss)
I0312 16:17:59.258173  1600 sgd_solver.cpp:106] Iteration 48400, lr = 0.1
I0312 16:18:08.240675  1600 solver.cpp:228] Iteration 48500, loss = 1.14609
I0312 16:18:08.240675  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:18:08.240675  1600 solver.cpp:244]     Train net output #1: loss = 1.14609 (* 1 = 1.14609 loss)
I0312 16:18:08.241175  1600 sgd_solver.cpp:106] Iteration 48500, lr = 0.1
I0312 16:18:17.238845  1600 solver.cpp:228] Iteration 48600, loss = 1.17641
I0312 16:18:17.238845  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:18:17.238845  1600 solver.cpp:244]     Train net output #1: loss = 1.17641 (* 1 = 1.17641 loss)
I0312 16:18:17.238845  1600 sgd_solver.cpp:106] Iteration 48600, lr = 0.1
I0312 16:18:26.237277  1600 solver.cpp:228] Iteration 48700, loss = 1.04966
I0312 16:18:26.237277  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:18:26.237277  1600 solver.cpp:244]     Train net output #1: loss = 1.04966 (* 1 = 1.04966 loss)
I0312 16:18:26.237277  1600 sgd_solver.cpp:106] Iteration 48700, lr = 0.1
I0312 16:18:35.423072  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_48800.caffemodel
I0312 16:18:35.438071  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_48800.solverstate
I0312 16:18:35.443071  1600 solver.cpp:337] Iteration 48800, Testing net (#0)
I0312 16:18:35.443071  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:18:39.177469  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5588
I0312 16:18:39.177469  1600 solver.cpp:404]     Test net output #1: loss = 1.72056 (* 1 = 1.72056 loss)
I0312 16:18:39.199462  1600 solver.cpp:228] Iteration 48800, loss = 1.1669
I0312 16:18:39.199462  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:18:39.199462  1600 solver.cpp:244]     Train net output #1: loss = 1.1669 (* 1 = 1.1669 loss)
I0312 16:18:39.199462  1600 sgd_solver.cpp:106] Iteration 48800, lr = 0.1
I0312 16:18:48.492208  1600 solver.cpp:228] Iteration 48900, loss = 0.919147
I0312 16:18:48.492208  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:18:48.492208  1600 solver.cpp:244]     Train net output #1: loss = 0.919147 (* 1 = 0.919147 loss)
I0312 16:18:48.492208  1600 sgd_solver.cpp:106] Iteration 48900, lr = 0.1
I0312 16:18:57.625445  1600 solver.cpp:228] Iteration 49000, loss = 0.910068
I0312 16:18:57.625445  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:18:57.625445  1600 solver.cpp:244]     Train net output #1: loss = 0.910068 (* 1 = 0.910068 loss)
I0312 16:18:57.625445  1600 sgd_solver.cpp:106] Iteration 49000, lr = 0.1
I0312 16:19:06.653739  1600 solver.cpp:228] Iteration 49100, loss = 1.34516
I0312 16:19:06.653739  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:19:06.653739  1600 solver.cpp:244]     Train net output #1: loss = 1.34516 (* 1 = 1.34516 loss)
I0312 16:19:06.653739  1600 sgd_solver.cpp:106] Iteration 49100, lr = 0.1
I0312 16:19:15.643659  1600 solver.cpp:228] Iteration 49200, loss = 1.20262
I0312 16:19:15.644137  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:19:15.644137  1600 solver.cpp:244]     Train net output #1: loss = 1.20262 (* 1 = 1.20262 loss)
I0312 16:19:15.644137  1600 sgd_solver.cpp:106] Iteration 49200, lr = 0.1
I0312 16:19:24.640885  1600 solver.cpp:228] Iteration 49300, loss = 1.18411
I0312 16:19:24.640885  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:19:24.640885  1600 solver.cpp:244]     Train net output #1: loss = 1.18411 (* 1 = 1.18411 loss)
I0312 16:19:24.640885  1600 sgd_solver.cpp:106] Iteration 49300, lr = 0.1
I0312 16:19:33.814916  1600 solver.cpp:228] Iteration 49400, loss = 0.944697
I0312 16:19:33.814916  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:19:33.814916  1600 solver.cpp:244]     Train net output #1: loss = 0.944697 (* 1 = 0.944697 loss)
I0312 16:19:33.814916  1600 sgd_solver.cpp:106] Iteration 49400, lr = 0.1
I0312 16:19:43.024706  1600 solver.cpp:228] Iteration 49500, loss = 1.00002
I0312 16:19:43.025210  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:19:43.025210  1600 solver.cpp:244]     Train net output #1: loss = 1.00002 (* 1 = 1.00002 loss)
I0312 16:19:43.025210  1600 sgd_solver.cpp:106] Iteration 49500, lr = 0.1
I0312 16:19:52.285434  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_49600.caffemodel
I0312 16:19:52.301434  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_49600.solverstate
I0312 16:19:52.306433  1600 solver.cpp:337] Iteration 49600, Testing net (#0)
I0312 16:19:52.306433  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:19:55.985658  1600 solver.cpp:404]     Test net output #0: accuracy = 0.5604
I0312 16:19:55.985658  1600 solver.cpp:404]     Test net output #1: loss = 1.74806 (* 1 = 1.74806 loss)
I0312 16:19:56.005662  1600 solver.cpp:228] Iteration 49600, loss = 0.958764
I0312 16:19:56.005662  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:19:56.005662  1600 solver.cpp:244]     Train net output #1: loss = 0.958764 (* 1 = 0.958764 loss)
I0312 16:19:56.005662  1600 sgd_solver.cpp:106] Iteration 49600, lr = 0.1
I0312 16:20:04.952029  1600 solver.cpp:228] Iteration 49700, loss = 1.14837
I0312 16:20:04.952029  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:20:04.952029  1600 solver.cpp:244]     Train net output #1: loss = 1.14837 (* 1 = 1.14837 loss)
I0312 16:20:04.952029  1600 sgd_solver.cpp:106] Iteration 49700, lr = 0.1
I0312 16:20:14.017395  1600 solver.cpp:228] Iteration 49800, loss = 1.33526
I0312 16:20:14.017395  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.578125
I0312 16:20:14.017395  1600 solver.cpp:244]     Train net output #1: loss = 1.33526 (* 1 = 1.33526 loss)
I0312 16:20:14.017395  1600 sgd_solver.cpp:106] Iteration 49800, lr = 0.1
I0312 16:20:23.169737  1600 solver.cpp:228] Iteration 49900, loss = 1.22987
I0312 16:20:23.170236  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:20:23.170236  1600 solver.cpp:244]     Train net output #1: loss = 1.22987 (* 1 = 1.22987 loss)
I0312 16:20:23.170236  1600 sgd_solver.cpp:106] Iteration 49900, lr = 0.1
I0312 16:20:32.484810  1600 solver.cpp:228] Iteration 50000, loss = 1.13409
I0312 16:20:32.484810  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:20:32.484810  1600 solver.cpp:244]     Train net output #1: loss = 1.13409 (* 1 = 1.13409 loss)
I0312 16:20:32.484810  1600 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I0312 16:20:32.484810  1600 sgd_solver.cpp:106] Iteration 50000, lr = 0.01
I0312 16:20:41.662680  1600 solver.cpp:228] Iteration 50100, loss = 1.03918
I0312 16:20:41.663180  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:20:41.663180  1600 solver.cpp:244]     Train net output #1: loss = 1.03918 (* 1 = 1.03918 loss)
I0312 16:20:41.663180  1600 sgd_solver.cpp:106] Iteration 50100, lr = 0.01
I0312 16:20:50.788883  1600 solver.cpp:228] Iteration 50200, loss = 0.667761
I0312 16:20:50.788883  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:20:50.788883  1600 solver.cpp:244]     Train net output #1: loss = 0.667761 (* 1 = 0.667761 loss)
I0312 16:20:50.788883  1600 sgd_solver.cpp:106] Iteration 50200, lr = 0.01
I0312 16:21:00.050037  1600 solver.cpp:228] Iteration 50300, loss = 0.701089
I0312 16:21:00.050037  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:21:00.050037  1600 solver.cpp:244]     Train net output #1: loss = 0.701089 (* 1 = 0.701089 loss)
I0312 16:21:00.050037  1600 sgd_solver.cpp:106] Iteration 50300, lr = 0.01
I0312 16:21:09.134589  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_50400.caffemodel
I0312 16:21:09.156081  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_50400.solverstate
I0312 16:21:09.161579  1600 solver.cpp:337] Iteration 50400, Testing net (#0)
I0312 16:21:09.161579  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:21:12.873090  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6092
I0312 16:21:12.873090  1600 solver.cpp:404]     Test net output #1: loss = 1.49116 (* 1 = 1.49116 loss)
I0312 16:21:12.910080  1600 solver.cpp:228] Iteration 50400, loss = 0.857269
I0312 16:21:12.910080  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:21:12.910080  1600 solver.cpp:244]     Train net output #1: loss = 0.857269 (* 1 = 0.857269 loss)
I0312 16:21:12.910080  1600 sgd_solver.cpp:106] Iteration 50400, lr = 0.01
I0312 16:21:22.198289  1600 solver.cpp:228] Iteration 50500, loss = 1.05236
I0312 16:21:22.198289  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:21:22.198289  1600 solver.cpp:244]     Train net output #1: loss = 1.05236 (* 1 = 1.05236 loss)
I0312 16:21:22.198289  1600 sgd_solver.cpp:106] Iteration 50500, lr = 0.01
I0312 16:21:29.962077  1600 solver.cpp:228] Iteration 50600, loss = 0.746693
I0312 16:21:29.962077  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:21:29.962077  1600 solver.cpp:244]     Train net output #1: loss = 0.746693 (* 1 = 0.746693 loss)
I0312 16:21:29.962077  1600 sgd_solver.cpp:106] Iteration 50600, lr = 0.01
I0312 16:21:35.772851  1600 solver.cpp:228] Iteration 50700, loss = 0.56668
I0312 16:21:35.772851  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:21:35.772851  1600 solver.cpp:244]     Train net output #1: loss = 0.56668 (* 1 = 0.56668 loss)
I0312 16:21:35.772851  1600 sgd_solver.cpp:106] Iteration 50700, lr = 0.01
I0312 16:21:41.568249  1600 solver.cpp:228] Iteration 50800, loss = 0.761478
I0312 16:21:41.568249  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:21:41.568249  1600 solver.cpp:244]     Train net output #1: loss = 0.761478 (* 1 = 0.761478 loss)
I0312 16:21:41.568249  1600 sgd_solver.cpp:106] Iteration 50800, lr = 0.01
I0312 16:21:48.659518  1600 solver.cpp:228] Iteration 50900, loss = 0.863522
I0312 16:21:48.659518  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:21:48.659518  1600 solver.cpp:244]     Train net output #1: loss = 0.863522 (* 1 = 0.863522 loss)
I0312 16:21:48.659518  1600 sgd_solver.cpp:106] Iteration 50900, lr = 0.01
I0312 16:21:57.897233  1600 solver.cpp:228] Iteration 51000, loss = 0.915414
I0312 16:21:57.897233  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:21:57.897233  1600 solver.cpp:244]     Train net output #1: loss = 0.915414 (* 1 = 0.915414 loss)
I0312 16:21:57.897233  1600 sgd_solver.cpp:106] Iteration 51000, lr = 0.01
I0312 16:22:06.980593  1600 solver.cpp:228] Iteration 51100, loss = 0.977879
I0312 16:22:06.980593  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:22:06.980593  1600 solver.cpp:244]     Train net output #1: loss = 0.977879 (* 1 = 0.977879 loss)
I0312 16:22:06.980593  1600 sgd_solver.cpp:106] Iteration 51100, lr = 0.01
I0312 16:22:16.213740  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_51200.caffemodel
I0312 16:22:16.247239  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_51200.solverstate
I0312 16:22:16.251739  1600 solver.cpp:337] Iteration 51200, Testing net (#0)
I0312 16:22:16.251739  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:22:19.968219  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6155
I0312 16:22:19.968219  1600 solver.cpp:404]     Test net output #1: loss = 1.495 (* 1 = 1.495 loss)
I0312 16:22:19.998217  1600 solver.cpp:228] Iteration 51200, loss = 0.982154
I0312 16:22:19.998217  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:22:19.998217  1600 solver.cpp:244]     Train net output #1: loss = 0.982154 (* 1 = 0.982154 loss)
I0312 16:22:19.998217  1600 sgd_solver.cpp:106] Iteration 51200, lr = 0.01
I0312 16:22:29.080559  1600 solver.cpp:228] Iteration 51300, loss = 0.720746
I0312 16:22:29.080559  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:22:29.080559  1600 solver.cpp:244]     Train net output #1: loss = 0.720746 (* 1 = 0.720746 loss)
I0312 16:22:29.080559  1600 sgd_solver.cpp:106] Iteration 51300, lr = 0.01
I0312 16:22:38.158211  1600 solver.cpp:228] Iteration 51400, loss = 0.757092
I0312 16:22:38.158211  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:22:38.158211  1600 solver.cpp:244]     Train net output #1: loss = 0.757092 (* 1 = 0.757092 loss)
I0312 16:22:38.158211  1600 sgd_solver.cpp:106] Iteration 51400, lr = 0.01
I0312 16:22:47.188865  1600 solver.cpp:228] Iteration 51500, loss = 0.66981
I0312 16:22:47.188865  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:22:47.188865  1600 solver.cpp:244]     Train net output #1: loss = 0.66981 (* 1 = 0.66981 loss)
I0312 16:22:47.188865  1600 sgd_solver.cpp:106] Iteration 51500, lr = 0.01
I0312 16:22:56.237471  1600 solver.cpp:228] Iteration 51600, loss = 1.12539
I0312 16:22:56.237471  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:22:56.237471  1600 solver.cpp:244]     Train net output #1: loss = 1.12539 (* 1 = 1.12539 loss)
I0312 16:22:56.237471  1600 sgd_solver.cpp:106] Iteration 51600, lr = 0.01
I0312 16:23:05.342469  1600 solver.cpp:228] Iteration 51700, loss = 1.14137
I0312 16:23:05.342469  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:23:05.342469  1600 solver.cpp:244]     Train net output #1: loss = 1.14137 (* 1 = 1.14137 loss)
I0312 16:23:05.342469  1600 sgd_solver.cpp:106] Iteration 51700, lr = 0.01
I0312 16:23:14.401885  1600 solver.cpp:228] Iteration 51800, loss = 0.706615
I0312 16:23:14.401885  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:23:14.401885  1600 solver.cpp:244]     Train net output #1: loss = 0.706615 (* 1 = 0.706615 loss)
I0312 16:23:14.401885  1600 sgd_solver.cpp:106] Iteration 51800, lr = 0.01
I0312 16:23:23.492112  1600 solver.cpp:228] Iteration 51900, loss = 0.815409
I0312 16:23:23.492112  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:23:23.492112  1600 solver.cpp:244]     Train net output #1: loss = 0.815409 (* 1 = 0.815409 loss)
I0312 16:23:23.492112  1600 sgd_solver.cpp:106] Iteration 51900, lr = 0.01
I0312 16:23:32.740422  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_52000.caffemodel
I0312 16:23:32.770422  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_52000.solverstate
I0312 16:23:32.775424  1600 solver.cpp:337] Iteration 52000, Testing net (#0)
I0312 16:23:32.775424  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:23:36.512717  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6162
I0312 16:23:36.512717  1600 solver.cpp:404]     Test net output #1: loss = 1.49023 (* 1 = 1.49023 loss)
I0312 16:23:36.552906  1600 solver.cpp:228] Iteration 52000, loss = 0.77113
I0312 16:23:36.552906  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:23:36.552906  1600 solver.cpp:244]     Train net output #1: loss = 0.77113 (* 1 = 0.77113 loss)
I0312 16:23:36.552906  1600 sgd_solver.cpp:106] Iteration 52000, lr = 0.01
I0312 16:23:45.615140  1600 solver.cpp:228] Iteration 52100, loss = 0.79736
I0312 16:23:45.615633  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:23:45.615633  1600 solver.cpp:244]     Train net output #1: loss = 0.79736 (* 1 = 0.79736 loss)
I0312 16:23:45.615633  1600 sgd_solver.cpp:106] Iteration 52100, lr = 0.01
I0312 16:23:54.759814  1600 solver.cpp:228] Iteration 52200, loss = 0.875462
I0312 16:23:54.760313  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:23:54.760313  1600 solver.cpp:244]     Train net output #1: loss = 0.875462 (* 1 = 0.875462 loss)
I0312 16:23:54.760313  1600 sgd_solver.cpp:106] Iteration 52200, lr = 0.01
I0312 16:24:03.948393  1600 solver.cpp:228] Iteration 52300, loss = 0.730207
I0312 16:24:03.948393  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:24:03.948393  1600 solver.cpp:244]     Train net output #1: loss = 0.730207 (* 1 = 0.730207 loss)
I0312 16:24:03.948393  1600 sgd_solver.cpp:106] Iteration 52300, lr = 0.01
I0312 16:24:13.108158  1600 solver.cpp:228] Iteration 52400, loss = 0.946605
I0312 16:24:13.108158  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.625
I0312 16:24:13.108158  1600 solver.cpp:244]     Train net output #1: loss = 0.946605 (* 1 = 0.946605 loss)
I0312 16:24:13.108158  1600 sgd_solver.cpp:106] Iteration 52400, lr = 0.01
I0312 16:24:22.287340  1600 solver.cpp:228] Iteration 52500, loss = 0.783614
I0312 16:24:22.287340  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:24:22.287340  1600 solver.cpp:244]     Train net output #1: loss = 0.783614 (* 1 = 0.783614 loss)
I0312 16:24:22.287340  1600 sgd_solver.cpp:106] Iteration 52500, lr = 0.01
I0312 16:24:31.363742  1600 solver.cpp:228] Iteration 52600, loss = 0.879014
I0312 16:24:31.363742  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:24:31.363742  1600 solver.cpp:244]     Train net output #1: loss = 0.879014 (* 1 = 0.879014 loss)
I0312 16:24:31.363742  1600 sgd_solver.cpp:106] Iteration 52600, lr = 0.01
I0312 16:24:40.504988  1600 solver.cpp:228] Iteration 52700, loss = 0.91241
I0312 16:24:40.504988  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:24:40.504988  1600 solver.cpp:244]     Train net output #1: loss = 0.91241 (* 1 = 0.91241 loss)
I0312 16:24:40.504988  1600 sgd_solver.cpp:106] Iteration 52700, lr = 0.01
I0312 16:24:49.623667  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_52800.caffemodel
I0312 16:24:49.640669  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_52800.solverstate
I0312 16:24:49.645668  1600 solver.cpp:337] Iteration 52800, Testing net (#0)
I0312 16:24:49.645668  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:24:53.436305  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6205
I0312 16:24:53.436305  1600 solver.cpp:404]     Test net output #1: loss = 1.49064 (* 1 = 1.49064 loss)
I0312 16:24:53.453305  1600 solver.cpp:228] Iteration 52800, loss = 0.61985
I0312 16:24:53.453305  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:24:53.453305  1600 solver.cpp:244]     Train net output #1: loss = 0.61985 (* 1 = 0.61985 loss)
I0312 16:24:53.453305  1600 sgd_solver.cpp:106] Iteration 52800, lr = 0.01
I0312 16:25:02.606834  1600 solver.cpp:228] Iteration 52900, loss = 0.793073
I0312 16:25:02.606834  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:25:02.606834  1600 solver.cpp:244]     Train net output #1: loss = 0.793073 (* 1 = 0.793073 loss)
I0312 16:25:02.606834  1600 sgd_solver.cpp:106] Iteration 52900, lr = 0.01
I0312 16:25:11.705641  1600 solver.cpp:228] Iteration 53000, loss = 0.469602
I0312 16:25:11.705641  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 16:25:11.705641  1600 solver.cpp:244]     Train net output #1: loss = 0.469602 (* 1 = 0.469602 loss)
I0312 16:25:11.705641  1600 sgd_solver.cpp:106] Iteration 53000, lr = 0.01
I0312 16:25:20.809273  1600 solver.cpp:228] Iteration 53100, loss = 0.683024
I0312 16:25:20.809273  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:25:20.809273  1600 solver.cpp:244]     Train net output #1: loss = 0.683024 (* 1 = 0.683024 loss)
I0312 16:25:20.809273  1600 sgd_solver.cpp:106] Iteration 53100, lr = 0.01
I0312 16:25:29.937500  1600 solver.cpp:228] Iteration 53200, loss = 1.13567
I0312 16:25:29.937500  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:25:29.937996  1600 solver.cpp:244]     Train net output #1: loss = 1.13567 (* 1 = 1.13567 loss)
I0312 16:25:29.937996  1600 sgd_solver.cpp:106] Iteration 53200, lr = 0.01
I0312 16:25:38.951495  1600 solver.cpp:228] Iteration 53300, loss = 0.892827
I0312 16:25:38.951495  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:25:38.951495  1600 solver.cpp:244]     Train net output #1: loss = 0.892827 (* 1 = 0.892827 loss)
I0312 16:25:38.951495  1600 sgd_solver.cpp:106] Iteration 53300, lr = 0.01
I0312 16:25:48.138684  1600 solver.cpp:228] Iteration 53400, loss = 0.71885
I0312 16:25:48.138684  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:25:48.138684  1600 solver.cpp:244]     Train net output #1: loss = 0.71885 (* 1 = 0.71885 loss)
I0312 16:25:48.138684  1600 sgd_solver.cpp:106] Iteration 53400, lr = 0.01
I0312 16:25:57.210502  1600 solver.cpp:228] Iteration 53500, loss = 0.854463
I0312 16:25:57.210502  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:25:57.210502  1600 solver.cpp:244]     Train net output #1: loss = 0.854463 (* 1 = 0.854463 loss)
I0312 16:25:57.210502  1600 sgd_solver.cpp:106] Iteration 53500, lr = 0.01
I0312 16:26:06.351227  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_53600.caffemodel
I0312 16:26:06.370223  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_53600.solverstate
I0312 16:26:06.375723  1600 solver.cpp:337] Iteration 53600, Testing net (#0)
I0312 16:26:06.375723  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:26:10.039765  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6193
I0312 16:26:10.039765  1600 solver.cpp:404]     Test net output #1: loss = 1.50025 (* 1 = 1.50025 loss)
I0312 16:26:10.079813  1600 solver.cpp:228] Iteration 53600, loss = 0.778493
I0312 16:26:10.079813  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:26:10.079813  1600 solver.cpp:244]     Train net output #1: loss = 0.778493 (* 1 = 0.778493 loss)
I0312 16:26:10.079813  1600 sgd_solver.cpp:106] Iteration 53600, lr = 0.01
I0312 16:26:19.226188  1600 solver.cpp:228] Iteration 53700, loss = 0.817899
I0312 16:26:19.226188  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:26:19.226188  1600 solver.cpp:244]     Train net output #1: loss = 0.817899 (* 1 = 0.817899 loss)
I0312 16:26:19.226188  1600 sgd_solver.cpp:106] Iteration 53700, lr = 0.01
I0312 16:26:28.290935  1600 solver.cpp:228] Iteration 53800, loss = 0.801728
I0312 16:26:28.291425  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:26:28.291425  1600 solver.cpp:244]     Train net output #1: loss = 0.801728 (* 1 = 0.801728 loss)
I0312 16:26:28.291425  1600 sgd_solver.cpp:106] Iteration 53800, lr = 0.01
I0312 16:26:35.939368  1600 solver.cpp:228] Iteration 53900, loss = 1.09786
I0312 16:26:35.939368  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:26:35.939368  1600 solver.cpp:244]     Train net output #1: loss = 1.09786 (* 1 = 1.09786 loss)
I0312 16:26:35.939368  1600 sgd_solver.cpp:106] Iteration 53900, lr = 0.01
I0312 16:26:41.773303  1600 solver.cpp:228] Iteration 54000, loss = 1.04093
I0312 16:26:41.773802  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:26:41.773802  1600 solver.cpp:244]     Train net output #1: loss = 1.04093 (* 1 = 1.04093 loss)
I0312 16:26:41.773802  1600 sgd_solver.cpp:106] Iteration 54000, lr = 0.01
I0312 16:26:47.573591  1600 solver.cpp:228] Iteration 54100, loss = 0.890824
I0312 16:26:47.573591  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:26:47.573591  1600 solver.cpp:244]     Train net output #1: loss = 0.890824 (* 1 = 0.890824 loss)
I0312 16:26:47.573591  1600 sgd_solver.cpp:106] Iteration 54100, lr = 0.01
I0312 16:26:55.046238  1600 solver.cpp:228] Iteration 54200, loss = 0.846712
I0312 16:26:55.046238  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:26:55.046238  1600 solver.cpp:244]     Train net output #1: loss = 0.846712 (* 1 = 0.846712 loss)
I0312 16:26:55.046238  1600 sgd_solver.cpp:106] Iteration 54200, lr = 0.01
I0312 16:27:04.214570  1600 solver.cpp:228] Iteration 54300, loss = 0.807672
I0312 16:27:04.214570  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:27:04.214570  1600 solver.cpp:244]     Train net output #1: loss = 0.807672 (* 1 = 0.807672 loss)
I0312 16:27:04.214570  1600 sgd_solver.cpp:106] Iteration 54300, lr = 0.01
I0312 16:27:13.021546  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_54400.caffemodel
I0312 16:27:13.036525  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_54400.solverstate
I0312 16:27:13.042029  1600 solver.cpp:337] Iteration 54400, Testing net (#0)
I0312 16:27:13.042029  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:27:16.761868  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6175
I0312 16:27:16.761868  1600 solver.cpp:404]     Test net output #1: loss = 1.50241 (* 1 = 1.50241 loss)
I0312 16:27:16.806365  1600 solver.cpp:228] Iteration 54400, loss = 0.613386
I0312 16:27:16.806365  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:27:16.806365  1600 solver.cpp:244]     Train net output #1: loss = 0.613386 (* 1 = 0.613386 loss)
I0312 16:27:16.806365  1600 sgd_solver.cpp:106] Iteration 54400, lr = 0.01
I0312 16:27:25.915508  1600 solver.cpp:228] Iteration 54500, loss = 0.850072
I0312 16:27:25.915508  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:27:25.915508  1600 solver.cpp:244]     Train net output #1: loss = 0.850072 (* 1 = 0.850072 loss)
I0312 16:27:25.915508  1600 sgd_solver.cpp:106] Iteration 54500, lr = 0.01
I0312 16:27:34.932768  1600 solver.cpp:228] Iteration 54600, loss = 0.92299
I0312 16:27:34.932768  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:27:34.932768  1600 solver.cpp:244]     Train net output #1: loss = 0.92299 (* 1 = 0.92299 loss)
I0312 16:27:34.932768  1600 sgd_solver.cpp:106] Iteration 54600, lr = 0.01
I0312 16:27:43.976444  1600 solver.cpp:228] Iteration 54700, loss = 0.704561
I0312 16:27:43.976444  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:27:43.976944  1600 solver.cpp:244]     Train net output #1: loss = 0.704561 (* 1 = 0.704561 loss)
I0312 16:27:43.976944  1600 sgd_solver.cpp:106] Iteration 54700, lr = 0.01
I0312 16:27:53.111155  1600 solver.cpp:228] Iteration 54800, loss = 0.642855
I0312 16:27:53.111155  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:27:53.111155  1600 solver.cpp:244]     Train net output #1: loss = 0.642855 (* 1 = 0.642855 loss)
I0312 16:27:53.111155  1600 sgd_solver.cpp:106] Iteration 54800, lr = 0.01
I0312 16:28:02.344472  1600 solver.cpp:228] Iteration 54900, loss = 0.95616
I0312 16:28:02.344472  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:28:02.344472  1600 solver.cpp:244]     Train net output #1: loss = 0.95616 (* 1 = 0.95616 loss)
I0312 16:28:02.344472  1600 sgd_solver.cpp:106] Iteration 54900, lr = 0.01
I0312 16:28:11.389088  1600 solver.cpp:228] Iteration 55000, loss = 0.862913
I0312 16:28:11.389088  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:28:11.389088  1600 solver.cpp:244]     Train net output #1: loss = 0.862913 (* 1 = 0.862913 loss)
I0312 16:28:11.389088  1600 sgd_solver.cpp:106] Iteration 55000, lr = 0.01
I0312 16:28:20.528019  1600 solver.cpp:228] Iteration 55100, loss = 1.00096
I0312 16:28:20.528019  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:28:20.528019  1600 solver.cpp:244]     Train net output #1: loss = 1.00096 (* 1 = 1.00096 loss)
I0312 16:28:20.528019  1600 sgd_solver.cpp:106] Iteration 55100, lr = 0.01
I0312 16:28:29.642302  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_55200.caffemodel
I0312 16:28:29.658284  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_55200.solverstate
I0312 16:28:29.663784  1600 solver.cpp:337] Iteration 55200, Testing net (#0)
I0312 16:28:29.663784  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:28:33.403863  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6183
I0312 16:28:33.403863  1600 solver.cpp:404]     Test net output #1: loss = 1.5018 (* 1 = 1.5018 loss)
I0312 16:28:33.428367  1600 solver.cpp:228] Iteration 55200, loss = 0.975173
I0312 16:28:33.428367  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:28:33.428367  1600 solver.cpp:244]     Train net output #1: loss = 0.975173 (* 1 = 0.975173 loss)
I0312 16:28:33.428367  1600 sgd_solver.cpp:106] Iteration 55200, lr = 0.01
I0312 16:28:42.318128  1600 solver.cpp:228] Iteration 55300, loss = 0.549884
I0312 16:28:42.318128  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:28:42.318128  1600 solver.cpp:244]     Train net output #1: loss = 0.549884 (* 1 = 0.549884 loss)
I0312 16:28:42.318128  1600 sgd_solver.cpp:106] Iteration 55300, lr = 0.01
I0312 16:28:51.388391  1600 solver.cpp:228] Iteration 55400, loss = 0.791747
I0312 16:28:51.388391  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:28:51.388391  1600 solver.cpp:244]     Train net output #1: loss = 0.791747 (* 1 = 0.791747 loss)
I0312 16:28:51.388391  1600 sgd_solver.cpp:106] Iteration 55400, lr = 0.01
I0312 16:29:00.595288  1600 solver.cpp:228] Iteration 55500, loss = 0.641355
I0312 16:29:00.595288  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:29:00.595288  1600 solver.cpp:244]     Train net output #1: loss = 0.641355 (* 1 = 0.641355 loss)
I0312 16:29:00.595288  1600 sgd_solver.cpp:106] Iteration 55500, lr = 0.01
I0312 16:29:09.723553  1600 solver.cpp:228] Iteration 55600, loss = 0.702324
I0312 16:29:09.723553  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:29:09.723553  1600 solver.cpp:244]     Train net output #1: loss = 0.702324 (* 1 = 0.702324 loss)
I0312 16:29:09.723553  1600 sgd_solver.cpp:106] Iteration 55600, lr = 0.01
I0312 16:29:18.828263  1600 solver.cpp:228] Iteration 55700, loss = 0.543744
I0312 16:29:18.828263  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:29:18.828263  1600 solver.cpp:244]     Train net output #1: loss = 0.543744 (* 1 = 0.543744 loss)
I0312 16:29:18.828263  1600 sgd_solver.cpp:106] Iteration 55700, lr = 0.01
I0312 16:29:28.041013  1600 solver.cpp:228] Iteration 55800, loss = 0.494057
I0312 16:29:28.041013  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:29:28.041013  1600 solver.cpp:244]     Train net output #1: loss = 0.494057 (* 1 = 0.494057 loss)
I0312 16:29:28.041013  1600 sgd_solver.cpp:106] Iteration 55800, lr = 0.01
I0312 16:29:37.095728  1600 solver.cpp:228] Iteration 55900, loss = 0.796519
I0312 16:29:37.095728  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:29:37.095728  1600 solver.cpp:244]     Train net output #1: loss = 0.796519 (* 1 = 0.796519 loss)
I0312 16:29:37.095728  1600 sgd_solver.cpp:106] Iteration 55900, lr = 0.01
I0312 16:29:46.332818  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_56000.caffemodel
I0312 16:29:46.349795  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_56000.solverstate
I0312 16:29:46.354796  1600 solver.cpp:337] Iteration 56000, Testing net (#0)
I0312 16:29:46.354796  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:29:49.993516  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6171
I0312 16:29:49.993516  1600 solver.cpp:404]     Test net output #1: loss = 1.51234 (* 1 = 1.51234 loss)
I0312 16:29:50.025001  1600 solver.cpp:228] Iteration 56000, loss = 0.835681
I0312 16:29:50.025501  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:29:50.025501  1600 solver.cpp:244]     Train net output #1: loss = 0.835681 (* 1 = 0.835681 loss)
I0312 16:29:50.025501  1600 sgd_solver.cpp:106] Iteration 56000, lr = 0.01
I0312 16:29:59.176342  1600 solver.cpp:228] Iteration 56100, loss = 0.919819
I0312 16:29:59.176826  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:29:59.176826  1600 solver.cpp:244]     Train net output #1: loss = 0.919819 (* 1 = 0.919819 loss)
I0312 16:29:59.176826  1600 sgd_solver.cpp:106] Iteration 56100, lr = 0.01
I0312 16:30:08.475333  1600 solver.cpp:228] Iteration 56200, loss = 0.90467
I0312 16:30:08.475333  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:30:08.475333  1600 solver.cpp:244]     Train net output #1: loss = 0.90467 (* 1 = 0.90467 loss)
I0312 16:30:08.475333  1600 sgd_solver.cpp:106] Iteration 56200, lr = 0.01
I0312 16:30:17.672080  1600 solver.cpp:228] Iteration 56300, loss = 0.989174
I0312 16:30:17.672080  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:30:17.672080  1600 solver.cpp:244]     Train net output #1: loss = 0.989174 (* 1 = 0.989174 loss)
I0312 16:30:17.672080  1600 sgd_solver.cpp:106] Iteration 56300, lr = 0.01
I0312 16:30:26.738742  1600 solver.cpp:228] Iteration 56400, loss = 0.955987
I0312 16:30:26.738742  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:30:26.738742  1600 solver.cpp:244]     Train net output #1: loss = 0.955987 (* 1 = 0.955987 loss)
I0312 16:30:26.738742  1600 sgd_solver.cpp:106] Iteration 56400, lr = 0.01
I0312 16:30:35.933682  1600 solver.cpp:228] Iteration 56500, loss = 0.630555
I0312 16:30:35.933682  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:30:35.933682  1600 solver.cpp:244]     Train net output #1: loss = 0.630555 (* 1 = 0.630555 loss)
I0312 16:30:35.933682  1600 sgd_solver.cpp:106] Iteration 56500, lr = 0.01
I0312 16:30:45.067066  1600 solver.cpp:228] Iteration 56600, loss = 0.612697
I0312 16:30:45.067066  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:30:45.067066  1600 solver.cpp:244]     Train net output #1: loss = 0.612697 (* 1 = 0.612697 loss)
I0312 16:30:45.067066  1600 sgd_solver.cpp:106] Iteration 56600, lr = 0.01
I0312 16:30:54.073695  1600 solver.cpp:228] Iteration 56700, loss = 0.647648
I0312 16:30:54.073695  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:30:54.073695  1600 solver.cpp:244]     Train net output #1: loss = 0.647648 (* 1 = 0.647648 loss)
I0312 16:30:54.073695  1600 sgd_solver.cpp:106] Iteration 56700, lr = 0.01
I0312 16:31:03.140050  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_56800.caffemodel
I0312 16:31:03.167050  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_56800.solverstate
I0312 16:31:03.172050  1600 solver.cpp:337] Iteration 56800, Testing net (#0)
I0312 16:31:03.172050  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:31:06.818806  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6193
I0312 16:31:06.818806  1600 solver.cpp:404]     Test net output #1: loss = 1.51506 (* 1 = 1.51506 loss)
I0312 16:31:06.828815  1600 solver.cpp:228] Iteration 56800, loss = 0.692297
I0312 16:31:06.828815  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:31:06.828815  1600 solver.cpp:244]     Train net output #1: loss = 0.692297 (* 1 = 0.692297 loss)
I0312 16:31:06.828815  1600 sgd_solver.cpp:106] Iteration 56800, lr = 0.01
I0312 16:31:16.020421  1600 solver.cpp:228] Iteration 56900, loss = 0.72731
I0312 16:31:16.020421  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:31:16.020421  1600 solver.cpp:244]     Train net output #1: loss = 0.72731 (* 1 = 0.72731 loss)
I0312 16:31:16.020421  1600 sgd_solver.cpp:106] Iteration 56900, lr = 0.01
I0312 16:31:25.002954  1600 solver.cpp:228] Iteration 57000, loss = 0.772033
I0312 16:31:25.002954  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:31:25.002954  1600 solver.cpp:244]     Train net output #1: loss = 0.772033 (* 1 = 0.772033 loss)
I0312 16:31:25.002954  1600 sgd_solver.cpp:106] Iteration 57000, lr = 0.01
I0312 16:31:33.981907  1600 solver.cpp:228] Iteration 57100, loss = 1.16712
I0312 16:31:33.981907  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:31:33.981907  1600 solver.cpp:244]     Train net output #1: loss = 1.16712 (* 1 = 1.16712 loss)
I0312 16:31:33.981907  1600 sgd_solver.cpp:106] Iteration 57100, lr = 0.01
I0312 16:31:41.159512  1600 solver.cpp:228] Iteration 57200, loss = 1.03917
I0312 16:31:41.159512  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:31:41.159512  1600 solver.cpp:244]     Train net output #1: loss = 1.03917 (* 1 = 1.03917 loss)
I0312 16:31:41.159512  1600 sgd_solver.cpp:106] Iteration 57200, lr = 0.01
I0312 16:31:46.941411  1600 solver.cpp:228] Iteration 57300, loss = 0.728398
I0312 16:31:46.941411  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:31:46.941411  1600 solver.cpp:244]     Train net output #1: loss = 0.728398 (* 1 = 0.728398 loss)
I0312 16:31:46.941411  1600 sgd_solver.cpp:106] Iteration 57300, lr = 0.01
I0312 16:31:52.752840  1600 solver.cpp:228] Iteration 57400, loss = 1.15624
I0312 16:31:52.752840  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:31:52.752840  1600 solver.cpp:244]     Train net output #1: loss = 1.15624 (* 1 = 1.15624 loss)
I0312 16:31:52.752840  1600 sgd_solver.cpp:106] Iteration 57400, lr = 0.01
I0312 16:32:00.349730  1600 solver.cpp:228] Iteration 57500, loss = 0.769246
I0312 16:32:00.349730  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:32:00.349730  1600 solver.cpp:244]     Train net output #1: loss = 0.769246 (* 1 = 0.769246 loss)
I0312 16:32:00.349730  1600 sgd_solver.cpp:106] Iteration 57500, lr = 0.01
I0312 16:32:09.286314  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_57600.caffemodel
I0312 16:32:09.301306  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_57600.solverstate
I0312 16:32:09.306305  1600 solver.cpp:337] Iteration 57600, Testing net (#0)
I0312 16:32:09.306805  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:32:12.973527  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6195
I0312 16:32:12.973527  1600 solver.cpp:404]     Test net output #1: loss = 1.50237 (* 1 = 1.50237 loss)
I0312 16:32:13.003530  1600 solver.cpp:228] Iteration 57600, loss = 1.20804
I0312 16:32:13.003530  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:32:13.003530  1600 solver.cpp:244]     Train net output #1: loss = 1.20804 (* 1 = 1.20804 loss)
I0312 16:32:13.003530  1600 sgd_solver.cpp:106] Iteration 57600, lr = 0.01
I0312 16:32:22.078143  1600 solver.cpp:228] Iteration 57700, loss = 0.906591
I0312 16:32:22.078143  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:32:22.078143  1600 solver.cpp:244]     Train net output #1: loss = 0.906591 (* 1 = 0.906591 loss)
I0312 16:32:22.078143  1600 sgd_solver.cpp:106] Iteration 57700, lr = 0.01
I0312 16:32:31.170469  1600 solver.cpp:228] Iteration 57800, loss = 0.975731
I0312 16:32:31.170469  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:32:31.170469  1600 solver.cpp:244]     Train net output #1: loss = 0.97573 (* 1 = 0.97573 loss)
I0312 16:32:31.170469  1600 sgd_solver.cpp:106] Iteration 57800, lr = 0.01
I0312 16:32:40.280737  1600 solver.cpp:228] Iteration 57900, loss = 0.704492
I0312 16:32:40.280737  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:32:40.280737  1600 solver.cpp:244]     Train net output #1: loss = 0.704492 (* 1 = 0.704492 loss)
I0312 16:32:40.280737  1600 sgd_solver.cpp:106] Iteration 57900, lr = 0.01
I0312 16:32:49.374501  1600 solver.cpp:228] Iteration 58000, loss = 0.673782
I0312 16:32:49.374501  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:32:49.374501  1600 solver.cpp:244]     Train net output #1: loss = 0.673782 (* 1 = 0.673782 loss)
I0312 16:32:49.374501  1600 sgd_solver.cpp:106] Iteration 58000, lr = 0.01
I0312 16:32:58.288558  1600 solver.cpp:228] Iteration 58100, loss = 0.742566
I0312 16:32:58.289053  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:32:58.289053  1600 solver.cpp:244]     Train net output #1: loss = 0.742566 (* 1 = 0.742566 loss)
I0312 16:32:58.289053  1600 sgd_solver.cpp:106] Iteration 58100, lr = 0.01
I0312 16:33:07.283826  1600 solver.cpp:228] Iteration 58200, loss = 0.836788
I0312 16:33:07.283826  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:33:07.283826  1600 solver.cpp:244]     Train net output #1: loss = 0.836788 (* 1 = 0.836788 loss)
I0312 16:33:07.283826  1600 sgd_solver.cpp:106] Iteration 58200, lr = 0.01
I0312 16:33:16.323806  1600 solver.cpp:228] Iteration 58300, loss = 0.950851
I0312 16:33:16.324306  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:33:16.324306  1600 solver.cpp:244]     Train net output #1: loss = 0.950851 (* 1 = 0.950851 loss)
I0312 16:33:16.324306  1600 sgd_solver.cpp:106] Iteration 58300, lr = 0.01
I0312 16:33:25.225622  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_58400.caffemodel
I0312 16:33:25.238612  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_58400.solverstate
I0312 16:33:25.243613  1600 solver.cpp:337] Iteration 58400, Testing net (#0)
I0312 16:33:25.243613  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:33:28.963214  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6173
I0312 16:33:28.963214  1600 solver.cpp:404]     Test net output #1: loss = 1.50301 (* 1 = 1.50301 loss)
I0312 16:33:29.008214  1600 solver.cpp:228] Iteration 58400, loss = 0.793663
I0312 16:33:29.008214  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:33:29.008214  1600 solver.cpp:244]     Train net output #1: loss = 0.793663 (* 1 = 0.793663 loss)
I0312 16:33:29.008214  1600 sgd_solver.cpp:106] Iteration 58400, lr = 0.01
I0312 16:33:38.094517  1600 solver.cpp:228] Iteration 58500, loss = 0.896122
I0312 16:33:38.094517  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:33:38.094517  1600 solver.cpp:244]     Train net output #1: loss = 0.896122 (* 1 = 0.896122 loss)
I0312 16:33:38.094517  1600 sgd_solver.cpp:106] Iteration 58500, lr = 0.01
I0312 16:33:47.247778  1600 solver.cpp:228] Iteration 58600, loss = 0.656851
I0312 16:33:47.247778  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:33:47.247778  1600 solver.cpp:244]     Train net output #1: loss = 0.65685 (* 1 = 0.65685 loss)
I0312 16:33:47.247778  1600 sgd_solver.cpp:106] Iteration 58600, lr = 0.01
I0312 16:33:56.524405  1600 solver.cpp:228] Iteration 58700, loss = 0.731543
I0312 16:33:56.524405  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:33:56.524405  1600 solver.cpp:244]     Train net output #1: loss = 0.731543 (* 1 = 0.731543 loss)
I0312 16:33:56.524405  1600 sgd_solver.cpp:106] Iteration 58700, lr = 0.01
I0312 16:34:05.643332  1600 solver.cpp:228] Iteration 58800, loss = 0.509252
I0312 16:34:05.643332  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:34:05.643332  1600 solver.cpp:244]     Train net output #1: loss = 0.509251 (* 1 = 0.509251 loss)
I0312 16:34:05.643831  1600 sgd_solver.cpp:106] Iteration 58800, lr = 0.01
I0312 16:34:14.711058  1600 solver.cpp:228] Iteration 58900, loss = 0.736639
I0312 16:34:14.711558  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:34:14.711558  1600 solver.cpp:244]     Train net output #1: loss = 0.736639 (* 1 = 0.736639 loss)
I0312 16:34:14.711558  1600 sgd_solver.cpp:106] Iteration 58900, lr = 0.01
I0312 16:34:23.858142  1600 solver.cpp:228] Iteration 59000, loss = 0.819942
I0312 16:34:23.858142  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:34:23.858142  1600 solver.cpp:244]     Train net output #1: loss = 0.819942 (* 1 = 0.819942 loss)
I0312 16:34:23.858142  1600 sgd_solver.cpp:106] Iteration 59000, lr = 0.01
I0312 16:34:32.906777  1600 solver.cpp:228] Iteration 59100, loss = 0.735085
I0312 16:34:32.906777  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:34:32.906777  1600 solver.cpp:244]     Train net output #1: loss = 0.735084 (* 1 = 0.735084 loss)
I0312 16:34:32.906777  1600 sgd_solver.cpp:106] Iteration 59100, lr = 0.01
I0312 16:34:41.909215  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_59200.caffemodel
I0312 16:34:41.941210  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_59200.solverstate
I0312 16:34:41.946213  1600 solver.cpp:337] Iteration 59200, Testing net (#0)
I0312 16:34:41.946213  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:34:45.626530  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6195
I0312 16:34:45.626530  1600 solver.cpp:404]     Test net output #1: loss = 1.51208 (* 1 = 1.51208 loss)
I0312 16:34:45.644527  1600 solver.cpp:228] Iteration 59200, loss = 0.639103
I0312 16:34:45.644527  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:34:45.644527  1600 solver.cpp:244]     Train net output #1: loss = 0.639103 (* 1 = 0.639103 loss)
I0312 16:34:45.644527  1600 sgd_solver.cpp:106] Iteration 59200, lr = 0.01
I0312 16:34:54.636312  1600 solver.cpp:228] Iteration 59300, loss = 0.700204
I0312 16:34:54.636312  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:34:54.636312  1600 solver.cpp:244]     Train net output #1: loss = 0.700204 (* 1 = 0.700204 loss)
I0312 16:34:54.636312  1600 sgd_solver.cpp:106] Iteration 59300, lr = 0.01
I0312 16:35:03.774904  1600 solver.cpp:228] Iteration 59400, loss = 0.822894
I0312 16:35:03.774904  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:35:03.774904  1600 solver.cpp:244]     Train net output #1: loss = 0.822894 (* 1 = 0.822894 loss)
I0312 16:35:03.774904  1600 sgd_solver.cpp:106] Iteration 59400, lr = 0.01
I0312 16:35:12.750388  1600 solver.cpp:228] Iteration 59500, loss = 0.667125
I0312 16:35:12.750388  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:35:12.750388  1600 solver.cpp:244]     Train net output #1: loss = 0.667125 (* 1 = 0.667125 loss)
I0312 16:35:12.750388  1600 sgd_solver.cpp:106] Iteration 59500, lr = 0.01
I0312 16:35:21.804539  1600 solver.cpp:228] Iteration 59600, loss = 0.945824
I0312 16:35:21.804539  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:35:21.804539  1600 solver.cpp:244]     Train net output #1: loss = 0.945824 (* 1 = 0.945824 loss)
I0312 16:35:21.804539  1600 sgd_solver.cpp:106] Iteration 59600, lr = 0.01
I0312 16:35:30.622788  1600 solver.cpp:228] Iteration 59700, loss = 0.831564
I0312 16:35:30.623287  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:35:30.623287  1600 solver.cpp:244]     Train net output #1: loss = 0.831563 (* 1 = 0.831563 loss)
I0312 16:35:30.623287  1600 sgd_solver.cpp:106] Iteration 59700, lr = 0.01
I0312 16:35:39.848635  1600 solver.cpp:228] Iteration 59800, loss = 0.943499
I0312 16:35:39.848635  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:35:39.848635  1600 solver.cpp:244]     Train net output #1: loss = 0.943499 (* 1 = 0.943499 loss)
I0312 16:35:39.848635  1600 sgd_solver.cpp:106] Iteration 59800, lr = 0.01
I0312 16:35:49.078095  1600 solver.cpp:228] Iteration 59900, loss = 1.12933
I0312 16:35:49.078095  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:35:49.078095  1600 solver.cpp:244]     Train net output #1: loss = 1.12933 (* 1 = 1.12933 loss)
I0312 16:35:49.078095  1600 sgd_solver.cpp:106] Iteration 59900, lr = 0.01
I0312 16:35:58.241581  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_60000.caffemodel
I0312 16:35:58.260582  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_60000.solverstate
I0312 16:35:58.265081  1600 solver.cpp:337] Iteration 60000, Testing net (#0)
I0312 16:35:58.265081  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:36:01.936849  1600 solver.cpp:404]     Test net output #0: accuracy = 0.621
I0312 16:36:01.936849  1600 solver.cpp:404]     Test net output #1: loss = 1.50232 (* 1 = 1.50232 loss)
I0312 16:36:01.962852  1600 solver.cpp:228] Iteration 60000, loss = 0.948016
I0312 16:36:01.962852  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:36:01.962852  1600 solver.cpp:244]     Train net output #1: loss = 0.948016 (* 1 = 0.948016 loss)
I0312 16:36:01.962852  1600 sgd_solver.cpp:106] Iteration 60000, lr = 0.01
I0312 16:36:11.014237  1600 solver.cpp:228] Iteration 60100, loss = 0.757651
I0312 16:36:11.014237  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:36:11.014237  1600 solver.cpp:244]     Train net output #1: loss = 0.757651 (* 1 = 0.757651 loss)
I0312 16:36:11.014237  1600 sgd_solver.cpp:106] Iteration 60100, lr = 0.01
I0312 16:36:20.075830  1600 solver.cpp:228] Iteration 60200, loss = 0.793551
I0312 16:36:20.075830  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:36:20.075830  1600 solver.cpp:244]     Train net output #1: loss = 0.793551 (* 1 = 0.793551 loss)
I0312 16:36:20.075830  1600 sgd_solver.cpp:106] Iteration 60200, lr = 0.01
I0312 16:36:29.096467  1600 solver.cpp:228] Iteration 60300, loss = 0.523067
I0312 16:36:29.096467  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 16:36:29.096467  1600 solver.cpp:244]     Train net output #1: loss = 0.523067 (* 1 = 0.523067 loss)
I0312 16:36:29.096467  1600 sgd_solver.cpp:106] Iteration 60300, lr = 0.01
I0312 16:36:38.244730  1600 solver.cpp:228] Iteration 60400, loss = 0.776203
I0312 16:36:38.244730  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:36:38.244730  1600 solver.cpp:244]     Train net output #1: loss = 0.776203 (* 1 = 0.776203 loss)
I0312 16:36:38.244730  1600 sgd_solver.cpp:106] Iteration 60400, lr = 0.01
I0312 16:36:45.649812  1600 solver.cpp:228] Iteration 60500, loss = 1.00778
I0312 16:36:45.649812  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:36:45.649812  1600 solver.cpp:244]     Train net output #1: loss = 1.00778 (* 1 = 1.00778 loss)
I0312 16:36:45.649812  1600 sgd_solver.cpp:106] Iteration 60500, lr = 0.01
I0312 16:36:51.463481  1600 solver.cpp:228] Iteration 60600, loss = 0.652493
I0312 16:36:51.463979  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:36:51.463979  1600 solver.cpp:244]     Train net output #1: loss = 0.652493 (* 1 = 0.652493 loss)
I0312 16:36:51.463979  1600 sgd_solver.cpp:106] Iteration 60600, lr = 0.01
I0312 16:36:57.263876  1600 solver.cpp:228] Iteration 60700, loss = 0.670789
I0312 16:36:57.263876  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:36:57.263876  1600 solver.cpp:244]     Train net output #1: loss = 0.670788 (* 1 = 0.670788 loss)
I0312 16:36:57.263876  1600 sgd_solver.cpp:106] Iteration 60700, lr = 0.01
I0312 16:37:04.677031  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_60800.caffemodel
I0312 16:37:04.695523  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_60800.solverstate
I0312 16:37:04.700539  1600 solver.cpp:337] Iteration 60800, Testing net (#0)
I0312 16:37:04.700539  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:37:08.438937  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6168
I0312 16:37:08.438937  1600 solver.cpp:404]     Test net output #1: loss = 1.50542 (* 1 = 1.50542 loss)
I0312 16:37:08.445940  1600 solver.cpp:228] Iteration 60800, loss = 0.582942
I0312 16:37:08.445940  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 16:37:08.445940  1600 solver.cpp:244]     Train net output #1: loss = 0.582941 (* 1 = 0.582941 loss)
I0312 16:37:08.445940  1600 sgd_solver.cpp:106] Iteration 60800, lr = 0.01
I0312 16:37:17.433364  1600 solver.cpp:228] Iteration 60900, loss = 0.460951
I0312 16:37:17.433364  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 16:37:17.433364  1600 solver.cpp:244]     Train net output #1: loss = 0.460951 (* 1 = 0.460951 loss)
I0312 16:37:17.433364  1600 sgd_solver.cpp:106] Iteration 60900, lr = 0.01
I0312 16:37:26.677417  1600 solver.cpp:228] Iteration 61000, loss = 0.81387
I0312 16:37:26.677417  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:37:26.677417  1600 solver.cpp:244]     Train net output #1: loss = 0.81387 (* 1 = 0.81387 loss)
I0312 16:37:26.677417  1600 sgd_solver.cpp:106] Iteration 61000, lr = 0.01
I0312 16:37:35.845880  1600 solver.cpp:228] Iteration 61100, loss = 0.812996
I0312 16:37:35.845880  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:37:35.845880  1600 solver.cpp:244]     Train net output #1: loss = 0.812996 (* 1 = 0.812996 loss)
I0312 16:37:35.845880  1600 sgd_solver.cpp:106] Iteration 61100, lr = 0.01
I0312 16:37:44.694401  1600 solver.cpp:228] Iteration 61200, loss = 0.865676
I0312 16:37:44.694401  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:37:44.694401  1600 solver.cpp:244]     Train net output #1: loss = 0.865676 (* 1 = 0.865676 loss)
I0312 16:37:44.694401  1600 sgd_solver.cpp:106] Iteration 61200, lr = 0.01
I0312 16:37:53.876236  1600 solver.cpp:228] Iteration 61300, loss = 0.808078
I0312 16:37:53.876236  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:37:53.876236  1600 solver.cpp:244]     Train net output #1: loss = 0.808078 (* 1 = 0.808078 loss)
I0312 16:37:53.876236  1600 sgd_solver.cpp:106] Iteration 61300, lr = 0.01
I0312 16:38:02.940645  1600 solver.cpp:228] Iteration 61400, loss = 0.557061
I0312 16:38:02.940645  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:38:02.940645  1600 solver.cpp:244]     Train net output #1: loss = 0.557061 (* 1 = 0.557061 loss)
I0312 16:38:02.940645  1600 sgd_solver.cpp:106] Iteration 61400, lr = 0.01
I0312 16:38:11.746363  1600 solver.cpp:228] Iteration 61500, loss = 0.74298
I0312 16:38:11.746363  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:38:11.746363  1600 solver.cpp:244]     Train net output #1: loss = 0.74298 (* 1 = 0.74298 loss)
I0312 16:38:11.746363  1600 sgd_solver.cpp:106] Iteration 61500, lr = 0.01
I0312 16:38:20.841547  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_61600.caffemodel
I0312 16:38:20.857547  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_61600.solverstate
I0312 16:38:20.862547  1600 solver.cpp:337] Iteration 61600, Testing net (#0)
I0312 16:38:20.862547  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:38:24.566898  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6171
I0312 16:38:24.567399  1600 solver.cpp:404]     Test net output #1: loss = 1.51131 (* 1 = 1.51131 loss)
I0312 16:38:24.608899  1600 solver.cpp:228] Iteration 61600, loss = 0.948208
I0312 16:38:24.608899  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:38:24.608899  1600 solver.cpp:244]     Train net output #1: loss = 0.948208 (* 1 = 0.948208 loss)
I0312 16:38:24.608899  1600 sgd_solver.cpp:106] Iteration 61600, lr = 0.01
I0312 16:38:33.599324  1600 solver.cpp:228] Iteration 61700, loss = 0.793524
I0312 16:38:33.599324  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:38:33.599324  1600 solver.cpp:244]     Train net output #1: loss = 0.793524 (* 1 = 0.793524 loss)
I0312 16:38:33.599324  1600 sgd_solver.cpp:106] Iteration 61700, lr = 0.01
I0312 16:38:42.592381  1600 solver.cpp:228] Iteration 61800, loss = 0.85652
I0312 16:38:42.592381  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:38:42.592381  1600 solver.cpp:244]     Train net output #1: loss = 0.85652 (* 1 = 0.85652 loss)
I0312 16:38:42.592381  1600 sgd_solver.cpp:106] Iteration 61800, lr = 0.01
I0312 16:38:51.589872  1600 solver.cpp:228] Iteration 61900, loss = 0.542478
I0312 16:38:51.589872  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:38:51.589872  1600 solver.cpp:244]     Train net output #1: loss = 0.542478 (* 1 = 0.542478 loss)
I0312 16:38:51.589872  1600 sgd_solver.cpp:106] Iteration 61900, lr = 0.01
I0312 16:39:00.861958  1600 solver.cpp:228] Iteration 62000, loss = 0.936766
I0312 16:39:00.861958  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:39:00.861958  1600 solver.cpp:244]     Train net output #1: loss = 0.936766 (* 1 = 0.936766 loss)
I0312 16:39:00.861958  1600 sgd_solver.cpp:106] Iteration 62000, lr = 0.01
I0312 16:39:09.830509  1600 solver.cpp:228] Iteration 62100, loss = 0.872506
I0312 16:39:09.831009  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:39:09.831009  1600 solver.cpp:244]     Train net output #1: loss = 0.872506 (* 1 = 0.872506 loss)
I0312 16:39:09.831009  1600 sgd_solver.cpp:106] Iteration 62100, lr = 0.01
I0312 16:39:18.791755  1600 solver.cpp:228] Iteration 62200, loss = 0.711783
I0312 16:39:18.791755  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:39:18.791755  1600 solver.cpp:244]     Train net output #1: loss = 0.711783 (* 1 = 0.711783 loss)
I0312 16:39:18.791755  1600 sgd_solver.cpp:106] Iteration 62200, lr = 0.01
I0312 16:39:27.944391  1600 solver.cpp:228] Iteration 62300, loss = 0.821918
I0312 16:39:27.944391  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:39:27.944391  1600 solver.cpp:244]     Train net output #1: loss = 0.821918 (* 1 = 0.821918 loss)
I0312 16:39:27.944391  1600 sgd_solver.cpp:106] Iteration 62300, lr = 0.01
I0312 16:39:37.016021  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_62400.caffemodel
I0312 16:39:37.037519  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_62400.solverstate
I0312 16:39:37.042019  1600 solver.cpp:337] Iteration 62400, Testing net (#0)
I0312 16:39:37.042019  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:39:40.816073  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6193
I0312 16:39:40.816073  1600 solver.cpp:404]     Test net output #1: loss = 1.51516 (* 1 = 1.51516 loss)
I0312 16:39:40.836073  1600 solver.cpp:228] Iteration 62400, loss = 0.929433
I0312 16:39:40.836073  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:39:40.836073  1600 solver.cpp:244]     Train net output #1: loss = 0.929432 (* 1 = 0.929432 loss)
I0312 16:39:40.836073  1600 sgd_solver.cpp:106] Iteration 62400, lr = 0.01
I0312 16:39:49.905966  1600 solver.cpp:228] Iteration 62500, loss = 0.998384
I0312 16:39:49.906466  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:39:49.906466  1600 solver.cpp:244]     Train net output #1: loss = 0.998384 (* 1 = 0.998384 loss)
I0312 16:39:49.906466  1600 sgd_solver.cpp:106] Iteration 62500, lr = 0.01
I0312 16:39:59.128813  1600 solver.cpp:228] Iteration 62600, loss = 1.00906
I0312 16:39:59.128813  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 16:39:59.128813  1600 solver.cpp:244]     Train net output #1: loss = 1.00906 (* 1 = 1.00906 loss)
I0312 16:39:59.128813  1600 sgd_solver.cpp:106] Iteration 62600, lr = 0.01
I0312 16:40:08.246752  1600 solver.cpp:228] Iteration 62700, loss = 0.638159
I0312 16:40:08.247253  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:40:08.247253  1600 solver.cpp:244]     Train net output #1: loss = 0.638159 (* 1 = 0.638159 loss)
I0312 16:40:08.247253  1600 sgd_solver.cpp:106] Iteration 62700, lr = 0.01
I0312 16:40:17.483291  1600 solver.cpp:228] Iteration 62800, loss = 0.494919
I0312 16:40:17.483291  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:40:17.483291  1600 solver.cpp:244]     Train net output #1: loss = 0.494918 (* 1 = 0.494918 loss)
I0312 16:40:17.483291  1600 sgd_solver.cpp:106] Iteration 62800, lr = 0.01
I0312 16:40:26.644282  1600 solver.cpp:228] Iteration 62900, loss = 0.656087
I0312 16:40:26.644282  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:40:26.644282  1600 solver.cpp:244]     Train net output #1: loss = 0.656087 (* 1 = 0.656087 loss)
I0312 16:40:26.644282  1600 sgd_solver.cpp:106] Iteration 62900, lr = 0.01
I0312 16:40:35.799867  1600 solver.cpp:228] Iteration 63000, loss = 0.776404
I0312 16:40:35.799867  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:40:35.799867  1600 solver.cpp:244]     Train net output #1: loss = 0.776404 (* 1 = 0.776404 loss)
I0312 16:40:35.799867  1600 sgd_solver.cpp:106] Iteration 63000, lr = 0.01
I0312 16:40:44.684936  1600 solver.cpp:228] Iteration 63100, loss = 0.561312
I0312 16:40:44.684936  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:40:44.684936  1600 solver.cpp:244]     Train net output #1: loss = 0.561312 (* 1 = 0.561312 loss)
I0312 16:40:44.684936  1600 sgd_solver.cpp:106] Iteration 63100, lr = 0.01
I0312 16:40:53.635897  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_63200.caffemodel
I0312 16:40:53.658396  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_63200.solverstate
I0312 16:40:53.663895  1600 solver.cpp:337] Iteration 63200, Testing net (#0)
I0312 16:40:53.663895  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:40:57.361280  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6209
I0312 16:40:57.361280  1600 solver.cpp:404]     Test net output #1: loss = 1.52267 (* 1 = 1.52267 loss)
I0312 16:40:57.390789  1600 solver.cpp:228] Iteration 63200, loss = 0.535865
I0312 16:40:57.390789  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 16:40:57.390789  1600 solver.cpp:244]     Train net output #1: loss = 0.535864 (* 1 = 0.535864 loss)
I0312 16:40:57.390789  1600 sgd_solver.cpp:106] Iteration 63200, lr = 0.01
I0312 16:41:06.452018  1600 solver.cpp:228] Iteration 63300, loss = 0.661545
I0312 16:41:06.452018  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:41:06.452018  1600 solver.cpp:244]     Train net output #1: loss = 0.661545 (* 1 = 0.661545 loss)
I0312 16:41:06.452018  1600 sgd_solver.cpp:106] Iteration 63300, lr = 0.01
I0312 16:41:15.491593  1600 solver.cpp:228] Iteration 63400, loss = 0.868078
I0312 16:41:15.491593  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:41:15.491593  1600 solver.cpp:244]     Train net output #1: loss = 0.868077 (* 1 = 0.868077 loss)
I0312 16:41:15.491593  1600 sgd_solver.cpp:106] Iteration 63400, lr = 0.01
I0312 16:41:24.510264  1600 solver.cpp:228] Iteration 63500, loss = 0.81249
I0312 16:41:24.510264  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:41:24.510264  1600 solver.cpp:244]     Train net output #1: loss = 0.81249 (* 1 = 0.81249 loss)
I0312 16:41:24.510264  1600 sgd_solver.cpp:106] Iteration 63500, lr = 0.01
I0312 16:41:33.587263  1600 solver.cpp:228] Iteration 63600, loss = 0.785002
I0312 16:41:33.587263  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:41:33.587263  1600 solver.cpp:244]     Train net output #1: loss = 0.785002 (* 1 = 0.785002 loss)
I0312 16:41:33.587263  1600 sgd_solver.cpp:106] Iteration 63600, lr = 0.01
I0312 16:41:42.517192  1600 solver.cpp:228] Iteration 63700, loss = 0.804827
I0312 16:41:42.517192  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:41:42.517691  1600 solver.cpp:244]     Train net output #1: loss = 0.804827 (* 1 = 0.804827 loss)
I0312 16:41:42.517691  1600 sgd_solver.cpp:106] Iteration 63700, lr = 0.01
I0312 16:41:50.181074  1600 solver.cpp:228] Iteration 63800, loss = 0.662793
I0312 16:41:50.181074  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:41:50.181074  1600 solver.cpp:244]     Train net output #1: loss = 0.662793 (* 1 = 0.662793 loss)
I0312 16:41:50.181074  1600 sgd_solver.cpp:106] Iteration 63800, lr = 0.01
I0312 16:41:56.002403  1600 solver.cpp:228] Iteration 63900, loss = 0.651488
I0312 16:41:56.002403  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:41:56.002403  1600 solver.cpp:244]     Train net output #1: loss = 0.651488 (* 1 = 0.651488 loss)
I0312 16:41:56.002403  1600 sgd_solver.cpp:106] Iteration 63900, lr = 0.01
I0312 16:42:01.773766  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_64000.caffemodel
I0312 16:42:01.783768  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_64000.solverstate
I0312 16:42:01.793766  1600 solver.cpp:337] Iteration 64000, Testing net (#0)
I0312 16:42:01.793766  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:42:04.234593  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6193
I0312 16:42:04.234593  1600 solver.cpp:404]     Test net output #1: loss = 1.52634 (* 1 = 1.52634 loss)
I0312 16:42:04.254590  1600 solver.cpp:228] Iteration 64000, loss = 0.645457
I0312 16:42:04.254590  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:42:04.254590  1600 solver.cpp:244]     Train net output #1: loss = 0.645457 (* 1 = 0.645457 loss)
I0312 16:42:04.254590  1600 sgd_solver.cpp:106] Iteration 64000, lr = 0.01
I0312 16:42:12.994895  1600 solver.cpp:228] Iteration 64100, loss = 1.01117
I0312 16:42:12.994895  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:42:12.994895  1600 solver.cpp:244]     Train net output #1: loss = 1.01117 (* 1 = 1.01117 loss)
I0312 16:42:12.994895  1600 sgd_solver.cpp:106] Iteration 64100, lr = 0.01
I0312 16:42:22.195775  1600 solver.cpp:228] Iteration 64200, loss = 1.02154
I0312 16:42:22.195775  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 16:42:22.195775  1600 solver.cpp:244]     Train net output #1: loss = 1.02154 (* 1 = 1.02154 loss)
I0312 16:42:22.195775  1600 sgd_solver.cpp:106] Iteration 64200, lr = 0.01
I0312 16:42:31.240439  1600 solver.cpp:228] Iteration 64300, loss = 0.680658
I0312 16:42:31.240439  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:42:31.240439  1600 solver.cpp:244]     Train net output #1: loss = 0.680658 (* 1 = 0.680658 loss)
I0312 16:42:31.240439  1600 sgd_solver.cpp:106] Iteration 64300, lr = 0.01
I0312 16:42:40.195516  1600 solver.cpp:228] Iteration 64400, loss = 0.793196
I0312 16:42:40.195516  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:42:40.195516  1600 solver.cpp:244]     Train net output #1: loss = 0.793196 (* 1 = 0.793196 loss)
I0312 16:42:40.195516  1600 sgd_solver.cpp:106] Iteration 64400, lr = 0.01
I0312 16:42:49.485116  1600 solver.cpp:228] Iteration 64500, loss = 0.62967
I0312 16:42:49.485617  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:42:49.485617  1600 solver.cpp:244]     Train net output #1: loss = 0.62967 (* 1 = 0.62967 loss)
I0312 16:42:49.485617  1600 sgd_solver.cpp:106] Iteration 64500, lr = 0.01
I0312 16:42:58.568714  1600 solver.cpp:228] Iteration 64600, loss = 0.788029
I0312 16:42:58.568714  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:42:58.568714  1600 solver.cpp:244]     Train net output #1: loss = 0.788029 (* 1 = 0.788029 loss)
I0312 16:42:58.568714  1600 sgd_solver.cpp:106] Iteration 64600, lr = 0.01
I0312 16:43:07.720058  1600 solver.cpp:228] Iteration 64700, loss = 0.97872
I0312 16:43:07.720058  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:43:07.720058  1600 solver.cpp:244]     Train net output #1: loss = 0.97872 (* 1 = 0.97872 loss)
I0312 16:43:07.720058  1600 sgd_solver.cpp:106] Iteration 64700, lr = 0.01
I0312 16:43:16.752398  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_64800.caffemodel
I0312 16:43:16.767398  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_64800.solverstate
I0312 16:43:16.772398  1600 solver.cpp:337] Iteration 64800, Testing net (#0)
I0312 16:43:16.772398  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:43:20.448947  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6204
I0312 16:43:20.449434  1600 solver.cpp:404]     Test net output #1: loss = 1.52306 (* 1 = 1.52306 loss)
I0312 16:43:20.465454  1600 solver.cpp:228] Iteration 64800, loss = 0.723139
I0312 16:43:20.465454  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:43:20.465454  1600 solver.cpp:244]     Train net output #1: loss = 0.723139 (* 1 = 0.723139 loss)
I0312 16:43:20.465454  1600 sgd_solver.cpp:106] Iteration 64800, lr = 0.01
I0312 16:43:29.592270  1600 solver.cpp:228] Iteration 64900, loss = 0.614427
I0312 16:43:29.592270  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:43:29.592775  1600 solver.cpp:244]     Train net output #1: loss = 0.614427 (* 1 = 0.614427 loss)
I0312 16:43:29.592775  1600 sgd_solver.cpp:106] Iteration 64900, lr = 0.01
I0312 16:43:38.588945  1600 solver.cpp:228] Iteration 65000, loss = 0.765651
I0312 16:43:38.588945  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:43:38.588945  1600 solver.cpp:244]     Train net output #1: loss = 0.765651 (* 1 = 0.765651 loss)
I0312 16:43:38.588945  1600 sgd_solver.cpp:106] Iteration 65000, lr = 0.01
I0312 16:43:47.542587  1600 solver.cpp:228] Iteration 65100, loss = 1.00051
I0312 16:43:47.542587  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:43:47.543084  1600 solver.cpp:244]     Train net output #1: loss = 1.00051 (* 1 = 1.00051 loss)
I0312 16:43:47.543084  1600 sgd_solver.cpp:106] Iteration 65100, lr = 0.01
I0312 16:43:56.849238  1600 solver.cpp:228] Iteration 65200, loss = 0.766457
I0312 16:43:56.849238  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:43:56.849238  1600 solver.cpp:244]     Train net output #1: loss = 0.766457 (* 1 = 0.766457 loss)
I0312 16:43:56.849238  1600 sgd_solver.cpp:106] Iteration 65200, lr = 0.01
I0312 16:44:05.867019  1600 solver.cpp:228] Iteration 65300, loss = 0.713207
I0312 16:44:05.867019  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:44:05.867019  1600 solver.cpp:244]     Train net output #1: loss = 0.713207 (* 1 = 0.713207 loss)
I0312 16:44:05.867019  1600 sgd_solver.cpp:106] Iteration 65300, lr = 0.01
I0312 16:44:14.993883  1600 solver.cpp:228] Iteration 65400, loss = 0.719552
I0312 16:44:14.993883  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:44:14.993883  1600 solver.cpp:244]     Train net output #1: loss = 0.719552 (* 1 = 0.719552 loss)
I0312 16:44:14.993883  1600 sgd_solver.cpp:106] Iteration 65400, lr = 0.01
I0312 16:44:23.994321  1600 solver.cpp:228] Iteration 65500, loss = 0.395392
I0312 16:44:23.994321  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 16:44:23.994321  1600 solver.cpp:244]     Train net output #1: loss = 0.395392 (* 1 = 0.395392 loss)
I0312 16:44:23.994321  1600 sgd_solver.cpp:106] Iteration 65500, lr = 0.01
I0312 16:44:32.883702  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_65600.caffemodel
I0312 16:44:32.902200  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_65600.solverstate
I0312 16:44:32.906700  1600 solver.cpp:337] Iteration 65600, Testing net (#0)
I0312 16:44:32.906700  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:44:36.554687  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6173
I0312 16:44:36.554687  1600 solver.cpp:404]     Test net output #1: loss = 1.53933 (* 1 = 1.53933 loss)
I0312 16:44:36.581702  1600 solver.cpp:228] Iteration 65600, loss = 0.628628
I0312 16:44:36.581702  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:44:36.581702  1600 solver.cpp:244]     Train net output #1: loss = 0.628628 (* 1 = 0.628628 loss)
I0312 16:44:36.581702  1600 sgd_solver.cpp:106] Iteration 65600, lr = 0.01
I0312 16:44:45.639046  1600 solver.cpp:228] Iteration 65700, loss = 0.858876
I0312 16:44:45.639046  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:44:45.639046  1600 solver.cpp:244]     Train net output #1: loss = 0.858876 (* 1 = 0.858876 loss)
I0312 16:44:45.639046  1600 sgd_solver.cpp:106] Iteration 65700, lr = 0.01
I0312 16:44:54.665793  1600 solver.cpp:228] Iteration 65800, loss = 0.640607
I0312 16:44:54.665793  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:44:54.665793  1600 solver.cpp:244]     Train net output #1: loss = 0.640607 (* 1 = 0.640607 loss)
I0312 16:44:54.665793  1600 sgd_solver.cpp:106] Iteration 65800, lr = 0.01
I0312 16:45:03.904757  1600 solver.cpp:228] Iteration 65900, loss = 0.732057
I0312 16:45:03.904757  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:45:03.904757  1600 solver.cpp:244]     Train net output #1: loss = 0.732057 (* 1 = 0.732057 loss)
I0312 16:45:03.904757  1600 sgd_solver.cpp:106] Iteration 65900, lr = 0.01
I0312 16:45:13.094542  1600 solver.cpp:228] Iteration 66000, loss = 0.58292
I0312 16:45:13.094542  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:45:13.094542  1600 solver.cpp:244]     Train net output #1: loss = 0.58292 (* 1 = 0.58292 loss)
I0312 16:45:13.094542  1600 sgd_solver.cpp:106] Iteration 66000, lr = 0.01
I0312 16:45:22.125356  1600 solver.cpp:228] Iteration 66100, loss = 0.668913
I0312 16:45:22.125356  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:45:22.125356  1600 solver.cpp:244]     Train net output #1: loss = 0.668913 (* 1 = 0.668913 loss)
I0312 16:45:22.125356  1600 sgd_solver.cpp:106] Iteration 66100, lr = 0.01
I0312 16:45:31.281996  1600 solver.cpp:228] Iteration 66200, loss = 0.856006
I0312 16:45:31.281996  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:45:31.281996  1600 solver.cpp:244]     Train net output #1: loss = 0.856006 (* 1 = 0.856006 loss)
I0312 16:45:31.281996  1600 sgd_solver.cpp:106] Iteration 66200, lr = 0.01
I0312 16:45:40.478224  1600 solver.cpp:228] Iteration 66300, loss = 0.877716
I0312 16:45:40.478224  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:45:40.478224  1600 solver.cpp:244]     Train net output #1: loss = 0.877716 (* 1 = 0.877716 loss)
I0312 16:45:40.478224  1600 sgd_solver.cpp:106] Iteration 66300, lr = 0.01
I0312 16:45:49.562448  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_66400.caffemodel
I0312 16:45:49.595952  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_66400.solverstate
I0312 16:45:49.600447  1600 solver.cpp:337] Iteration 66400, Testing net (#0)
I0312 16:45:49.600447  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:45:53.341239  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6155
I0312 16:45:53.341239  1600 solver.cpp:404]     Test net output #1: loss = 1.5394 (* 1 = 1.5394 loss)
I0312 16:45:53.381237  1600 solver.cpp:228] Iteration 66400, loss = 0.960745
I0312 16:45:53.381237  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:45:53.381237  1600 solver.cpp:244]     Train net output #1: loss = 0.960745 (* 1 = 0.960745 loss)
I0312 16:45:53.381237  1600 sgd_solver.cpp:106] Iteration 66400, lr = 0.01
I0312 16:46:02.372566  1600 solver.cpp:228] Iteration 66500, loss = 1.01232
I0312 16:46:02.372566  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:46:02.372566  1600 solver.cpp:244]     Train net output #1: loss = 1.01232 (* 1 = 1.01232 loss)
I0312 16:46:02.372566  1600 sgd_solver.cpp:106] Iteration 66500, lr = 0.01
I0312 16:46:11.700197  1600 solver.cpp:228] Iteration 66600, loss = 0.677267
I0312 16:46:11.700197  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:46:11.700197  1600 solver.cpp:244]     Train net output #1: loss = 0.677267 (* 1 = 0.677267 loss)
I0312 16:46:11.700197  1600 sgd_solver.cpp:106] Iteration 66600, lr = 0.01
I0312 16:46:20.793915  1600 solver.cpp:228] Iteration 66700, loss = 0.699376
I0312 16:46:20.793915  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 16:46:20.793915  1600 solver.cpp:244]     Train net output #1: loss = 0.699376 (* 1 = 0.699376 loss)
I0312 16:46:20.793915  1600 sgd_solver.cpp:106] Iteration 66700, lr = 0.01
I0312 16:46:29.920032  1600 solver.cpp:228] Iteration 66800, loss = 0.684473
I0312 16:46:29.920032  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:46:29.920032  1600 solver.cpp:244]     Train net output #1: loss = 0.684473 (* 1 = 0.684473 loss)
I0312 16:46:29.920032  1600 sgd_solver.cpp:106] Iteration 66800, lr = 0.01
I0312 16:46:39.113773  1600 solver.cpp:228] Iteration 66900, loss = 0.773628
I0312 16:46:39.113773  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:46:39.113773  1600 solver.cpp:244]     Train net output #1: loss = 0.773628 (* 1 = 0.773628 loss)
I0312 16:46:39.113773  1600 sgd_solver.cpp:106] Iteration 66900, lr = 0.01
I0312 16:46:48.239554  1600 solver.cpp:228] Iteration 67000, loss = 0.761679
I0312 16:46:48.239554  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:46:48.239554  1600 solver.cpp:244]     Train net output #1: loss = 0.761679 (* 1 = 0.761679 loss)
I0312 16:46:48.239554  1600 sgd_solver.cpp:106] Iteration 67000, lr = 0.01
I0312 16:46:55.779176  1600 solver.cpp:228] Iteration 67100, loss = 0.888283
I0312 16:46:55.779176  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:46:55.779176  1600 solver.cpp:244]     Train net output #1: loss = 0.888283 (* 1 = 0.888283 loss)
I0312 16:46:55.779176  1600 sgd_solver.cpp:106] Iteration 67100, lr = 0.01
I0312 16:47:01.580718  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_67200.caffemodel
I0312 16:47:01.600703  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_67200.solverstate
I0312 16:47:01.612213  1600 solver.cpp:337] Iteration 67200, Testing net (#0)
I0312 16:47:01.612213  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:47:04.091554  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6168
I0312 16:47:04.091554  1600 solver.cpp:404]     Test net output #1: loss = 1.5267 (* 1 = 1.5267 loss)
I0312 16:47:04.119043  1600 solver.cpp:228] Iteration 67200, loss = 0.710494
I0312 16:47:04.119043  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:47:04.119043  1600 solver.cpp:244]     Train net output #1: loss = 0.710494 (* 1 = 0.710494 loss)
I0312 16:47:04.119043  1600 sgd_solver.cpp:106] Iteration 67200, lr = 0.01
I0312 16:47:09.952615  1600 solver.cpp:228] Iteration 67300, loss = 0.465893
I0312 16:47:09.952615  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 16:47:09.952615  1600 solver.cpp:244]     Train net output #1: loss = 0.465893 (* 1 = 0.465893 loss)
I0312 16:47:09.952615  1600 sgd_solver.cpp:106] Iteration 67300, lr = 0.01
I0312 16:47:18.996387  1600 solver.cpp:228] Iteration 67400, loss = 0.877561
I0312 16:47:18.996387  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:47:18.996387  1600 solver.cpp:244]     Train net output #1: loss = 0.877561 (* 1 = 0.877561 loss)
I0312 16:47:18.996387  1600 sgd_solver.cpp:106] Iteration 67400, lr = 0.01
I0312 16:47:28.090865  1600 solver.cpp:228] Iteration 67500, loss = 0.847274
I0312 16:47:28.090865  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:47:28.090865  1600 solver.cpp:244]     Train net output #1: loss = 0.847274 (* 1 = 0.847274 loss)
I0312 16:47:28.090865  1600 sgd_solver.cpp:106] Iteration 67500, lr = 0.01
I0312 16:47:37.397572  1600 solver.cpp:228] Iteration 67600, loss = 0.731899
I0312 16:47:37.397572  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:47:37.397572  1600 solver.cpp:244]     Train net output #1: loss = 0.731899 (* 1 = 0.731899 loss)
I0312 16:47:37.397572  1600 sgd_solver.cpp:106] Iteration 67600, lr = 0.01
I0312 16:47:46.498469  1600 solver.cpp:228] Iteration 67700, loss = 0.794374
I0312 16:47:46.498469  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:47:46.498469  1600 solver.cpp:244]     Train net output #1: loss = 0.794374 (* 1 = 0.794374 loss)
I0312 16:47:46.498469  1600 sgd_solver.cpp:106] Iteration 67700, lr = 0.01
I0312 16:47:55.640806  1600 solver.cpp:228] Iteration 67800, loss = 0.47564
I0312 16:47:55.641317  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:47:55.641317  1600 solver.cpp:244]     Train net output #1: loss = 0.47564 (* 1 = 0.47564 loss)
I0312 16:47:55.641317  1600 sgd_solver.cpp:106] Iteration 67800, lr = 0.01
I0312 16:48:04.592617  1600 solver.cpp:228] Iteration 67900, loss = 0.975477
I0312 16:48:04.593116  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 16:48:04.593116  1600 solver.cpp:244]     Train net output #1: loss = 0.975477 (* 1 = 0.975477 loss)
I0312 16:48:04.593116  1600 sgd_solver.cpp:106] Iteration 67900, lr = 0.01
I0312 16:48:13.746220  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_68000.caffemodel
I0312 16:48:13.764721  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_68000.solverstate
I0312 16:48:13.769721  1600 solver.cpp:337] Iteration 68000, Testing net (#0)
I0312 16:48:13.770221  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:48:17.459197  1600 solver.cpp:404]     Test net output #0: accuracy = 0.619
I0312 16:48:17.459197  1600 solver.cpp:404]     Test net output #1: loss = 1.53533 (* 1 = 1.53533 loss)
I0312 16:48:17.493202  1600 solver.cpp:228] Iteration 68000, loss = 0.55704
I0312 16:48:17.493202  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:48:17.493202  1600 solver.cpp:244]     Train net output #1: loss = 0.55704 (* 1 = 0.55704 loss)
I0312 16:48:17.493202  1600 sgd_solver.cpp:106] Iteration 68000, lr = 0.01
I0312 16:48:26.354442  1600 solver.cpp:228] Iteration 68100, loss = 0.573868
I0312 16:48:26.354442  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:48:26.354442  1600 solver.cpp:244]     Train net output #1: loss = 0.573868 (* 1 = 0.573868 loss)
I0312 16:48:26.354442  1600 sgd_solver.cpp:106] Iteration 68100, lr = 0.01
I0312 16:48:35.398649  1600 solver.cpp:228] Iteration 68200, loss = 0.388516
I0312 16:48:35.399149  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 16:48:35.399149  1600 solver.cpp:244]     Train net output #1: loss = 0.388516 (* 1 = 0.388516 loss)
I0312 16:48:35.399149  1600 sgd_solver.cpp:106] Iteration 68200, lr = 0.01
I0312 16:48:44.548797  1600 solver.cpp:228] Iteration 68300, loss = 0.532989
I0312 16:48:44.548797  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:48:44.548797  1600 solver.cpp:244]     Train net output #1: loss = 0.532989 (* 1 = 0.532989 loss)
I0312 16:48:44.548797  1600 sgd_solver.cpp:106] Iteration 68300, lr = 0.01
I0312 16:48:53.462960  1600 solver.cpp:228] Iteration 68400, loss = 0.606291
I0312 16:48:53.462960  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:48:53.462960  1600 solver.cpp:244]     Train net output #1: loss = 0.606291 (* 1 = 0.606291 loss)
I0312 16:48:53.462960  1600 sgd_solver.cpp:106] Iteration 68400, lr = 0.01
I0312 16:49:02.620151  1600 solver.cpp:228] Iteration 68500, loss = 0.62738
I0312 16:49:02.620151  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:49:02.620151  1600 solver.cpp:244]     Train net output #1: loss = 0.62738 (* 1 = 0.62738 loss)
I0312 16:49:02.620151  1600 sgd_solver.cpp:106] Iteration 68500, lr = 0.01
I0312 16:49:11.655427  1600 solver.cpp:228] Iteration 68600, loss = 0.765498
I0312 16:49:11.655427  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:49:11.655427  1600 solver.cpp:244]     Train net output #1: loss = 0.765498 (* 1 = 0.765498 loss)
I0312 16:49:11.655427  1600 sgd_solver.cpp:106] Iteration 68600, lr = 0.01
I0312 16:49:20.842939  1600 solver.cpp:228] Iteration 68700, loss = 0.723065
I0312 16:49:20.842939  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:49:20.842939  1600 solver.cpp:244]     Train net output #1: loss = 0.723065 (* 1 = 0.723065 loss)
I0312 16:49:20.842939  1600 sgd_solver.cpp:106] Iteration 68700, lr = 0.01
I0312 16:49:29.794509  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_68800.caffemodel
I0312 16:49:29.825511  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_68800.solverstate
I0312 16:49:29.831017  1600 solver.cpp:337] Iteration 68800, Testing net (#0)
I0312 16:49:29.831017  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:49:33.543246  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6218
I0312 16:49:33.543246  1600 solver.cpp:404]     Test net output #1: loss = 1.54087 (* 1 = 1.54087 loss)
I0312 16:49:33.583745  1600 solver.cpp:228] Iteration 68800, loss = 0.870259
I0312 16:49:33.583745  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:49:33.583745  1600 solver.cpp:244]     Train net output #1: loss = 0.870259 (* 1 = 0.870259 loss)
I0312 16:49:33.583745  1600 sgd_solver.cpp:106] Iteration 68800, lr = 0.01
I0312 16:49:42.621150  1600 solver.cpp:228] Iteration 68900, loss = 0.879028
I0312 16:49:42.621150  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:49:42.621150  1600 solver.cpp:244]     Train net output #1: loss = 0.879028 (* 1 = 0.879028 loss)
I0312 16:49:42.621150  1600 sgd_solver.cpp:106] Iteration 68900, lr = 0.01
I0312 16:49:51.828943  1600 solver.cpp:228] Iteration 69000, loss = 0.626252
I0312 16:49:51.828943  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 16:49:51.828943  1600 solver.cpp:244]     Train net output #1: loss = 0.626252 (* 1 = 0.626252 loss)
I0312 16:49:51.828943  1600 sgd_solver.cpp:106] Iteration 69000, lr = 0.01
I0312 16:50:01.036677  1600 solver.cpp:228] Iteration 69100, loss = 0.615353
I0312 16:50:01.036677  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:50:01.036677  1600 solver.cpp:244]     Train net output #1: loss = 0.615353 (* 1 = 0.615353 loss)
I0312 16:50:01.036677  1600 sgd_solver.cpp:106] Iteration 69100, lr = 0.01
I0312 16:50:10.209403  1600 solver.cpp:228] Iteration 69200, loss = 0.566101
I0312 16:50:10.209403  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:50:10.209403  1600 solver.cpp:244]     Train net output #1: loss = 0.566101 (* 1 = 0.566101 loss)
I0312 16:50:10.209403  1600 sgd_solver.cpp:106] Iteration 69200, lr = 0.01
I0312 16:50:19.304220  1600 solver.cpp:228] Iteration 69300, loss = 0.685332
I0312 16:50:19.304220  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:50:19.304220  1600 solver.cpp:244]     Train net output #1: loss = 0.685332 (* 1 = 0.685332 loss)
I0312 16:50:19.304220  1600 sgd_solver.cpp:106] Iteration 69300, lr = 0.01
I0312 16:50:28.441984  1600 solver.cpp:228] Iteration 69400, loss = 0.670309
I0312 16:50:28.441984  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:50:28.441984  1600 solver.cpp:244]     Train net output #1: loss = 0.670309 (* 1 = 0.670309 loss)
I0312 16:50:28.441984  1600 sgd_solver.cpp:106] Iteration 69400, lr = 0.01
I0312 16:50:37.522406  1600 solver.cpp:228] Iteration 69500, loss = 0.693454
I0312 16:50:37.522406  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:50:37.522406  1600 solver.cpp:244]     Train net output #1: loss = 0.693454 (* 1 = 0.693454 loss)
I0312 16:50:37.522406  1600 sgd_solver.cpp:106] Iteration 69500, lr = 0.01
I0312 16:50:46.550999  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_69600.caffemodel
I0312 16:50:46.580000  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_69600.solverstate
I0312 16:50:46.585000  1600 solver.cpp:337] Iteration 69600, Testing net (#0)
I0312 16:50:46.585000  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:50:50.343132  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6214
I0312 16:50:50.343132  1600 solver.cpp:404]     Test net output #1: loss = 1.54269 (* 1 = 1.54269 loss)
I0312 16:50:50.375618  1600 solver.cpp:228] Iteration 69600, loss = 1.04192
I0312 16:50:50.375618  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:50:50.375618  1600 solver.cpp:244]     Train net output #1: loss = 1.04192 (* 1 = 1.04192 loss)
I0312 16:50:50.375618  1600 sgd_solver.cpp:106] Iteration 69600, lr = 0.01
I0312 16:50:59.311889  1600 solver.cpp:228] Iteration 69700, loss = 0.894582
I0312 16:50:59.311889  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:50:59.311889  1600 solver.cpp:244]     Train net output #1: loss = 0.894582 (* 1 = 0.894582 loss)
I0312 16:50:59.311889  1600 sgd_solver.cpp:106] Iteration 69700, lr = 0.01
I0312 16:51:08.383107  1600 solver.cpp:228] Iteration 69800, loss = 0.742531
I0312 16:51:08.383107  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:51:08.383107  1600 solver.cpp:244]     Train net output #1: loss = 0.742531 (* 1 = 0.742531 loss)
I0312 16:51:08.383107  1600 sgd_solver.cpp:106] Iteration 69800, lr = 0.01
I0312 16:51:17.522439  1600 solver.cpp:228] Iteration 69900, loss = 0.874864
I0312 16:51:17.522439  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:51:17.522439  1600 solver.cpp:244]     Train net output #1: loss = 0.874864 (* 1 = 0.874864 loss)
I0312 16:51:17.522439  1600 sgd_solver.cpp:106] Iteration 69900, lr = 0.01
I0312 16:51:26.749860  1600 solver.cpp:228] Iteration 70000, loss = 0.935849
I0312 16:51:26.749860  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 16:51:26.749860  1600 solver.cpp:244]     Train net output #1: loss = 0.935849 (* 1 = 0.935849 loss)
I0312 16:51:26.749860  1600 sgd_solver.cpp:106] Iteration 70000, lr = 0.01
I0312 16:51:35.758349  1600 solver.cpp:228] Iteration 70100, loss = 1.01823
I0312 16:51:35.758349  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:51:35.758349  1600 solver.cpp:244]     Train net output #1: loss = 1.01823 (* 1 = 1.01823 loss)
I0312 16:51:35.758349  1600 sgd_solver.cpp:106] Iteration 70100, lr = 0.01
I0312 16:51:44.773377  1600 solver.cpp:228] Iteration 70200, loss = 0.615142
I0312 16:51:44.773377  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:51:44.773377  1600 solver.cpp:244]     Train net output #1: loss = 0.615142 (* 1 = 0.615142 loss)
I0312 16:51:44.773377  1600 sgd_solver.cpp:106] Iteration 70200, lr = 0.01
I0312 16:51:53.829637  1600 solver.cpp:228] Iteration 70300, loss = 1.04765
I0312 16:51:53.829637  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:51:53.829637  1600 solver.cpp:244]     Train net output #1: loss = 1.04765 (* 1 = 1.04765 loss)
I0312 16:51:53.829637  1600 sgd_solver.cpp:106] Iteration 70300, lr = 0.01
I0312 16:52:00.899765  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_70400.caffemodel
I0312 16:52:00.919767  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_70400.solverstate
I0312 16:52:00.920771  1600 solver.cpp:337] Iteration 70400, Testing net (#0)
I0312 16:52:00.920771  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:52:03.371803  1600 solver.cpp:404]     Test net output #0: accuracy = 0.62
I0312 16:52:03.371803  1600 solver.cpp:404]     Test net output #1: loss = 1.55429 (* 1 = 1.55429 loss)
I0312 16:52:03.391813  1600 solver.cpp:228] Iteration 70400, loss = 0.865336
I0312 16:52:03.391813  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:52:03.391813  1600 solver.cpp:244]     Train net output #1: loss = 0.865336 (* 1 = 0.865336 loss)
I0312 16:52:03.391813  1600 sgd_solver.cpp:106] Iteration 70400, lr = 0.01
I0312 16:52:09.245076  1600 solver.cpp:228] Iteration 70500, loss = 0.692758
I0312 16:52:09.245076  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:52:09.245076  1600 solver.cpp:244]     Train net output #1: loss = 0.692758 (* 1 = 0.692758 loss)
I0312 16:52:09.245076  1600 sgd_solver.cpp:106] Iteration 70500, lr = 0.01
I0312 16:52:15.225903  1600 solver.cpp:228] Iteration 70600, loss = 0.674135
I0312 16:52:15.225903  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:52:15.225903  1600 solver.cpp:244]     Train net output #1: loss = 0.674135 (* 1 = 0.674135 loss)
I0312 16:52:15.225903  1600 sgd_solver.cpp:106] Iteration 70600, lr = 0.01
I0312 16:52:24.358009  1600 solver.cpp:228] Iteration 70700, loss = 0.844078
I0312 16:52:24.358009  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:52:24.358009  1600 solver.cpp:244]     Train net output #1: loss = 0.844078 (* 1 = 0.844078 loss)
I0312 16:52:24.358009  1600 sgd_solver.cpp:106] Iteration 70700, lr = 0.01
I0312 16:52:33.475783  1600 solver.cpp:228] Iteration 70800, loss = 0.766745
I0312 16:52:33.475783  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:52:33.476284  1600 solver.cpp:244]     Train net output #1: loss = 0.766745 (* 1 = 0.766745 loss)
I0312 16:52:33.476284  1600 sgd_solver.cpp:106] Iteration 70800, lr = 0.01
I0312 16:52:42.500574  1600 solver.cpp:228] Iteration 70900, loss = 0.797294
I0312 16:52:42.500574  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:52:42.500574  1600 solver.cpp:244]     Train net output #1: loss = 0.797294 (* 1 = 0.797294 loss)
I0312 16:52:42.500574  1600 sgd_solver.cpp:106] Iteration 70900, lr = 0.01
I0312 16:52:51.522197  1600 solver.cpp:228] Iteration 71000, loss = 0.983115
I0312 16:52:51.522197  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 16:52:51.522197  1600 solver.cpp:244]     Train net output #1: loss = 0.983115 (* 1 = 0.983115 loss)
I0312 16:52:51.522197  1600 sgd_solver.cpp:106] Iteration 71000, lr = 0.01
I0312 16:53:00.700073  1600 solver.cpp:228] Iteration 71100, loss = 0.68075
I0312 16:53:00.700073  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:53:00.700073  1600 solver.cpp:244]     Train net output #1: loss = 0.68075 (* 1 = 0.68075 loss)
I0312 16:53:00.700073  1600 sgd_solver.cpp:106] Iteration 71100, lr = 0.01
I0312 16:53:09.752305  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_71200.caffemodel
I0312 16:53:09.770787  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_71200.solverstate
I0312 16:53:09.776288  1600 solver.cpp:337] Iteration 71200, Testing net (#0)
I0312 16:53:09.776288  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:53:13.479329  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6202
I0312 16:53:13.479329  1600 solver.cpp:404]     Test net output #1: loss = 1.5475 (* 1 = 1.5475 loss)
I0312 16:53:13.500828  1600 solver.cpp:228] Iteration 71200, loss = 0.621639
I0312 16:53:13.500828  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 16:53:13.500828  1600 solver.cpp:244]     Train net output #1: loss = 0.621639 (* 1 = 0.621639 loss)
I0312 16:53:13.500828  1600 sgd_solver.cpp:106] Iteration 71200, lr = 0.01
I0312 16:53:22.686343  1600 solver.cpp:228] Iteration 71300, loss = 0.538786
I0312 16:53:22.686343  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:53:22.686343  1600 solver.cpp:244]     Train net output #1: loss = 0.538786 (* 1 = 0.538786 loss)
I0312 16:53:22.686343  1600 sgd_solver.cpp:106] Iteration 71300, lr = 0.01
I0312 16:53:31.756736  1600 solver.cpp:228] Iteration 71400, loss = 0.540241
I0312 16:53:31.756736  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:53:31.756736  1600 solver.cpp:244]     Train net output #1: loss = 0.540241 (* 1 = 0.540241 loss)
I0312 16:53:31.756736  1600 sgd_solver.cpp:106] Iteration 71400, lr = 0.01
I0312 16:53:40.739358  1600 solver.cpp:228] Iteration 71500, loss = 0.781686
I0312 16:53:40.739358  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:53:40.739358  1600 solver.cpp:244]     Train net output #1: loss = 0.781686 (* 1 = 0.781686 loss)
I0312 16:53:40.739358  1600 sgd_solver.cpp:106] Iteration 71500, lr = 0.01
I0312 16:53:49.669773  1600 solver.cpp:228] Iteration 71600, loss = 0.633574
I0312 16:53:49.669773  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:53:49.669773  1600 solver.cpp:244]     Train net output #1: loss = 0.633574 (* 1 = 0.633574 loss)
I0312 16:53:49.669773  1600 sgd_solver.cpp:106] Iteration 71600, lr = 0.01
I0312 16:53:58.841161  1600 solver.cpp:228] Iteration 71700, loss = 0.790581
I0312 16:53:58.841161  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:53:58.841161  1600 solver.cpp:244]     Train net output #1: loss = 0.790581 (* 1 = 0.790581 loss)
I0312 16:53:58.841161  1600 sgd_solver.cpp:106] Iteration 71700, lr = 0.01
I0312 16:54:07.823055  1600 solver.cpp:228] Iteration 71800, loss = 0.6454
I0312 16:54:07.823055  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:54:07.823055  1600 solver.cpp:244]     Train net output #1: loss = 0.6454 (* 1 = 0.6454 loss)
I0312 16:54:07.823055  1600 sgd_solver.cpp:106] Iteration 71800, lr = 0.01
I0312 16:54:16.934403  1600 solver.cpp:228] Iteration 71900, loss = 0.811612
I0312 16:54:16.934403  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 16:54:16.934403  1600 solver.cpp:244]     Train net output #1: loss = 0.811612 (* 1 = 0.811612 loss)
I0312 16:54:16.934403  1600 sgd_solver.cpp:106] Iteration 71900, lr = 0.01
I0312 16:54:25.906725  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_72000.caffemodel
I0312 16:54:25.935228  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_72000.solverstate
I0312 16:54:25.935228  1600 solver.cpp:337] Iteration 72000, Testing net (#0)
I0312 16:54:25.935228  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:54:29.677436  1600 solver.cpp:404]     Test net output #0: accuracy = 0.618
I0312 16:54:29.677436  1600 solver.cpp:404]     Test net output #1: loss = 1.54439 (* 1 = 1.54439 loss)
I0312 16:54:29.707434  1600 solver.cpp:228] Iteration 72000, loss = 0.683882
I0312 16:54:29.707434  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:54:29.707434  1600 solver.cpp:244]     Train net output #1: loss = 0.683882 (* 1 = 0.683882 loss)
I0312 16:54:29.707434  1600 sgd_solver.cpp:106] Iteration 72000, lr = 0.01
I0312 16:54:38.760704  1600 solver.cpp:228] Iteration 72100, loss = 0.712592
I0312 16:54:38.760704  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:54:38.760704  1600 solver.cpp:244]     Train net output #1: loss = 0.712592 (* 1 = 0.712592 loss)
I0312 16:54:38.760704  1600 sgd_solver.cpp:106] Iteration 72100, lr = 0.01
I0312 16:54:47.981763  1600 solver.cpp:228] Iteration 72200, loss = 0.589613
I0312 16:54:47.981763  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:54:47.981763  1600 solver.cpp:244]     Train net output #1: loss = 0.589614 (* 1 = 0.589614 loss)
I0312 16:54:47.981763  1600 sgd_solver.cpp:106] Iteration 72200, lr = 0.01
I0312 16:54:57.210045  1600 solver.cpp:228] Iteration 72300, loss = 0.855456
I0312 16:54:57.210045  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:54:57.210045  1600 solver.cpp:244]     Train net output #1: loss = 0.855456 (* 1 = 0.855456 loss)
I0312 16:54:57.210045  1600 sgd_solver.cpp:106] Iteration 72300, lr = 0.01
I0312 16:55:06.036970  1600 solver.cpp:228] Iteration 72400, loss = 0.835999
I0312 16:55:06.036970  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:55:06.036970  1600 solver.cpp:244]     Train net output #1: loss = 0.835999 (* 1 = 0.835999 loss)
I0312 16:55:06.036970  1600 sgd_solver.cpp:106] Iteration 72400, lr = 0.01
I0312 16:55:15.109448  1600 solver.cpp:228] Iteration 72500, loss = 0.947541
I0312 16:55:15.109448  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:55:15.109448  1600 solver.cpp:244]     Train net output #1: loss = 0.947541 (* 1 = 0.947541 loss)
I0312 16:55:15.109448  1600 sgd_solver.cpp:106] Iteration 72500, lr = 0.01
I0312 16:55:24.413573  1600 solver.cpp:228] Iteration 72600, loss = 0.835372
I0312 16:55:24.413573  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:55:24.413573  1600 solver.cpp:244]     Train net output #1: loss = 0.835372 (* 1 = 0.835372 loss)
I0312 16:55:24.413573  1600 sgd_solver.cpp:106] Iteration 72600, lr = 0.01
I0312 16:55:33.542294  1600 solver.cpp:228] Iteration 72700, loss = 1.02583
I0312 16:55:33.542294  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:55:33.542294  1600 solver.cpp:244]     Train net output #1: loss = 1.02583 (* 1 = 1.02583 loss)
I0312 16:55:33.542294  1600 sgd_solver.cpp:106] Iteration 72700, lr = 0.01
I0312 16:55:42.676237  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_72800.caffemodel
I0312 16:55:42.691238  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_72800.solverstate
I0312 16:55:42.696236  1600 solver.cpp:337] Iteration 72800, Testing net (#0)
I0312 16:55:42.696236  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:55:46.376312  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6186
I0312 16:55:46.376312  1600 solver.cpp:404]     Test net output #1: loss = 1.55635 (* 1 = 1.55635 loss)
I0312 16:55:46.406309  1600 solver.cpp:228] Iteration 72800, loss = 0.502194
I0312 16:55:46.406309  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 16:55:46.406309  1600 solver.cpp:244]     Train net output #1: loss = 0.502195 (* 1 = 0.502195 loss)
I0312 16:55:46.406309  1600 sgd_solver.cpp:106] Iteration 72800, lr = 0.01
I0312 16:55:55.585464  1600 solver.cpp:228] Iteration 72900, loss = 0.550493
I0312 16:55:55.585464  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 16:55:55.585464  1600 solver.cpp:244]     Train net output #1: loss = 0.550493 (* 1 = 0.550493 loss)
I0312 16:55:55.585464  1600 sgd_solver.cpp:106] Iteration 72900, lr = 0.01
I0312 16:56:04.629570  1600 solver.cpp:228] Iteration 73000, loss = 0.979189
I0312 16:56:04.629570  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:56:04.629570  1600 solver.cpp:244]     Train net output #1: loss = 0.979189 (* 1 = 0.979189 loss)
I0312 16:56:04.629570  1600 sgd_solver.cpp:106] Iteration 73000, lr = 0.01
I0312 16:56:13.630842  1600 solver.cpp:228] Iteration 73100, loss = 0.746125
I0312 16:56:13.630842  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:56:13.630842  1600 solver.cpp:244]     Train net output #1: loss = 0.746125 (* 1 = 0.746125 loss)
I0312 16:56:13.631342  1600 sgd_solver.cpp:106] Iteration 73100, lr = 0.01
I0312 16:56:22.799706  1600 solver.cpp:228] Iteration 73200, loss = 0.508942
I0312 16:56:22.799706  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:56:22.799706  1600 solver.cpp:244]     Train net output #1: loss = 0.508942 (* 1 = 0.508942 loss)
I0312 16:56:22.799706  1600 sgd_solver.cpp:106] Iteration 73200, lr = 0.01
I0312 16:56:31.685289  1600 solver.cpp:228] Iteration 73300, loss = 0.620813
I0312 16:56:31.685789  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 16:56:31.685789  1600 solver.cpp:244]     Train net output #1: loss = 0.620813 (* 1 = 0.620813 loss)
I0312 16:56:31.685789  1600 sgd_solver.cpp:106] Iteration 73300, lr = 0.01
I0312 16:56:40.806133  1600 solver.cpp:228] Iteration 73400, loss = 0.493191
I0312 16:56:40.806133  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:56:40.806133  1600 solver.cpp:244]     Train net output #1: loss = 0.493192 (* 1 = 0.493192 loss)
I0312 16:56:40.806133  1600 sgd_solver.cpp:106] Iteration 73400, lr = 0.01
I0312 16:56:49.856016  1600 solver.cpp:228] Iteration 73500, loss = 0.728105
I0312 16:56:49.856516  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:56:49.856516  1600 solver.cpp:244]     Train net output #1: loss = 0.728105 (* 1 = 0.728105 loss)
I0312 16:56:49.856516  1600 sgd_solver.cpp:106] Iteration 73500, lr = 0.01
I0312 16:56:59.069280  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_73600.caffemodel
I0312 16:56:59.097779  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_73600.solverstate
I0312 16:56:59.102778  1600 solver.cpp:337] Iteration 73600, Testing net (#0)
I0312 16:56:59.102778  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:57:02.790534  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6244
I0312 16:57:02.790534  1600 solver.cpp:404]     Test net output #1: loss = 1.54755 (* 1 = 1.54755 loss)
I0312 16:57:02.808549  1600 solver.cpp:228] Iteration 73600, loss = 0.914938
I0312 16:57:02.809051  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:57:02.809051  1600 solver.cpp:244]     Train net output #1: loss = 0.914938 (* 1 = 0.914938 loss)
I0312 16:57:02.809051  1600 sgd_solver.cpp:106] Iteration 73600, lr = 0.01
I0312 16:57:08.722116  1600 solver.cpp:228] Iteration 73700, loss = 0.649758
I0312 16:57:08.722116  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:57:08.722116  1600 solver.cpp:244]     Train net output #1: loss = 0.649758 (* 1 = 0.649758 loss)
I0312 16:57:08.722116  1600 sgd_solver.cpp:106] Iteration 73700, lr = 0.01
I0312 16:57:14.505836  1600 solver.cpp:228] Iteration 73800, loss = 0.748392
I0312 16:57:14.505836  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:57:14.505836  1600 solver.cpp:244]     Train net output #1: loss = 0.748392 (* 1 = 0.748392 loss)
I0312 16:57:14.505836  1600 sgd_solver.cpp:106] Iteration 73800, lr = 0.01
I0312 16:57:20.296188  1600 solver.cpp:228] Iteration 73900, loss = 0.616324
I0312 16:57:20.296188  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:57:20.296188  1600 solver.cpp:244]     Train net output #1: loss = 0.616324 (* 1 = 0.616324 loss)
I0312 16:57:20.296188  1600 sgd_solver.cpp:106] Iteration 73900, lr = 0.01
I0312 16:57:29.308045  1600 solver.cpp:228] Iteration 74000, loss = 0.592372
I0312 16:57:29.308045  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:57:29.308045  1600 solver.cpp:244]     Train net output #1: loss = 0.592372 (* 1 = 0.592372 loss)
I0312 16:57:29.308045  1600 sgd_solver.cpp:106] Iteration 74000, lr = 0.01
I0312 16:57:38.394647  1600 solver.cpp:228] Iteration 74100, loss = 0.888746
I0312 16:57:38.394647  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 16:57:38.394647  1600 solver.cpp:244]     Train net output #1: loss = 0.888746 (* 1 = 0.888746 loss)
I0312 16:57:38.394647  1600 sgd_solver.cpp:106] Iteration 74100, lr = 0.01
I0312 16:57:47.539737  1600 solver.cpp:228] Iteration 74200, loss = 0.623668
I0312 16:57:47.539737  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 16:57:47.539737  1600 solver.cpp:244]     Train net output #1: loss = 0.623668 (* 1 = 0.623668 loss)
I0312 16:57:47.539737  1600 sgd_solver.cpp:106] Iteration 74200, lr = 0.01
I0312 16:57:56.673050  1600 solver.cpp:228] Iteration 74300, loss = 0.801216
I0312 16:57:56.673050  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:57:56.673050  1600 solver.cpp:244]     Train net output #1: loss = 0.801216 (* 1 = 0.801216 loss)
I0312 16:57:56.673050  1600 sgd_solver.cpp:106] Iteration 74300, lr = 0.01
I0312 16:58:05.828624  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_74400.caffemodel
I0312 16:58:05.848124  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_74400.solverstate
I0312 16:58:05.853132  1600 solver.cpp:337] Iteration 74400, Testing net (#0)
I0312 16:58:05.853622  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:58:09.519268  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6228
I0312 16:58:09.519268  1600 solver.cpp:404]     Test net output #1: loss = 1.55367 (* 1 = 1.55367 loss)
I0312 16:58:09.540769  1600 solver.cpp:228] Iteration 74400, loss = 0.463991
I0312 16:58:09.540769  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 16:58:09.540769  1600 solver.cpp:244]     Train net output #1: loss = 0.463991 (* 1 = 0.463991 loss)
I0312 16:58:09.540769  1600 sgd_solver.cpp:106] Iteration 74400, lr = 0.01
I0312 16:58:18.534967  1600 solver.cpp:228] Iteration 74500, loss = 0.690649
I0312 16:58:18.534967  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:58:18.534967  1600 solver.cpp:244]     Train net output #1: loss = 0.690649 (* 1 = 0.690649 loss)
I0312 16:58:18.534967  1600 sgd_solver.cpp:106] Iteration 74500, lr = 0.01
I0312 16:58:27.602979  1600 solver.cpp:228] Iteration 74600, loss = 0.744339
I0312 16:58:27.602979  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 16:58:27.603478  1600 solver.cpp:244]     Train net output #1: loss = 0.744339 (* 1 = 0.744339 loss)
I0312 16:58:27.603478  1600 sgd_solver.cpp:106] Iteration 74600, lr = 0.01
I0312 16:58:36.614161  1600 solver.cpp:228] Iteration 74700, loss = 0.715078
I0312 16:58:36.614161  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:58:36.614161  1600 solver.cpp:244]     Train net output #1: loss = 0.715078 (* 1 = 0.715078 loss)
I0312 16:58:36.614161  1600 sgd_solver.cpp:106] Iteration 74700, lr = 0.01
I0312 16:58:45.613652  1600 solver.cpp:228] Iteration 74800, loss = 0.815449
I0312 16:58:45.613652  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:58:45.613652  1600 solver.cpp:244]     Train net output #1: loss = 0.815449 (* 1 = 0.815449 loss)
I0312 16:58:45.613652  1600 sgd_solver.cpp:106] Iteration 74800, lr = 0.01
I0312 16:58:54.692932  1600 solver.cpp:228] Iteration 74900, loss = 0.643839
I0312 16:58:54.692932  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:58:54.692932  1600 solver.cpp:244]     Train net output #1: loss = 0.643839 (* 1 = 0.643839 loss)
I0312 16:58:54.692932  1600 sgd_solver.cpp:106] Iteration 74900, lr = 0.01
I0312 16:59:03.562222  1600 solver.cpp:228] Iteration 75000, loss = 0.825093
I0312 16:59:03.562731  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 16:59:03.562731  1600 solver.cpp:244]     Train net output #1: loss = 0.825093 (* 1 = 0.825093 loss)
I0312 16:59:03.562731  1600 sgd_solver.cpp:106] Iteration 75000, lr = 0.01
I0312 16:59:12.673194  1600 solver.cpp:228] Iteration 75100, loss = 0.772161
I0312 16:59:12.673194  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 16:59:12.673194  1600 solver.cpp:244]     Train net output #1: loss = 0.772161 (* 1 = 0.772161 loss)
I0312 16:59:12.673194  1600 sgd_solver.cpp:106] Iteration 75100, lr = 0.01
I0312 16:59:21.685724  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_75200.caffemodel
I0312 16:59:21.714221  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_75200.solverstate
I0312 16:59:21.719221  1600 solver.cpp:337] Iteration 75200, Testing net (#0)
I0312 16:59:21.719221  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 16:59:25.423369  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6174
I0312 16:59:25.423369  1600 solver.cpp:404]     Test net output #1: loss = 1.56232 (* 1 = 1.56232 loss)
I0312 16:59:25.443372  1600 solver.cpp:228] Iteration 75200, loss = 0.723874
I0312 16:59:25.443372  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 16:59:25.443372  1600 solver.cpp:244]     Train net output #1: loss = 0.723875 (* 1 = 0.723875 loss)
I0312 16:59:25.443372  1600 sgd_solver.cpp:106] Iteration 75200, lr = 0.01
I0312 16:59:34.418520  1600 solver.cpp:228] Iteration 75300, loss = 0.573689
I0312 16:59:34.418520  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:59:34.419020  1600 solver.cpp:244]     Train net output #1: loss = 0.57369 (* 1 = 0.57369 loss)
I0312 16:59:34.419020  1600 sgd_solver.cpp:106] Iteration 75300, lr = 0.01
I0312 16:59:43.494658  1600 solver.cpp:228] Iteration 75400, loss = 0.603614
I0312 16:59:43.494658  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 16:59:43.494658  1600 solver.cpp:244]     Train net output #1: loss = 0.603614 (* 1 = 0.603614 loss)
I0312 16:59:43.494658  1600 sgd_solver.cpp:106] Iteration 75400, lr = 0.01
I0312 16:59:52.615214  1600 solver.cpp:228] Iteration 75500, loss = 0.571493
I0312 16:59:52.615214  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 16:59:52.615214  1600 solver.cpp:244]     Train net output #1: loss = 0.571493 (* 1 = 0.571493 loss)
I0312 16:59:52.615214  1600 sgd_solver.cpp:106] Iteration 75500, lr = 0.01
I0312 17:00:01.988682  1600 solver.cpp:228] Iteration 75600, loss = 0.686666
I0312 17:00:01.988682  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:00:01.988682  1600 solver.cpp:244]     Train net output #1: loss = 0.686666 (* 1 = 0.686666 loss)
I0312 17:00:01.988682  1600 sgd_solver.cpp:106] Iteration 75600, lr = 0.01
I0312 17:00:10.853575  1600 solver.cpp:228] Iteration 75700, loss = 0.629957
I0312 17:00:10.853575  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:00:10.853575  1600 solver.cpp:244]     Train net output #1: loss = 0.629957 (* 1 = 0.629957 loss)
I0312 17:00:10.853575  1600 sgd_solver.cpp:106] Iteration 75700, lr = 0.01
I0312 17:00:20.020309  1600 solver.cpp:228] Iteration 75800, loss = 0.570101
I0312 17:00:20.020309  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:00:20.020309  1600 solver.cpp:244]     Train net output #1: loss = 0.570101 (* 1 = 0.570101 loss)
I0312 17:00:20.020309  1600 sgd_solver.cpp:106] Iteration 75800, lr = 0.01
I0312 17:00:29.394068  1600 solver.cpp:228] Iteration 75900, loss = 0.735717
I0312 17:00:29.394068  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:00:29.394068  1600 solver.cpp:244]     Train net output #1: loss = 0.735717 (* 1 = 0.735717 loss)
I0312 17:00:29.394068  1600 sgd_solver.cpp:106] Iteration 75900, lr = 0.01
I0312 17:00:38.265545  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_76000.caffemodel
I0312 17:00:38.281546  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_76000.solverstate
I0312 17:00:38.288049  1600 solver.cpp:337] Iteration 76000, Testing net (#0)
I0312 17:00:38.288049  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:00:41.938060  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6187
I0312 17:00:41.938060  1600 solver.cpp:404]     Test net output #1: loss = 1.56303 (* 1 = 1.56303 loss)
I0312 17:00:41.955545  1600 solver.cpp:228] Iteration 76000, loss = 0.557764
I0312 17:00:41.955545  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:00:41.955545  1600 solver.cpp:244]     Train net output #1: loss = 0.557764 (* 1 = 0.557764 loss)
I0312 17:00:41.955545  1600 sgd_solver.cpp:106] Iteration 76000, lr = 0.01
I0312 17:00:51.003072  1600 solver.cpp:228] Iteration 76100, loss = 0.579078
I0312 17:00:51.003072  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:00:51.003072  1600 solver.cpp:244]     Train net output #1: loss = 0.579078 (* 1 = 0.579078 loss)
I0312 17:00:51.003072  1600 sgd_solver.cpp:106] Iteration 76100, lr = 0.01
I0312 17:01:00.173001  1600 solver.cpp:228] Iteration 76200, loss = 0.831218
I0312 17:01:00.173001  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:01:00.173001  1600 solver.cpp:244]     Train net output #1: loss = 0.831218 (* 1 = 0.831218 loss)
I0312 17:01:00.173001  1600 sgd_solver.cpp:106] Iteration 76200, lr = 0.01
I0312 17:01:09.258452  1600 solver.cpp:228] Iteration 76300, loss = 0.665155
I0312 17:01:09.258452  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:01:09.258452  1600 solver.cpp:244]     Train net output #1: loss = 0.665156 (* 1 = 0.665156 loss)
I0312 17:01:09.258452  1600 sgd_solver.cpp:106] Iteration 76300, lr = 0.01
I0312 17:01:18.535449  1600 solver.cpp:228] Iteration 76400, loss = 0.582585
I0312 17:01:18.535449  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:01:18.535449  1600 solver.cpp:244]     Train net output #1: loss = 0.582585 (* 1 = 0.582585 loss)
I0312 17:01:18.535449  1600 sgd_solver.cpp:106] Iteration 76400, lr = 0.01
I0312 17:01:27.753857  1600 solver.cpp:228] Iteration 76500, loss = 0.507877
I0312 17:01:27.753857  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:01:27.753857  1600 solver.cpp:244]     Train net output #1: loss = 0.507877 (* 1 = 0.507877 loss)
I0312 17:01:27.753857  1600 sgd_solver.cpp:106] Iteration 76500, lr = 0.01
I0312 17:01:36.787354  1600 solver.cpp:228] Iteration 76600, loss = 1.09096
I0312 17:01:36.787354  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 17:01:36.787354  1600 solver.cpp:244]     Train net output #1: loss = 1.09096 (* 1 = 1.09096 loss)
I0312 17:01:36.787354  1600 sgd_solver.cpp:106] Iteration 76600, lr = 0.01
I0312 17:01:45.875896  1600 solver.cpp:228] Iteration 76700, loss = 1.0212
I0312 17:01:45.875896  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 17:01:45.875896  1600 solver.cpp:244]     Train net output #1: loss = 1.0212 (* 1 = 1.0212 loss)
I0312 17:01:45.875896  1600 sgd_solver.cpp:106] Iteration 76700, lr = 0.01
I0312 17:01:54.863646  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_76800.caffemodel
I0312 17:01:54.882148  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_76800.solverstate
I0312 17:01:54.887006  1600 solver.cpp:337] Iteration 76800, Testing net (#0)
I0312 17:01:54.887006  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:01:58.545040  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6211
I0312 17:01:58.545040  1600 solver.cpp:404]     Test net output #1: loss = 1.55657 (* 1 = 1.55657 loss)
I0312 17:01:58.565043  1600 solver.cpp:228] Iteration 76800, loss = 0.511662
I0312 17:01:58.565043  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:01:58.565043  1600 solver.cpp:244]     Train net output #1: loss = 0.511662 (* 1 = 0.511662 loss)
I0312 17:01:58.565043  1600 sgd_solver.cpp:106] Iteration 76800, lr = 0.01
I0312 17:02:07.859418  1600 solver.cpp:228] Iteration 76900, loss = 0.794903
I0312 17:02:07.859418  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:02:07.859418  1600 solver.cpp:244]     Train net output #1: loss = 0.794903 (* 1 = 0.794903 loss)
I0312 17:02:07.859418  1600 sgd_solver.cpp:106] Iteration 76900, lr = 0.01
I0312 17:02:13.874904  1600 solver.cpp:228] Iteration 77000, loss = 0.788929
I0312 17:02:13.874904  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:02:13.874904  1600 solver.cpp:244]     Train net output #1: loss = 0.788929 (* 1 = 0.788929 loss)
I0312 17:02:13.874904  1600 sgd_solver.cpp:106] Iteration 77000, lr = 0.01
I0312 17:02:19.653568  1600 solver.cpp:228] Iteration 77100, loss = 0.753668
I0312 17:02:19.653568  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:02:19.653568  1600 solver.cpp:244]     Train net output #1: loss = 0.753668 (* 1 = 0.753668 loss)
I0312 17:02:19.653568  1600 sgd_solver.cpp:106] Iteration 77100, lr = 0.01
I0312 17:02:25.500747  1600 solver.cpp:228] Iteration 77200, loss = 0.607699
I0312 17:02:25.500747  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:02:25.500747  1600 solver.cpp:244]     Train net output #1: loss = 0.607699 (* 1 = 0.607699 loss)
I0312 17:02:25.500747  1600 sgd_solver.cpp:106] Iteration 77200, lr = 0.01
I0312 17:02:34.676560  1600 solver.cpp:228] Iteration 77300, loss = 0.668006
I0312 17:02:34.676560  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:02:34.676560  1600 solver.cpp:244]     Train net output #1: loss = 0.668006 (* 1 = 0.668006 loss)
I0312 17:02:34.676560  1600 sgd_solver.cpp:106] Iteration 77300, lr = 0.01
I0312 17:02:43.854409  1600 solver.cpp:228] Iteration 77400, loss = 0.673159
I0312 17:02:43.854909  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:02:43.854909  1600 solver.cpp:244]     Train net output #1: loss = 0.673159 (* 1 = 0.673159 loss)
I0312 17:02:43.854909  1600 sgd_solver.cpp:106] Iteration 77400, lr = 0.01
I0312 17:02:53.042546  1600 solver.cpp:228] Iteration 77500, loss = 0.738499
I0312 17:02:53.042546  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:02:53.042546  1600 solver.cpp:244]     Train net output #1: loss = 0.738499 (* 1 = 0.738499 loss)
I0312 17:02:53.042546  1600 sgd_solver.cpp:106] Iteration 77500, lr = 0.01
I0312 17:03:02.012847  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_77600.caffemodel
I0312 17:03:02.042846  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_77600.solverstate
I0312 17:03:02.047845  1600 solver.cpp:337] Iteration 77600, Testing net (#0)
I0312 17:03:02.047845  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:03:05.786294  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6221
I0312 17:03:05.786294  1600 solver.cpp:404]     Test net output #1: loss = 1.55272 (* 1 = 1.55272 loss)
I0312 17:03:05.806295  1600 solver.cpp:228] Iteration 77600, loss = 0.767002
I0312 17:03:05.806295  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:03:05.806295  1600 solver.cpp:244]     Train net output #1: loss = 0.767002 (* 1 = 0.767002 loss)
I0312 17:03:05.806295  1600 sgd_solver.cpp:106] Iteration 77600, lr = 0.01
I0312 17:03:15.041491  1600 solver.cpp:228] Iteration 77700, loss = 0.834967
I0312 17:03:15.041491  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:03:15.041491  1600 solver.cpp:244]     Train net output #1: loss = 0.834967 (* 1 = 0.834967 loss)
I0312 17:03:15.041491  1600 sgd_solver.cpp:106] Iteration 77700, lr = 0.01
I0312 17:03:24.105541  1600 solver.cpp:228] Iteration 77800, loss = 0.475344
I0312 17:03:24.105541  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:03:24.105541  1600 solver.cpp:244]     Train net output #1: loss = 0.475345 (* 1 = 0.475345 loss)
I0312 17:03:24.105541  1600 sgd_solver.cpp:106] Iteration 77800, lr = 0.01
I0312 17:03:33.197026  1600 solver.cpp:228] Iteration 77900, loss = 0.739126
I0312 17:03:33.197026  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:03:33.197026  1600 solver.cpp:244]     Train net output #1: loss = 0.739126 (* 1 = 0.739126 loss)
I0312 17:03:33.197026  1600 sgd_solver.cpp:106] Iteration 77900, lr = 0.01
I0312 17:03:42.421306  1600 solver.cpp:228] Iteration 78000, loss = 0.351986
I0312 17:03:42.421306  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:03:42.421306  1600 solver.cpp:244]     Train net output #1: loss = 0.351987 (* 1 = 0.351987 loss)
I0312 17:03:42.421306  1600 sgd_solver.cpp:106] Iteration 78000, lr = 0.01
I0312 17:03:51.601788  1600 solver.cpp:228] Iteration 78100, loss = 0.703039
I0312 17:03:51.601788  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:03:51.601788  1600 solver.cpp:244]     Train net output #1: loss = 0.703039 (* 1 = 0.703039 loss)
I0312 17:03:51.601788  1600 sgd_solver.cpp:106] Iteration 78100, lr = 0.01
I0312 17:04:00.545126  1600 solver.cpp:228] Iteration 78200, loss = 0.979463
I0312 17:04:00.545126  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:04:00.545126  1600 solver.cpp:244]     Train net output #1: loss = 0.979463 (* 1 = 0.979463 loss)
I0312 17:04:00.545126  1600 sgd_solver.cpp:106] Iteration 78200, lr = 0.01
I0312 17:04:09.538056  1600 solver.cpp:228] Iteration 78300, loss = 0.587318
I0312 17:04:09.538056  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:04:09.538056  1600 solver.cpp:244]     Train net output #1: loss = 0.587318 (* 1 = 0.587318 loss)
I0312 17:04:09.538056  1600 sgd_solver.cpp:106] Iteration 78300, lr = 0.01
I0312 17:04:18.511996  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_78400.caffemodel
I0312 17:04:18.522004  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_78400.solverstate
I0312 17:04:18.532001  1600 solver.cpp:337] Iteration 78400, Testing net (#0)
I0312 17:04:18.532001  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:04:22.413215  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6221
I0312 17:04:22.413215  1600 solver.cpp:404]     Test net output #1: loss = 1.56854 (* 1 = 1.56854 loss)
I0312 17:04:22.443229  1600 solver.cpp:228] Iteration 78400, loss = 0.714875
I0312 17:04:22.443229  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:04:22.443229  1600 solver.cpp:244]     Train net output #1: loss = 0.714875 (* 1 = 0.714875 loss)
I0312 17:04:22.443229  1600 sgd_solver.cpp:106] Iteration 78400, lr = 0.01
I0312 17:04:31.702900  1600 solver.cpp:228] Iteration 78500, loss = 0.638671
I0312 17:04:31.702900  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:04:31.702900  1600 solver.cpp:244]     Train net output #1: loss = 0.638671 (* 1 = 0.638671 loss)
I0312 17:04:31.702900  1600 sgd_solver.cpp:106] Iteration 78500, lr = 0.01
I0312 17:04:40.877482  1600 solver.cpp:228] Iteration 78600, loss = 0.759389
I0312 17:04:40.877482  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:04:40.877482  1600 solver.cpp:244]     Train net output #1: loss = 0.759389 (* 1 = 0.759389 loss)
I0312 17:04:40.877482  1600 sgd_solver.cpp:106] Iteration 78600, lr = 0.01
I0312 17:04:49.889523  1600 solver.cpp:228] Iteration 78700, loss = 0.747484
I0312 17:04:49.889523  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:04:49.889523  1600 solver.cpp:244]     Train net output #1: loss = 0.747484 (* 1 = 0.747484 loss)
I0312 17:04:49.889523  1600 sgd_solver.cpp:106] Iteration 78700, lr = 0.01
I0312 17:04:58.957070  1600 solver.cpp:228] Iteration 78800, loss = 0.761309
I0312 17:04:58.957070  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:04:58.957070  1600 solver.cpp:244]     Train net output #1: loss = 0.761309 (* 1 = 0.761309 loss)
I0312 17:04:58.957070  1600 sgd_solver.cpp:106] Iteration 78800, lr = 0.01
I0312 17:05:07.991148  1600 solver.cpp:228] Iteration 78900, loss = 0.969453
I0312 17:05:07.991148  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 17:05:07.991148  1600 solver.cpp:244]     Train net output #1: loss = 0.969453 (* 1 = 0.969453 loss)
I0312 17:05:07.991148  1600 sgd_solver.cpp:106] Iteration 78900, lr = 0.01
I0312 17:05:16.917759  1600 solver.cpp:228] Iteration 79000, loss = 0.937291
I0312 17:05:16.917759  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:05:16.917759  1600 solver.cpp:244]     Train net output #1: loss = 0.937291 (* 1 = 0.937291 loss)
I0312 17:05:16.917759  1600 sgd_solver.cpp:106] Iteration 79000, lr = 0.01
I0312 17:05:25.938161  1600 solver.cpp:228] Iteration 79100, loss = 0.588078
I0312 17:05:25.938161  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:05:25.938161  1600 solver.cpp:244]     Train net output #1: loss = 0.588078 (* 1 = 0.588078 loss)
I0312 17:05:25.938161  1600 sgd_solver.cpp:106] Iteration 79100, lr = 0.01
I0312 17:05:35.013676  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_79200.caffemodel
I0312 17:05:35.038216  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_79200.solverstate
I0312 17:05:35.043216  1600 solver.cpp:337] Iteration 79200, Testing net (#0)
I0312 17:05:35.043216  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:05:39.001201  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6238
I0312 17:05:39.001201  1600 solver.cpp:404]     Test net output #1: loss = 1.55787 (* 1 = 1.55787 loss)
I0312 17:05:39.050021  1600 solver.cpp:228] Iteration 79200, loss = 0.614738
I0312 17:05:39.050021  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:05:39.050021  1600 solver.cpp:244]     Train net output #1: loss = 0.614738 (* 1 = 0.614738 loss)
I0312 17:05:39.050021  1600 sgd_solver.cpp:106] Iteration 79200, lr = 0.01
I0312 17:05:48.311600  1600 solver.cpp:228] Iteration 79300, loss = 0.794948
I0312 17:05:48.312600  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:05:48.312600  1600 solver.cpp:244]     Train net output #1: loss = 0.794948 (* 1 = 0.794948 loss)
I0312 17:05:48.312600  1600 sgd_solver.cpp:106] Iteration 79300, lr = 0.01
I0312 17:05:57.487833  1600 solver.cpp:228] Iteration 79400, loss = 0.61002
I0312 17:05:57.487833  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:05:57.487833  1600 solver.cpp:244]     Train net output #1: loss = 0.61002 (* 1 = 0.61002 loss)
I0312 17:05:57.487833  1600 sgd_solver.cpp:106] Iteration 79400, lr = 0.01
I0312 17:06:06.442595  1600 solver.cpp:228] Iteration 79500, loss = 0.729769
I0312 17:06:06.442595  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:06:06.442595  1600 solver.cpp:244]     Train net output #1: loss = 0.729769 (* 1 = 0.729769 loss)
I0312 17:06:06.442595  1600 sgd_solver.cpp:106] Iteration 79500, lr = 0.01
I0312 17:06:15.568706  1600 solver.cpp:228] Iteration 79600, loss = 0.927487
I0312 17:06:15.568706  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:06:15.568706  1600 solver.cpp:244]     Train net output #1: loss = 0.927487 (* 1 = 0.927487 loss)
I0312 17:06:15.568706  1600 sgd_solver.cpp:106] Iteration 79600, lr = 0.01
I0312 17:06:24.779748  1600 solver.cpp:228] Iteration 79700, loss = 0.770318
I0312 17:06:24.779748  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:06:24.779748  1600 solver.cpp:244]     Train net output #1: loss = 0.770318 (* 1 = 0.770318 loss)
I0312 17:06:24.779748  1600 sgd_solver.cpp:106] Iteration 79700, lr = 0.01
I0312 17:06:33.822010  1600 solver.cpp:228] Iteration 79800, loss = 0.648424
I0312 17:06:33.822010  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:06:33.822010  1600 solver.cpp:244]     Train net output #1: loss = 0.648424 (* 1 = 0.648424 loss)
I0312 17:06:33.822010  1600 sgd_solver.cpp:106] Iteration 79800, lr = 0.01
I0312 17:06:42.928963  1600 solver.cpp:228] Iteration 79900, loss = 0.781258
I0312 17:06:42.928963  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:06:42.928963  1600 solver.cpp:244]     Train net output #1: loss = 0.781258 (* 1 = 0.781258 loss)
I0312 17:06:42.928963  1600 sgd_solver.cpp:106] Iteration 79900, lr = 0.01
I0312 17:06:52.009454  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_80000.caffemodel
I0312 17:06:52.046455  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_80000.solverstate
I0312 17:06:52.051954  1600 solver.cpp:337] Iteration 80000, Testing net (#0)
I0312 17:06:52.051954  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:06:55.779994  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6213
I0312 17:06:55.779994  1600 solver.cpp:404]     Test net output #1: loss = 1.56496 (* 1 = 1.56496 loss)
I0312 17:06:55.829996  1600 solver.cpp:228] Iteration 80000, loss = 0.709404
I0312 17:06:55.829996  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:06:55.829996  1600 solver.cpp:244]     Train net output #1: loss = 0.709404 (* 1 = 0.709404 loss)
I0312 17:06:55.829996  1600 sgd_solver.cpp:106] Iteration 80000, lr = 0.01
I0312 17:07:04.838889  1600 solver.cpp:228] Iteration 80100, loss = 0.730584
I0312 17:07:04.839387  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:07:04.839387  1600 solver.cpp:244]     Train net output #1: loss = 0.730584 (* 1 = 0.730584 loss)
I0312 17:07:04.839387  1600 sgd_solver.cpp:106] Iteration 80100, lr = 0.01
I0312 17:07:13.856809  1600 solver.cpp:228] Iteration 80200, loss = 0.661248
I0312 17:07:13.856809  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:07:13.856809  1600 solver.cpp:244]     Train net output #1: loss = 0.661248 (* 1 = 0.661248 loss)
I0312 17:07:13.856809  1600 sgd_solver.cpp:106] Iteration 80200, lr = 0.01
I0312 17:07:20.150241  1600 solver.cpp:228] Iteration 80300, loss = 0.452103
I0312 17:07:20.150241  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 17:07:20.150241  1600 solver.cpp:244]     Train net output #1: loss = 0.452103 (* 1 = 0.452103 loss)
I0312 17:07:20.150241  1600 sgd_solver.cpp:106] Iteration 80300, lr = 0.01
I0312 17:07:25.988852  1600 solver.cpp:228] Iteration 80400, loss = 0.708272
I0312 17:07:25.988852  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:07:25.988852  1600 solver.cpp:244]     Train net output #1: loss = 0.708272 (* 1 = 0.708272 loss)
I0312 17:07:25.988852  1600 sgd_solver.cpp:106] Iteration 80400, lr = 0.01
I0312 17:07:31.816072  1600 solver.cpp:228] Iteration 80500, loss = 0.550147
I0312 17:07:31.816072  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:07:31.816571  1600 solver.cpp:244]     Train net output #1: loss = 0.550147 (* 1 = 0.550147 loss)
I0312 17:07:31.816571  1600 sgd_solver.cpp:106] Iteration 80500, lr = 0.01
I0312 17:07:40.543634  1600 solver.cpp:228] Iteration 80600, loss = 0.471104
I0312 17:07:40.544136  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:07:40.544136  1600 solver.cpp:244]     Train net output #1: loss = 0.471104 (* 1 = 0.471104 loss)
I0312 17:07:40.544136  1600 sgd_solver.cpp:106] Iteration 80600, lr = 0.01
I0312 17:07:49.496806  1600 solver.cpp:228] Iteration 80700, loss = 0.379024
I0312 17:07:49.496806  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:07:49.496806  1600 solver.cpp:244]     Train net output #1: loss = 0.379024 (* 1 = 0.379024 loss)
I0312 17:07:49.496806  1600 sgd_solver.cpp:106] Iteration 80700, lr = 0.01
I0312 17:07:58.578514  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_80800.caffemodel
I0312 17:07:58.605496  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_80800.solverstate
I0312 17:07:58.610496  1600 solver.cpp:337] Iteration 80800, Testing net (#0)
I0312 17:07:58.610496  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:08:02.313521  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6185
I0312 17:08:02.313521  1600 solver.cpp:404]     Test net output #1: loss = 1.56496 (* 1 = 1.56496 loss)
I0312 17:08:02.338038  1600 solver.cpp:228] Iteration 80800, loss = 0.50879
I0312 17:08:02.338038  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:08:02.338038  1600 solver.cpp:244]     Train net output #1: loss = 0.508791 (* 1 = 0.508791 loss)
I0312 17:08:02.338038  1600 sgd_solver.cpp:106] Iteration 80800, lr = 0.01
I0312 17:08:11.573997  1600 solver.cpp:228] Iteration 80900, loss = 0.639974
I0312 17:08:11.573997  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:08:11.573997  1600 solver.cpp:244]     Train net output #1: loss = 0.639975 (* 1 = 0.639975 loss)
I0312 17:08:11.573997  1600 sgd_solver.cpp:106] Iteration 80900, lr = 0.01
I0312 17:08:20.481678  1600 solver.cpp:228] Iteration 81000, loss = 0.589117
I0312 17:08:20.481678  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:08:20.481678  1600 solver.cpp:244]     Train net output #1: loss = 0.589117 (* 1 = 0.589117 loss)
I0312 17:08:20.481678  1600 sgd_solver.cpp:106] Iteration 81000, lr = 0.01
I0312 17:08:29.624953  1600 solver.cpp:228] Iteration 81100, loss = 0.704504
I0312 17:08:29.624953  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:08:29.624953  1600 solver.cpp:244]     Train net output #1: loss = 0.704504 (* 1 = 0.704504 loss)
I0312 17:08:29.624953  1600 sgd_solver.cpp:106] Iteration 81100, lr = 0.01
I0312 17:08:38.745229  1600 solver.cpp:228] Iteration 81200, loss = 0.615292
I0312 17:08:38.745229  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:08:38.745229  1600 solver.cpp:244]     Train net output #1: loss = 0.615293 (* 1 = 0.615293 loss)
I0312 17:08:38.745229  1600 sgd_solver.cpp:106] Iteration 81200, lr = 0.01
I0312 17:08:47.978514  1600 solver.cpp:228] Iteration 81300, loss = 0.903375
I0312 17:08:47.978514  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:08:47.978514  1600 solver.cpp:244]     Train net output #1: loss = 0.903375 (* 1 = 0.903375 loss)
I0312 17:08:47.978514  1600 sgd_solver.cpp:106] Iteration 81300, lr = 0.01
I0312 17:08:57.100626  1600 solver.cpp:228] Iteration 81400, loss = 0.789714
I0312 17:08:57.101125  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:08:57.101125  1600 solver.cpp:244]     Train net output #1: loss = 0.789714 (* 1 = 0.789714 loss)
I0312 17:08:57.101125  1600 sgd_solver.cpp:106] Iteration 81400, lr = 0.01
I0312 17:09:06.302592  1600 solver.cpp:228] Iteration 81500, loss = 0.621865
I0312 17:09:06.302592  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:09:06.302592  1600 solver.cpp:244]     Train net output #1: loss = 0.621865 (* 1 = 0.621865 loss)
I0312 17:09:06.302592  1600 sgd_solver.cpp:106] Iteration 81500, lr = 0.01
I0312 17:09:15.260716  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_81600.caffemodel
I0312 17:09:15.280719  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_81600.solverstate
I0312 17:09:15.280719  1600 solver.cpp:337] Iteration 81600, Testing net (#0)
I0312 17:09:15.280719  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:09:19.094197  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6228
I0312 17:09:19.094197  1600 solver.cpp:404]     Test net output #1: loss = 1.57496 (* 1 = 1.57496 loss)
I0312 17:09:19.118140  1600 solver.cpp:228] Iteration 81600, loss = 0.653482
I0312 17:09:19.118140  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:09:19.118140  1600 solver.cpp:244]     Train net output #1: loss = 0.653482 (* 1 = 0.653482 loss)
I0312 17:09:19.118140  1600 sgd_solver.cpp:106] Iteration 81600, lr = 0.01
I0312 17:09:28.342597  1600 solver.cpp:228] Iteration 81700, loss = 0.56928
I0312 17:09:28.342597  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:09:28.343598  1600 solver.cpp:244]     Train net output #1: loss = 0.56928 (* 1 = 0.56928 loss)
I0312 17:09:28.343598  1600 sgd_solver.cpp:106] Iteration 81700, lr = 0.01
I0312 17:09:37.648313  1600 solver.cpp:228] Iteration 81800, loss = 0.936396
I0312 17:09:37.648313  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:09:37.648313  1600 solver.cpp:244]     Train net output #1: loss = 0.936396 (* 1 = 0.936396 loss)
I0312 17:09:37.648313  1600 sgd_solver.cpp:106] Iteration 81800, lr = 0.01
I0312 17:09:47.176550  1600 solver.cpp:228] Iteration 81900, loss = 0.6573
I0312 17:09:47.176550  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:09:47.176550  1600 solver.cpp:244]     Train net output #1: loss = 0.6573 (* 1 = 0.6573 loss)
I0312 17:09:47.176550  1600 sgd_solver.cpp:106] Iteration 81900, lr = 0.01
I0312 17:09:56.543615  1600 solver.cpp:228] Iteration 82000, loss = 0.770845
I0312 17:09:56.544114  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:09:56.544114  1600 solver.cpp:244]     Train net output #1: loss = 0.770845 (* 1 = 0.770845 loss)
I0312 17:09:56.544114  1600 sgd_solver.cpp:106] Iteration 82000, lr = 0.01
I0312 17:10:05.677575  1600 solver.cpp:228] Iteration 82100, loss = 0.961229
I0312 17:10:05.677575  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:10:05.677575  1600 solver.cpp:244]     Train net output #1: loss = 0.961229 (* 1 = 0.961229 loss)
I0312 17:10:05.677575  1600 sgd_solver.cpp:106] Iteration 82100, lr = 0.01
I0312 17:10:15.168896  1600 solver.cpp:228] Iteration 82200, loss = 0.83696
I0312 17:10:15.168896  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:10:15.168896  1600 solver.cpp:244]     Train net output #1: loss = 0.83696 (* 1 = 0.83696 loss)
I0312 17:10:15.168896  1600 sgd_solver.cpp:106] Iteration 82200, lr = 0.01
I0312 17:10:24.348990  1600 solver.cpp:228] Iteration 82300, loss = 0.621628
I0312 17:10:24.348990  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:10:24.348990  1600 solver.cpp:244]     Train net output #1: loss = 0.621628 (* 1 = 0.621628 loss)
I0312 17:10:24.348990  1600 sgd_solver.cpp:106] Iteration 82300, lr = 0.01
I0312 17:10:33.365317  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_82400.caffemodel
I0312 17:10:33.397817  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_82400.solverstate
I0312 17:10:33.403317  1600 solver.cpp:337] Iteration 82400, Testing net (#0)
I0312 17:10:33.403317  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:10:37.381423  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6195
I0312 17:10:37.381423  1600 solver.cpp:404]     Test net output #1: loss = 1.59138 (* 1 = 1.59138 loss)
I0312 17:10:37.423926  1600 solver.cpp:228] Iteration 82400, loss = 0.906768
I0312 17:10:37.423926  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:10:37.423926  1600 solver.cpp:244]     Train net output #1: loss = 0.906768 (* 1 = 0.906768 loss)
I0312 17:10:37.423926  1600 sgd_solver.cpp:106] Iteration 82400, lr = 0.01
I0312 17:10:46.762830  1600 solver.cpp:228] Iteration 82500, loss = 0.879918
I0312 17:10:46.762830  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:10:46.762830  1600 solver.cpp:244]     Train net output #1: loss = 0.879918 (* 1 = 0.879918 loss)
I0312 17:10:46.762830  1600 sgd_solver.cpp:106] Iteration 82500, lr = 0.01
I0312 17:10:56.159885  1600 solver.cpp:228] Iteration 82600, loss = 1.01913
I0312 17:10:56.159885  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:10:56.159885  1600 solver.cpp:244]     Train net output #1: loss = 1.01913 (* 1 = 1.01913 loss)
I0312 17:10:56.159885  1600 sgd_solver.cpp:106] Iteration 82600, lr = 0.01
I0312 17:11:05.339893  1600 solver.cpp:228] Iteration 82700, loss = 0.643747
I0312 17:11:05.339893  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:11:05.339893  1600 solver.cpp:244]     Train net output #1: loss = 0.643747 (* 1 = 0.643747 loss)
I0312 17:11:05.339893  1600 sgd_solver.cpp:106] Iteration 82700, lr = 0.01
I0312 17:11:14.398330  1600 solver.cpp:228] Iteration 82800, loss = 1.08238
I0312 17:11:14.398830  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.640625
I0312 17:11:14.398830  1600 solver.cpp:244]     Train net output #1: loss = 1.08238 (* 1 = 1.08238 loss)
I0312 17:11:14.398830  1600 sgd_solver.cpp:106] Iteration 82800, lr = 0.01
I0312 17:11:23.531890  1600 solver.cpp:228] Iteration 82900, loss = 0.605872
I0312 17:11:23.531890  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:11:23.531890  1600 solver.cpp:244]     Train net output #1: loss = 0.605872 (* 1 = 0.605872 loss)
I0312 17:11:23.531890  1600 sgd_solver.cpp:106] Iteration 82900, lr = 0.01
I0312 17:11:32.975324  1600 solver.cpp:228] Iteration 83000, loss = 0.600823
I0312 17:11:32.975324  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:11:32.975324  1600 solver.cpp:244]     Train net output #1: loss = 0.600824 (* 1 = 0.600824 loss)
I0312 17:11:32.975324  1600 sgd_solver.cpp:106] Iteration 83000, lr = 0.01
I0312 17:11:42.028885  1600 solver.cpp:228] Iteration 83100, loss = 0.641331
I0312 17:11:42.028885  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:11:42.028885  1600 solver.cpp:244]     Train net output #1: loss = 0.641331 (* 1 = 0.641331 loss)
I0312 17:11:42.028885  1600 sgd_solver.cpp:106] Iteration 83100, lr = 0.01
I0312 17:11:51.130615  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_83200.caffemodel
I0312 17:11:51.146596  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_83200.solverstate
I0312 17:11:51.151597  1600 solver.cpp:337] Iteration 83200, Testing net (#0)
I0312 17:11:51.151597  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:11:54.892694  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6232
I0312 17:11:54.893193  1600 solver.cpp:404]     Test net output #1: loss = 1.58124 (* 1 = 1.58124 loss)
I0312 17:11:54.909767  1600 solver.cpp:228] Iteration 83200, loss = 0.823871
I0312 17:11:54.909767  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:11:54.909767  1600 solver.cpp:244]     Train net output #1: loss = 0.823871 (* 1 = 0.823871 loss)
I0312 17:11:54.909767  1600 sgd_solver.cpp:106] Iteration 83200, lr = 0.01
I0312 17:12:03.915693  1600 solver.cpp:228] Iteration 83300, loss = 0.874883
I0312 17:12:03.915693  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:12:03.915693  1600 solver.cpp:244]     Train net output #1: loss = 0.874883 (* 1 = 0.874883 loss)
I0312 17:12:03.916188  1600 sgd_solver.cpp:106] Iteration 83300, lr = 0.01
I0312 17:12:13.097632  1600 solver.cpp:228] Iteration 83400, loss = 0.602362
I0312 17:12:13.097632  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:12:13.097632  1600 solver.cpp:244]     Train net output #1: loss = 0.602362 (* 1 = 0.602362 loss)
I0312 17:12:13.097632  1600 sgd_solver.cpp:106] Iteration 83400, lr = 0.01
I0312 17:12:22.062669  1600 solver.cpp:228] Iteration 83500, loss = 0.587578
I0312 17:12:22.062669  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:12:22.062669  1600 solver.cpp:244]     Train net output #1: loss = 0.587578 (* 1 = 0.587578 loss)
I0312 17:12:22.062669  1600 sgd_solver.cpp:106] Iteration 83500, lr = 0.01
I0312 17:12:28.275068  1600 solver.cpp:228] Iteration 83600, loss = 0.587956
I0312 17:12:28.275068  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:12:28.275068  1600 solver.cpp:244]     Train net output #1: loss = 0.587957 (* 1 = 0.587957 loss)
I0312 17:12:28.275068  1600 sgd_solver.cpp:106] Iteration 83600, lr = 0.01
I0312 17:12:34.157649  1600 solver.cpp:228] Iteration 83700, loss = 0.526524
I0312 17:12:34.157649  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:12:34.157649  1600 solver.cpp:244]     Train net output #1: loss = 0.526524 (* 1 = 0.526524 loss)
I0312 17:12:34.157649  1600 sgd_solver.cpp:106] Iteration 83700, lr = 0.01
I0312 17:12:40.073806  1600 solver.cpp:228] Iteration 83800, loss = 0.484212
I0312 17:12:40.073806  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:12:40.073806  1600 solver.cpp:244]     Train net output #1: loss = 0.484212 (* 1 = 0.484212 loss)
I0312 17:12:40.073806  1600 sgd_solver.cpp:106] Iteration 83800, lr = 0.01
I0312 17:12:49.042727  1600 solver.cpp:228] Iteration 83900, loss = 0.623877
I0312 17:12:49.042727  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:12:49.042727  1600 solver.cpp:244]     Train net output #1: loss = 0.623877 (* 1 = 0.623877 loss)
I0312 17:12:49.042727  1600 sgd_solver.cpp:106] Iteration 83900, lr = 0.01
I0312 17:12:58.140774  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_84000.caffemodel
I0312 17:12:58.173274  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_84000.solverstate
I0312 17:12:58.177773  1600 solver.cpp:337] Iteration 84000, Testing net (#0)
I0312 17:12:58.178273  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:13:01.925102  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6215
I0312 17:13:01.926085  1600 solver.cpp:404]     Test net output #1: loss = 1.57747 (* 1 = 1.57747 loss)
I0312 17:13:01.953083  1600 solver.cpp:228] Iteration 84000, loss = 0.786864
I0312 17:13:01.953083  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:13:01.953083  1600 solver.cpp:244]     Train net output #1: loss = 0.786864 (* 1 = 0.786864 loss)
I0312 17:13:01.953083  1600 sgd_solver.cpp:106] Iteration 84000, lr = 0.01
I0312 17:13:11.218793  1600 solver.cpp:228] Iteration 84100, loss = 0.646029
I0312 17:13:11.218793  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:13:11.218793  1600 solver.cpp:244]     Train net output #1: loss = 0.646029 (* 1 = 0.646029 loss)
I0312 17:13:11.218793  1600 sgd_solver.cpp:106] Iteration 84100, lr = 0.01
I0312 17:13:20.418745  1600 solver.cpp:228] Iteration 84200, loss = 0.454576
I0312 17:13:20.418745  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:13:20.418745  1600 solver.cpp:244]     Train net output #1: loss = 0.454576 (* 1 = 0.454576 loss)
I0312 17:13:20.418745  1600 sgd_solver.cpp:106] Iteration 84200, lr = 0.01
I0312 17:13:29.584396  1600 solver.cpp:228] Iteration 84300, loss = 0.684575
I0312 17:13:29.584396  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:13:29.584897  1600 solver.cpp:244]     Train net output #1: loss = 0.684575 (* 1 = 0.684575 loss)
I0312 17:13:29.584897  1600 sgd_solver.cpp:106] Iteration 84300, lr = 0.01
I0312 17:13:38.861498  1600 solver.cpp:228] Iteration 84400, loss = 0.909684
I0312 17:13:38.861498  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:13:38.861498  1600 solver.cpp:244]     Train net output #1: loss = 0.909684 (* 1 = 0.909684 loss)
I0312 17:13:38.861498  1600 sgd_solver.cpp:106] Iteration 84400, lr = 0.01
I0312 17:13:48.038700  1600 solver.cpp:228] Iteration 84500, loss = 0.593114
I0312 17:13:48.039201  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:13:48.039201  1600 solver.cpp:244]     Train net output #1: loss = 0.593114 (* 1 = 0.593114 loss)
I0312 17:13:48.039201  1600 sgd_solver.cpp:106] Iteration 84500, lr = 0.01
I0312 17:13:57.102524  1600 solver.cpp:228] Iteration 84600, loss = 0.583533
I0312 17:13:57.102524  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:13:57.102524  1600 solver.cpp:244]     Train net output #1: loss = 0.583533 (* 1 = 0.583533 loss)
I0312 17:13:57.102524  1600 sgd_solver.cpp:106] Iteration 84600, lr = 0.01
I0312 17:14:06.269420  1600 solver.cpp:228] Iteration 84700, loss = 0.505764
I0312 17:14:06.269420  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:14:06.269420  1600 solver.cpp:244]     Train net output #1: loss = 0.505764 (* 1 = 0.505764 loss)
I0312 17:14:06.269420  1600 sgd_solver.cpp:106] Iteration 84700, lr = 0.01
I0312 17:14:15.464337  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_84800.caffemodel
I0312 17:14:15.479833  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_84800.solverstate
I0312 17:14:15.484834  1600 solver.cpp:337] Iteration 84800, Testing net (#0)
I0312 17:14:15.484834  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:14:19.142949  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6188
I0312 17:14:19.142949  1600 solver.cpp:404]     Test net output #1: loss = 1.57758 (* 1 = 1.57758 loss)
I0312 17:14:19.182948  1600 solver.cpp:228] Iteration 84800, loss = 0.912212
I0312 17:14:19.182948  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:14:19.182948  1600 solver.cpp:244]     Train net output #1: loss = 0.912213 (* 1 = 0.912213 loss)
I0312 17:14:19.182948  1600 sgd_solver.cpp:106] Iteration 84800, lr = 0.01
I0312 17:14:28.380481  1600 solver.cpp:228] Iteration 84900, loss = 0.84699
I0312 17:14:28.380481  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:14:28.380481  1600 solver.cpp:244]     Train net output #1: loss = 0.84699 (* 1 = 0.84699 loss)
I0312 17:14:28.380481  1600 sgd_solver.cpp:106] Iteration 84900, lr = 0.01
I0312 17:14:37.621477  1600 solver.cpp:228] Iteration 85000, loss = 0.924018
I0312 17:14:37.621477  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:14:37.621477  1600 solver.cpp:244]     Train net output #1: loss = 0.924018 (* 1 = 0.924018 loss)
I0312 17:14:37.621477  1600 sgd_solver.cpp:106] Iteration 85000, lr = 0.01
I0312 17:14:46.684900  1600 solver.cpp:228] Iteration 85100, loss = 0.668241
I0312 17:14:46.684900  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:14:46.684900  1600 solver.cpp:244]     Train net output #1: loss = 0.668241 (* 1 = 0.668241 loss)
I0312 17:14:46.684900  1600 sgd_solver.cpp:106] Iteration 85100, lr = 0.01
I0312 17:14:55.630275  1600 solver.cpp:228] Iteration 85200, loss = 0.92666
I0312 17:14:55.630275  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:14:55.630275  1600 solver.cpp:244]     Train net output #1: loss = 0.92666 (* 1 = 0.92666 loss)
I0312 17:14:55.630275  1600 sgd_solver.cpp:106] Iteration 85200, lr = 0.01
I0312 17:15:04.858547  1600 solver.cpp:228] Iteration 85300, loss = 0.56392
I0312 17:15:04.858547  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:15:04.858547  1600 solver.cpp:244]     Train net output #1: loss = 0.56392 (* 1 = 0.56392 loss)
I0312 17:15:04.858547  1600 sgd_solver.cpp:106] Iteration 85300, lr = 0.01
I0312 17:15:14.050165  1600 solver.cpp:228] Iteration 85400, loss = 0.750295
I0312 17:15:14.050664  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:15:14.050664  1600 solver.cpp:244]     Train net output #1: loss = 0.750295 (* 1 = 0.750295 loss)
I0312 17:15:14.050664  1600 sgd_solver.cpp:106] Iteration 85400, lr = 0.01
I0312 17:15:23.287353  1600 solver.cpp:228] Iteration 85500, loss = 0.867759
I0312 17:15:23.287353  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:15:23.287853  1600 solver.cpp:244]     Train net output #1: loss = 0.867759 (* 1 = 0.867759 loss)
I0312 17:15:23.287853  1600 sgd_solver.cpp:106] Iteration 85500, lr = 0.01
I0312 17:15:32.342278  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_85600.caffemodel
I0312 17:15:32.362285  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_85600.solverstate
I0312 17:15:32.372287  1600 solver.cpp:337] Iteration 85600, Testing net (#0)
I0312 17:15:32.372287  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:15:36.268383  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6199
I0312 17:15:36.268383  1600 solver.cpp:404]     Test net output #1: loss = 1.57776 (* 1 = 1.57776 loss)
I0312 17:15:36.290372  1600 solver.cpp:228] Iteration 85600, loss = 0.721658
I0312 17:15:36.290372  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:15:36.290372  1600 solver.cpp:244]     Train net output #1: loss = 0.721658 (* 1 = 0.721658 loss)
I0312 17:15:36.290372  1600 sgd_solver.cpp:106] Iteration 85600, lr = 0.01
I0312 17:15:45.570390  1600 solver.cpp:228] Iteration 85700, loss = 0.593406
I0312 17:15:45.570390  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:15:45.570390  1600 solver.cpp:244]     Train net output #1: loss = 0.593406 (* 1 = 0.593406 loss)
I0312 17:15:45.570390  1600 sgd_solver.cpp:106] Iteration 85700, lr = 0.01
I0312 17:15:54.794471  1600 solver.cpp:228] Iteration 85800, loss = 0.626093
I0312 17:15:54.794471  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:15:54.794471  1600 solver.cpp:244]     Train net output #1: loss = 0.626093 (* 1 = 0.626093 loss)
I0312 17:15:54.794471  1600 sgd_solver.cpp:106] Iteration 85800, lr = 0.01
I0312 17:16:03.858017  1600 solver.cpp:228] Iteration 85900, loss = 0.508077
I0312 17:16:03.858017  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:16:03.858017  1600 solver.cpp:244]     Train net output #1: loss = 0.508078 (* 1 = 0.508078 loss)
I0312 17:16:03.858017  1600 sgd_solver.cpp:106] Iteration 85900, lr = 0.01
I0312 17:16:12.982097  1600 solver.cpp:228] Iteration 86000, loss = 0.619726
I0312 17:16:12.982097  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:16:12.982097  1600 solver.cpp:244]     Train net output #1: loss = 0.619727 (* 1 = 0.619727 loss)
I0312 17:16:12.982097  1600 sgd_solver.cpp:106] Iteration 86000, lr = 0.01
I0312 17:16:22.306593  1600 solver.cpp:228] Iteration 86100, loss = 0.792326
I0312 17:16:22.306593  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:16:22.306593  1600 solver.cpp:244]     Train net output #1: loss = 0.792326 (* 1 = 0.792326 loss)
I0312 17:16:22.306593  1600 sgd_solver.cpp:106] Iteration 86100, lr = 0.01
I0312 17:16:31.283818  1600 solver.cpp:228] Iteration 86200, loss = 0.588277
I0312 17:16:31.283818  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:16:31.283818  1600 solver.cpp:244]     Train net output #1: loss = 0.588277 (* 1 = 0.588277 loss)
I0312 17:16:31.284332  1600 sgd_solver.cpp:106] Iteration 86200, lr = 0.01
I0312 17:16:40.417579  1600 solver.cpp:228] Iteration 86300, loss = 0.770464
I0312 17:16:40.417579  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:16:40.417579  1600 solver.cpp:244]     Train net output #1: loss = 0.770464 (* 1 = 0.770464 loss)
I0312 17:16:40.417579  1600 sgd_solver.cpp:106] Iteration 86300, lr = 0.01
I0312 17:16:49.399428  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_86400.caffemodel
I0312 17:16:49.415427  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_86400.solverstate
I0312 17:16:49.421429  1600 solver.cpp:337] Iteration 86400, Testing net (#0)
I0312 17:16:49.421429  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:16:53.087519  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6198
I0312 17:16:53.087519  1600 solver.cpp:404]     Test net output #1: loss = 1.59575 (* 1 = 1.59575 loss)
I0312 17:16:53.117518  1600 solver.cpp:228] Iteration 86400, loss = 0.660577
I0312 17:16:53.117518  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:16:53.117518  1600 solver.cpp:244]     Train net output #1: loss = 0.660577 (* 1 = 0.660577 loss)
I0312 17:16:53.117518  1600 sgd_solver.cpp:106] Iteration 86400, lr = 0.01
I0312 17:17:02.292943  1600 solver.cpp:228] Iteration 86500, loss = 0.469457
I0312 17:17:02.292943  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:17:02.292943  1600 solver.cpp:244]     Train net output #1: loss = 0.469457 (* 1 = 0.469457 loss)
I0312 17:17:02.292943  1600 sgd_solver.cpp:106] Iteration 86500, lr = 0.01
I0312 17:17:11.414988  1600 solver.cpp:228] Iteration 86600, loss = 0.817833
I0312 17:17:11.414988  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:17:11.414988  1600 solver.cpp:244]     Train net output #1: loss = 0.817833 (* 1 = 0.817833 loss)
I0312 17:17:11.414988  1600 sgd_solver.cpp:106] Iteration 86600, lr = 0.01
I0312 17:17:20.685792  1600 solver.cpp:228] Iteration 86700, loss = 0.759106
I0312 17:17:20.685792  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:17:20.685792  1600 solver.cpp:244]     Train net output #1: loss = 0.759106 (* 1 = 0.759106 loss)
I0312 17:17:20.685792  1600 sgd_solver.cpp:106] Iteration 86700, lr = 0.01
I0312 17:17:29.736846  1600 solver.cpp:228] Iteration 86800, loss = 0.652925
I0312 17:17:29.737355  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:17:29.737355  1600 solver.cpp:244]     Train net output #1: loss = 0.652925 (* 1 = 0.652925 loss)
I0312 17:17:29.737355  1600 sgd_solver.cpp:106] Iteration 86800, lr = 0.01
I0312 17:17:36.356251  1600 solver.cpp:228] Iteration 86900, loss = 0.484971
I0312 17:17:36.356251  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:17:36.356251  1600 solver.cpp:244]     Train net output #1: loss = 0.484971 (* 1 = 0.484971 loss)
I0312 17:17:36.356251  1600 sgd_solver.cpp:106] Iteration 86900, lr = 0.01
I0312 17:17:42.142163  1600 solver.cpp:228] Iteration 87000, loss = 0.877717
I0312 17:17:42.142663  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:17:42.142663  1600 solver.cpp:244]     Train net output #1: loss = 0.877717 (* 1 = 0.877717 loss)
I0312 17:17:42.142663  1600 sgd_solver.cpp:106] Iteration 87000, lr = 0.01
I0312 17:17:47.968456  1600 solver.cpp:228] Iteration 87100, loss = 0.787132
I0312 17:17:47.968456  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:17:47.968456  1600 solver.cpp:244]     Train net output #1: loss = 0.787132 (* 1 = 0.787132 loss)
I0312 17:17:47.968456  1600 sgd_solver.cpp:106] Iteration 87100, lr = 0.01
I0312 17:17:56.442044  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_87200.caffemodel
I0312 17:17:56.457531  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_87200.solverstate
I0312 17:17:56.463030  1600 solver.cpp:337] Iteration 87200, Testing net (#0)
I0312 17:17:56.463030  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:18:00.273581  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6225
I0312 17:18:00.273581  1600 solver.cpp:404]     Test net output #1: loss = 1.58941 (* 1 = 1.58941 loss)
I0312 17:18:00.318581  1600 solver.cpp:228] Iteration 87200, loss = 0.771982
I0312 17:18:00.318581  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:18:00.318581  1600 solver.cpp:244]     Train net output #1: loss = 0.771982 (* 1 = 0.771982 loss)
I0312 17:18:00.318581  1600 sgd_solver.cpp:106] Iteration 87200, lr = 0.01
I0312 17:18:09.542119  1600 solver.cpp:228] Iteration 87300, loss = 0.761249
I0312 17:18:09.542119  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:18:09.542119  1600 solver.cpp:244]     Train net output #1: loss = 0.761249 (* 1 = 0.761249 loss)
I0312 17:18:09.542119  1600 sgd_solver.cpp:106] Iteration 87300, lr = 0.01
I0312 17:18:18.933683  1600 solver.cpp:228] Iteration 87400, loss = 0.697113
I0312 17:18:18.933683  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:18:18.933683  1600 solver.cpp:244]     Train net output #1: loss = 0.697113 (* 1 = 0.697113 loss)
I0312 17:18:18.933683  1600 sgd_solver.cpp:106] Iteration 87400, lr = 0.01
I0312 17:18:27.914746  1600 solver.cpp:228] Iteration 87500, loss = 0.824529
I0312 17:18:27.914746  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:18:27.914746  1600 solver.cpp:244]     Train net output #1: loss = 0.824529 (* 1 = 0.824529 loss)
I0312 17:18:27.914746  1600 sgd_solver.cpp:106] Iteration 87500, lr = 0.01
I0312 17:18:37.178432  1600 solver.cpp:228] Iteration 87600, loss = 0.727182
I0312 17:18:37.178432  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:18:37.178432  1600 solver.cpp:244]     Train net output #1: loss = 0.727183 (* 1 = 0.727183 loss)
I0312 17:18:37.178432  1600 sgd_solver.cpp:106] Iteration 87600, lr = 0.01
I0312 17:18:46.341755  1600 solver.cpp:228] Iteration 87700, loss = 0.459512
I0312 17:18:46.341755  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:18:46.341755  1600 solver.cpp:244]     Train net output #1: loss = 0.459512 (* 1 = 0.459512 loss)
I0312 17:18:46.341755  1600 sgd_solver.cpp:106] Iteration 87700, lr = 0.01
I0312 17:18:55.573415  1600 solver.cpp:228] Iteration 87800, loss = 0.516192
I0312 17:18:55.573415  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:18:55.573415  1600 solver.cpp:244]     Train net output #1: loss = 0.516192 (* 1 = 0.516192 loss)
I0312 17:18:55.573415  1600 sgd_solver.cpp:106] Iteration 87800, lr = 0.01
I0312 17:19:04.630653  1600 solver.cpp:228] Iteration 87900, loss = 0.494308
I0312 17:19:04.630653  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:19:04.630653  1600 solver.cpp:244]     Train net output #1: loss = 0.494308 (* 1 = 0.494308 loss)
I0312 17:19:04.630653  1600 sgd_solver.cpp:106] Iteration 87900, lr = 0.01
I0312 17:19:13.609498  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_88000.caffemodel
I0312 17:19:13.636998  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_88000.solverstate
I0312 17:19:13.642498  1600 solver.cpp:337] Iteration 88000, Testing net (#0)
I0312 17:19:13.642498  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:19:17.396015  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6215
I0312 17:19:17.396015  1600 solver.cpp:404]     Test net output #1: loss = 1.59831 (* 1 = 1.59831 loss)
I0312 17:19:17.458695  1600 solver.cpp:228] Iteration 88000, loss = 0.672414
I0312 17:19:17.458695  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:19:17.458695  1600 solver.cpp:244]     Train net output #1: loss = 0.672414 (* 1 = 0.672414 loss)
I0312 17:19:17.458695  1600 sgd_solver.cpp:106] Iteration 88000, lr = 0.01
I0312 17:19:26.577893  1600 solver.cpp:228] Iteration 88100, loss = 0.497824
I0312 17:19:26.578395  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:19:26.578395  1600 solver.cpp:244]     Train net output #1: loss = 0.497824 (* 1 = 0.497824 loss)
I0312 17:19:26.578395  1600 sgd_solver.cpp:106] Iteration 88100, lr = 0.01
I0312 17:19:35.838181  1600 solver.cpp:228] Iteration 88200, loss = 0.508654
I0312 17:19:35.838680  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:19:35.838680  1600 solver.cpp:244]     Train net output #1: loss = 0.508654 (* 1 = 0.508654 loss)
I0312 17:19:35.838680  1600 sgd_solver.cpp:106] Iteration 88200, lr = 0.01
I0312 17:19:44.794385  1600 solver.cpp:228] Iteration 88300, loss = 0.601408
I0312 17:19:44.794885  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:19:44.794885  1600 solver.cpp:244]     Train net output #1: loss = 0.601409 (* 1 = 0.601409 loss)
I0312 17:19:44.794885  1600 sgd_solver.cpp:106] Iteration 88300, lr = 0.01
I0312 17:19:54.075402  1600 solver.cpp:228] Iteration 88400, loss = 0.605344
I0312 17:19:54.075402  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:19:54.075402  1600 solver.cpp:244]     Train net output #1: loss = 0.605344 (* 1 = 0.605344 loss)
I0312 17:19:54.075402  1600 sgd_solver.cpp:106] Iteration 88400, lr = 0.01
I0312 17:20:03.230129  1600 solver.cpp:228] Iteration 88500, loss = 0.69601
I0312 17:20:03.230129  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:20:03.230129  1600 solver.cpp:244]     Train net output #1: loss = 0.69601 (* 1 = 0.69601 loss)
I0312 17:20:03.230129  1600 sgd_solver.cpp:106] Iteration 88500, lr = 0.01
I0312 17:20:12.323777  1600 solver.cpp:228] Iteration 88600, loss = 0.681384
I0312 17:20:12.324277  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:20:12.324277  1600 solver.cpp:244]     Train net output #1: loss = 0.681384 (* 1 = 0.681384 loss)
I0312 17:20:12.324277  1600 sgd_solver.cpp:106] Iteration 88600, lr = 0.01
I0312 17:20:21.495882  1600 solver.cpp:228] Iteration 88700, loss = 0.772143
I0312 17:20:21.495882  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:20:21.495882  1600 solver.cpp:244]     Train net output #1: loss = 0.772144 (* 1 = 0.772144 loss)
I0312 17:20:21.495882  1600 sgd_solver.cpp:106] Iteration 88700, lr = 0.01
I0312 17:20:30.635989  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_88800.caffemodel
I0312 17:20:30.653489  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_88800.solverstate
I0312 17:20:30.657989  1600 solver.cpp:337] Iteration 88800, Testing net (#0)
I0312 17:20:30.657989  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:20:34.418090  1600 solver.cpp:404]     Test net output #0: accuracy = 0.618
I0312 17:20:34.418090  1600 solver.cpp:404]     Test net output #1: loss = 1.60285 (* 1 = 1.60285 loss)
I0312 17:20:34.428092  1600 solver.cpp:228] Iteration 88800, loss = 0.623946
I0312 17:20:34.428092  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:20:34.428092  1600 solver.cpp:244]     Train net output #1: loss = 0.623946 (* 1 = 0.623946 loss)
I0312 17:20:34.428092  1600 sgd_solver.cpp:106] Iteration 88800, lr = 0.01
I0312 17:20:43.683382  1600 solver.cpp:228] Iteration 88900, loss = 0.608426
I0312 17:20:43.683382  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:20:43.683382  1600 solver.cpp:244]     Train net output #1: loss = 0.608426 (* 1 = 0.608426 loss)
I0312 17:20:43.683382  1600 sgd_solver.cpp:106] Iteration 88900, lr = 0.01
I0312 17:20:52.807312  1600 solver.cpp:228] Iteration 89000, loss = 0.404158
I0312 17:20:52.807312  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.9375
I0312 17:20:52.807312  1600 solver.cpp:244]     Train net output #1: loss = 0.404159 (* 1 = 0.404159 loss)
I0312 17:20:52.807312  1600 sgd_solver.cpp:106] Iteration 89000, lr = 0.01
I0312 17:21:01.937412  1600 solver.cpp:228] Iteration 89100, loss = 0.78753
I0312 17:21:01.937412  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:21:01.937412  1600 solver.cpp:244]     Train net output #1: loss = 0.78753 (* 1 = 0.78753 loss)
I0312 17:21:01.937412  1600 sgd_solver.cpp:106] Iteration 89100, lr = 0.01
I0312 17:21:11.109973  1600 solver.cpp:228] Iteration 89200, loss = 0.85322
I0312 17:21:11.109973  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:21:11.109973  1600 solver.cpp:244]     Train net output #1: loss = 0.85322 (* 1 = 0.85322 loss)
I0312 17:21:11.109973  1600 sgd_solver.cpp:106] Iteration 89200, lr = 0.01
I0312 17:21:20.151669  1600 solver.cpp:228] Iteration 89300, loss = 0.55618
I0312 17:21:20.151669  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:21:20.151669  1600 solver.cpp:244]     Train net output #1: loss = 0.55618 (* 1 = 0.55618 loss)
I0312 17:21:20.151669  1600 sgd_solver.cpp:106] Iteration 89300, lr = 0.01
I0312 17:21:29.153646  1600 solver.cpp:228] Iteration 89400, loss = 0.611925
I0312 17:21:29.154145  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:21:29.154145  1600 solver.cpp:244]     Train net output #1: loss = 0.611925 (* 1 = 0.611925 loss)
I0312 17:21:29.154145  1600 sgd_solver.cpp:106] Iteration 89400, lr = 0.01
I0312 17:21:38.249886  1600 solver.cpp:228] Iteration 89500, loss = 0.798682
I0312 17:21:38.249886  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:21:38.249886  1600 solver.cpp:244]     Train net output #1: loss = 0.798683 (* 1 = 0.798683 loss)
I0312 17:21:38.249886  1600 sgd_solver.cpp:106] Iteration 89500, lr = 0.01
I0312 17:21:47.340991  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_89600.caffemodel
I0312 17:21:47.372514  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_89600.solverstate
I0312 17:21:47.377496  1600 solver.cpp:337] Iteration 89600, Testing net (#0)
I0312 17:21:47.377496  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:21:51.138492  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6229
I0312 17:21:51.138492  1600 solver.cpp:404]     Test net output #1: loss = 1.6013 (* 1 = 1.6013 loss)
I0312 17:21:51.176491  1600 solver.cpp:228] Iteration 89600, loss = 0.520152
I0312 17:21:51.176491  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:21:51.176491  1600 solver.cpp:244]     Train net output #1: loss = 0.520153 (* 1 = 0.520153 loss)
I0312 17:21:51.176491  1600 sgd_solver.cpp:106] Iteration 89600, lr = 0.01
I0312 17:22:00.319391  1600 solver.cpp:228] Iteration 89700, loss = 0.539485
I0312 17:22:00.319391  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:22:00.319391  1600 solver.cpp:244]     Train net output #1: loss = 0.539485 (* 1 = 0.539485 loss)
I0312 17:22:00.319391  1600 sgd_solver.cpp:106] Iteration 89700, lr = 0.01
I0312 17:22:09.507027  1600 solver.cpp:228] Iteration 89800, loss = 0.663103
I0312 17:22:09.507027  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:22:09.507027  1600 solver.cpp:244]     Train net output #1: loss = 0.663103 (* 1 = 0.663103 loss)
I0312 17:22:09.507027  1600 sgd_solver.cpp:106] Iteration 89800, lr = 0.01
I0312 17:22:18.535141  1600 solver.cpp:228] Iteration 89900, loss = 0.544325
I0312 17:22:18.535141  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:22:18.535141  1600 solver.cpp:244]     Train net output #1: loss = 0.544325 (* 1 = 0.544325 loss)
I0312 17:22:18.535141  1600 sgd_solver.cpp:106] Iteration 89900, lr = 0.01
I0312 17:22:27.723320  1600 solver.cpp:228] Iteration 90000, loss = 0.535487
I0312 17:22:27.723822  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:22:27.723822  1600 solver.cpp:244]     Train net output #1: loss = 0.535487 (* 1 = 0.535487 loss)
I0312 17:22:27.723822  1600 sgd_solver.cpp:106] Iteration 90000, lr = 0.01
I0312 17:22:36.735865  1600 solver.cpp:228] Iteration 90100, loss = 0.891041
I0312 17:22:36.735865  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:22:36.735865  1600 solver.cpp:244]     Train net output #1: loss = 0.891042 (* 1 = 0.891042 loss)
I0312 17:22:36.735865  1600 sgd_solver.cpp:106] Iteration 90100, lr = 0.01
I0312 17:22:43.716282  1600 solver.cpp:228] Iteration 90200, loss = 0.654163
I0312 17:22:43.716282  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:22:43.716282  1600 solver.cpp:244]     Train net output #1: loss = 0.654163 (* 1 = 0.654163 loss)
I0312 17:22:43.716282  1600 sgd_solver.cpp:106] Iteration 90200, lr = 0.01
I0312 17:22:49.752318  1600 solver.cpp:228] Iteration 90300, loss = 0.54986
I0312 17:22:49.752318  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:22:49.752318  1600 solver.cpp:244]     Train net output #1: loss = 0.54986 (* 1 = 0.54986 loss)
I0312 17:22:49.752318  1600 sgd_solver.cpp:106] Iteration 90300, lr = 0.01
I0312 17:22:55.529285  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_90400.caffemodel
I0312 17:22:55.549288  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_90400.solverstate
I0312 17:22:55.549288  1600 solver.cpp:337] Iteration 90400, Testing net (#0)
I0312 17:22:55.549288  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:22:58.413130  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6191
I0312 17:22:58.413130  1600 solver.cpp:404]     Test net output #1: loss = 1.61084 (* 1 = 1.61084 loss)
I0312 17:22:58.443131  1600 solver.cpp:228] Iteration 90400, loss = 0.664829
I0312 17:22:58.443131  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:22:58.443131  1600 solver.cpp:244]     Train net output #1: loss = 0.664829 (* 1 = 0.664829 loss)
I0312 17:22:58.443131  1600 sgd_solver.cpp:106] Iteration 90400, lr = 0.01
I0312 17:23:07.798987  1600 solver.cpp:228] Iteration 90500, loss = 0.470635
I0312 17:23:07.798987  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:23:07.798987  1600 solver.cpp:244]     Train net output #1: loss = 0.470635 (* 1 = 0.470635 loss)
I0312 17:23:07.798987  1600 sgd_solver.cpp:106] Iteration 90500, lr = 0.01
I0312 17:23:17.300559  1600 solver.cpp:228] Iteration 90600, loss = 0.791423
I0312 17:23:17.300559  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:23:17.300559  1600 solver.cpp:244]     Train net output #1: loss = 0.791423 (* 1 = 0.791423 loss)
I0312 17:23:17.300559  1600 sgd_solver.cpp:106] Iteration 90600, lr = 0.01
I0312 17:23:26.302134  1600 solver.cpp:228] Iteration 90700, loss = 0.715212
I0312 17:23:26.302134  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:23:26.302134  1600 solver.cpp:244]     Train net output #1: loss = 0.715212 (* 1 = 0.715212 loss)
I0312 17:23:26.302134  1600 sgd_solver.cpp:106] Iteration 90700, lr = 0.01
I0312 17:23:35.527673  1600 solver.cpp:228] Iteration 90800, loss = 0.474358
I0312 17:23:35.528172  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:23:35.528172  1600 solver.cpp:244]     Train net output #1: loss = 0.474358 (* 1 = 0.474358 loss)
I0312 17:23:35.528172  1600 sgd_solver.cpp:106] Iteration 90800, lr = 0.01
I0312 17:23:44.717234  1600 solver.cpp:228] Iteration 90900, loss = 0.709926
I0312 17:23:44.717234  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:23:44.717234  1600 solver.cpp:244]     Train net output #1: loss = 0.709926 (* 1 = 0.709926 loss)
I0312 17:23:44.717234  1600 sgd_solver.cpp:106] Iteration 90900, lr = 0.01
I0312 17:23:53.920001  1600 solver.cpp:228] Iteration 91000, loss = 0.735989
I0312 17:23:53.920001  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:23:53.920001  1600 solver.cpp:244]     Train net output #1: loss = 0.735989 (* 1 = 0.735989 loss)
I0312 17:23:53.920001  1600 sgd_solver.cpp:106] Iteration 91000, lr = 0.01
I0312 17:24:03.294775  1600 solver.cpp:228] Iteration 91100, loss = 0.773915
I0312 17:24:03.294775  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:24:03.294775  1600 solver.cpp:244]     Train net output #1: loss = 0.773915 (* 1 = 0.773915 loss)
I0312 17:24:03.294775  1600 sgd_solver.cpp:106] Iteration 91100, lr = 0.01
I0312 17:24:12.757026  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_91200.caffemodel
I0312 17:24:12.787030  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_91200.solverstate
I0312 17:24:12.787030  1600 solver.cpp:337] Iteration 91200, Testing net (#0)
I0312 17:24:12.787030  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:24:16.657896  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6189
I0312 17:24:16.657896  1600 solver.cpp:404]     Test net output #1: loss = 1.60212 (* 1 = 1.60212 loss)
I0312 17:24:16.676895  1600 solver.cpp:228] Iteration 91200, loss = 0.865249
I0312 17:24:16.676895  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:24:16.676895  1600 solver.cpp:244]     Train net output #1: loss = 0.865249 (* 1 = 0.865249 loss)
I0312 17:24:16.676895  1600 sgd_solver.cpp:106] Iteration 91200, lr = 0.01
I0312 17:24:26.554571  1600 solver.cpp:228] Iteration 91300, loss = 0.755886
I0312 17:24:26.555070  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:24:26.555070  1600 solver.cpp:244]     Train net output #1: loss = 0.755886 (* 1 = 0.755886 loss)
I0312 17:24:26.555070  1600 sgd_solver.cpp:106] Iteration 91300, lr = 0.01
I0312 17:24:36.013360  1600 solver.cpp:228] Iteration 91400, loss = 1.01554
I0312 17:24:36.013360  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:24:36.013360  1600 solver.cpp:244]     Train net output #1: loss = 1.01554 (* 1 = 1.01554 loss)
I0312 17:24:36.013360  1600 sgd_solver.cpp:106] Iteration 91400, lr = 0.01
I0312 17:24:45.095289  1600 solver.cpp:228] Iteration 91500, loss = 0.960525
I0312 17:24:45.095289  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:24:45.095289  1600 solver.cpp:244]     Train net output #1: loss = 0.960526 (* 1 = 0.960526 loss)
I0312 17:24:45.095289  1600 sgd_solver.cpp:106] Iteration 91500, lr = 0.01
I0312 17:24:54.634637  1600 solver.cpp:228] Iteration 91600, loss = 0.626097
I0312 17:24:54.634637  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:24:54.634637  1600 solver.cpp:244]     Train net output #1: loss = 0.626097 (* 1 = 0.626097 loss)
I0312 17:24:54.634637  1600 sgd_solver.cpp:106] Iteration 91600, lr = 0.01
I0312 17:25:03.902791  1600 solver.cpp:228] Iteration 91700, loss = 0.811526
I0312 17:25:03.903291  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:25:03.903291  1600 solver.cpp:244]     Train net output #1: loss = 0.811527 (* 1 = 0.811527 loss)
I0312 17:25:03.903291  1600 sgd_solver.cpp:106] Iteration 91700, lr = 0.01
I0312 17:25:13.218889  1600 solver.cpp:228] Iteration 91800, loss = 0.643081
I0312 17:25:13.218889  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:25:13.218889  1600 solver.cpp:244]     Train net output #1: loss = 0.643081 (* 1 = 0.643081 loss)
I0312 17:25:13.218889  1600 sgd_solver.cpp:106] Iteration 91800, lr = 0.01
I0312 17:25:23.019376  1600 solver.cpp:228] Iteration 91900, loss = 0.536164
I0312 17:25:23.019376  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:25:23.019876  1600 solver.cpp:244]     Train net output #1: loss = 0.536165 (* 1 = 0.536165 loss)
I0312 17:25:23.019876  1600 sgd_solver.cpp:106] Iteration 91900, lr = 0.01
I0312 17:25:32.693369  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_92000.caffemodel
I0312 17:25:32.713376  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_92000.solverstate
I0312 17:25:32.713376  1600 solver.cpp:337] Iteration 92000, Testing net (#0)
I0312 17:25:32.713376  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:25:36.515841  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6187
I0312 17:25:36.515841  1600 solver.cpp:404]     Test net output #1: loss = 1.60704 (* 1 = 1.60704 loss)
I0312 17:25:36.542346  1600 solver.cpp:228] Iteration 92000, loss = 0.757152
I0312 17:25:36.542346  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:25:36.542346  1600 solver.cpp:244]     Train net output #1: loss = 0.757153 (* 1 = 0.757153 loss)
I0312 17:25:36.542346  1600 sgd_solver.cpp:106] Iteration 92000, lr = 0.01
I0312 17:25:46.437526  1600 solver.cpp:228] Iteration 92100, loss = 0.606419
I0312 17:25:46.437526  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:25:46.437526  1600 solver.cpp:244]     Train net output #1: loss = 0.606419 (* 1 = 0.606419 loss)
I0312 17:25:46.437526  1600 sgd_solver.cpp:106] Iteration 92100, lr = 0.01
I0312 17:25:55.797211  1600 solver.cpp:228] Iteration 92200, loss = 0.792652
I0312 17:25:55.797211  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:25:55.797211  1600 solver.cpp:244]     Train net output #1: loss = 0.792652 (* 1 = 0.792652 loss)
I0312 17:25:55.797211  1600 sgd_solver.cpp:106] Iteration 92200, lr = 0.01
I0312 17:26:05.365300  1600 solver.cpp:228] Iteration 92300, loss = 0.451804
I0312 17:26:05.365300  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:26:05.365300  1600 solver.cpp:244]     Train net output #1: loss = 0.451804 (* 1 = 0.451804 loss)
I0312 17:26:05.365300  1600 sgd_solver.cpp:106] Iteration 92300, lr = 0.01
I0312 17:26:14.769207  1600 solver.cpp:228] Iteration 92400, loss = 0.709925
I0312 17:26:14.769207  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:26:14.769207  1600 solver.cpp:244]     Train net output #1: loss = 0.709925 (* 1 = 0.709925 loss)
I0312 17:26:14.769207  1600 sgd_solver.cpp:106] Iteration 92400, lr = 0.01
I0312 17:26:24.021319  1600 solver.cpp:228] Iteration 92500, loss = 0.622834
I0312 17:26:24.021319  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:26:24.021319  1600 solver.cpp:244]     Train net output #1: loss = 0.622834 (* 1 = 0.622834 loss)
I0312 17:26:24.021319  1600 sgd_solver.cpp:106] Iteration 92500, lr = 0.01
I0312 17:26:33.243639  1600 solver.cpp:228] Iteration 92600, loss = 0.785122
I0312 17:26:33.243639  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:26:33.243639  1600 solver.cpp:244]     Train net output #1: loss = 0.785122 (* 1 = 0.785122 loss)
I0312 17:26:33.243639  1600 sgd_solver.cpp:106] Iteration 92600, lr = 0.01
I0312 17:26:42.315946  1600 solver.cpp:228] Iteration 92700, loss = 0.633525
I0312 17:26:42.315946  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:26:42.315946  1600 solver.cpp:244]     Train net output #1: loss = 0.633525 (* 1 = 0.633525 loss)
I0312 17:26:42.315946  1600 sgd_solver.cpp:106] Iteration 92700, lr = 0.01
I0312 17:26:51.477859  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_92800.caffemodel
I0312 17:26:51.510360  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_92800.solverstate
I0312 17:26:51.515359  1600 solver.cpp:337] Iteration 92800, Testing net (#0)
I0312 17:26:51.515359  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:26:55.214988  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6268
I0312 17:26:55.214988  1600 solver.cpp:404]     Test net output #1: loss = 1.6024 (* 1 = 1.6024 loss)
I0312 17:26:55.234989  1600 solver.cpp:228] Iteration 92800, loss = 0.522595
I0312 17:26:55.234989  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:26:55.234989  1600 solver.cpp:244]     Train net output #1: loss = 0.522595 (* 1 = 0.522595 loss)
I0312 17:26:55.234989  1600 sgd_solver.cpp:106] Iteration 92800, lr = 0.01
I0312 17:27:04.470758  1600 solver.cpp:228] Iteration 92900, loss = 0.62562
I0312 17:27:04.470758  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:27:04.470758  1600 solver.cpp:244]     Train net output #1: loss = 0.62562 (* 1 = 0.62562 loss)
I0312 17:27:04.470758  1600 sgd_solver.cpp:106] Iteration 92900, lr = 0.01
I0312 17:27:13.662506  1600 solver.cpp:228] Iteration 93000, loss = 0.602944
I0312 17:27:13.662506  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:27:13.662506  1600 solver.cpp:244]     Train net output #1: loss = 0.602944 (* 1 = 0.602944 loss)
I0312 17:27:13.662506  1600 sgd_solver.cpp:106] Iteration 93000, lr = 0.01
I0312 17:27:22.880158  1600 solver.cpp:228] Iteration 93100, loss = 0.69052
I0312 17:27:22.880158  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:27:22.880158  1600 solver.cpp:244]     Train net output #1: loss = 0.69052 (* 1 = 0.69052 loss)
I0312 17:27:22.880158  1600 sgd_solver.cpp:106] Iteration 93100, lr = 0.01
I0312 17:27:31.842725  1600 solver.cpp:228] Iteration 93200, loss = 0.374269
I0312 17:27:31.842725  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.921875
I0312 17:27:31.842725  1600 solver.cpp:244]     Train net output #1: loss = 0.374269 (* 1 = 0.374269 loss)
I0312 17:27:31.842725  1600 sgd_solver.cpp:106] Iteration 93200, lr = 0.01
I0312 17:27:40.345643  1600 solver.cpp:228] Iteration 93300, loss = 0.34522
I0312 17:27:40.345643  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 17:27:40.346148  1600 solver.cpp:244]     Train net output #1: loss = 0.34522 (* 1 = 0.34522 loss)
I0312 17:27:40.346148  1600 sgd_solver.cpp:106] Iteration 93300, lr = 0.01
I0312 17:27:49.184738  1600 solver.cpp:228] Iteration 93400, loss = 0.578263
I0312 17:27:49.184738  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:27:49.184738  1600 solver.cpp:244]     Train net output #1: loss = 0.578263 (* 1 = 0.578263 loss)
I0312 17:27:49.184738  1600 sgd_solver.cpp:106] Iteration 93400, lr = 0.01
I0312 17:27:56.253000  1600 solver.cpp:228] Iteration 93500, loss = 0.543281
I0312 17:27:56.253000  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:27:56.253000  1600 solver.cpp:244]     Train net output #1: loss = 0.543281 (* 1 = 0.543281 loss)
I0312 17:27:56.253000  1600 sgd_solver.cpp:106] Iteration 93500, lr = 0.01
I0312 17:28:02.081329  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_93600.caffemodel
I0312 17:28:02.100831  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_93600.solverstate
I0312 17:28:02.109329  1600 solver.cpp:337] Iteration 93600, Testing net (#0)
I0312 17:28:02.109329  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:28:04.622790  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6231
I0312 17:28:04.622790  1600 solver.cpp:404]     Test net output #1: loss = 1.59484 (* 1 = 1.59484 loss)
I0312 17:28:04.644285  1600 solver.cpp:228] Iteration 93600, loss = 0.728757
I0312 17:28:04.644285  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:28:04.644285  1600 solver.cpp:244]     Train net output #1: loss = 0.728757 (* 1 = 0.728757 loss)
I0312 17:28:04.644285  1600 sgd_solver.cpp:106] Iteration 93600, lr = 0.01
I0312 17:28:10.807953  1600 solver.cpp:228] Iteration 93700, loss = 0.58351
I0312 17:28:10.807953  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:28:10.807953  1600 solver.cpp:244]     Train net output #1: loss = 0.58351 (* 1 = 0.58351 loss)
I0312 17:28:10.807953  1600 sgd_solver.cpp:106] Iteration 93700, lr = 0.01
I0312 17:28:20.032794  1600 solver.cpp:228] Iteration 93800, loss = 0.562689
I0312 17:28:20.032794  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:28:20.032794  1600 solver.cpp:244]     Train net output #1: loss = 0.562689 (* 1 = 0.562689 loss)
I0312 17:28:20.032794  1600 sgd_solver.cpp:106] Iteration 93800, lr = 0.01
I0312 17:28:29.126533  1600 solver.cpp:228] Iteration 93900, loss = 0.899664
I0312 17:28:29.126533  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:28:29.126533  1600 solver.cpp:244]     Train net output #1: loss = 0.899664 (* 1 = 0.899664 loss)
I0312 17:28:29.126533  1600 sgd_solver.cpp:106] Iteration 93900, lr = 0.01
I0312 17:28:38.050781  1600 solver.cpp:228] Iteration 94000, loss = 0.477766
I0312 17:28:38.050781  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:28:38.050781  1600 solver.cpp:244]     Train net output #1: loss = 0.477766 (* 1 = 0.477766 loss)
I0312 17:28:38.050781  1600 sgd_solver.cpp:106] Iteration 94000, lr = 0.01
I0312 17:28:47.334046  1600 solver.cpp:228] Iteration 94100, loss = 0.490017
I0312 17:28:47.334046  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:28:47.334046  1600 solver.cpp:244]     Train net output #1: loss = 0.490017 (* 1 = 0.490017 loss)
I0312 17:28:47.334046  1600 sgd_solver.cpp:106] Iteration 94100, lr = 0.01
I0312 17:28:56.403149  1600 solver.cpp:228] Iteration 94200, loss = 0.695408
I0312 17:28:56.403149  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:28:56.403149  1600 solver.cpp:244]     Train net output #1: loss = 0.695408 (* 1 = 0.695408 loss)
I0312 17:28:56.403149  1600 sgd_solver.cpp:106] Iteration 94200, lr = 0.01
I0312 17:29:05.778240  1600 solver.cpp:228] Iteration 94300, loss = 0.654072
I0312 17:29:05.778240  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:29:05.778240  1600 solver.cpp:244]     Train net output #1: loss = 0.654072 (* 1 = 0.654072 loss)
I0312 17:29:05.778240  1600 sgd_solver.cpp:106] Iteration 94300, lr = 0.01
I0312 17:29:14.928735  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_94400.caffemodel
I0312 17:29:14.943719  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_94400.solverstate
I0312 17:29:14.951722  1600 solver.cpp:337] Iteration 94400, Testing net (#0)
I0312 17:29:14.951722  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:29:18.701494  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6186
I0312 17:29:18.701494  1600 solver.cpp:404]     Test net output #1: loss = 1.59882 (* 1 = 1.59882 loss)
I0312 17:29:18.741514  1600 solver.cpp:228] Iteration 94400, loss = 0.667162
I0312 17:29:18.741514  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:29:18.741514  1600 solver.cpp:244]     Train net output #1: loss = 0.667162 (* 1 = 0.667162 loss)
I0312 17:29:18.741514  1600 sgd_solver.cpp:106] Iteration 94400, lr = 0.01
I0312 17:29:28.000879  1600 solver.cpp:228] Iteration 94500, loss = 0.618891
I0312 17:29:28.000879  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:29:28.000879  1600 solver.cpp:244]     Train net output #1: loss = 0.618891 (* 1 = 0.618891 loss)
I0312 17:29:28.000879  1600 sgd_solver.cpp:106] Iteration 94500, lr = 0.01
I0312 17:29:37.316721  1600 solver.cpp:228] Iteration 94600, loss = 0.975498
I0312 17:29:37.316721  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:29:37.316721  1600 solver.cpp:244]     Train net output #1: loss = 0.975499 (* 1 = 0.975499 loss)
I0312 17:29:37.316721  1600 sgd_solver.cpp:106] Iteration 94600, lr = 0.01
I0312 17:29:46.424517  1600 solver.cpp:228] Iteration 94700, loss = 0.922426
I0312 17:29:46.424517  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:29:46.424517  1600 solver.cpp:244]     Train net output #1: loss = 0.922426 (* 1 = 0.922426 loss)
I0312 17:29:46.424517  1600 sgd_solver.cpp:106] Iteration 94700, lr = 0.01
I0312 17:29:55.656283  1600 solver.cpp:228] Iteration 94800, loss = 0.664158
I0312 17:29:55.656283  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:29:55.656283  1600 solver.cpp:244]     Train net output #1: loss = 0.664158 (* 1 = 0.664158 loss)
I0312 17:29:55.656283  1600 sgd_solver.cpp:106] Iteration 94800, lr = 0.01
I0312 17:30:04.769139  1600 solver.cpp:228] Iteration 94900, loss = 0.967727
I0312 17:30:04.769139  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.671875
I0312 17:30:04.769139  1600 solver.cpp:244]     Train net output #1: loss = 0.967727 (* 1 = 0.967727 loss)
I0312 17:30:04.769139  1600 sgd_solver.cpp:106] Iteration 94900, lr = 0.01
I0312 17:30:13.929600  1600 solver.cpp:228] Iteration 95000, loss = 0.705741
I0312 17:30:13.929600  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:30:13.929600  1600 solver.cpp:244]     Train net output #1: loss = 0.705741 (* 1 = 0.705741 loss)
I0312 17:30:13.929600  1600 sgd_solver.cpp:46] MultiStep Status: Iteration 95000, step = 2
I0312 17:30:13.929600  1600 sgd_solver.cpp:106] Iteration 95000, lr = 0.001
I0312 17:30:23.084082  1600 solver.cpp:228] Iteration 95100, loss = 0.940734
I0312 17:30:23.084082  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:30:23.094081  1600 solver.cpp:244]     Train net output #1: loss = 0.940734 (* 1 = 0.940734 loss)
I0312 17:30:23.094081  1600 sgd_solver.cpp:106] Iteration 95100, lr = 0.001
I0312 17:30:32.232887  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_95200.caffemodel
I0312 17:30:32.252007  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_95200.solverstate
I0312 17:30:32.257005  1600 solver.cpp:337] Iteration 95200, Testing net (#0)
I0312 17:30:32.257005  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:30:36.047094  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6231
I0312 17:30:36.047094  1600 solver.cpp:404]     Test net output #1: loss = 1.593 (* 1 = 1.593 loss)
I0312 17:30:36.064095  1600 solver.cpp:228] Iteration 95200, loss = 0.648698
I0312 17:30:36.064095  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:30:36.064095  1600 solver.cpp:244]     Train net output #1: loss = 0.648698 (* 1 = 0.648698 loss)
I0312 17:30:36.064095  1600 sgd_solver.cpp:106] Iteration 95200, lr = 0.001
I0312 17:30:45.201325  1600 solver.cpp:228] Iteration 95300, loss = 0.730136
I0312 17:30:45.201325  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:30:45.201325  1600 solver.cpp:244]     Train net output #1: loss = 0.730136 (* 1 = 0.730136 loss)
I0312 17:30:45.201325  1600 sgd_solver.cpp:106] Iteration 95300, lr = 0.001
I0312 17:30:54.512259  1600 solver.cpp:228] Iteration 95400, loss = 0.664146
I0312 17:30:54.512259  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:30:54.512259  1600 solver.cpp:244]     Train net output #1: loss = 0.664146 (* 1 = 0.664146 loss)
I0312 17:30:54.512259  1600 sgd_solver.cpp:106] Iteration 95400, lr = 0.001
I0312 17:31:03.718900  1600 solver.cpp:228] Iteration 95500, loss = 0.620184
I0312 17:31:03.718900  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:31:03.718900  1600 solver.cpp:244]     Train net output #1: loss = 0.620184 (* 1 = 0.620184 loss)
I0312 17:31:03.718900  1600 sgd_solver.cpp:106] Iteration 95500, lr = 0.001
I0312 17:31:13.062563  1600 solver.cpp:228] Iteration 95600, loss = 0.873155
I0312 17:31:13.062563  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:31:13.062563  1600 solver.cpp:244]     Train net output #1: loss = 0.873155 (* 1 = 0.873155 loss)
I0312 17:31:13.062563  1600 sgd_solver.cpp:106] Iteration 95600, lr = 0.001
I0312 17:31:22.289774  1600 solver.cpp:228] Iteration 95700, loss = 0.770436
I0312 17:31:22.289774  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:31:22.289774  1600 solver.cpp:244]     Train net output #1: loss = 0.770436 (* 1 = 0.770436 loss)
I0312 17:31:22.289774  1600 sgd_solver.cpp:106] Iteration 95700, lr = 0.001
I0312 17:31:31.372872  1600 solver.cpp:228] Iteration 95800, loss = 0.936171
I0312 17:31:31.372872  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:31:31.372872  1600 solver.cpp:244]     Train net output #1: loss = 0.936171 (* 1 = 0.936171 loss)
I0312 17:31:31.372872  1600 sgd_solver.cpp:106] Iteration 95800, lr = 0.001
I0312 17:31:40.635291  1600 solver.cpp:228] Iteration 95900, loss = 0.517793
I0312 17:31:40.635291  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:31:40.635291  1600 solver.cpp:244]     Train net output #1: loss = 0.517793 (* 1 = 0.517793 loss)
I0312 17:31:40.635291  1600 sgd_solver.cpp:106] Iteration 95900, lr = 0.001
I0312 17:31:49.950438  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_96000.caffemodel
I0312 17:31:49.976634  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_96000.solverstate
I0312 17:31:49.986629  1600 solver.cpp:337] Iteration 96000, Testing net (#0)
I0312 17:31:49.986629  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:31:53.757727  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6262
I0312 17:31:53.757727  1600 solver.cpp:404]     Test net output #1: loss = 1.59171 (* 1 = 1.59171 loss)
I0312 17:31:53.801730  1600 solver.cpp:228] Iteration 96000, loss = 0.664616
I0312 17:31:53.801730  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:31:53.802232  1600 solver.cpp:244]     Train net output #1: loss = 0.664616 (* 1 = 0.664616 loss)
I0312 17:31:53.802232  1600 sgd_solver.cpp:106] Iteration 96000, lr = 0.001
I0312 17:32:02.963886  1600 solver.cpp:228] Iteration 96100, loss = 0.648665
I0312 17:32:02.963886  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:32:02.963886  1600 solver.cpp:244]     Train net output #1: loss = 0.648665 (* 1 = 0.648665 loss)
I0312 17:32:02.963886  1600 sgd_solver.cpp:106] Iteration 96100, lr = 0.001
I0312 17:32:12.282634  1600 solver.cpp:228] Iteration 96200, loss = 0.574569
I0312 17:32:12.282634  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:32:12.282634  1600 solver.cpp:244]     Train net output #1: loss = 0.574569 (* 1 = 0.574569 loss)
I0312 17:32:12.282634  1600 sgd_solver.cpp:106] Iteration 96200, lr = 0.001
I0312 17:32:21.308267  1600 solver.cpp:228] Iteration 96300, loss = 0.354665
I0312 17:32:21.308267  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:32:21.308267  1600 solver.cpp:244]     Train net output #1: loss = 0.354665 (* 1 = 0.354665 loss)
I0312 17:32:21.308267  1600 sgd_solver.cpp:106] Iteration 96300, lr = 0.001
I0312 17:32:30.385452  1600 solver.cpp:228] Iteration 96400, loss = 0.695101
I0312 17:32:30.385452  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:32:30.385452  1600 solver.cpp:244]     Train net output #1: loss = 0.695102 (* 1 = 0.695102 loss)
I0312 17:32:30.385452  1600 sgd_solver.cpp:106] Iteration 96400, lr = 0.001
I0312 17:32:39.511899  1600 solver.cpp:228] Iteration 96500, loss = 0.669446
I0312 17:32:39.511899  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:32:39.511899  1600 solver.cpp:244]     Train net output #1: loss = 0.669446 (* 1 = 0.669446 loss)
I0312 17:32:39.511899  1600 sgd_solver.cpp:106] Iteration 96500, lr = 0.001
I0312 17:32:48.902576  1600 solver.cpp:228] Iteration 96600, loss = 0.578424
I0312 17:32:48.902576  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:32:48.902576  1600 solver.cpp:244]     Train net output #1: loss = 0.578425 (* 1 = 0.578425 loss)
I0312 17:32:48.902576  1600 sgd_solver.cpp:106] Iteration 96600, lr = 0.001
I0312 17:32:58.102398  1600 solver.cpp:228] Iteration 96700, loss = 0.606738
I0312 17:32:58.102398  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:32:58.102398  1600 solver.cpp:244]     Train net output #1: loss = 0.606738 (* 1 = 0.606738 loss)
I0312 17:32:58.102398  1600 sgd_solver.cpp:106] Iteration 96700, lr = 0.001
I0312 17:33:04.622826  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_96800.caffemodel
I0312 17:33:04.643326  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_96800.solverstate
I0312 17:33:04.648826  1600 solver.cpp:337] Iteration 96800, Testing net (#0)
I0312 17:33:04.648826  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:33:07.200779  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6254
I0312 17:33:07.200779  1600 solver.cpp:404]     Test net output #1: loss = 1.59089 (* 1 = 1.59089 loss)
I0312 17:33:07.224773  1600 solver.cpp:228] Iteration 96800, loss = 0.445842
I0312 17:33:07.224773  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:33:07.224773  1600 solver.cpp:244]     Train net output #1: loss = 0.445842 (* 1 = 0.445842 loss)
I0312 17:33:07.224773  1600 sgd_solver.cpp:106] Iteration 96800, lr = 0.001
I0312 17:33:13.248137  1600 solver.cpp:228] Iteration 96900, loss = 0.807601
I0312 17:33:13.248137  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:33:13.248137  1600 solver.cpp:244]     Train net output #1: loss = 0.807601 (* 1 = 0.807601 loss)
I0312 17:33:13.248137  1600 sgd_solver.cpp:106] Iteration 96900, lr = 0.001
I0312 17:33:19.848233  1600 solver.cpp:228] Iteration 97000, loss = 0.446198
I0312 17:33:19.848733  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:33:19.848733  1600 solver.cpp:244]     Train net output #1: loss = 0.446198 (* 1 = 0.446198 loss)
I0312 17:33:19.848733  1600 sgd_solver.cpp:106] Iteration 97000, lr = 0.001
I0312 17:33:28.934377  1600 solver.cpp:228] Iteration 97100, loss = 0.49119
I0312 17:33:28.934377  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:33:28.934377  1600 solver.cpp:244]     Train net output #1: loss = 0.49119 (* 1 = 0.49119 loss)
I0312 17:33:28.934377  1600 sgd_solver.cpp:106] Iteration 97100, lr = 0.001
I0312 17:33:37.998944  1600 solver.cpp:228] Iteration 97200, loss = 0.453765
I0312 17:33:37.998944  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:33:37.998944  1600 solver.cpp:244]     Train net output #1: loss = 0.453765 (* 1 = 0.453765 loss)
I0312 17:33:37.998944  1600 sgd_solver.cpp:106] Iteration 97200, lr = 0.001
I0312 17:33:47.015324  1600 solver.cpp:228] Iteration 97300, loss = 0.78281
I0312 17:33:47.015324  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:33:47.015324  1600 solver.cpp:244]     Train net output #1: loss = 0.78281 (* 1 = 0.78281 loss)
I0312 17:33:47.015324  1600 sgd_solver.cpp:106] Iteration 97300, lr = 0.001
I0312 17:33:56.203409  1600 solver.cpp:228] Iteration 97400, loss = 0.774278
I0312 17:33:56.203409  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:33:56.203409  1600 solver.cpp:244]     Train net output #1: loss = 0.774278 (* 1 = 0.774278 loss)
I0312 17:33:56.203409  1600 sgd_solver.cpp:106] Iteration 97400, lr = 0.001
I0312 17:34:05.638231  1600 solver.cpp:228] Iteration 97500, loss = 0.83435
I0312 17:34:05.638231  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:34:05.638231  1600 solver.cpp:244]     Train net output #1: loss = 0.834351 (* 1 = 0.834351 loss)
I0312 17:34:05.638231  1600 sgd_solver.cpp:106] Iteration 97500, lr = 0.001
I0312 17:34:14.855188  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_97600.caffemodel
I0312 17:34:14.870678  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_97600.solverstate
I0312 17:34:14.875178  1600 solver.cpp:337] Iteration 97600, Testing net (#0)
I0312 17:34:14.875178  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:34:18.725266  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6273
I0312 17:34:18.725266  1600 solver.cpp:404]     Test net output #1: loss = 1.58768 (* 1 = 1.58768 loss)
I0312 17:34:18.736764  1600 solver.cpp:228] Iteration 97600, loss = 0.664016
I0312 17:34:18.736764  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:34:18.736764  1600 solver.cpp:244]     Train net output #1: loss = 0.664016 (* 1 = 0.664016 loss)
I0312 17:34:18.736764  1600 sgd_solver.cpp:106] Iteration 97600, lr = 0.001
I0312 17:34:27.918627  1600 solver.cpp:228] Iteration 97700, loss = 0.579635
I0312 17:34:27.918627  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:34:27.918627  1600 solver.cpp:244]     Train net output #1: loss = 0.579635 (* 1 = 0.579635 loss)
I0312 17:34:27.918627  1600 sgd_solver.cpp:106] Iteration 97700, lr = 0.001
I0312 17:34:37.109266  1600 solver.cpp:228] Iteration 97800, loss = 0.569198
I0312 17:34:37.109266  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:34:37.109266  1600 solver.cpp:244]     Train net output #1: loss = 0.569198 (* 1 = 0.569198 loss)
I0312 17:34:37.109266  1600 sgd_solver.cpp:106] Iteration 97800, lr = 0.001
I0312 17:34:46.348007  1600 solver.cpp:228] Iteration 97900, loss = 0.51484
I0312 17:34:46.348007  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:34:46.348007  1600 solver.cpp:244]     Train net output #1: loss = 0.51484 (* 1 = 0.51484 loss)
I0312 17:34:46.348007  1600 sgd_solver.cpp:106] Iteration 97900, lr = 0.001
I0312 17:34:55.440383  1600 solver.cpp:228] Iteration 98000, loss = 0.821619
I0312 17:34:55.440882  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:34:55.440882  1600 solver.cpp:244]     Train net output #1: loss = 0.821619 (* 1 = 0.821619 loss)
I0312 17:34:55.440882  1600 sgd_solver.cpp:106] Iteration 98000, lr = 0.001
I0312 17:35:04.395772  1600 solver.cpp:228] Iteration 98100, loss = 0.369885
I0312 17:35:04.395772  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.921875
I0312 17:35:04.395772  1600 solver.cpp:244]     Train net output #1: loss = 0.369886 (* 1 = 0.369886 loss)
I0312 17:35:04.395772  1600 sgd_solver.cpp:106] Iteration 98100, lr = 0.001
I0312 17:35:13.124536  1600 solver.cpp:228] Iteration 98200, loss = 0.657263
I0312 17:35:13.124536  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:35:13.124536  1600 solver.cpp:244]     Train net output #1: loss = 0.657263 (* 1 = 0.657263 loss)
I0312 17:35:13.124536  1600 sgd_solver.cpp:106] Iteration 98200, lr = 0.001
I0312 17:35:22.288417  1600 solver.cpp:228] Iteration 98300, loss = 0.600905
I0312 17:35:22.288417  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:35:22.288417  1600 solver.cpp:244]     Train net output #1: loss = 0.600906 (* 1 = 0.600906 loss)
I0312 17:35:22.288417  1600 sgd_solver.cpp:106] Iteration 98300, lr = 0.001
I0312 17:35:31.367465  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_98400.caffemodel
I0312 17:35:31.382467  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_98400.solverstate
I0312 17:35:31.387466  1600 solver.cpp:337] Iteration 98400, Testing net (#0)
I0312 17:35:31.387466  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:35:35.119139  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6271
I0312 17:35:35.119139  1600 solver.cpp:404]     Test net output #1: loss = 1.58994 (* 1 = 1.58994 loss)
I0312 17:35:35.149143  1600 solver.cpp:228] Iteration 98400, loss = 0.404128
I0312 17:35:35.149143  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 17:35:35.149143  1600 solver.cpp:244]     Train net output #1: loss = 0.404128 (* 1 = 0.404128 loss)
I0312 17:35:35.149143  1600 sgd_solver.cpp:106] Iteration 98400, lr = 0.001
I0312 17:35:44.228719  1600 solver.cpp:228] Iteration 98500, loss = 0.538426
I0312 17:35:44.228719  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:35:44.228719  1600 solver.cpp:244]     Train net output #1: loss = 0.538426 (* 1 = 0.538426 loss)
I0312 17:35:44.229218  1600 sgd_solver.cpp:106] Iteration 98500, lr = 0.001
I0312 17:35:53.416046  1600 solver.cpp:228] Iteration 98600, loss = 0.536755
I0312 17:35:53.416046  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:35:53.416046  1600 solver.cpp:244]     Train net output #1: loss = 0.536755 (* 1 = 0.536755 loss)
I0312 17:35:53.416046  1600 sgd_solver.cpp:106] Iteration 98600, lr = 0.001
I0312 17:36:02.584527  1600 solver.cpp:228] Iteration 98700, loss = 0.683646
I0312 17:36:02.584527  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:36:02.584527  1600 solver.cpp:244]     Train net output #1: loss = 0.683646 (* 1 = 0.683646 loss)
I0312 17:36:02.584527  1600 sgd_solver.cpp:106] Iteration 98700, lr = 0.001
I0312 17:36:11.790556  1600 solver.cpp:228] Iteration 98800, loss = 0.841085
I0312 17:36:11.790556  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:36:11.791056  1600 solver.cpp:244]     Train net output #1: loss = 0.841086 (* 1 = 0.841086 loss)
I0312 17:36:11.791056  1600 sgd_solver.cpp:106] Iteration 98800, lr = 0.001
I0312 17:36:20.815073  1600 solver.cpp:228] Iteration 98900, loss = 0.455495
I0312 17:36:20.815073  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:36:20.815073  1600 solver.cpp:244]     Train net output #1: loss = 0.455495 (* 1 = 0.455495 loss)
I0312 17:36:20.815073  1600 sgd_solver.cpp:106] Iteration 98900, lr = 0.001
I0312 17:36:29.814201  1600 solver.cpp:228] Iteration 99000, loss = 0.671882
I0312 17:36:29.814201  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:36:29.814201  1600 solver.cpp:244]     Train net output #1: loss = 0.671883 (* 1 = 0.671883 loss)
I0312 17:36:29.814201  1600 sgd_solver.cpp:106] Iteration 99000, lr = 0.001
I0312 17:36:39.003108  1600 solver.cpp:228] Iteration 99100, loss = 0.825582
I0312 17:36:39.003108  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:36:39.003108  1600 solver.cpp:244]     Train net output #1: loss = 0.825582 (* 1 = 0.825582 loss)
I0312 17:36:39.003108  1600 sgd_solver.cpp:106] Iteration 99100, lr = 0.001
I0312 17:36:48.067026  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_99200.caffemodel
I0312 17:36:48.084026  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_99200.solverstate
I0312 17:36:48.089026  1600 solver.cpp:337] Iteration 99200, Testing net (#0)
I0312 17:36:48.089026  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:36:52.003453  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6246
I0312 17:36:52.003453  1600 solver.cpp:404]     Test net output #1: loss = 1.58959 (* 1 = 1.58959 loss)
I0312 17:36:52.023457  1600 solver.cpp:228] Iteration 99200, loss = 0.595353
I0312 17:36:52.023457  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:36:52.023457  1600 solver.cpp:244]     Train net output #1: loss = 0.595353 (* 1 = 0.595353 loss)
I0312 17:36:52.023457  1600 sgd_solver.cpp:106] Iteration 99200, lr = 0.001
I0312 17:37:01.252085  1600 solver.cpp:228] Iteration 99300, loss = 0.785515
I0312 17:37:01.252085  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:37:01.252085  1600 solver.cpp:244]     Train net output #1: loss = 0.785515 (* 1 = 0.785515 loss)
I0312 17:37:01.252085  1600 sgd_solver.cpp:106] Iteration 99300, lr = 0.001
I0312 17:37:10.244736  1600 solver.cpp:228] Iteration 99400, loss = 0.476028
I0312 17:37:10.244736  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 17:37:10.245239  1600 solver.cpp:244]     Train net output #1: loss = 0.476028 (* 1 = 0.476028 loss)
I0312 17:37:10.245239  1600 sgd_solver.cpp:106] Iteration 99400, lr = 0.001
I0312 17:37:19.194794  1600 solver.cpp:228] Iteration 99500, loss = 0.740032
I0312 17:37:19.195296  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:37:19.195296  1600 solver.cpp:244]     Train net output #1: loss = 0.740032 (* 1 = 0.740032 loss)
I0312 17:37:19.195296  1600 sgd_solver.cpp:106] Iteration 99500, lr = 0.001
I0312 17:37:28.292114  1600 solver.cpp:228] Iteration 99600, loss = 0.725926
I0312 17:37:28.292114  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:37:28.292114  1600 solver.cpp:244]     Train net output #1: loss = 0.725926 (* 1 = 0.725926 loss)
I0312 17:37:28.292114  1600 sgd_solver.cpp:106] Iteration 99600, lr = 0.001
I0312 17:37:37.528615  1600 solver.cpp:228] Iteration 99700, loss = 0.62444
I0312 17:37:37.528615  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:37:37.528615  1600 solver.cpp:244]     Train net output #1: loss = 0.62444 (* 1 = 0.62444 loss)
I0312 17:37:37.528615  1600 sgd_solver.cpp:106] Iteration 99700, lr = 0.001
I0312 17:37:46.504000  1600 solver.cpp:228] Iteration 99800, loss = 0.668556
I0312 17:37:46.504000  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:37:46.504498  1600 solver.cpp:244]     Train net output #1: loss = 0.668556 (* 1 = 0.668556 loss)
I0312 17:37:46.504498  1600 sgd_solver.cpp:106] Iteration 99800, lr = 0.001
I0312 17:37:55.446910  1600 solver.cpp:228] Iteration 99900, loss = 0.836924
I0312 17:37:55.446910  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:37:55.446910  1600 solver.cpp:244]     Train net output #1: loss = 0.836924 (* 1 = 0.836924 loss)
I0312 17:37:55.446910  1600 sgd_solver.cpp:106] Iteration 99900, lr = 0.001
I0312 17:38:04.574182  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_100000.caffemodel
I0312 17:38:04.595155  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_100000.solverstate
I0312 17:38:04.600157  1600 solver.cpp:337] Iteration 100000, Testing net (#0)
I0312 17:38:04.600157  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:38:07.777736  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6283
I0312 17:38:07.777736  1600 solver.cpp:404]     Test net output #1: loss = 1.58417 (* 1 = 1.58417 loss)
I0312 17:38:07.787734  1600 solver.cpp:228] Iteration 100000, loss = 0.565969
I0312 17:38:07.787734  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:38:07.787734  1600 solver.cpp:244]     Train net output #1: loss = 0.565969 (* 1 = 0.565969 loss)
I0312 17:38:07.787734  1600 sgd_solver.cpp:106] Iteration 100000, lr = 0.001
I0312 17:38:13.569360  1600 solver.cpp:228] Iteration 100100, loss = 0.734614
I0312 17:38:13.569360  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:38:13.569360  1600 solver.cpp:244]     Train net output #1: loss = 0.734615 (* 1 = 0.734615 loss)
I0312 17:38:13.569360  1600 sgd_solver.cpp:106] Iteration 100100, lr = 0.001
I0312 17:38:19.392055  1600 solver.cpp:228] Iteration 100200, loss = 0.540493
I0312 17:38:19.392055  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:38:19.392055  1600 solver.cpp:244]     Train net output #1: loss = 0.540493 (* 1 = 0.540493 loss)
I0312 17:38:19.392055  1600 sgd_solver.cpp:106] Iteration 100200, lr = 0.001
I0312 17:38:25.761111  1600 solver.cpp:228] Iteration 100300, loss = 0.525541
I0312 17:38:25.761611  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:38:25.761611  1600 solver.cpp:244]     Train net output #1: loss = 0.525541 (* 1 = 0.525541 loss)
I0312 17:38:25.761611  1600 sgd_solver.cpp:106] Iteration 100300, lr = 0.001
I0312 17:38:34.735208  1600 solver.cpp:228] Iteration 100400, loss = 0.567419
I0312 17:38:34.735208  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:38:34.735208  1600 solver.cpp:244]     Train net output #1: loss = 0.567419 (* 1 = 0.567419 loss)
I0312 17:38:34.735208  1600 sgd_solver.cpp:106] Iteration 100400, lr = 0.001
I0312 17:38:43.696260  1600 solver.cpp:228] Iteration 100500, loss = 0.5842
I0312 17:38:43.696260  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:38:43.696260  1600 solver.cpp:244]     Train net output #1: loss = 0.5842 (* 1 = 0.5842 loss)
I0312 17:38:43.696260  1600 sgd_solver.cpp:106] Iteration 100500, lr = 0.001
I0312 17:38:52.837715  1600 solver.cpp:228] Iteration 100600, loss = 0.602943
I0312 17:38:52.837715  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:38:52.837715  1600 solver.cpp:244]     Train net output #1: loss = 0.602944 (* 1 = 0.602944 loss)
I0312 17:38:52.837715  1600 sgd_solver.cpp:106] Iteration 100600, lr = 0.001
I0312 17:39:01.869205  1600 solver.cpp:228] Iteration 100700, loss = 0.429596
I0312 17:39:01.869205  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:39:01.869205  1600 solver.cpp:244]     Train net output #1: loss = 0.429596 (* 1 = 0.429596 loss)
I0312 17:39:01.869205  1600 sgd_solver.cpp:106] Iteration 100700, lr = 0.001
I0312 17:39:10.884137  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_100800.caffemodel
I0312 17:39:10.905618  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_100800.solverstate
I0312 17:39:10.910619  1600 solver.cpp:337] Iteration 100800, Testing net (#0)
I0312 17:39:10.911119  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:39:14.690301  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6272
I0312 17:39:14.690301  1600 solver.cpp:404]     Test net output #1: loss = 1.58401 (* 1 = 1.58401 loss)
I0312 17:39:14.710305  1600 solver.cpp:228] Iteration 100800, loss = 0.500621
I0312 17:39:14.710305  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 17:39:14.710305  1600 solver.cpp:244]     Train net output #1: loss = 0.500621 (* 1 = 0.500621 loss)
I0312 17:39:14.710305  1600 sgd_solver.cpp:106] Iteration 100800, lr = 0.001
I0312 17:39:23.799811  1600 solver.cpp:228] Iteration 100900, loss = 0.671273
I0312 17:39:23.799811  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:39:23.799811  1600 solver.cpp:244]     Train net output #1: loss = 0.671274 (* 1 = 0.671274 loss)
I0312 17:39:23.799811  1600 sgd_solver.cpp:106] Iteration 100900, lr = 0.001
I0312 17:39:32.912446  1600 solver.cpp:228] Iteration 101000, loss = 0.545868
I0312 17:39:32.912446  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:39:32.912446  1600 solver.cpp:244]     Train net output #1: loss = 0.545869 (* 1 = 0.545869 loss)
I0312 17:39:32.912446  1600 sgd_solver.cpp:106] Iteration 101000, lr = 0.001
I0312 17:39:42.017606  1600 solver.cpp:228] Iteration 101100, loss = 0.55277
I0312 17:39:42.017606  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:39:42.017606  1600 solver.cpp:244]     Train net output #1: loss = 0.55277 (* 1 = 0.55277 loss)
I0312 17:39:42.017606  1600 sgd_solver.cpp:106] Iteration 101100, lr = 0.001
I0312 17:39:51.138031  1600 solver.cpp:228] Iteration 101200, loss = 0.858263
I0312 17:39:51.138031  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:39:51.138031  1600 solver.cpp:244]     Train net output #1: loss = 0.858263 (* 1 = 0.858263 loss)
I0312 17:39:51.138031  1600 sgd_solver.cpp:106] Iteration 101200, lr = 0.001
I0312 17:40:00.122135  1600 solver.cpp:228] Iteration 101300, loss = 0.538596
I0312 17:40:00.122135  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:40:00.122135  1600 solver.cpp:244]     Train net output #1: loss = 0.538596 (* 1 = 0.538596 loss)
I0312 17:40:00.122135  1600 sgd_solver.cpp:106] Iteration 101300, lr = 0.001
I0312 17:40:09.251348  1600 solver.cpp:228] Iteration 101400, loss = 0.466495
I0312 17:40:09.251348  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:40:09.251348  1600 solver.cpp:244]     Train net output #1: loss = 0.466495 (* 1 = 0.466495 loss)
I0312 17:40:09.251348  1600 sgd_solver.cpp:106] Iteration 101400, lr = 0.001
I0312 17:40:18.592636  1600 solver.cpp:228] Iteration 101500, loss = 0.509703
I0312 17:40:18.592636  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:40:18.592636  1600 solver.cpp:244]     Train net output #1: loss = 0.509703 (* 1 = 0.509703 loss)
I0312 17:40:18.592636  1600 sgd_solver.cpp:106] Iteration 101500, lr = 0.001
I0312 17:40:27.575269  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_101600.caffemodel
I0312 17:40:27.607769  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_101600.solverstate
I0312 17:40:27.612768  1600 solver.cpp:337] Iteration 101600, Testing net (#0)
I0312 17:40:27.612768  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:40:31.451308  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6268
I0312 17:40:31.451308  1600 solver.cpp:404]     Test net output #1: loss = 1.58657 (* 1 = 1.58657 loss)
I0312 17:40:31.475318  1600 solver.cpp:228] Iteration 101600, loss = 0.688944
I0312 17:40:31.475318  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:40:31.475318  1600 solver.cpp:244]     Train net output #1: loss = 0.688945 (* 1 = 0.688945 loss)
I0312 17:40:31.475318  1600 sgd_solver.cpp:106] Iteration 101600, lr = 0.001
I0312 17:40:40.658308  1600 solver.cpp:228] Iteration 101700, loss = 0.736823
I0312 17:40:40.658809  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:40:40.658809  1600 solver.cpp:244]     Train net output #1: loss = 0.736823 (* 1 = 0.736823 loss)
I0312 17:40:40.658809  1600 sgd_solver.cpp:106] Iteration 101700, lr = 0.001
I0312 17:40:50.037607  1600 solver.cpp:228] Iteration 101800, loss = 0.518615
I0312 17:40:50.037607  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:40:50.037607  1600 solver.cpp:244]     Train net output #1: loss = 0.518615 (* 1 = 0.518615 loss)
I0312 17:40:50.037607  1600 sgd_solver.cpp:106] Iteration 101800, lr = 0.001
I0312 17:40:59.317224  1600 solver.cpp:228] Iteration 101900, loss = 0.656518
I0312 17:40:59.317224  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:40:59.317224  1600 solver.cpp:244]     Train net output #1: loss = 0.656518 (* 1 = 0.656518 loss)
I0312 17:40:59.317224  1600 sgd_solver.cpp:106] Iteration 101900, lr = 0.001
I0312 17:41:08.536422  1600 solver.cpp:228] Iteration 102000, loss = 0.75356
I0312 17:41:08.536422  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:41:08.536422  1600 solver.cpp:244]     Train net output #1: loss = 0.75356 (* 1 = 0.75356 loss)
I0312 17:41:08.536422  1600 sgd_solver.cpp:106] Iteration 102000, lr = 0.001
I0312 17:41:17.690994  1600 solver.cpp:228] Iteration 102100, loss = 0.457697
I0312 17:41:17.690994  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:41:17.690994  1600 solver.cpp:244]     Train net output #1: loss = 0.457697 (* 1 = 0.457697 loss)
I0312 17:41:17.690994  1600 sgd_solver.cpp:106] Iteration 102100, lr = 0.001
I0312 17:41:26.920838  1600 solver.cpp:228] Iteration 102200, loss = 0.471332
I0312 17:41:26.920838  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:41:26.920838  1600 solver.cpp:244]     Train net output #1: loss = 0.471333 (* 1 = 0.471333 loss)
I0312 17:41:26.920838  1600 sgd_solver.cpp:106] Iteration 102200, lr = 0.001
I0312 17:41:36.037462  1600 solver.cpp:228] Iteration 102300, loss = 0.519404
I0312 17:41:36.037462  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:41:36.037462  1600 solver.cpp:244]     Train net output #1: loss = 0.519404 (* 1 = 0.519404 loss)
I0312 17:41:36.037462  1600 sgd_solver.cpp:106] Iteration 102300, lr = 0.001
I0312 17:41:45.056965  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_102400.caffemodel
I0312 17:41:45.087466  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_102400.solverstate
I0312 17:41:45.092465  1600 solver.cpp:337] Iteration 102400, Testing net (#0)
I0312 17:41:45.092465  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:41:48.863528  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6281
I0312 17:41:48.863528  1600 solver.cpp:404]     Test net output #1: loss = 1.58956 (* 1 = 1.58956 loss)
I0312 17:41:48.888027  1600 solver.cpp:228] Iteration 102400, loss = 0.521313
I0312 17:41:48.888027  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:41:48.888027  1600 solver.cpp:244]     Train net output #1: loss = 0.521314 (* 1 = 0.521314 loss)
I0312 17:41:48.888027  1600 sgd_solver.cpp:106] Iteration 102400, lr = 0.001
I0312 17:41:57.915570  1600 solver.cpp:228] Iteration 102500, loss = 0.476194
I0312 17:41:57.915570  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:41:57.915570  1600 solver.cpp:244]     Train net output #1: loss = 0.476195 (* 1 = 0.476195 loss)
I0312 17:41:57.915570  1600 sgd_solver.cpp:106] Iteration 102500, lr = 0.001
I0312 17:42:07.076020  1600 solver.cpp:228] Iteration 102600, loss = 0.795734
I0312 17:42:07.076020  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:42:07.076020  1600 solver.cpp:244]     Train net output #1: loss = 0.795734 (* 1 = 0.795734 loss)
I0312 17:42:07.076020  1600 sgd_solver.cpp:106] Iteration 102600, lr = 0.001
I0312 17:42:16.385758  1600 solver.cpp:228] Iteration 102700, loss = 0.545964
I0312 17:42:16.385758  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:42:16.385758  1600 solver.cpp:244]     Train net output #1: loss = 0.545964 (* 1 = 0.545964 loss)
I0312 17:42:16.385758  1600 sgd_solver.cpp:106] Iteration 102700, lr = 0.001
I0312 17:42:25.321946  1600 solver.cpp:228] Iteration 102800, loss = 0.364069
I0312 17:42:25.321946  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.921875
I0312 17:42:25.321946  1600 solver.cpp:244]     Train net output #1: loss = 0.364069 (* 1 = 0.364069 loss)
I0312 17:42:25.321946  1600 sgd_solver.cpp:106] Iteration 102800, lr = 0.001
I0312 17:42:34.461158  1600 solver.cpp:228] Iteration 102900, loss = 0.678984
I0312 17:42:34.461158  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:42:34.461158  1600 solver.cpp:244]     Train net output #1: loss = 0.678984 (* 1 = 0.678984 loss)
I0312 17:42:34.461158  1600 sgd_solver.cpp:106] Iteration 102900, lr = 0.001
I0312 17:42:43.571326  1600 solver.cpp:228] Iteration 103000, loss = 0.513058
I0312 17:42:43.571326  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:42:43.571326  1600 solver.cpp:244]     Train net output #1: loss = 0.513058 (* 1 = 0.513058 loss)
I0312 17:42:43.571326  1600 sgd_solver.cpp:106] Iteration 103000, lr = 0.001
I0312 17:42:52.808423  1600 solver.cpp:228] Iteration 103100, loss = 0.695738
I0312 17:42:52.808423  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:42:52.808423  1600 solver.cpp:244]     Train net output #1: loss = 0.695738 (* 1 = 0.695738 loss)
I0312 17:42:52.808423  1600 sgd_solver.cpp:106] Iteration 103100, lr = 0.001
I0312 17:43:02.121603  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_103200.caffemodel
I0312 17:43:02.134615  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_103200.solverstate
I0312 17:43:02.144614  1600 solver.cpp:337] Iteration 103200, Testing net (#0)
I0312 17:43:02.144614  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:43:05.846174  1600 solver.cpp:404]     Test net output #0: accuracy = 0.627
I0312 17:43:05.846174  1600 solver.cpp:404]     Test net output #1: loss = 1.59208 (* 1 = 1.59208 loss)
I0312 17:43:05.866176  1600 solver.cpp:228] Iteration 103200, loss = 0.653119
I0312 17:43:05.866176  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:43:05.866176  1600 solver.cpp:244]     Train net output #1: loss = 0.653119 (* 1 = 0.653119 loss)
I0312 17:43:05.866176  1600 sgd_solver.cpp:106] Iteration 103200, lr = 0.001
I0312 17:43:14.562065  1600 solver.cpp:228] Iteration 103300, loss = 0.666044
I0312 17:43:14.562065  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:43:14.562065  1600 solver.cpp:244]     Train net output #1: loss = 0.666044 (* 1 = 0.666044 loss)
I0312 17:43:14.562065  1600 sgd_solver.cpp:106] Iteration 103300, lr = 0.001
I0312 17:43:20.570650  1600 solver.cpp:228] Iteration 103400, loss = 0.617281
I0312 17:43:20.570650  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:43:20.570650  1600 solver.cpp:244]     Train net output #1: loss = 0.617281 (* 1 = 0.617281 loss)
I0312 17:43:20.570650  1600 sgd_solver.cpp:106] Iteration 103400, lr = 0.001
I0312 17:43:26.475272  1600 solver.cpp:228] Iteration 103500, loss = 0.578303
I0312 17:43:26.475272  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:43:26.475272  1600 solver.cpp:244]     Train net output #1: loss = 0.578303 (* 1 = 0.578303 loss)
I0312 17:43:26.475272  1600 sgd_solver.cpp:106] Iteration 103500, lr = 0.001
I0312 17:43:32.927748  1600 solver.cpp:228] Iteration 103600, loss = 0.53214
I0312 17:43:32.927748  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:43:32.927748  1600 solver.cpp:244]     Train net output #1: loss = 0.53214 (* 1 = 0.53214 loss)
I0312 17:43:32.927748  1600 sgd_solver.cpp:106] Iteration 103600, lr = 0.001
I0312 17:43:42.437501  1600 solver.cpp:228] Iteration 103700, loss = 0.792412
I0312 17:43:42.437501  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:43:42.437501  1600 solver.cpp:244]     Train net output #1: loss = 0.792413 (* 1 = 0.792413 loss)
I0312 17:43:42.437501  1600 sgd_solver.cpp:106] Iteration 103700, lr = 0.001
I0312 17:43:51.942349  1600 solver.cpp:228] Iteration 103800, loss = 0.794889
I0312 17:43:51.942349  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:43:51.942349  1600 solver.cpp:244]     Train net output #1: loss = 0.794889 (* 1 = 0.794889 loss)
I0312 17:43:51.942349  1600 sgd_solver.cpp:106] Iteration 103800, lr = 0.001
I0312 17:44:01.571465  1600 solver.cpp:228] Iteration 103900, loss = 0.995031
I0312 17:44:01.571465  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:44:01.571465  1600 solver.cpp:244]     Train net output #1: loss = 0.995031 (* 1 = 0.995031 loss)
I0312 17:44:01.571465  1600 sgd_solver.cpp:106] Iteration 103900, lr = 0.001
I0312 17:44:10.930786  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_104000.caffemodel
I0312 17:44:10.947789  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_104000.solverstate
I0312 17:44:10.952787  1600 solver.cpp:337] Iteration 104000, Testing net (#0)
I0312 17:44:10.952787  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:44:14.836395  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6278
I0312 17:44:14.836395  1600 solver.cpp:404]     Test net output #1: loss = 1.5938 (* 1 = 1.5938 loss)
I0312 17:44:14.869395  1600 solver.cpp:228] Iteration 104000, loss = 0.847721
I0312 17:44:14.869395  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:44:14.869395  1600 solver.cpp:244]     Train net output #1: loss = 0.847721 (* 1 = 0.847721 loss)
I0312 17:44:14.869395  1600 sgd_solver.cpp:106] Iteration 104000, lr = 0.001
I0312 17:44:24.510771  1600 solver.cpp:228] Iteration 104100, loss = 0.633625
I0312 17:44:24.510771  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:44:24.511271  1600 solver.cpp:244]     Train net output #1: loss = 0.633626 (* 1 = 0.633626 loss)
I0312 17:44:24.511271  1600 sgd_solver.cpp:106] Iteration 104100, lr = 0.001
I0312 17:44:34.275348  1600 solver.cpp:228] Iteration 104200, loss = 0.600734
I0312 17:44:34.275348  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:44:34.275348  1600 solver.cpp:244]     Train net output #1: loss = 0.600734 (* 1 = 0.600734 loss)
I0312 17:44:34.275348  1600 sgd_solver.cpp:106] Iteration 104200, lr = 0.001
I0312 17:44:43.734774  1600 solver.cpp:228] Iteration 104300, loss = 0.617814
I0312 17:44:43.734774  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:44:43.734774  1600 solver.cpp:244]     Train net output #1: loss = 0.617815 (* 1 = 0.617815 loss)
I0312 17:44:43.734774  1600 sgd_solver.cpp:106] Iteration 104300, lr = 0.001
I0312 17:44:52.877127  1600 solver.cpp:228] Iteration 104400, loss = 0.661304
I0312 17:44:52.877127  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:44:52.877127  1600 solver.cpp:244]     Train net output #1: loss = 0.661305 (* 1 = 0.661305 loss)
I0312 17:44:52.877127  1600 sgd_solver.cpp:106] Iteration 104400, lr = 0.001
I0312 17:45:01.926687  1600 solver.cpp:228] Iteration 104500, loss = 0.827671
I0312 17:45:01.926687  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:45:01.926687  1600 solver.cpp:244]     Train net output #1: loss = 0.827671 (* 1 = 0.827671 loss)
I0312 17:45:01.926687  1600 sgd_solver.cpp:106] Iteration 104500, lr = 0.001
I0312 17:45:10.942013  1600 solver.cpp:228] Iteration 104600, loss = 0.664088
I0312 17:45:10.942013  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:45:10.942013  1600 solver.cpp:244]     Train net output #1: loss = 0.664088 (* 1 = 0.664088 loss)
I0312 17:45:10.942013  1600 sgd_solver.cpp:106] Iteration 104600, lr = 0.001
I0312 17:45:19.896798  1600 solver.cpp:228] Iteration 104700, loss = 0.612551
I0312 17:45:19.896798  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:45:19.896798  1600 solver.cpp:244]     Train net output #1: loss = 0.612551 (* 1 = 0.612551 loss)
I0312 17:45:19.896798  1600 sgd_solver.cpp:106] Iteration 104700, lr = 0.001
I0312 17:45:28.705802  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_104800.caffemodel
I0312 17:45:28.721803  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_104800.solverstate
I0312 17:45:28.726303  1600 solver.cpp:337] Iteration 104800, Testing net (#0)
I0312 17:45:28.726303  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:45:32.468065  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6282
I0312 17:45:32.468065  1600 solver.cpp:404]     Test net output #1: loss = 1.59055 (* 1 = 1.59055 loss)
I0312 17:45:32.486570  1600 solver.cpp:228] Iteration 104800, loss = 0.56773
I0312 17:45:32.486570  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:45:32.486570  1600 solver.cpp:244]     Train net output #1: loss = 0.56773 (* 1 = 0.56773 loss)
I0312 17:45:32.486570  1600 sgd_solver.cpp:106] Iteration 104800, lr = 0.001
I0312 17:45:41.625620  1600 solver.cpp:228] Iteration 104900, loss = 0.529034
I0312 17:45:41.625620  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:45:41.625620  1600 solver.cpp:244]     Train net output #1: loss = 0.529035 (* 1 = 0.529035 loss)
I0312 17:45:41.625620  1600 sgd_solver.cpp:106] Iteration 104900, lr = 0.001
I0312 17:45:50.765946  1600 solver.cpp:228] Iteration 105000, loss = 0.778249
I0312 17:45:50.765946  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:45:50.765946  1600 solver.cpp:244]     Train net output #1: loss = 0.77825 (* 1 = 0.77825 loss)
I0312 17:45:50.765946  1600 sgd_solver.cpp:106] Iteration 105000, lr = 0.001
I0312 17:45:59.897284  1600 solver.cpp:228] Iteration 105100, loss = 0.698725
I0312 17:45:59.897284  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:45:59.897284  1600 solver.cpp:244]     Train net output #1: loss = 0.698725 (* 1 = 0.698725 loss)
I0312 17:45:59.897284  1600 sgd_solver.cpp:106] Iteration 105100, lr = 0.001
I0312 17:46:09.134032  1600 solver.cpp:228] Iteration 105200, loss = 0.718895
I0312 17:46:09.134032  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:46:09.134032  1600 solver.cpp:244]     Train net output #1: loss = 0.718896 (* 1 = 0.718896 loss)
I0312 17:46:09.134032  1600 sgd_solver.cpp:106] Iteration 105200, lr = 0.001
I0312 17:46:19.335381  1600 solver.cpp:228] Iteration 105300, loss = 0.388391
I0312 17:46:19.335381  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 17:46:19.335381  1600 solver.cpp:244]     Train net output #1: loss = 0.388391 (* 1 = 0.388391 loss)
I0312 17:46:19.335381  1600 sgd_solver.cpp:106] Iteration 105300, lr = 0.001
I0312 17:46:29.179749  1600 solver.cpp:228] Iteration 105400, loss = 0.678817
I0312 17:46:29.179749  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:46:29.179749  1600 solver.cpp:244]     Train net output #1: loss = 0.678817 (* 1 = 0.678817 loss)
I0312 17:46:29.179749  1600 sgd_solver.cpp:106] Iteration 105400, lr = 0.001
I0312 17:46:38.347431  1600 solver.cpp:228] Iteration 105500, loss = 0.431938
I0312 17:46:38.347431  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:46:38.347431  1600 solver.cpp:244]     Train net output #1: loss = 0.431939 (* 1 = 0.431939 loss)
I0312 17:46:38.347431  1600 sgd_solver.cpp:106] Iteration 105500, lr = 0.001
I0312 17:46:47.343461  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_105600.caffemodel
I0312 17:46:47.379962  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_105600.solverstate
I0312 17:46:47.384961  1600 solver.cpp:337] Iteration 105600, Testing net (#0)
I0312 17:46:47.384961  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:46:51.149657  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6286
I0312 17:46:51.149657  1600 solver.cpp:404]     Test net output #1: loss = 1.59264 (* 1 = 1.59264 loss)
I0312 17:46:51.159657  1600 solver.cpp:228] Iteration 105600, loss = 0.505832
I0312 17:46:51.159657  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:46:51.159657  1600 solver.cpp:244]     Train net output #1: loss = 0.505832 (* 1 = 0.505832 loss)
I0312 17:46:51.159657  1600 sgd_solver.cpp:106] Iteration 105600, lr = 0.001
I0312 17:47:00.354823  1600 solver.cpp:228] Iteration 105700, loss = 0.493366
I0312 17:47:00.355321  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:47:00.355321  1600 solver.cpp:244]     Train net output #1: loss = 0.493366 (* 1 = 0.493366 loss)
I0312 17:47:00.355321  1600 sgd_solver.cpp:106] Iteration 105700, lr = 0.001
I0312 17:47:09.397467  1600 solver.cpp:228] Iteration 105800, loss = 0.297971
I0312 17:47:09.397467  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 17:47:09.397467  1600 solver.cpp:244]     Train net output #1: loss = 0.297971 (* 1 = 0.297971 loss)
I0312 17:47:09.397467  1600 sgd_solver.cpp:106] Iteration 105800, lr = 0.001
I0312 17:47:18.675413  1600 solver.cpp:228] Iteration 105900, loss = 0.543421
I0312 17:47:18.675413  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:47:18.675413  1600 solver.cpp:244]     Train net output #1: loss = 0.543421 (* 1 = 0.543421 loss)
I0312 17:47:18.675413  1600 sgd_solver.cpp:106] Iteration 105900, lr = 0.001
I0312 17:47:27.909488  1600 solver.cpp:228] Iteration 106000, loss = 0.650819
I0312 17:47:27.909488  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:47:27.909488  1600 solver.cpp:244]     Train net output #1: loss = 0.650819 (* 1 = 0.650819 loss)
I0312 17:47:27.909488  1600 sgd_solver.cpp:106] Iteration 106000, lr = 0.001
I0312 17:47:37.061040  1600 solver.cpp:228] Iteration 106100, loss = 0.882466
I0312 17:47:37.061040  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:47:37.061040  1600 solver.cpp:244]     Train net output #1: loss = 0.882466 (* 1 = 0.882466 loss)
I0312 17:47:37.061040  1600 sgd_solver.cpp:106] Iteration 106100, lr = 0.001
I0312 17:47:46.308729  1600 solver.cpp:228] Iteration 106200, loss = 0.64266
I0312 17:47:46.308729  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:47:46.308729  1600 solver.cpp:244]     Train net output #1: loss = 0.64266 (* 1 = 0.64266 loss)
I0312 17:47:46.309228  1600 sgd_solver.cpp:106] Iteration 106200, lr = 0.001
I0312 17:47:55.573899  1600 solver.cpp:228] Iteration 106300, loss = 0.705884
I0312 17:47:55.573899  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:47:55.573899  1600 solver.cpp:244]     Train net output #1: loss = 0.705884 (* 1 = 0.705884 loss)
I0312 17:47:55.573899  1600 sgd_solver.cpp:106] Iteration 106300, lr = 0.001
I0312 17:48:04.542542  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_106400.caffemodel
I0312 17:48:04.569041  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_106400.solverstate
I0312 17:48:04.574540  1600 solver.cpp:337] Iteration 106400, Testing net (#0)
I0312 17:48:04.574540  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:48:08.313050  1600 solver.cpp:404]     Test net output #0: accuracy = 0.626301
I0312 17:48:08.313050  1600 solver.cpp:404]     Test net output #1: loss = 1.59556 (* 1 = 1.59556 loss)
I0312 17:48:08.341540  1600 solver.cpp:228] Iteration 106400, loss = 0.747932
I0312 17:48:08.341540  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:48:08.341540  1600 solver.cpp:244]     Train net output #1: loss = 0.747932 (* 1 = 0.747932 loss)
I0312 17:48:08.342041  1600 sgd_solver.cpp:106] Iteration 106400, lr = 0.001
I0312 17:48:17.471143  1600 solver.cpp:228] Iteration 106500, loss = 0.49472
I0312 17:48:17.471143  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:48:17.471143  1600 solver.cpp:244]     Train net output #1: loss = 0.49472 (* 1 = 0.49472 loss)
I0312 17:48:17.471143  1600 sgd_solver.cpp:106] Iteration 106500, lr = 0.001
I0312 17:48:26.205256  1600 solver.cpp:228] Iteration 106600, loss = 0.488333
I0312 17:48:26.205256  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:48:26.205256  1600 solver.cpp:244]     Train net output #1: loss = 0.488333 (* 1 = 0.488333 loss)
I0312 17:48:26.205256  1600 sgd_solver.cpp:106] Iteration 106600, lr = 0.001
I0312 17:48:32.009006  1600 solver.cpp:228] Iteration 106700, loss = 0.612939
I0312 17:48:32.009006  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:48:32.009006  1600 solver.cpp:244]     Train net output #1: loss = 0.612939 (* 1 = 0.612939 loss)
I0312 17:48:32.009006  1600 sgd_solver.cpp:106] Iteration 106700, lr = 0.001
I0312 17:48:37.821434  1600 solver.cpp:228] Iteration 106800, loss = 0.512623
I0312 17:48:37.821434  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:48:37.821434  1600 solver.cpp:244]     Train net output #1: loss = 0.512623 (* 1 = 0.512623 loss)
I0312 17:48:37.821434  1600 sgd_solver.cpp:106] Iteration 106800, lr = 0.001
I0312 17:48:44.159859  1600 solver.cpp:228] Iteration 106900, loss = 0.586575
I0312 17:48:44.160359  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:48:44.160359  1600 solver.cpp:244]     Train net output #1: loss = 0.586575 (* 1 = 0.586575 loss)
I0312 17:48:44.160359  1600 sgd_solver.cpp:106] Iteration 106900, lr = 0.001
I0312 17:48:53.449892  1600 solver.cpp:228] Iteration 107000, loss = 0.709439
I0312 17:48:53.449892  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:48:53.450389  1600 solver.cpp:244]     Train net output #1: loss = 0.709439 (* 1 = 0.709439 loss)
I0312 17:48:53.450389  1600 sgd_solver.cpp:106] Iteration 107000, lr = 0.001
I0312 17:49:02.630986  1600 solver.cpp:228] Iteration 107100, loss = 1.01967
I0312 17:49:02.630986  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:49:02.630986  1600 solver.cpp:244]     Train net output #1: loss = 1.01967 (* 1 = 1.01967 loss)
I0312 17:49:02.630986  1600 sgd_solver.cpp:106] Iteration 107100, lr = 0.001
I0312 17:49:11.708571  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_107200.caffemodel
I0312 17:49:11.729567  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_107200.solverstate
I0312 17:49:11.734565  1600 solver.cpp:337] Iteration 107200, Testing net (#0)
I0312 17:49:11.734565  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:49:15.453644  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6262
I0312 17:49:15.453644  1600 solver.cpp:404]     Test net output #1: loss = 1.59878 (* 1 = 1.59878 loss)
I0312 17:49:15.499150  1600 solver.cpp:228] Iteration 107200, loss = 0.950436
I0312 17:49:15.499150  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:49:15.499150  1600 solver.cpp:244]     Train net output #1: loss = 0.950436 (* 1 = 0.950436 loss)
I0312 17:49:15.499150  1600 sgd_solver.cpp:106] Iteration 107200, lr = 0.001
I0312 17:49:24.687743  1600 solver.cpp:228] Iteration 107300, loss = 0.571092
I0312 17:49:24.687743  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:49:24.687743  1600 solver.cpp:244]     Train net output #1: loss = 0.571092 (* 1 = 0.571092 loss)
I0312 17:49:24.687743  1600 sgd_solver.cpp:106] Iteration 107300, lr = 0.001
I0312 17:49:33.722275  1600 solver.cpp:228] Iteration 107400, loss = 0.905884
I0312 17:49:33.722275  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:49:33.722275  1600 solver.cpp:244]     Train net output #1: loss = 0.905884 (* 1 = 0.905884 loss)
I0312 17:49:33.722275  1600 sgd_solver.cpp:106] Iteration 107400, lr = 0.001
I0312 17:49:42.819942  1600 solver.cpp:228] Iteration 107500, loss = 0.752656
I0312 17:49:42.819942  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:49:42.819942  1600 solver.cpp:244]     Train net output #1: loss = 0.752656 (* 1 = 0.752656 loss)
I0312 17:49:42.819942  1600 sgd_solver.cpp:106] Iteration 107500, lr = 0.001
I0312 17:49:52.009232  1600 solver.cpp:228] Iteration 107600, loss = 0.843706
I0312 17:49:52.009232  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:49:52.009232  1600 solver.cpp:244]     Train net output #1: loss = 0.843706 (* 1 = 0.843706 loss)
I0312 17:49:52.009232  1600 sgd_solver.cpp:106] Iteration 107600, lr = 0.001
I0312 17:50:01.063015  1600 solver.cpp:228] Iteration 107700, loss = 0.664568
I0312 17:50:01.063015  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:50:01.063015  1600 solver.cpp:244]     Train net output #1: loss = 0.664568 (* 1 = 0.664568 loss)
I0312 17:50:01.063015  1600 sgd_solver.cpp:106] Iteration 107700, lr = 0.001
I0312 17:50:10.206539  1600 solver.cpp:228] Iteration 107800, loss = 0.955783
I0312 17:50:10.206539  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:50:10.206539  1600 solver.cpp:244]     Train net output #1: loss = 0.955783 (* 1 = 0.955783 loss)
I0312 17:50:10.206539  1600 sgd_solver.cpp:106] Iteration 107800, lr = 0.001
I0312 17:50:19.387243  1600 solver.cpp:228] Iteration 107900, loss = 0.689161
I0312 17:50:19.387243  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:50:19.387243  1600 solver.cpp:244]     Train net output #1: loss = 0.689161 (* 1 = 0.689161 loss)
I0312 17:50:19.387243  1600 sgd_solver.cpp:106] Iteration 107900, lr = 0.001
I0312 17:50:28.409901  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_108000.caffemodel
I0312 17:50:28.437402  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_108000.solverstate
I0312 17:50:28.442401  1600 solver.cpp:337] Iteration 108000, Testing net (#0)
I0312 17:50:28.442903  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:50:32.168529  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6255
I0312 17:50:32.168529  1600 solver.cpp:404]     Test net output #1: loss = 1.59617 (* 1 = 1.59617 loss)
I0312 17:50:32.208528  1600 solver.cpp:228] Iteration 108000, loss = 0.47969
I0312 17:50:32.208528  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:50:32.208528  1600 solver.cpp:244]     Train net output #1: loss = 0.47969 (* 1 = 0.47969 loss)
I0312 17:50:32.208528  1600 sgd_solver.cpp:106] Iteration 108000, lr = 0.001
I0312 17:50:41.401976  1600 solver.cpp:228] Iteration 108100, loss = 0.657293
I0312 17:50:41.401976  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:50:41.402477  1600 solver.cpp:244]     Train net output #1: loss = 0.657292 (* 1 = 0.657292 loss)
I0312 17:50:41.402477  1600 sgd_solver.cpp:106] Iteration 108100, lr = 0.001
I0312 17:50:50.782121  1600 solver.cpp:228] Iteration 108200, loss = 0.566834
I0312 17:50:50.782121  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:50:50.782121  1600 solver.cpp:244]     Train net output #1: loss = 0.566834 (* 1 = 0.566834 loss)
I0312 17:50:50.782121  1600 sgd_solver.cpp:106] Iteration 108200, lr = 0.001
I0312 17:50:59.806735  1600 solver.cpp:228] Iteration 108300, loss = 0.765739
I0312 17:50:59.807235  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:50:59.807235  1600 solver.cpp:244]     Train net output #1: loss = 0.765739 (* 1 = 0.765739 loss)
I0312 17:50:59.807235  1600 sgd_solver.cpp:106] Iteration 108300, lr = 0.001
I0312 17:51:08.902668  1600 solver.cpp:228] Iteration 108400, loss = 0.64296
I0312 17:51:08.902668  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:51:08.902668  1600 solver.cpp:244]     Train net output #1: loss = 0.64296 (* 1 = 0.64296 loss)
I0312 17:51:08.902668  1600 sgd_solver.cpp:106] Iteration 108400, lr = 0.001
I0312 17:51:17.976104  1600 solver.cpp:228] Iteration 108500, loss = 0.577147
I0312 17:51:17.976104  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:51:17.976104  1600 solver.cpp:244]     Train net output #1: loss = 0.577147 (* 1 = 0.577147 loss)
I0312 17:51:17.976104  1600 sgd_solver.cpp:106] Iteration 108500, lr = 0.001
I0312 17:51:27.114835  1600 solver.cpp:228] Iteration 108600, loss = 0.477144
I0312 17:51:27.114835  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:51:27.114835  1600 solver.cpp:244]     Train net output #1: loss = 0.477144 (* 1 = 0.477144 loss)
I0312 17:51:27.114835  1600 sgd_solver.cpp:106] Iteration 108600, lr = 0.001
I0312 17:51:36.395414  1600 solver.cpp:228] Iteration 108700, loss = 0.595938
I0312 17:51:36.395414  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:51:36.395414  1600 solver.cpp:244]     Train net output #1: loss = 0.595938 (* 1 = 0.595938 loss)
I0312 17:51:36.395414  1600 sgd_solver.cpp:106] Iteration 108700, lr = 0.001
I0312 17:51:45.370961  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_108800.caffemodel
I0312 17:51:45.392962  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_108800.solverstate
I0312 17:51:45.397961  1600 solver.cpp:337] Iteration 108800, Testing net (#0)
I0312 17:51:45.397961  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:51:49.149005  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6273
I0312 17:51:49.149005  1600 solver.cpp:404]     Test net output #1: loss = 1.5994 (* 1 = 1.5994 loss)
I0312 17:51:49.166501  1600 solver.cpp:228] Iteration 108800, loss = 0.444406
I0312 17:51:49.166501  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:51:49.166501  1600 solver.cpp:244]     Train net output #1: loss = 0.444406 (* 1 = 0.444406 loss)
I0312 17:51:49.166501  1600 sgd_solver.cpp:106] Iteration 108800, lr = 0.001
I0312 17:51:58.324019  1600 solver.cpp:228] Iteration 108900, loss = 0.437211
I0312 17:51:58.324019  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:51:58.324019  1600 solver.cpp:244]     Train net output #1: loss = 0.437211 (* 1 = 0.437211 loss)
I0312 17:51:58.324019  1600 sgd_solver.cpp:106] Iteration 108900, lr = 0.001
I0312 17:52:07.383991  1600 solver.cpp:228] Iteration 109000, loss = 0.602844
I0312 17:52:07.383991  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:52:07.383991  1600 solver.cpp:244]     Train net output #1: loss = 0.602844 (* 1 = 0.602844 loss)
I0312 17:52:07.383991  1600 sgd_solver.cpp:106] Iteration 109000, lr = 0.001
I0312 17:52:16.296502  1600 solver.cpp:228] Iteration 109100, loss = 0.524523
I0312 17:52:16.296502  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:52:16.296502  1600 solver.cpp:244]     Train net output #1: loss = 0.524523 (* 1 = 0.524523 loss)
I0312 17:52:16.296502  1600 sgd_solver.cpp:106] Iteration 109100, lr = 0.001
I0312 17:52:25.353088  1600 solver.cpp:228] Iteration 109200, loss = 0.680493
I0312 17:52:25.353088  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:52:25.353088  1600 solver.cpp:244]     Train net output #1: loss = 0.680493 (* 1 = 0.680493 loss)
I0312 17:52:25.353088  1600 sgd_solver.cpp:106] Iteration 109200, lr = 0.001
I0312 17:52:34.489642  1600 solver.cpp:228] Iteration 109300, loss = 0.664613
I0312 17:52:34.489642  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:52:34.489642  1600 solver.cpp:244]     Train net output #1: loss = 0.664613 (* 1 = 0.664613 loss)
I0312 17:52:34.489642  1600 sgd_solver.cpp:106] Iteration 109300, lr = 0.001
I0312 17:52:43.669452  1600 solver.cpp:228] Iteration 109400, loss = 0.834321
I0312 17:52:43.669452  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:52:43.669452  1600 solver.cpp:244]     Train net output #1: loss = 0.834321 (* 1 = 0.834321 loss)
I0312 17:52:43.669452  1600 sgd_solver.cpp:106] Iteration 109400, lr = 0.001
I0312 17:52:52.767266  1600 solver.cpp:228] Iteration 109500, loss = 0.612949
I0312 17:52:52.767266  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:52:52.767266  1600 solver.cpp:244]     Train net output #1: loss = 0.612948 (* 1 = 0.612948 loss)
I0312 17:52:52.767266  1600 sgd_solver.cpp:106] Iteration 109500, lr = 0.001
I0312 17:53:01.937485  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_109600.caffemodel
I0312 17:53:01.958984  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_109600.solverstate
I0312 17:53:01.963485  1600 solver.cpp:337] Iteration 109600, Testing net (#0)
I0312 17:53:01.963485  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:53:05.726704  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6261
I0312 17:53:05.726704  1600 solver.cpp:404]     Test net output #1: loss = 1.60162 (* 1 = 1.60162 loss)
I0312 17:53:05.746703  1600 solver.cpp:228] Iteration 109600, loss = 0.75306
I0312 17:53:05.746703  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:53:05.746703  1600 solver.cpp:244]     Train net output #1: loss = 0.75306 (* 1 = 0.75306 loss)
I0312 17:53:05.746703  1600 sgd_solver.cpp:106] Iteration 109600, lr = 0.001
I0312 17:53:15.004250  1600 solver.cpp:228] Iteration 109700, loss = 0.407552
I0312 17:53:15.004250  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 17:53:15.004250  1600 solver.cpp:244]     Train net output #1: loss = 0.407552 (* 1 = 0.407552 loss)
I0312 17:53:15.004250  1600 sgd_solver.cpp:106] Iteration 109700, lr = 0.001
I0312 17:53:24.111136  1600 solver.cpp:228] Iteration 109800, loss = 0.904314
I0312 17:53:24.111136  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 17:53:24.111136  1600 solver.cpp:244]     Train net output #1: loss = 0.904314 (* 1 = 0.904314 loss)
I0312 17:53:24.111136  1600 sgd_solver.cpp:106] Iteration 109800, lr = 0.001
I0312 17:53:32.399140  1600 solver.cpp:228] Iteration 109900, loss = 1.01779
I0312 17:53:32.399140  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:53:32.399140  1600 solver.cpp:244]     Train net output #1: loss = 1.01779 (* 1 = 1.01779 loss)
I0312 17:53:32.399140  1600 sgd_solver.cpp:106] Iteration 109900, lr = 0.001
I0312 17:53:38.255828  1600 solver.cpp:228] Iteration 110000, loss = 0.769789
I0312 17:53:38.255828  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:53:38.255828  1600 solver.cpp:244]     Train net output #1: loss = 0.769789 (* 1 = 0.769789 loss)
I0312 17:53:38.255828  1600 sgd_solver.cpp:106] Iteration 110000, lr = 0.001
I0312 17:53:44.042927  1600 solver.cpp:228] Iteration 110100, loss = 0.640949
I0312 17:53:44.042927  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:53:44.042927  1600 solver.cpp:244]     Train net output #1: loss = 0.640949 (* 1 = 0.640949 loss)
I0312 17:53:44.042927  1600 sgd_solver.cpp:106] Iteration 110100, lr = 0.001
I0312 17:53:50.819777  1600 solver.cpp:228] Iteration 110200, loss = 0.674693
I0312 17:53:50.819777  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 17:53:50.820276  1600 solver.cpp:244]     Train net output #1: loss = 0.674693 (* 1 = 0.674693 loss)
I0312 17:53:50.820276  1600 sgd_solver.cpp:106] Iteration 110200, lr = 0.001
I0312 17:54:00.061777  1600 solver.cpp:228] Iteration 110300, loss = 0.39939
I0312 17:54:00.061777  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 17:54:00.061777  1600 solver.cpp:244]     Train net output #1: loss = 0.39939 (* 1 = 0.39939 loss)
I0312 17:54:00.061777  1600 sgd_solver.cpp:106] Iteration 110300, lr = 0.001
I0312 17:54:09.455173  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_110400.caffemodel
I0312 17:54:09.470686  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_110400.solverstate
I0312 17:54:09.475687  1600 solver.cpp:337] Iteration 110400, Testing net (#0)
I0312 17:54:09.475687  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:54:13.212831  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6274
I0312 17:54:13.212831  1600 solver.cpp:404]     Test net output #1: loss = 1.59786 (* 1 = 1.59786 loss)
I0312 17:54:13.248831  1600 solver.cpp:228] Iteration 110400, loss = 0.529253
I0312 17:54:13.248831  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:54:13.248831  1600 solver.cpp:244]     Train net output #1: loss = 0.529253 (* 1 = 0.529253 loss)
I0312 17:54:13.248831  1600 sgd_solver.cpp:106] Iteration 110400, lr = 0.001
I0312 17:54:22.246891  1600 solver.cpp:228] Iteration 110500, loss = 0.932661
I0312 17:54:22.246891  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:54:22.246891  1600 solver.cpp:244]     Train net output #1: loss = 0.932661 (* 1 = 0.932661 loss)
I0312 17:54:22.246891  1600 sgd_solver.cpp:106] Iteration 110500, lr = 0.001
I0312 17:54:31.552212  1600 solver.cpp:228] Iteration 110600, loss = 0.426067
I0312 17:54:31.552212  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.921875
I0312 17:54:31.552212  1600 solver.cpp:244]     Train net output #1: loss = 0.426067 (* 1 = 0.426067 loss)
I0312 17:54:31.552212  1600 sgd_solver.cpp:106] Iteration 110600, lr = 0.001
I0312 17:54:40.714722  1600 solver.cpp:228] Iteration 110700, loss = 0.58761
I0312 17:54:40.714722  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:54:40.714722  1600 solver.cpp:244]     Train net output #1: loss = 0.58761 (* 1 = 0.58761 loss)
I0312 17:54:40.714722  1600 sgd_solver.cpp:106] Iteration 110700, lr = 0.001
I0312 17:54:49.783552  1600 solver.cpp:228] Iteration 110800, loss = 0.55008
I0312 17:54:49.783552  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:54:49.783552  1600 solver.cpp:244]     Train net output #1: loss = 0.55008 (* 1 = 0.55008 loss)
I0312 17:54:49.783552  1600 sgd_solver.cpp:106] Iteration 110800, lr = 0.001
I0312 17:54:58.788995  1600 solver.cpp:228] Iteration 110900, loss = 0.482666
I0312 17:54:58.788995  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 17:54:58.788995  1600 solver.cpp:244]     Train net output #1: loss = 0.482666 (* 1 = 0.482666 loss)
I0312 17:54:58.788995  1600 sgd_solver.cpp:106] Iteration 110900, lr = 0.001
I0312 17:55:08.025261  1600 solver.cpp:228] Iteration 111000, loss = 0.693336
I0312 17:55:08.025261  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:55:08.025261  1600 solver.cpp:244]     Train net output #1: loss = 0.693336 (* 1 = 0.693336 loss)
I0312 17:55:08.025261  1600 sgd_solver.cpp:106] Iteration 111000, lr = 0.001
I0312 17:55:17.016494  1600 solver.cpp:228] Iteration 111100, loss = 0.549157
I0312 17:55:17.016494  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:55:17.016494  1600 solver.cpp:244]     Train net output #1: loss = 0.549157 (* 1 = 0.549157 loss)
I0312 17:55:17.016494  1600 sgd_solver.cpp:106] Iteration 111100, lr = 0.001
I0312 17:55:26.189705  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_111200.caffemodel
I0312 17:55:26.220206  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_111200.solverstate
I0312 17:55:26.224705  1600 solver.cpp:337] Iteration 111200, Testing net (#0)
I0312 17:55:26.224705  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:55:29.861207  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6285
I0312 17:55:29.861207  1600 solver.cpp:404]     Test net output #1: loss = 1.59681 (* 1 = 1.59681 loss)
I0312 17:55:29.906703  1600 solver.cpp:228] Iteration 111200, loss = 0.569661
I0312 17:55:29.907203  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:55:29.907203  1600 solver.cpp:244]     Train net output #1: loss = 0.569661 (* 1 = 0.569661 loss)
I0312 17:55:29.907203  1600 sgd_solver.cpp:106] Iteration 111200, lr = 0.001
I0312 17:55:39.026859  1600 solver.cpp:228] Iteration 111300, loss = 0.700883
I0312 17:55:39.026859  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:55:39.026859  1600 solver.cpp:244]     Train net output #1: loss = 0.700883 (* 1 = 0.700883 loss)
I0312 17:55:39.026859  1600 sgd_solver.cpp:106] Iteration 111300, lr = 0.001
I0312 17:55:48.172132  1600 solver.cpp:228] Iteration 111400, loss = 0.517117
I0312 17:55:48.172132  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:55:48.172132  1600 solver.cpp:244]     Train net output #1: loss = 0.517117 (* 1 = 0.517117 loss)
I0312 17:55:48.172132  1600 sgd_solver.cpp:106] Iteration 111400, lr = 0.001
I0312 17:55:57.547268  1600 solver.cpp:228] Iteration 111500, loss = 0.612247
I0312 17:55:57.547268  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:55:57.547268  1600 solver.cpp:244]     Train net output #1: loss = 0.612247 (* 1 = 0.612247 loss)
I0312 17:55:57.547268  1600 sgd_solver.cpp:106] Iteration 111500, lr = 0.001
I0312 17:56:06.707273  1600 solver.cpp:228] Iteration 111600, loss = 0.953377
I0312 17:56:06.707273  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:56:06.707273  1600 solver.cpp:244]     Train net output #1: loss = 0.953377 (* 1 = 0.953377 loss)
I0312 17:56:06.707273  1600 sgd_solver.cpp:106] Iteration 111600, lr = 0.001
I0312 17:56:15.804175  1600 solver.cpp:228] Iteration 111700, loss = 0.767438
I0312 17:56:15.804175  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 17:56:15.804175  1600 solver.cpp:244]     Train net output #1: loss = 0.767438 (* 1 = 0.767438 loss)
I0312 17:56:15.804175  1600 sgd_solver.cpp:106] Iteration 111700, lr = 0.001
I0312 17:56:24.851685  1600 solver.cpp:228] Iteration 111800, loss = 0.803834
I0312 17:56:24.851685  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:56:24.851685  1600 solver.cpp:244]     Train net output #1: loss = 0.803834 (* 1 = 0.803834 loss)
I0312 17:56:24.851685  1600 sgd_solver.cpp:106] Iteration 111800, lr = 0.001
I0312 17:56:34.084748  1600 solver.cpp:228] Iteration 111900, loss = 0.527076
I0312 17:56:34.084748  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 17:56:34.084748  1600 solver.cpp:244]     Train net output #1: loss = 0.527076 (* 1 = 0.527076 loss)
I0312 17:56:34.084748  1600 sgd_solver.cpp:106] Iteration 111900, lr = 0.001
I0312 17:56:43.324940  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_112000.caffemodel
I0312 17:56:43.355440  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_112000.solverstate
I0312 17:56:43.360438  1600 solver.cpp:337] Iteration 112000, Testing net (#0)
I0312 17:56:43.360438  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:56:47.010437  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6275
I0312 17:56:47.010937  1600 solver.cpp:404]     Test net output #1: loss = 1.59974 (* 1 = 1.59974 loss)
I0312 17:56:47.061437  1600 solver.cpp:228] Iteration 112000, loss = 0.671277
I0312 17:56:47.061437  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:56:47.061437  1600 solver.cpp:244]     Train net output #1: loss = 0.671277 (* 1 = 0.671277 loss)
I0312 17:56:47.061437  1600 sgd_solver.cpp:106] Iteration 112000, lr = 0.001
I0312 17:56:56.290148  1600 solver.cpp:228] Iteration 112100, loss = 0.717892
I0312 17:56:56.290148  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:56:56.290148  1600 solver.cpp:244]     Train net output #1: loss = 0.717892 (* 1 = 0.717892 loss)
I0312 17:56:56.290148  1600 sgd_solver.cpp:106] Iteration 112100, lr = 0.001
I0312 17:57:05.396476  1600 solver.cpp:228] Iteration 112200, loss = 0.601335
I0312 17:57:05.396476  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:57:05.396476  1600 solver.cpp:244]     Train net output #1: loss = 0.601335 (* 1 = 0.601335 loss)
I0312 17:57:05.396476  1600 sgd_solver.cpp:106] Iteration 112200, lr = 0.001
I0312 17:57:14.436715  1600 solver.cpp:228] Iteration 112300, loss = 0.767139
I0312 17:57:14.436715  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 17:57:14.436715  1600 solver.cpp:244]     Train net output #1: loss = 0.767139 (* 1 = 0.767139 loss)
I0312 17:57:14.436715  1600 sgd_solver.cpp:106] Iteration 112300, lr = 0.001
I0312 17:57:23.415216  1600 solver.cpp:228] Iteration 112400, loss = 0.727803
I0312 17:57:23.415216  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:57:23.415216  1600 solver.cpp:244]     Train net output #1: loss = 0.727803 (* 1 = 0.727803 loss)
I0312 17:57:23.415216  1600 sgd_solver.cpp:106] Iteration 112400, lr = 0.001
I0312 17:57:32.548761  1600 solver.cpp:228] Iteration 112500, loss = 0.664896
I0312 17:57:32.548761  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:57:32.548761  1600 solver.cpp:244]     Train net output #1: loss = 0.664895 (* 1 = 0.664895 loss)
I0312 17:57:32.548761  1600 sgd_solver.cpp:106] Iteration 112500, lr = 0.001
I0312 17:57:41.687320  1600 solver.cpp:228] Iteration 112600, loss = 0.696342
I0312 17:57:41.687320  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 17:57:41.687811  1600 solver.cpp:244]     Train net output #1: loss = 0.696342 (* 1 = 0.696342 loss)
I0312 17:57:41.687811  1600 sgd_solver.cpp:106] Iteration 112600, lr = 0.001
I0312 17:57:50.884116  1600 solver.cpp:228] Iteration 112700, loss = 0.489623
I0312 17:57:50.884116  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:57:50.884116  1600 solver.cpp:244]     Train net output #1: loss = 0.489623 (* 1 = 0.489623 loss)
I0312 17:57:50.884116  1600 sgd_solver.cpp:106] Iteration 112700, lr = 0.001
I0312 17:58:00.066226  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_112800.caffemodel
I0312 17:58:00.095723  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_112800.solverstate
I0312 17:58:00.100723  1600 solver.cpp:337] Iteration 112800, Testing net (#0)
I0312 17:58:00.100723  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:58:03.723305  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6264
I0312 17:58:03.723305  1600 solver.cpp:404]     Test net output #1: loss = 1.59536 (* 1 = 1.59536 loss)
I0312 17:58:03.753301  1600 solver.cpp:228] Iteration 112800, loss = 0.352804
I0312 17:58:03.753301  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.921875
I0312 17:58:03.753301  1600 solver.cpp:244]     Train net output #1: loss = 0.352804 (* 1 = 0.352804 loss)
I0312 17:58:03.753301  1600 sgd_solver.cpp:106] Iteration 112800, lr = 0.001
I0312 17:58:12.788295  1600 solver.cpp:228] Iteration 112900, loss = 0.578423
I0312 17:58:12.788295  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:58:12.788295  1600 solver.cpp:244]     Train net output #1: loss = 0.578423 (* 1 = 0.578423 loss)
I0312 17:58:12.788295  1600 sgd_solver.cpp:106] Iteration 112900, lr = 0.001
I0312 17:58:21.885958  1600 solver.cpp:228] Iteration 113000, loss = 0.413048
I0312 17:58:21.885958  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:58:21.885958  1600 solver.cpp:244]     Train net output #1: loss = 0.413048 (* 1 = 0.413048 loss)
I0312 17:58:21.885958  1600 sgd_solver.cpp:106] Iteration 113000, lr = 0.001
I0312 17:58:31.080935  1600 solver.cpp:228] Iteration 113100, loss = 0.494815
I0312 17:58:31.080935  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 17:58:31.080935  1600 solver.cpp:244]     Train net output #1: loss = 0.494814 (* 1 = 0.494814 loss)
I0312 17:58:31.080935  1600 sgd_solver.cpp:106] Iteration 113100, lr = 0.001
I0312 17:58:38.522317  1600 solver.cpp:228] Iteration 113200, loss = 0.434293
I0312 17:58:38.522817  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 17:58:38.522817  1600 solver.cpp:244]     Train net output #1: loss = 0.434293 (* 1 = 0.434293 loss)
I0312 17:58:38.522817  1600 sgd_solver.cpp:106] Iteration 113200, lr = 0.001
I0312 17:58:44.371621  1600 solver.cpp:228] Iteration 113300, loss = 0.455797
I0312 17:58:44.371621  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 17:58:44.371621  1600 solver.cpp:244]     Train net output #1: loss = 0.455797 (* 1 = 0.455797 loss)
I0312 17:58:44.371621  1600 sgd_solver.cpp:106] Iteration 113300, lr = 0.001
I0312 17:58:50.183118  1600 solver.cpp:228] Iteration 113400, loss = 0.514027
I0312 17:58:50.183118  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:58:50.183118  1600 solver.cpp:244]     Train net output #1: loss = 0.514027 (* 1 = 0.514027 loss)
I0312 17:58:50.183118  1600 sgd_solver.cpp:106] Iteration 113400, lr = 0.001
I0312 17:58:57.747437  1600 solver.cpp:228] Iteration 113500, loss = 0.578899
I0312 17:58:57.747437  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 17:58:57.747437  1600 solver.cpp:244]     Train net output #1: loss = 0.578899 (* 1 = 0.578899 loss)
I0312 17:58:57.747437  1600 sgd_solver.cpp:106] Iteration 113500, lr = 0.001
I0312 17:59:06.817348  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_113600.caffemodel
I0312 17:59:06.832823  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_113600.solverstate
I0312 17:59:06.837822  1600 solver.cpp:337] Iteration 113600, Testing net (#0)
I0312 17:59:06.837822  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 17:59:10.577934  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6281
I0312 17:59:10.577934  1600 solver.cpp:404]     Test net output #1: loss = 1.60041 (* 1 = 1.60041 loss)
I0312 17:59:10.607924  1600 solver.cpp:228] Iteration 113600, loss = 0.663437
I0312 17:59:10.607924  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:59:10.607924  1600 solver.cpp:244]     Train net output #1: loss = 0.663437 (* 1 = 0.663437 loss)
I0312 17:59:10.607924  1600 sgd_solver.cpp:106] Iteration 113600, lr = 0.001
I0312 17:59:19.762562  1600 solver.cpp:228] Iteration 113700, loss = 0.651845
I0312 17:59:19.763063  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:59:19.763063  1600 solver.cpp:244]     Train net output #1: loss = 0.651845 (* 1 = 0.651845 loss)
I0312 17:59:19.763063  1600 sgd_solver.cpp:106] Iteration 113700, lr = 0.001
I0312 17:59:28.991425  1600 solver.cpp:228] Iteration 113800, loss = 0.529087
I0312 17:59:28.991425  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 17:59:28.991425  1600 solver.cpp:244]     Train net output #1: loss = 0.529087 (* 1 = 0.529087 loss)
I0312 17:59:28.991425  1600 sgd_solver.cpp:106] Iteration 113800, lr = 0.001
I0312 17:59:37.968066  1600 solver.cpp:228] Iteration 113900, loss = 0.678931
I0312 17:59:37.968066  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 17:59:37.968066  1600 solver.cpp:244]     Train net output #1: loss = 0.678931 (* 1 = 0.678931 loss)
I0312 17:59:37.968066  1600 sgd_solver.cpp:106] Iteration 113900, lr = 0.001
I0312 17:59:47.266157  1600 solver.cpp:228] Iteration 114000, loss = 0.463661
I0312 17:59:47.266157  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 17:59:47.266157  1600 solver.cpp:244]     Train net output #1: loss = 0.463661 (* 1 = 0.463661 loss)
I0312 17:59:47.266157  1600 sgd_solver.cpp:106] Iteration 114000, lr = 0.001
I0312 17:59:56.220346  1600 solver.cpp:228] Iteration 114100, loss = 1.0076
I0312 17:59:56.220346  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 17:59:56.220346  1600 solver.cpp:244]     Train net output #1: loss = 1.0076 (* 1 = 1.0076 loss)
I0312 17:59:56.220346  1600 sgd_solver.cpp:106] Iteration 114100, lr = 0.001
I0312 18:00:05.323166  1600 solver.cpp:228] Iteration 114200, loss = 1.2308
I0312 18:00:05.323166  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.65625
I0312 18:00:05.323166  1600 solver.cpp:244]     Train net output #1: loss = 1.2308 (* 1 = 1.2308 loss)
I0312 18:00:05.323166  1600 sgd_solver.cpp:106] Iteration 114200, lr = 0.001
I0312 18:00:14.351670  1600 solver.cpp:228] Iteration 114300, loss = 0.475723
I0312 18:00:14.351670  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:00:14.351670  1600 solver.cpp:244]     Train net output #1: loss = 0.475722 (* 1 = 0.475722 loss)
I0312 18:00:14.351670  1600 sgd_solver.cpp:106] Iteration 114300, lr = 0.001
I0312 18:00:23.392725  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_114400.caffemodel
I0312 18:00:23.421222  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_114400.solverstate
I0312 18:00:23.426723  1600 solver.cpp:337] Iteration 114400, Testing net (#0)
I0312 18:00:23.426723  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:00:27.173321  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6268
I0312 18:00:27.173321  1600 solver.cpp:404]     Test net output #1: loss = 1.59922 (* 1 = 1.59922 loss)
I0312 18:00:27.213321  1600 solver.cpp:228] Iteration 114400, loss = 0.717737
I0312 18:00:27.213321  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:00:27.213321  1600 solver.cpp:244]     Train net output #1: loss = 0.717737 (* 1 = 0.717737 loss)
I0312 18:00:27.213321  1600 sgd_solver.cpp:106] Iteration 114400, lr = 0.001
I0312 18:00:36.495553  1600 solver.cpp:228] Iteration 114500, loss = 0.704999
I0312 18:00:36.495553  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:00:36.495553  1600 solver.cpp:244]     Train net output #1: loss = 0.704999 (* 1 = 0.704999 loss)
I0312 18:00:36.495553  1600 sgd_solver.cpp:106] Iteration 114500, lr = 0.001
I0312 18:00:45.571758  1600 solver.cpp:228] Iteration 114600, loss = 0.589541
I0312 18:00:45.572257  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:00:45.572257  1600 solver.cpp:244]     Train net output #1: loss = 0.589541 (* 1 = 0.589541 loss)
I0312 18:00:45.572257  1600 sgd_solver.cpp:106] Iteration 114600, lr = 0.001
I0312 18:00:54.759757  1600 solver.cpp:228] Iteration 114700, loss = 0.606477
I0312 18:00:54.759757  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:00:54.759757  1600 solver.cpp:244]     Train net output #1: loss = 0.606477 (* 1 = 0.606477 loss)
I0312 18:00:54.759757  1600 sgd_solver.cpp:106] Iteration 114700, lr = 0.001
I0312 18:01:03.860011  1600 solver.cpp:228] Iteration 114800, loss = 0.814249
I0312 18:01:03.860011  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:01:03.860011  1600 solver.cpp:244]     Train net output #1: loss = 0.814249 (* 1 = 0.814249 loss)
I0312 18:01:03.860011  1600 sgd_solver.cpp:106] Iteration 114800, lr = 0.001
I0312 18:01:12.839946  1600 solver.cpp:228] Iteration 114900, loss = 0.560956
I0312 18:01:12.839946  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:01:12.839946  1600 solver.cpp:244]     Train net output #1: loss = 0.560956 (* 1 = 0.560956 loss)
I0312 18:01:12.839946  1600 sgd_solver.cpp:106] Iteration 114900, lr = 0.001
I0312 18:01:22.055053  1600 solver.cpp:228] Iteration 115000, loss = 0.533873
I0312 18:01:22.055053  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:01:22.055053  1600 solver.cpp:244]     Train net output #1: loss = 0.533873 (* 1 = 0.533873 loss)
I0312 18:01:22.055053  1600 sgd_solver.cpp:106] Iteration 115000, lr = 0.001
I0312 18:01:31.232595  1600 solver.cpp:228] Iteration 115100, loss = 0.669131
I0312 18:01:31.232595  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:01:31.232595  1600 solver.cpp:244]     Train net output #1: loss = 0.66913 (* 1 = 0.66913 loss)
I0312 18:01:31.232595  1600 sgd_solver.cpp:106] Iteration 115100, lr = 0.001
I0312 18:01:40.364784  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_115200.caffemodel
I0312 18:01:40.385282  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_115200.solverstate
I0312 18:01:40.390281  1600 solver.cpp:337] Iteration 115200, Testing net (#0)
I0312 18:01:40.390281  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:01:44.084338  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6296
I0312 18:01:44.084338  1600 solver.cpp:404]     Test net output #1: loss = 1.59922 (* 1 = 1.59922 loss)
I0312 18:01:44.111338  1600 solver.cpp:228] Iteration 115200, loss = 0.846556
I0312 18:01:44.111338  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:01:44.111338  1600 solver.cpp:244]     Train net output #1: loss = 0.846556 (* 1 = 0.846556 loss)
I0312 18:01:44.111338  1600 sgd_solver.cpp:106] Iteration 115200, lr = 0.001
I0312 18:01:53.266718  1600 solver.cpp:228] Iteration 115300, loss = 0.49369
I0312 18:01:53.267218  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:01:53.267218  1600 solver.cpp:244]     Train net output #1: loss = 0.49369 (* 1 = 0.49369 loss)
I0312 18:01:53.267218  1600 sgd_solver.cpp:106] Iteration 115300, lr = 0.001
I0312 18:02:02.269701  1600 solver.cpp:228] Iteration 115400, loss = 0.675208
I0312 18:02:02.270200  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:02:02.270200  1600 solver.cpp:244]     Train net output #1: loss = 0.675208 (* 1 = 0.675208 loss)
I0312 18:02:02.270200  1600 sgd_solver.cpp:106] Iteration 115400, lr = 0.001
I0312 18:02:11.425838  1600 solver.cpp:228] Iteration 115500, loss = 0.280642
I0312 18:02:11.426337  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:02:11.426337  1600 solver.cpp:244]     Train net output #1: loss = 0.280642 (* 1 = 0.280642 loss)
I0312 18:02:11.426337  1600 sgd_solver.cpp:106] Iteration 115500, lr = 0.001
I0312 18:02:20.787400  1600 solver.cpp:228] Iteration 115600, loss = 0.53387
I0312 18:02:20.787400  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:02:20.787400  1600 solver.cpp:244]     Train net output #1: loss = 0.53387 (* 1 = 0.53387 loss)
I0312 18:02:20.787400  1600 sgd_solver.cpp:106] Iteration 115600, lr = 0.001
I0312 18:02:29.840039  1600 solver.cpp:228] Iteration 115700, loss = 0.72291
I0312 18:02:29.840039  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:02:29.840039  1600 solver.cpp:244]     Train net output #1: loss = 0.72291 (* 1 = 0.72291 loss)
I0312 18:02:29.840039  1600 sgd_solver.cpp:106] Iteration 115700, lr = 0.001
I0312 18:02:39.013643  1600 solver.cpp:228] Iteration 115800, loss = 0.536019
I0312 18:02:39.013643  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:02:39.013643  1600 solver.cpp:244]     Train net output #1: loss = 0.536019 (* 1 = 0.536019 loss)
I0312 18:02:39.013643  1600 sgd_solver.cpp:106] Iteration 115800, lr = 0.001
I0312 18:02:48.181284  1600 solver.cpp:228] Iteration 115900, loss = 0.620268
I0312 18:02:48.181284  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:02:48.181784  1600 solver.cpp:244]     Train net output #1: loss = 0.620268 (* 1 = 0.620268 loss)
I0312 18:02:48.181784  1600 sgd_solver.cpp:106] Iteration 115900, lr = 0.001
I0312 18:02:57.295555  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_116000.caffemodel
I0312 18:02:57.316555  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_116000.solverstate
I0312 18:02:57.321055  1600 solver.cpp:337] Iteration 116000, Testing net (#0)
I0312 18:02:57.321555  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:03:01.001472  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6282
I0312 18:03:01.001472  1600 solver.cpp:404]     Test net output #1: loss = 1.60528 (* 1 = 1.60528 loss)
I0312 18:03:01.021487  1600 solver.cpp:228] Iteration 116000, loss = 0.4821
I0312 18:03:01.021487  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:03:01.021487  1600 solver.cpp:244]     Train net output #1: loss = 0.482099 (* 1 = 0.482099 loss)
I0312 18:03:01.021487  1600 sgd_solver.cpp:106] Iteration 116000, lr = 0.001
I0312 18:03:10.028714  1600 solver.cpp:228] Iteration 116100, loss = 0.543211
I0312 18:03:10.028714  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:03:10.028714  1600 solver.cpp:244]     Train net output #1: loss = 0.543211 (* 1 = 0.543211 loss)
I0312 18:03:10.028714  1600 sgd_solver.cpp:106] Iteration 116100, lr = 0.001
I0312 18:03:18.977494  1600 solver.cpp:228] Iteration 116200, loss = 0.537489
I0312 18:03:18.977494  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:03:18.977494  1600 solver.cpp:244]     Train net output #1: loss = 0.537488 (* 1 = 0.537488 loss)
I0312 18:03:18.977494  1600 sgd_solver.cpp:106] Iteration 116200, lr = 0.001
I0312 18:03:28.368703  1600 solver.cpp:228] Iteration 116300, loss = 0.758248
I0312 18:03:28.369209  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:03:28.369209  1600 solver.cpp:244]     Train net output #1: loss = 0.758248 (* 1 = 0.758248 loss)
I0312 18:03:28.369209  1600 sgd_solver.cpp:106] Iteration 116300, lr = 0.001
I0312 18:03:37.471797  1600 solver.cpp:228] Iteration 116400, loss = 0.841016
I0312 18:03:37.471797  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:03:37.471797  1600 solver.cpp:244]     Train net output #1: loss = 0.841015 (* 1 = 0.841015 loss)
I0312 18:03:37.471797  1600 sgd_solver.cpp:106] Iteration 116400, lr = 0.001
I0312 18:03:44.467046  1600 solver.cpp:228] Iteration 116500, loss = 0.940693
I0312 18:03:44.467046  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:03:44.467046  1600 solver.cpp:244]     Train net output #1: loss = 0.940693 (* 1 = 0.940693 loss)
I0312 18:03:44.467046  1600 sgd_solver.cpp:106] Iteration 116500, lr = 0.001
I0312 18:03:50.271834  1600 solver.cpp:228] Iteration 116600, loss = 0.537245
I0312 18:03:50.271834  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:03:50.271834  1600 solver.cpp:244]     Train net output #1: loss = 0.537245 (* 1 = 0.537245 loss)
I0312 18:03:50.271834  1600 sgd_solver.cpp:106] Iteration 116600, lr = 0.001
I0312 18:03:56.080137  1600 solver.cpp:228] Iteration 116700, loss = 0.705411
I0312 18:03:56.080137  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:03:56.080137  1600 solver.cpp:244]     Train net output #1: loss = 0.705411 (* 1 = 0.705411 loss)
I0312 18:03:56.080137  1600 sgd_solver.cpp:106] Iteration 116700, lr = 0.001
I0312 18:04:04.017446  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_116800.caffemodel
I0312 18:04:04.049965  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_116800.solverstate
I0312 18:04:04.054462  1600 solver.cpp:337] Iteration 116800, Testing net (#0)
I0312 18:04:04.054462  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:04:07.787189  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6297
I0312 18:04:07.787189  1600 solver.cpp:404]     Test net output #1: loss = 1.6028 (* 1 = 1.6028 loss)
I0312 18:04:07.807188  1600 solver.cpp:228] Iteration 116800, loss = 0.726112
I0312 18:04:07.807188  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:04:07.807188  1600 solver.cpp:244]     Train net output #1: loss = 0.726111 (* 1 = 0.726111 loss)
I0312 18:04:07.807188  1600 sgd_solver.cpp:106] Iteration 116800, lr = 0.001
I0312 18:04:16.903887  1600 solver.cpp:228] Iteration 116900, loss = 0.65014
I0312 18:04:16.903887  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:04:16.903887  1600 solver.cpp:244]     Train net output #1: loss = 0.650139 (* 1 = 0.650139 loss)
I0312 18:04:16.903887  1600 sgd_solver.cpp:106] Iteration 116900, lr = 0.001
I0312 18:04:26.175561  1600 solver.cpp:228] Iteration 117000, loss = 0.748671
I0312 18:04:26.175561  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:04:26.175561  1600 solver.cpp:244]     Train net output #1: loss = 0.748671 (* 1 = 0.748671 loss)
I0312 18:04:26.175561  1600 sgd_solver.cpp:106] Iteration 117000, lr = 0.001
I0312 18:04:35.384810  1600 solver.cpp:228] Iteration 117100, loss = 0.610914
I0312 18:04:35.384810  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:04:35.384810  1600 solver.cpp:244]     Train net output #1: loss = 0.610914 (* 1 = 0.610914 loss)
I0312 18:04:35.384810  1600 sgd_solver.cpp:106] Iteration 117100, lr = 0.001
I0312 18:04:44.712061  1600 solver.cpp:228] Iteration 117200, loss = 0.727607
I0312 18:04:44.712061  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:04:44.712061  1600 solver.cpp:244]     Train net output #1: loss = 0.727606 (* 1 = 0.727606 loss)
I0312 18:04:44.712061  1600 sgd_solver.cpp:106] Iteration 117200, lr = 0.001
I0312 18:04:53.774973  1600 solver.cpp:228] Iteration 117300, loss = 0.488201
I0312 18:04:53.774973  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:04:53.774973  1600 solver.cpp:244]     Train net output #1: loss = 0.488201 (* 1 = 0.488201 loss)
I0312 18:04:53.774973  1600 sgd_solver.cpp:106] Iteration 117300, lr = 0.001
I0312 18:05:03.191579  1600 solver.cpp:228] Iteration 117400, loss = 0.676097
I0312 18:05:03.191579  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:05:03.191579  1600 solver.cpp:244]     Train net output #1: loss = 0.676097 (* 1 = 0.676097 loss)
I0312 18:05:03.191579  1600 sgd_solver.cpp:106] Iteration 117400, lr = 0.001
I0312 18:05:12.229758  1600 solver.cpp:228] Iteration 117500, loss = 0.592448
I0312 18:05:12.229758  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:05:12.229758  1600 solver.cpp:244]     Train net output #1: loss = 0.592448 (* 1 = 0.592448 loss)
I0312 18:05:12.229758  1600 sgd_solver.cpp:106] Iteration 117500, lr = 0.001
I0312 18:05:21.252106  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_117600.caffemodel
I0312 18:05:21.267606  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_117600.solverstate
I0312 18:05:21.272605  1600 solver.cpp:337] Iteration 117600, Testing net (#0)
I0312 18:05:21.272605  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:05:24.964891  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6292
I0312 18:05:24.964891  1600 solver.cpp:404]     Test net output #1: loss = 1.60238 (* 1 = 1.60238 loss)
I0312 18:05:24.984897  1600 solver.cpp:228] Iteration 117600, loss = 0.691958
I0312 18:05:24.984897  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:05:24.984897  1600 solver.cpp:244]     Train net output #1: loss = 0.691958 (* 1 = 0.691958 loss)
I0312 18:05:24.984897  1600 sgd_solver.cpp:106] Iteration 117600, lr = 0.001
I0312 18:05:34.253026  1600 solver.cpp:228] Iteration 117700, loss = 0.55472
I0312 18:05:34.253026  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:05:34.253026  1600 solver.cpp:244]     Train net output #1: loss = 0.55472 (* 1 = 0.55472 loss)
I0312 18:05:34.253026  1600 sgd_solver.cpp:106] Iteration 117700, lr = 0.001
I0312 18:05:43.326735  1600 solver.cpp:228] Iteration 117800, loss = 0.661453
I0312 18:05:43.326735  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:05:43.326735  1600 solver.cpp:244]     Train net output #1: loss = 0.661452 (* 1 = 0.661452 loss)
I0312 18:05:43.326735  1600 sgd_solver.cpp:106] Iteration 117800, lr = 0.001
I0312 18:05:52.445442  1600 solver.cpp:228] Iteration 117900, loss = 0.662145
I0312 18:05:52.445442  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:05:52.445442  1600 solver.cpp:244]     Train net output #1: loss = 0.662144 (* 1 = 0.662144 loss)
I0312 18:05:52.445442  1600 sgd_solver.cpp:106] Iteration 117900, lr = 0.001
I0312 18:06:01.707255  1600 solver.cpp:228] Iteration 118000, loss = 0.532765
I0312 18:06:01.707255  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:06:01.707255  1600 solver.cpp:244]     Train net output #1: loss = 0.532765 (* 1 = 0.532765 loss)
I0312 18:06:01.707255  1600 sgd_solver.cpp:106] Iteration 118000, lr = 0.001
I0312 18:06:11.095351  1600 solver.cpp:228] Iteration 118100, loss = 0.451687
I0312 18:06:11.095351  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:06:11.095351  1600 solver.cpp:244]     Train net output #1: loss = 0.451687 (* 1 = 0.451687 loss)
I0312 18:06:11.095351  1600 sgd_solver.cpp:106] Iteration 118100, lr = 0.001
I0312 18:06:20.258741  1600 solver.cpp:228] Iteration 118200, loss = 0.340893
I0312 18:06:20.258741  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:06:20.258741  1600 solver.cpp:244]     Train net output #1: loss = 0.340893 (* 1 = 0.340893 loss)
I0312 18:06:20.258741  1600 sgd_solver.cpp:106] Iteration 118200, lr = 0.001
I0312 18:06:29.471298  1600 solver.cpp:228] Iteration 118300, loss = 0.439028
I0312 18:06:29.471798  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:06:29.471798  1600 solver.cpp:244]     Train net output #1: loss = 0.439028 (* 1 = 0.439028 loss)
I0312 18:06:29.471798  1600 sgd_solver.cpp:106] Iteration 118300, lr = 0.001
I0312 18:06:38.627472  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_118400.caffemodel
I0312 18:06:38.658473  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_118400.solverstate
I0312 18:06:38.662971  1600 solver.cpp:337] Iteration 118400, Testing net (#0)
I0312 18:06:38.662971  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:06:42.420563  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6266
I0312 18:06:42.420563  1600 solver.cpp:404]     Test net output #1: loss = 1.59547 (* 1 = 1.59547 loss)
I0312 18:06:42.442062  1600 solver.cpp:228] Iteration 118400, loss = 0.396214
I0312 18:06:42.442062  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:06:42.442062  1600 solver.cpp:244]     Train net output #1: loss = 0.396214 (* 1 = 0.396214 loss)
I0312 18:06:42.442062  1600 sgd_solver.cpp:106] Iteration 118400, lr = 0.001
I0312 18:06:51.596612  1600 solver.cpp:228] Iteration 118500, loss = 0.700191
I0312 18:06:51.596612  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:06:51.596612  1600 solver.cpp:244]     Train net output #1: loss = 0.700191 (* 1 = 0.700191 loss)
I0312 18:06:51.596612  1600 sgd_solver.cpp:106] Iteration 118500, lr = 0.001
I0312 18:07:00.512008  1600 solver.cpp:228] Iteration 118600, loss = 0.893113
I0312 18:07:00.512008  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:07:00.512008  1600 solver.cpp:244]     Train net output #1: loss = 0.893113 (* 1 = 0.893113 loss)
I0312 18:07:00.512008  1600 sgd_solver.cpp:106] Iteration 118600, lr = 0.001
I0312 18:07:09.699185  1600 solver.cpp:228] Iteration 118700, loss = 0.449571
I0312 18:07:09.699185  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:07:09.699185  1600 solver.cpp:244]     Train net output #1: loss = 0.449571 (* 1 = 0.449571 loss)
I0312 18:07:09.699185  1600 sgd_solver.cpp:106] Iteration 118700, lr = 0.001
I0312 18:07:18.842993  1600 solver.cpp:228] Iteration 118800, loss = 0.712705
I0312 18:07:18.842993  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:07:18.842993  1600 solver.cpp:244]     Train net output #1: loss = 0.712705 (* 1 = 0.712705 loss)
I0312 18:07:18.842993  1600 sgd_solver.cpp:106] Iteration 118800, lr = 0.001
I0312 18:07:27.993072  1600 solver.cpp:228] Iteration 118900, loss = 0.739214
I0312 18:07:27.993072  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:07:27.993072  1600 solver.cpp:244]     Train net output #1: loss = 0.739213 (* 1 = 0.739213 loss)
I0312 18:07:27.993072  1600 sgd_solver.cpp:106] Iteration 118900, lr = 0.001
I0312 18:07:37.303241  1600 solver.cpp:228] Iteration 119000, loss = 0.42128
I0312 18:07:37.303241  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:07:37.303241  1600 solver.cpp:244]     Train net output #1: loss = 0.42128 (* 1 = 0.42128 loss)
I0312 18:07:37.303241  1600 sgd_solver.cpp:106] Iteration 119000, lr = 0.001
I0312 18:07:46.573722  1600 solver.cpp:228] Iteration 119100, loss = 0.675088
I0312 18:07:46.573722  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:07:46.573722  1600 solver.cpp:244]     Train net output #1: loss = 0.675088 (* 1 = 0.675088 loss)
I0312 18:07:46.573722  1600 sgd_solver.cpp:106] Iteration 119100, lr = 0.001
I0312 18:07:55.659266  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_119200.caffemodel
I0312 18:07:55.679261  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_119200.solverstate
I0312 18:07:55.684262  1600 solver.cpp:337] Iteration 119200, Testing net (#0)
I0312 18:07:55.684262  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:07:59.404038  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6279
I0312 18:07:59.404038  1600 solver.cpp:404]     Test net output #1: loss = 1.60217 (* 1 = 1.60217 loss)
I0312 18:07:59.447671  1600 solver.cpp:228] Iteration 119200, loss = 0.695987
I0312 18:07:59.447671  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:07:59.447671  1600 solver.cpp:244]     Train net output #1: loss = 0.695987 (* 1 = 0.695987 loss)
I0312 18:07:59.447671  1600 sgd_solver.cpp:106] Iteration 119200, lr = 0.001
I0312 18:08:08.678073  1600 solver.cpp:228] Iteration 119300, loss = 0.464379
I0312 18:08:08.678073  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:08:08.678073  1600 solver.cpp:244]     Train net output #1: loss = 0.464379 (* 1 = 0.464379 loss)
I0312 18:08:08.678073  1600 sgd_solver.cpp:106] Iteration 119300, lr = 0.001
I0312 18:08:17.791031  1600 solver.cpp:228] Iteration 119400, loss = 0.607741
I0312 18:08:17.791031  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:08:17.791031  1600 solver.cpp:244]     Train net output #1: loss = 0.60774 (* 1 = 0.60774 loss)
I0312 18:08:17.791031  1600 sgd_solver.cpp:106] Iteration 119400, lr = 0.001
I0312 18:08:27.206478  1600 solver.cpp:228] Iteration 119500, loss = 0.518518
I0312 18:08:27.206979  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:08:27.206979  1600 solver.cpp:244]     Train net output #1: loss = 0.518518 (* 1 = 0.518518 loss)
I0312 18:08:27.206979  1600 sgd_solver.cpp:106] Iteration 119500, lr = 0.001
I0312 18:08:36.247619  1600 solver.cpp:228] Iteration 119600, loss = 0.758024
I0312 18:08:36.247619  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:08:36.247619  1600 solver.cpp:244]     Train net output #1: loss = 0.758023 (* 1 = 0.758023 loss)
I0312 18:08:36.247619  1600 sgd_solver.cpp:106] Iteration 119600, lr = 0.001
I0312 18:08:45.335850  1600 solver.cpp:228] Iteration 119700, loss = 0.791824
I0312 18:08:45.335850  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:08:45.335850  1600 solver.cpp:244]     Train net output #1: loss = 0.791823 (* 1 = 0.791823 loss)
I0312 18:08:45.335850  1600 sgd_solver.cpp:106] Iteration 119700, lr = 0.001
I0312 18:08:51.244722  1600 solver.cpp:228] Iteration 119800, loss = 0.607268
I0312 18:08:51.244722  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:08:51.244722  1600 solver.cpp:244]     Train net output #1: loss = 0.607268 (* 1 = 0.607268 loss)
I0312 18:08:51.244722  1600 sgd_solver.cpp:106] Iteration 119800, lr = 0.001
I0312 18:08:57.073035  1600 solver.cpp:228] Iteration 119900, loss = 0.788752
I0312 18:08:57.073035  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:08:57.073035  1600 solver.cpp:244]     Train net output #1: loss = 0.788752 (* 1 = 0.788752 loss)
I0312 18:08:57.073035  1600 sgd_solver.cpp:106] Iteration 119900, lr = 0.001
I0312 18:09:02.883857  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_120000.caffemodel
I0312 18:09:02.899863  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_120000.solverstate
I0312 18:09:02.905356  1600 solver.cpp:337] Iteration 120000, Testing net (#0)
I0312 18:09:02.905855  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:09:06.709059  1600 solver.cpp:404]     Test net output #0: accuracy = 0.627701
I0312 18:09:06.709059  1600 solver.cpp:404]     Test net output #1: loss = 1.60883 (* 1 = 1.60883 loss)
I0312 18:09:06.746062  1600 solver.cpp:228] Iteration 120000, loss = 0.578939
I0312 18:09:06.746062  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:09:06.746062  1600 solver.cpp:244]     Train net output #1: loss = 0.578939 (* 1 = 0.578939 loss)
I0312 18:09:06.746062  1600 sgd_solver.cpp:106] Iteration 120000, lr = 0.001
I0312 18:09:15.762866  1600 solver.cpp:228] Iteration 120100, loss = 0.738347
I0312 18:09:15.762866  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:09:15.762866  1600 solver.cpp:244]     Train net output #1: loss = 0.738347 (* 1 = 0.738347 loss)
I0312 18:09:15.762866  1600 sgd_solver.cpp:106] Iteration 120100, lr = 0.001
I0312 18:09:24.899566  1600 solver.cpp:228] Iteration 120200, loss = 0.756065
I0312 18:09:24.899566  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:09:24.900066  1600 solver.cpp:244]     Train net output #1: loss = 0.756065 (* 1 = 0.756065 loss)
I0312 18:09:24.900066  1600 sgd_solver.cpp:106] Iteration 120200, lr = 0.001
I0312 18:09:34.062958  1600 solver.cpp:228] Iteration 120300, loss = 0.86109
I0312 18:09:34.062958  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:09:34.062958  1600 solver.cpp:244]     Train net output #1: loss = 0.861089 (* 1 = 0.861089 loss)
I0312 18:09:34.062958  1600 sgd_solver.cpp:106] Iteration 120300, lr = 0.001
I0312 18:09:43.179797  1600 solver.cpp:228] Iteration 120400, loss = 0.585884
I0312 18:09:43.179797  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:09:43.179797  1600 solver.cpp:244]     Train net output #1: loss = 0.585884 (* 1 = 0.585884 loss)
I0312 18:09:43.179797  1600 sgd_solver.cpp:106] Iteration 120400, lr = 0.001
I0312 18:09:52.205415  1600 solver.cpp:228] Iteration 120500, loss = 0.7559
I0312 18:09:52.205415  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:09:52.205916  1600 solver.cpp:244]     Train net output #1: loss = 0.7559 (* 1 = 0.7559 loss)
I0312 18:09:52.205916  1600 sgd_solver.cpp:106] Iteration 120500, lr = 0.001
I0312 18:10:01.320488  1600 solver.cpp:228] Iteration 120600, loss = 0.596447
I0312 18:10:01.320488  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:10:01.320488  1600 solver.cpp:244]     Train net output #1: loss = 0.596447 (* 1 = 0.596447 loss)
I0312 18:10:01.320488  1600 sgd_solver.cpp:106] Iteration 120600, lr = 0.001
I0312 18:10:10.429729  1600 solver.cpp:228] Iteration 120700, loss = 0.612563
I0312 18:10:10.429729  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:10:10.429729  1600 solver.cpp:244]     Train net output #1: loss = 0.612562 (* 1 = 0.612562 loss)
I0312 18:10:10.429729  1600 sgd_solver.cpp:106] Iteration 120700, lr = 0.001
I0312 18:10:19.551035  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_120800.caffemodel
I0312 18:10:19.566534  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_120800.solverstate
I0312 18:10:19.571534  1600 solver.cpp:337] Iteration 120800, Testing net (#0)
I0312 18:10:19.572034  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:10:23.328277  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6304
I0312 18:10:23.328277  1600 solver.cpp:404]     Test net output #1: loss = 1.6065 (* 1 = 1.6065 loss)
I0312 18:10:23.352277  1600 solver.cpp:228] Iteration 120800, loss = 0.767276
I0312 18:10:23.352277  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:10:23.352277  1600 solver.cpp:244]     Train net output #1: loss = 0.767275 (* 1 = 0.767275 loss)
I0312 18:10:23.352277  1600 sgd_solver.cpp:106] Iteration 120800, lr = 0.001
I0312 18:10:32.636255  1600 solver.cpp:228] Iteration 120900, loss = 0.712639
I0312 18:10:32.636255  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:10:32.636754  1600 solver.cpp:244]     Train net output #1: loss = 0.712639 (* 1 = 0.712639 loss)
I0312 18:10:32.636754  1600 sgd_solver.cpp:106] Iteration 120900, lr = 0.001
I0312 18:10:41.972650  1600 solver.cpp:228] Iteration 121000, loss = 0.548589
I0312 18:10:41.972650  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:10:41.972650  1600 solver.cpp:244]     Train net output #1: loss = 0.548589 (* 1 = 0.548589 loss)
I0312 18:10:41.973150  1600 sgd_solver.cpp:106] Iteration 121000, lr = 0.001
I0312 18:10:51.162930  1600 solver.cpp:228] Iteration 121100, loss = 0.574285
I0312 18:10:51.162930  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:10:51.162930  1600 solver.cpp:244]     Train net output #1: loss = 0.574285 (* 1 = 0.574285 loss)
I0312 18:10:51.162930  1600 sgd_solver.cpp:106] Iteration 121100, lr = 0.001
I0312 18:11:00.242965  1600 solver.cpp:228] Iteration 121200, loss = 0.729279
I0312 18:11:00.242965  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:11:00.242965  1600 solver.cpp:244]     Train net output #1: loss = 0.729279 (* 1 = 0.729279 loss)
I0312 18:11:00.242965  1600 sgd_solver.cpp:106] Iteration 121200, lr = 0.001
I0312 18:11:09.531599  1600 solver.cpp:228] Iteration 121300, loss = 0.391386
I0312 18:11:09.531599  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:11:09.531599  1600 solver.cpp:244]     Train net output #1: loss = 0.391385 (* 1 = 0.391385 loss)
I0312 18:11:09.531599  1600 sgd_solver.cpp:106] Iteration 121300, lr = 0.001
I0312 18:11:18.791544  1600 solver.cpp:228] Iteration 121400, loss = 0.513286
I0312 18:11:18.791544  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:11:18.791544  1600 solver.cpp:244]     Train net output #1: loss = 0.513286 (* 1 = 0.513286 loss)
I0312 18:11:18.791544  1600 sgd_solver.cpp:106] Iteration 121400, lr = 0.001
I0312 18:11:27.855967  1600 solver.cpp:228] Iteration 121500, loss = 0.600936
I0312 18:11:27.855967  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:11:27.855967  1600 solver.cpp:244]     Train net output #1: loss = 0.600936 (* 1 = 0.600936 loss)
I0312 18:11:27.855967  1600 sgd_solver.cpp:106] Iteration 121500, lr = 0.001
I0312 18:11:37.097949  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_121600.caffemodel
I0312 18:11:37.121953  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_121600.solverstate
I0312 18:11:37.126952  1600 solver.cpp:337] Iteration 121600, Testing net (#0)
I0312 18:11:37.126952  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:11:40.889868  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6284
I0312 18:11:40.889868  1600 solver.cpp:404]     Test net output #1: loss = 1.60174 (* 1 = 1.60174 loss)
I0312 18:11:40.934866  1600 solver.cpp:228] Iteration 121600, loss = 0.527556
I0312 18:11:40.935366  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:11:40.935366  1600 solver.cpp:244]     Train net output #1: loss = 0.527556 (* 1 = 0.527556 loss)
I0312 18:11:40.935366  1600 sgd_solver.cpp:106] Iteration 121600, lr = 0.001
I0312 18:11:48.071082  1600 solver.cpp:228] Iteration 121700, loss = 0.473168
I0312 18:11:48.071082  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:11:48.071082  1600 solver.cpp:244]     Train net output #1: loss = 0.473168 (* 1 = 0.473168 loss)
I0312 18:11:48.071082  1600 sgd_solver.cpp:106] Iteration 121700, lr = 0.001
I0312 18:11:52.061296  1600 solver.cpp:228] Iteration 121800, loss = 0.531067
I0312 18:11:52.061296  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:11:52.061296  1600 solver.cpp:244]     Train net output #1: loss = 0.531067 (* 1 = 0.531067 loss)
I0312 18:11:52.061296  1600 sgd_solver.cpp:106] Iteration 121800, lr = 0.001
I0312 18:11:56.049901  1600 solver.cpp:228] Iteration 121900, loss = 0.603485
I0312 18:11:56.050402  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:11:56.050402  1600 solver.cpp:244]     Train net output #1: loss = 0.603484 (* 1 = 0.603484 loss)
I0312 18:11:56.050402  1600 sgd_solver.cpp:106] Iteration 121900, lr = 0.001
I0312 18:12:00.072572  1600 solver.cpp:228] Iteration 122000, loss = 0.514989
I0312 18:12:00.072572  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:12:00.072572  1600 solver.cpp:244]     Train net output #1: loss = 0.514989 (* 1 = 0.514989 loss)
I0312 18:12:00.072572  1600 sgd_solver.cpp:106] Iteration 122000, lr = 0.001
I0312 18:12:04.033516  1600 solver.cpp:228] Iteration 122100, loss = 0.678052
I0312 18:12:04.033516  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:12:04.033516  1600 solver.cpp:244]     Train net output #1: loss = 0.678052 (* 1 = 0.678052 loss)
I0312 18:12:04.033516  1600 sgd_solver.cpp:106] Iteration 122100, lr = 0.001
I0312 18:12:07.996178  1600 solver.cpp:228] Iteration 122200, loss = 0.489246
I0312 18:12:07.996178  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:12:07.996178  1600 solver.cpp:244]     Train net output #1: loss = 0.489246 (* 1 = 0.489246 loss)
I0312 18:12:07.996178  1600 sgd_solver.cpp:106] Iteration 122200, lr = 0.001
I0312 18:12:11.986096  1600 solver.cpp:228] Iteration 122300, loss = 0.656187
I0312 18:12:11.986096  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:12:11.986096  1600 solver.cpp:244]     Train net output #1: loss = 0.656187 (* 1 = 0.656187 loss)
I0312 18:12:11.986096  1600 sgd_solver.cpp:106] Iteration 122300, lr = 0.001
I0312 18:12:15.975118  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_122400.caffemodel
I0312 18:12:15.988620  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_122400.solverstate
I0312 18:12:15.992614  1600 solver.cpp:337] Iteration 122400, Testing net (#0)
I0312 18:12:15.992614  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:12:17.597540  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6277
I0312 18:12:17.597540  1600 solver.cpp:404]     Test net output #1: loss = 1.60062 (* 1 = 1.60062 loss)
I0312 18:12:17.617542  1600 solver.cpp:228] Iteration 122400, loss = 0.775637
I0312 18:12:17.617542  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:12:17.617542  1600 solver.cpp:244]     Train net output #1: loss = 0.775636 (* 1 = 0.775636 loss)
I0312 18:12:17.617542  1600 sgd_solver.cpp:106] Iteration 122400, lr = 0.001
I0312 18:12:21.601893  1600 solver.cpp:228] Iteration 122500, loss = 0.812645
I0312 18:12:21.601893  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:12:21.601893  1600 solver.cpp:244]     Train net output #1: loss = 0.812645 (* 1 = 0.812645 loss)
I0312 18:12:21.601893  1600 sgd_solver.cpp:106] Iteration 122500, lr = 0.001
I0312 18:12:25.573287  1600 solver.cpp:228] Iteration 122600, loss = 0.704771
I0312 18:12:25.573787  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:12:25.573787  1600 solver.cpp:244]     Train net output #1: loss = 0.704771 (* 1 = 0.704771 loss)
I0312 18:12:25.573787  1600 sgd_solver.cpp:106] Iteration 122600, lr = 0.001
I0312 18:12:29.575021  1600 solver.cpp:228] Iteration 122700, loss = 0.513383
I0312 18:12:29.575021  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:12:29.575021  1600 solver.cpp:244]     Train net output #1: loss = 0.513383 (* 1 = 0.513383 loss)
I0312 18:12:29.575021  1600 sgd_solver.cpp:106] Iteration 122700, lr = 0.001
I0312 18:12:33.590950  1600 solver.cpp:228] Iteration 122800, loss = 0.36684
I0312 18:12:33.590950  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:12:33.590950  1600 solver.cpp:244]     Train net output #1: loss = 0.36684 (* 1 = 0.36684 loss)
I0312 18:12:33.590950  1600 sgd_solver.cpp:106] Iteration 122800, lr = 0.001
I0312 18:12:37.585949  1600 solver.cpp:228] Iteration 122900, loss = 0.50073
I0312 18:12:37.585949  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:12:37.585949  1600 solver.cpp:244]     Train net output #1: loss = 0.50073 (* 1 = 0.50073 loss)
I0312 18:12:37.585949  1600 sgd_solver.cpp:106] Iteration 122900, lr = 0.001
I0312 18:12:41.607933  1600 solver.cpp:228] Iteration 123000, loss = 0.833416
I0312 18:12:41.607933  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:12:41.607933  1600 solver.cpp:244]     Train net output #1: loss = 0.833416 (* 1 = 0.833416 loss)
I0312 18:12:41.607933  1600 sgd_solver.cpp:106] Iteration 123000, lr = 0.001
I0312 18:12:45.586300  1600 solver.cpp:228] Iteration 123100, loss = 0.43133
I0312 18:12:45.586300  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:12:45.586300  1600 solver.cpp:244]     Train net output #1: loss = 0.43133 (* 1 = 0.43133 loss)
I0312 18:12:45.586300  1600 sgd_solver.cpp:106] Iteration 123100, lr = 0.001
I0312 18:12:49.527575  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_123200.caffemodel
I0312 18:12:49.539578  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_123200.solverstate
I0312 18:12:49.544072  1600 solver.cpp:337] Iteration 123200, Testing net (#0)
I0312 18:12:49.544072  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:12:51.159818  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6265
I0312 18:12:51.159818  1600 solver.cpp:404]     Test net output #1: loss = 1.60263 (* 1 = 1.60263 loss)
I0312 18:12:51.179821  1600 solver.cpp:228] Iteration 123200, loss = 0.652973
I0312 18:12:51.179821  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:12:51.179821  1600 solver.cpp:244]     Train net output #1: loss = 0.652972 (* 1 = 0.652972 loss)
I0312 18:12:51.179821  1600 sgd_solver.cpp:106] Iteration 123200, lr = 0.001
I0312 18:12:55.136322  1600 solver.cpp:228] Iteration 123300, loss = 0.717534
I0312 18:12:55.136322  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:12:55.136322  1600 solver.cpp:244]     Train net output #1: loss = 0.717534 (* 1 = 0.717534 loss)
I0312 18:12:55.136322  1600 sgd_solver.cpp:106] Iteration 123300, lr = 0.001
I0312 18:12:59.103886  1600 solver.cpp:228] Iteration 123400, loss = 0.423107
I0312 18:12:59.103886  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:12:59.103886  1600 solver.cpp:244]     Train net output #1: loss = 0.423107 (* 1 = 0.423107 loss)
I0312 18:12:59.103886  1600 sgd_solver.cpp:106] Iteration 123400, lr = 0.001
I0312 18:13:03.060775  1600 solver.cpp:228] Iteration 123500, loss = 0.674285
I0312 18:13:03.060775  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:13:03.060775  1600 solver.cpp:244]     Train net output #1: loss = 0.674285 (* 1 = 0.674285 loss)
I0312 18:13:03.060775  1600 sgd_solver.cpp:106] Iteration 123500, lr = 0.001
I0312 18:13:07.022702  1600 solver.cpp:228] Iteration 123600, loss = 0.753453
I0312 18:13:07.022702  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:13:07.022702  1600 solver.cpp:244]     Train net output #1: loss = 0.753452 (* 1 = 0.753452 loss)
I0312 18:13:07.022702  1600 sgd_solver.cpp:106] Iteration 123600, lr = 0.001
I0312 18:13:11.022652  1600 solver.cpp:228] Iteration 123700, loss = 0.479639
I0312 18:13:11.023152  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:13:11.023152  1600 solver.cpp:244]     Train net output #1: loss = 0.479639 (* 1 = 0.479639 loss)
I0312 18:13:11.023152  1600 sgd_solver.cpp:106] Iteration 123700, lr = 0.001
I0312 18:13:14.993856  1600 solver.cpp:228] Iteration 123800, loss = 0.623708
I0312 18:13:14.994356  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:13:14.994356  1600 solver.cpp:244]     Train net output #1: loss = 0.623708 (* 1 = 0.623708 loss)
I0312 18:13:14.994356  1600 sgd_solver.cpp:106] Iteration 123800, lr = 0.001
I0312 18:13:18.959535  1600 solver.cpp:228] Iteration 123900, loss = 0.427326
I0312 18:13:18.959535  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:13:18.959535  1600 solver.cpp:244]     Train net output #1: loss = 0.427326 (* 1 = 0.427326 loss)
I0312 18:13:18.959535  1600 sgd_solver.cpp:106] Iteration 123900, lr = 0.001
I0312 18:13:22.907829  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_124000.caffemodel
I0312 18:13:22.921332  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_124000.solverstate
I0312 18:13:22.925830  1600 solver.cpp:337] Iteration 124000, Testing net (#0)
I0312 18:13:22.925830  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:13:24.534179  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6267
I0312 18:13:24.534179  1600 solver.cpp:404]     Test net output #1: loss = 1.60427 (* 1 = 1.60427 loss)
I0312 18:13:24.549687  1600 solver.cpp:228] Iteration 124000, loss = 0.461918
I0312 18:13:24.549687  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:13:24.549687  1600 solver.cpp:244]     Train net output #1: loss = 0.461918 (* 1 = 0.461918 loss)
I0312 18:13:24.549687  1600 sgd_solver.cpp:106] Iteration 124000, lr = 0.001
I0312 18:13:28.513083  1600 solver.cpp:228] Iteration 124100, loss = 0.680141
I0312 18:13:28.513083  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:13:28.513083  1600 solver.cpp:244]     Train net output #1: loss = 0.68014 (* 1 = 0.68014 loss)
I0312 18:13:28.513083  1600 sgd_solver.cpp:106] Iteration 124100, lr = 0.001
I0312 18:13:32.477401  1600 solver.cpp:228] Iteration 124200, loss = 0.548956
I0312 18:13:32.477401  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:13:32.477401  1600 solver.cpp:244]     Train net output #1: loss = 0.548956 (* 1 = 0.548956 loss)
I0312 18:13:32.477901  1600 sgd_solver.cpp:106] Iteration 124200, lr = 0.001
I0312 18:13:36.446247  1600 solver.cpp:228] Iteration 124300, loss = 0.682719
I0312 18:13:36.446247  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:13:36.446247  1600 solver.cpp:244]     Train net output #1: loss = 0.682719 (* 1 = 0.682719 loss)
I0312 18:13:36.446247  1600 sgd_solver.cpp:106] Iteration 124300, lr = 0.001
I0312 18:13:40.426290  1600 solver.cpp:228] Iteration 124400, loss = 0.407103
I0312 18:13:40.426290  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:13:40.426290  1600 solver.cpp:244]     Train net output #1: loss = 0.407103 (* 1 = 0.407103 loss)
I0312 18:13:40.426290  1600 sgd_solver.cpp:106] Iteration 124400, lr = 0.001
I0312 18:13:44.418243  1600 solver.cpp:228] Iteration 124500, loss = 0.874459
I0312 18:13:44.418243  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:13:44.418243  1600 solver.cpp:244]     Train net output #1: loss = 0.874459 (* 1 = 0.874459 loss)
I0312 18:13:44.418243  1600 sgd_solver.cpp:106] Iteration 124500, lr = 0.001
I0312 18:13:48.413511  1600 solver.cpp:228] Iteration 124600, loss = 0.822876
I0312 18:13:48.413511  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:13:48.413511  1600 solver.cpp:244]     Train net output #1: loss = 0.822875 (* 1 = 0.822875 loss)
I0312 18:13:48.413511  1600 sgd_solver.cpp:106] Iteration 124600, lr = 0.001
I0312 18:13:52.391664  1600 solver.cpp:228] Iteration 124700, loss = 0.668532
I0312 18:13:52.391664  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:13:52.391664  1600 solver.cpp:244]     Train net output #1: loss = 0.668532 (* 1 = 0.668532 loss)
I0312 18:13:52.391664  1600 sgd_solver.cpp:106] Iteration 124700, lr = 0.001
I0312 18:13:56.364529  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_124800.caffemodel
I0312 18:13:56.377037  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_124800.solverstate
I0312 18:13:56.381531  1600 solver.cpp:337] Iteration 124800, Testing net (#0)
I0312 18:13:56.381531  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:13:58.001898  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6277
I0312 18:13:58.001898  1600 solver.cpp:404]     Test net output #1: loss = 1.60178 (* 1 = 1.60178 loss)
I0312 18:13:58.011904  1600 solver.cpp:228] Iteration 124800, loss = 0.701313
I0312 18:13:58.011904  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:13:58.011904  1600 solver.cpp:244]     Train net output #1: loss = 0.701313 (* 1 = 0.701313 loss)
I0312 18:13:58.011904  1600 sgd_solver.cpp:106] Iteration 124800, lr = 0.001
I0312 18:14:02.052299  1600 solver.cpp:228] Iteration 124900, loss = 0.673043
I0312 18:14:02.052299  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:14:02.052299  1600 solver.cpp:244]     Train net output #1: loss = 0.673043 (* 1 = 0.673043 loss)
I0312 18:14:02.052299  1600 sgd_solver.cpp:106] Iteration 124900, lr = 0.001
I0312 18:14:06.043354  1600 solver.cpp:228] Iteration 125000, loss = 0.553237
I0312 18:14:06.043354  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:14:06.043354  1600 solver.cpp:244]     Train net output #1: loss = 0.553237 (* 1 = 0.553237 loss)
I0312 18:14:06.043354  1600 sgd_solver.cpp:106] Iteration 125000, lr = 0.001
I0312 18:14:10.015226  1600 solver.cpp:228] Iteration 125100, loss = 0.688198
I0312 18:14:10.015226  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:14:10.015226  1600 solver.cpp:244]     Train net output #1: loss = 0.688198 (* 1 = 0.688198 loss)
I0312 18:14:10.015226  1600 sgd_solver.cpp:106] Iteration 125100, lr = 0.001
I0312 18:14:13.980033  1600 solver.cpp:228] Iteration 125200, loss = 0.451528
I0312 18:14:13.980033  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:14:13.980033  1600 solver.cpp:244]     Train net output #1: loss = 0.451527 (* 1 = 0.451527 loss)
I0312 18:14:13.980033  1600 sgd_solver.cpp:106] Iteration 125200, lr = 0.001
I0312 18:14:17.944535  1600 solver.cpp:228] Iteration 125300, loss = 0.462367
I0312 18:14:17.945034  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:14:17.945034  1600 solver.cpp:244]     Train net output #1: loss = 0.462367 (* 1 = 0.462367 loss)
I0312 18:14:17.945034  1600 sgd_solver.cpp:106] Iteration 125300, lr = 0.001
I0312 18:14:21.916218  1600 solver.cpp:228] Iteration 125400, loss = 0.536369
I0312 18:14:21.916218  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:14:21.916218  1600 solver.cpp:244]     Train net output #1: loss = 0.536369 (* 1 = 0.536369 loss)
I0312 18:14:21.916218  1600 sgd_solver.cpp:106] Iteration 125400, lr = 0.001
I0312 18:14:25.887948  1600 solver.cpp:228] Iteration 125500, loss = 0.522979
I0312 18:14:25.887948  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:14:25.887948  1600 solver.cpp:244]     Train net output #1: loss = 0.522979 (* 1 = 0.522979 loss)
I0312 18:14:25.887948  1600 sgd_solver.cpp:106] Iteration 125500, lr = 0.001
I0312 18:14:29.841435  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_125600.caffemodel
I0312 18:14:29.853443  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_125600.solverstate
I0312 18:14:29.857935  1600 solver.cpp:337] Iteration 125600, Testing net (#0)
I0312 18:14:29.857935  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:14:31.486186  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6284
I0312 18:14:31.486676  1600 solver.cpp:404]     Test net output #1: loss = 1.60529 (* 1 = 1.60529 loss)
I0312 18:14:31.495671  1600 solver.cpp:228] Iteration 125600, loss = 0.647262
I0312 18:14:31.495671  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:14:31.495671  1600 solver.cpp:244]     Train net output #1: loss = 0.647262 (* 1 = 0.647262 loss)
I0312 18:14:31.495671  1600 sgd_solver.cpp:106] Iteration 125600, lr = 0.001
I0312 18:14:35.481245  1600 solver.cpp:228] Iteration 125700, loss = 0.561333
I0312 18:14:35.481741  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:14:35.481741  1600 solver.cpp:244]     Train net output #1: loss = 0.561333 (* 1 = 0.561333 loss)
I0312 18:14:35.481741  1600 sgd_solver.cpp:106] Iteration 125700, lr = 0.001
I0312 18:14:39.439816  1600 solver.cpp:228] Iteration 125800, loss = 0.423319
I0312 18:14:39.439816  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:14:39.440325  1600 solver.cpp:244]     Train net output #1: loss = 0.423319 (* 1 = 0.423319 loss)
I0312 18:14:39.440325  1600 sgd_solver.cpp:106] Iteration 125800, lr = 0.001
I0312 18:14:43.392393  1600 solver.cpp:228] Iteration 125900, loss = 0.688177
I0312 18:14:43.392393  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:14:43.392393  1600 solver.cpp:244]     Train net output #1: loss = 0.688177 (* 1 = 0.688177 loss)
I0312 18:14:43.392393  1600 sgd_solver.cpp:106] Iteration 125900, lr = 0.001
I0312 18:14:47.337543  1600 solver.cpp:228] Iteration 126000, loss = 0.651138
I0312 18:14:47.337543  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:14:47.337543  1600 solver.cpp:244]     Train net output #1: loss = 0.651138 (* 1 = 0.651138 loss)
I0312 18:14:47.337543  1600 sgd_solver.cpp:106] Iteration 126000, lr = 0.001
I0312 18:14:51.299196  1600 solver.cpp:228] Iteration 126100, loss = 0.461321
I0312 18:14:51.299196  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:14:51.299196  1600 solver.cpp:244]     Train net output #1: loss = 0.461321 (* 1 = 0.461321 loss)
I0312 18:14:51.299196  1600 sgd_solver.cpp:106] Iteration 126100, lr = 0.001
I0312 18:14:55.258574  1600 solver.cpp:228] Iteration 126200, loss = 0.663957
I0312 18:14:55.258574  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:14:55.258574  1600 solver.cpp:244]     Train net output #1: loss = 0.663957 (* 1 = 0.663957 loss)
I0312 18:14:55.258574  1600 sgd_solver.cpp:106] Iteration 126200, lr = 0.001
I0312 18:14:59.218643  1600 solver.cpp:228] Iteration 126300, loss = 0.698623
I0312 18:14:59.218643  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:14:59.218643  1600 solver.cpp:244]     Train net output #1: loss = 0.698623 (* 1 = 0.698623 loss)
I0312 18:14:59.218643  1600 sgd_solver.cpp:106] Iteration 126300, lr = 0.001
I0312 18:15:03.164646  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_126400.caffemodel
I0312 18:15:03.177153  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_126400.solverstate
I0312 18:15:03.182653  1600 solver.cpp:337] Iteration 126400, Testing net (#0)
I0312 18:15:03.183153  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:15:04.830235  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6269
I0312 18:15:04.830235  1600 solver.cpp:404]     Test net output #1: loss = 1.60304 (* 1 = 1.60304 loss)
I0312 18:15:04.840236  1600 solver.cpp:228] Iteration 126400, loss = 0.404652
I0312 18:15:04.840236  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:15:04.840236  1600 solver.cpp:244]     Train net output #1: loss = 0.404652 (* 1 = 0.404652 loss)
I0312 18:15:04.840236  1600 sgd_solver.cpp:106] Iteration 126400, lr = 0.001
I0312 18:15:08.917245  1600 solver.cpp:228] Iteration 126500, loss = 0.400646
I0312 18:15:08.917245  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:15:08.917245  1600 solver.cpp:244]     Train net output #1: loss = 0.400646 (* 1 = 0.400646 loss)
I0312 18:15:08.917245  1600 sgd_solver.cpp:106] Iteration 126500, lr = 0.001
I0312 18:15:12.909747  1600 solver.cpp:228] Iteration 126600, loss = 0.775777
I0312 18:15:12.909747  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:15:12.909747  1600 solver.cpp:244]     Train net output #1: loss = 0.775777 (* 1 = 0.775777 loss)
I0312 18:15:12.909747  1600 sgd_solver.cpp:106] Iteration 126600, lr = 0.001
I0312 18:15:16.895733  1600 solver.cpp:228] Iteration 126700, loss = 0.919321
I0312 18:15:16.896234  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:15:16.896234  1600 solver.cpp:244]     Train net output #1: loss = 0.919321 (* 1 = 0.919321 loss)
I0312 18:15:16.896234  1600 sgd_solver.cpp:106] Iteration 126700, lr = 0.001
I0312 18:15:20.868979  1600 solver.cpp:228] Iteration 126800, loss = 0.375884
I0312 18:15:20.868979  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:15:20.868979  1600 solver.cpp:244]     Train net output #1: loss = 0.375884 (* 1 = 0.375884 loss)
I0312 18:15:20.868979  1600 sgd_solver.cpp:106] Iteration 126800, lr = 0.001
I0312 18:15:24.812381  1600 solver.cpp:228] Iteration 126900, loss = 0.538307
I0312 18:15:24.812381  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:15:24.812381  1600 solver.cpp:244]     Train net output #1: loss = 0.538307 (* 1 = 0.538307 loss)
I0312 18:15:24.812381  1600 sgd_solver.cpp:106] Iteration 126900, lr = 0.001
I0312 18:15:28.757912  1600 solver.cpp:228] Iteration 127000, loss = 0.640213
I0312 18:15:28.758412  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:15:28.758412  1600 solver.cpp:244]     Train net output #1: loss = 0.640213 (* 1 = 0.640213 loss)
I0312 18:15:28.758412  1600 sgd_solver.cpp:106] Iteration 127000, lr = 0.001
I0312 18:15:32.703306  1600 solver.cpp:228] Iteration 127100, loss = 0.708248
I0312 18:15:32.703306  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:15:32.703306  1600 solver.cpp:244]     Train net output #1: loss = 0.708248 (* 1 = 0.708248 loss)
I0312 18:15:32.703306  1600 sgd_solver.cpp:106] Iteration 127100, lr = 0.001
I0312 18:15:36.641299  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_127200.caffemodel
I0312 18:15:36.652832  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_127200.solverstate
I0312 18:15:36.657333  1600 solver.cpp:337] Iteration 127200, Testing net (#0)
I0312 18:15:36.657832  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:15:38.271467  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6263
I0312 18:15:38.271467  1600 solver.cpp:404]     Test net output #1: loss = 1.60181 (* 1 = 1.60181 loss)
I0312 18:15:38.281471  1600 solver.cpp:228] Iteration 127200, loss = 0.557155
I0312 18:15:38.281471  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:15:38.281471  1600 solver.cpp:244]     Train net output #1: loss = 0.557155 (* 1 = 0.557155 loss)
I0312 18:15:38.281471  1600 sgd_solver.cpp:106] Iteration 127200, lr = 0.001
I0312 18:15:42.237582  1600 solver.cpp:228] Iteration 127300, loss = 0.489281
I0312 18:15:42.237582  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:15:42.237582  1600 solver.cpp:244]     Train net output #1: loss = 0.489281 (* 1 = 0.489281 loss)
I0312 18:15:42.237582  1600 sgd_solver.cpp:106] Iteration 127300, lr = 0.001
I0312 18:15:46.188006  1600 solver.cpp:228] Iteration 127400, loss = 0.484405
I0312 18:15:46.188006  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:15:46.188006  1600 solver.cpp:244]     Train net output #1: loss = 0.484405 (* 1 = 0.484405 loss)
I0312 18:15:46.188006  1600 sgd_solver.cpp:106] Iteration 127400, lr = 0.001
I0312 18:15:50.127274  1600 solver.cpp:228] Iteration 127500, loss = 0.726088
I0312 18:15:50.127274  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:15:50.127274  1600 solver.cpp:244]     Train net output #1: loss = 0.726088 (* 1 = 0.726088 loss)
I0312 18:15:50.127274  1600 sgd_solver.cpp:106] Iteration 127500, lr = 0.001
I0312 18:15:54.076133  1600 solver.cpp:228] Iteration 127600, loss = 0.518689
I0312 18:15:54.076133  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:15:54.076133  1600 solver.cpp:244]     Train net output #1: loss = 0.518689 (* 1 = 0.518689 loss)
I0312 18:15:54.076133  1600 sgd_solver.cpp:106] Iteration 127600, lr = 0.001
I0312 18:15:58.025164  1600 solver.cpp:228] Iteration 127700, loss = 0.663912
I0312 18:15:58.025164  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:15:58.025164  1600 solver.cpp:244]     Train net output #1: loss = 0.663912 (* 1 = 0.663912 loss)
I0312 18:15:58.025164  1600 sgd_solver.cpp:106] Iteration 127700, lr = 0.001
I0312 18:16:01.960809  1600 solver.cpp:228] Iteration 127800, loss = 0.345671
I0312 18:16:01.960809  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.9375
I0312 18:16:01.960809  1600 solver.cpp:244]     Train net output #1: loss = 0.345671 (* 1 = 0.345671 loss)
I0312 18:16:01.960809  1600 sgd_solver.cpp:106] Iteration 127800, lr = 0.001
I0312 18:16:05.914139  1600 solver.cpp:228] Iteration 127900, loss = 0.550672
I0312 18:16:05.914139  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:16:05.914139  1600 solver.cpp:244]     Train net output #1: loss = 0.550672 (* 1 = 0.550672 loss)
I0312 18:16:05.914139  1600 sgd_solver.cpp:106] Iteration 127900, lr = 0.001
I0312 18:16:09.859782  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_128000.caffemodel
I0312 18:16:09.871804  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_128000.solverstate
I0312 18:16:09.875818  1600 solver.cpp:337] Iteration 128000, Testing net (#0)
I0312 18:16:09.875818  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:16:11.492094  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6253
I0312 18:16:11.492094  1600 solver.cpp:404]     Test net output #1: loss = 1.60282 (* 1 = 1.60282 loss)
I0312 18:16:11.502110  1600 solver.cpp:228] Iteration 128000, loss = 0.505056
I0312 18:16:11.502110  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:16:11.502110  1600 solver.cpp:244]     Train net output #1: loss = 0.505056 (* 1 = 0.505056 loss)
I0312 18:16:11.502110  1600 sgd_solver.cpp:106] Iteration 128000, lr = 0.001
I0312 18:16:15.504853  1600 solver.cpp:228] Iteration 128100, loss = 0.439876
I0312 18:16:15.504853  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:16:15.504853  1600 solver.cpp:244]     Train net output #1: loss = 0.439876 (* 1 = 0.439876 loss)
I0312 18:16:15.504853  1600 sgd_solver.cpp:106] Iteration 128100, lr = 0.001
I0312 18:16:19.512755  1600 solver.cpp:228] Iteration 128200, loss = 0.795295
I0312 18:16:19.512755  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:16:19.512755  1600 solver.cpp:244]     Train net output #1: loss = 0.795295 (* 1 = 0.795295 loss)
I0312 18:16:19.512755  1600 sgd_solver.cpp:106] Iteration 128200, lr = 0.001
I0312 18:16:23.504406  1600 solver.cpp:228] Iteration 128300, loss = 0.575907
I0312 18:16:23.504406  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:16:23.504406  1600 solver.cpp:244]     Train net output #1: loss = 0.575907 (* 1 = 0.575907 loss)
I0312 18:16:23.504406  1600 sgd_solver.cpp:106] Iteration 128300, lr = 0.001
I0312 18:16:27.561507  1600 solver.cpp:228] Iteration 128400, loss = 0.614432
I0312 18:16:27.562007  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:16:27.562007  1600 solver.cpp:244]     Train net output #1: loss = 0.614432 (* 1 = 0.614432 loss)
I0312 18:16:27.562007  1600 sgd_solver.cpp:106] Iteration 128400, lr = 0.001
I0312 18:16:31.571977  1600 solver.cpp:228] Iteration 128500, loss = 0.585979
I0312 18:16:31.571977  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:16:31.571977  1600 solver.cpp:244]     Train net output #1: loss = 0.585979 (* 1 = 0.585979 loss)
I0312 18:16:31.571977  1600 sgd_solver.cpp:106] Iteration 128500, lr = 0.001
I0312 18:16:35.547401  1600 solver.cpp:228] Iteration 128600, loss = 0.794618
I0312 18:16:35.547401  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:16:35.547401  1600 solver.cpp:244]     Train net output #1: loss = 0.794618 (* 1 = 0.794618 loss)
I0312 18:16:35.547401  1600 sgd_solver.cpp:106] Iteration 128600, lr = 0.001
I0312 18:16:39.559236  1600 solver.cpp:228] Iteration 128700, loss = 0.55467
I0312 18:16:39.559236  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:16:39.559236  1600 solver.cpp:244]     Train net output #1: loss = 0.55467 (* 1 = 0.55467 loss)
I0312 18:16:39.559236  1600 sgd_solver.cpp:106] Iteration 128700, lr = 0.001
I0312 18:16:43.520548  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_128800.caffemodel
I0312 18:16:43.533540  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_128800.solverstate
I0312 18:16:43.538040  1600 solver.cpp:337] Iteration 128800, Testing net (#0)
I0312 18:16:43.538040  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:16:45.141904  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6244
I0312 18:16:45.141904  1600 solver.cpp:404]     Test net output #1: loss = 1.60361 (* 1 = 1.60361 loss)
I0312 18:16:45.161907  1600 solver.cpp:228] Iteration 128800, loss = 0.665207
I0312 18:16:45.161907  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:16:45.161907  1600 solver.cpp:244]     Train net output #1: loss = 0.665207 (* 1 = 0.665207 loss)
I0312 18:16:45.161907  1600 sgd_solver.cpp:106] Iteration 128800, lr = 0.001
I0312 18:16:49.113766  1600 solver.cpp:228] Iteration 128900, loss = 0.7333
I0312 18:16:49.113766  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:16:49.113766  1600 solver.cpp:244]     Train net output #1: loss = 0.7333 (* 1 = 0.7333 loss)
I0312 18:16:49.113766  1600 sgd_solver.cpp:106] Iteration 128900, lr = 0.001
I0312 18:16:53.061676  1600 solver.cpp:228] Iteration 129000, loss = 0.920117
I0312 18:16:53.061676  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:16:53.061676  1600 solver.cpp:244]     Train net output #1: loss = 0.920117 (* 1 = 0.920117 loss)
I0312 18:16:53.061676  1600 sgd_solver.cpp:106] Iteration 129000, lr = 0.001
I0312 18:16:57.031949  1600 solver.cpp:228] Iteration 129100, loss = 0.46194
I0312 18:16:57.031949  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:16:57.031949  1600 solver.cpp:244]     Train net output #1: loss = 0.46194 (* 1 = 0.46194 loss)
I0312 18:16:57.031949  1600 sgd_solver.cpp:106] Iteration 129100, lr = 0.001
I0312 18:17:00.992202  1600 solver.cpp:228] Iteration 129200, loss = 0.504189
I0312 18:17:00.992202  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:17:00.992202  1600 solver.cpp:244]     Train net output #1: loss = 0.504189 (* 1 = 0.504189 loss)
I0312 18:17:00.992202  1600 sgd_solver.cpp:106] Iteration 129200, lr = 0.001
I0312 18:17:04.951048  1600 solver.cpp:228] Iteration 129300, loss = 0.563372
I0312 18:17:04.951548  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:17:04.951548  1600 solver.cpp:244]     Train net output #1: loss = 0.563372 (* 1 = 0.563372 loss)
I0312 18:17:04.951548  1600 sgd_solver.cpp:106] Iteration 129300, lr = 0.001
I0312 18:17:08.959513  1600 solver.cpp:228] Iteration 129400, loss = 0.633751
I0312 18:17:08.960013  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:17:08.960013  1600 solver.cpp:244]     Train net output #1: loss = 0.633751 (* 1 = 0.633751 loss)
I0312 18:17:08.960013  1600 sgd_solver.cpp:106] Iteration 129400, lr = 0.001
I0312 18:17:12.929394  1600 solver.cpp:228] Iteration 129500, loss = 0.584071
I0312 18:17:12.929394  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:17:12.929394  1600 solver.cpp:244]     Train net output #1: loss = 0.584071 (* 1 = 0.584071 loss)
I0312 18:17:12.929394  1600 sgd_solver.cpp:106] Iteration 129500, lr = 0.001
I0312 18:17:16.886520  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_129600.caffemodel
I0312 18:17:16.898597  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_129600.solverstate
I0312 18:17:16.903096  1600 solver.cpp:337] Iteration 129600, Testing net (#0)
I0312 18:17:16.903597  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:17:18.537997  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6254
I0312 18:17:18.537997  1600 solver.cpp:404]     Test net output #1: loss = 1.60628 (* 1 = 1.60628 loss)
I0312 18:17:18.558002  1600 solver.cpp:228] Iteration 129600, loss = 0.603645
I0312 18:17:18.558002  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:17:18.558002  1600 solver.cpp:244]     Train net output #1: loss = 0.603645 (* 1 = 0.603645 loss)
I0312 18:17:18.558002  1600 sgd_solver.cpp:106] Iteration 129600, lr = 0.001
I0312 18:17:22.689441  1600 solver.cpp:228] Iteration 129700, loss = 0.642233
I0312 18:17:22.689441  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:17:22.689441  1600 solver.cpp:244]     Train net output #1: loss = 0.642233 (* 1 = 0.642233 loss)
I0312 18:17:22.689441  1600 sgd_solver.cpp:106] Iteration 129700, lr = 0.001
I0312 18:17:26.694614  1600 solver.cpp:228] Iteration 129800, loss = 0.647005
I0312 18:17:26.694614  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:17:26.694614  1600 solver.cpp:244]     Train net output #1: loss = 0.647005 (* 1 = 0.647005 loss)
I0312 18:17:26.694614  1600 sgd_solver.cpp:106] Iteration 129800, lr = 0.001
I0312 18:17:30.637969  1600 solver.cpp:228] Iteration 129900, loss = 0.563132
I0312 18:17:30.637969  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:17:30.637969  1600 solver.cpp:244]     Train net output #1: loss = 0.563132 (* 1 = 0.563132 loss)
I0312 18:17:30.637969  1600 sgd_solver.cpp:106] Iteration 129900, lr = 0.001
I0312 18:17:34.615084  1600 solver.cpp:228] Iteration 130000, loss = 0.813979
I0312 18:17:34.615084  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:17:34.615084  1600 solver.cpp:244]     Train net output #1: loss = 0.813979 (* 1 = 0.813979 loss)
I0312 18:17:34.615084  1600 sgd_solver.cpp:106] Iteration 130000, lr = 0.001
I0312 18:17:38.606310  1600 solver.cpp:228] Iteration 130100, loss = 0.637778
I0312 18:17:38.606310  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:17:38.606310  1600 solver.cpp:244]     Train net output #1: loss = 0.637778 (* 1 = 0.637778 loss)
I0312 18:17:38.606310  1600 sgd_solver.cpp:106] Iteration 130100, lr = 0.001
I0312 18:17:42.568933  1600 solver.cpp:228] Iteration 130200, loss = 0.771846
I0312 18:17:42.568933  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:17:42.568933  1600 solver.cpp:244]     Train net output #1: loss = 0.771846 (* 1 = 0.771846 loss)
I0312 18:17:42.568933  1600 sgd_solver.cpp:106] Iteration 130200, lr = 0.001
I0312 18:17:46.526302  1600 solver.cpp:228] Iteration 130300, loss = 0.400517
I0312 18:17:46.526302  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:17:46.526302  1600 solver.cpp:244]     Train net output #1: loss = 0.400517 (* 1 = 0.400517 loss)
I0312 18:17:46.526302  1600 sgd_solver.cpp:106] Iteration 130300, lr = 0.001
I0312 18:17:50.483732  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_130400.caffemodel
I0312 18:17:50.497732  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_130400.solverstate
I0312 18:17:50.503238  1600 solver.cpp:337] Iteration 130400, Testing net (#0)
I0312 18:17:50.503238  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:17:52.259131  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6282
I0312 18:17:52.259131  1600 solver.cpp:404]     Test net output #1: loss = 1.60906 (* 1 = 1.60906 loss)
I0312 18:17:52.269140  1600 solver.cpp:228] Iteration 130400, loss = 0.548333
I0312 18:17:52.269140  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:17:52.269140  1600 solver.cpp:244]     Train net output #1: loss = 0.548333 (* 1 = 0.548333 loss)
I0312 18:17:52.269140  1600 sgd_solver.cpp:106] Iteration 130400, lr = 0.001
I0312 18:17:56.417206  1600 solver.cpp:228] Iteration 130500, loss = 0.472211
I0312 18:17:56.417206  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:17:56.417206  1600 solver.cpp:244]     Train net output #1: loss = 0.472211 (* 1 = 0.472211 loss)
I0312 18:17:56.417206  1600 sgd_solver.cpp:106] Iteration 130500, lr = 0.001
I0312 18:18:00.461132  1600 solver.cpp:228] Iteration 130600, loss = 0.477548
I0312 18:18:00.461132  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:18:00.461132  1600 solver.cpp:244]     Train net output #1: loss = 0.477548 (* 1 = 0.477548 loss)
I0312 18:18:00.461132  1600 sgd_solver.cpp:106] Iteration 130600, lr = 0.001
I0312 18:18:04.457741  1600 solver.cpp:228] Iteration 130700, loss = 0.316618
I0312 18:18:04.457741  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:18:04.457741  1600 solver.cpp:244]     Train net output #1: loss = 0.316618 (* 1 = 0.316618 loss)
I0312 18:18:04.457741  1600 sgd_solver.cpp:106] Iteration 130700, lr = 0.001
I0312 18:18:08.450050  1600 solver.cpp:228] Iteration 130800, loss = 0.387074
I0312 18:18:08.450551  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:18:08.450551  1600 solver.cpp:244]     Train net output #1: loss = 0.387075 (* 1 = 0.387075 loss)
I0312 18:18:08.450551  1600 sgd_solver.cpp:106] Iteration 130800, lr = 0.001
I0312 18:18:12.394470  1600 solver.cpp:228] Iteration 130900, loss = 0.526171
I0312 18:18:12.394470  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:18:12.394470  1600 solver.cpp:244]     Train net output #1: loss = 0.526171 (* 1 = 0.526171 loss)
I0312 18:18:12.394470  1600 sgd_solver.cpp:106] Iteration 130900, lr = 0.001
I0312 18:18:16.378425  1600 solver.cpp:228] Iteration 131000, loss = 0.687086
I0312 18:18:16.378425  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:18:16.378425  1600 solver.cpp:244]     Train net output #1: loss = 0.687086 (* 1 = 0.687086 loss)
I0312 18:18:16.378425  1600 sgd_solver.cpp:106] Iteration 131000, lr = 0.001
I0312 18:18:20.342680  1600 solver.cpp:228] Iteration 131100, loss = 0.726508
I0312 18:18:20.342680  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:18:20.342680  1600 solver.cpp:244]     Train net output #1: loss = 0.726508 (* 1 = 0.726508 loss)
I0312 18:18:20.342680  1600 sgd_solver.cpp:106] Iteration 131100, lr = 0.001
I0312 18:18:24.271283  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_131200.caffemodel
I0312 18:18:24.283774  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_131200.solverstate
I0312 18:18:24.288275  1600 solver.cpp:337] Iteration 131200, Testing net (#0)
I0312 18:18:24.288275  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:18:25.919925  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6265
I0312 18:18:25.919925  1600 solver.cpp:404]     Test net output #1: loss = 1.60715 (* 1 = 1.60715 loss)
I0312 18:18:25.937923  1600 solver.cpp:228] Iteration 131200, loss = 0.626006
I0312 18:18:25.937923  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:18:25.937923  1600 solver.cpp:244]     Train net output #1: loss = 0.626006 (* 1 = 0.626006 loss)
I0312 18:18:25.937923  1600 sgd_solver.cpp:106] Iteration 131200, lr = 0.001
I0312 18:18:30.017931  1600 solver.cpp:228] Iteration 131300, loss = 0.675717
I0312 18:18:30.017931  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:18:30.017931  1600 solver.cpp:244]     Train net output #1: loss = 0.675717 (* 1 = 0.675717 loss)
I0312 18:18:30.017931  1600 sgd_solver.cpp:106] Iteration 131300, lr = 0.001
I0312 18:18:34.093966  1600 solver.cpp:228] Iteration 131400, loss = 0.774709
I0312 18:18:34.093966  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:18:34.093966  1600 solver.cpp:244]     Train net output #1: loss = 0.774709 (* 1 = 0.774709 loss)
I0312 18:18:34.093966  1600 sgd_solver.cpp:106] Iteration 131400, lr = 0.001
I0312 18:18:38.058209  1600 solver.cpp:228] Iteration 131500, loss = 0.6128
I0312 18:18:38.058209  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:18:38.058209  1600 solver.cpp:244]     Train net output #1: loss = 0.6128 (* 1 = 0.6128 loss)
I0312 18:18:38.058209  1600 sgd_solver.cpp:106] Iteration 131500, lr = 0.001
I0312 18:18:42.018364  1600 solver.cpp:228] Iteration 131600, loss = 0.41734
I0312 18:18:42.018864  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:18:42.018864  1600 solver.cpp:244]     Train net output #1: loss = 0.417341 (* 1 = 0.417341 loss)
I0312 18:18:42.018864  1600 sgd_solver.cpp:106] Iteration 131600, lr = 0.001
I0312 18:18:45.971586  1600 solver.cpp:228] Iteration 131700, loss = 0.468774
I0312 18:18:45.971586  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:18:45.971586  1600 solver.cpp:244]     Train net output #1: loss = 0.468774 (* 1 = 0.468774 loss)
I0312 18:18:45.971586  1600 sgd_solver.cpp:106] Iteration 131700, lr = 0.001
I0312 18:18:49.924633  1600 solver.cpp:228] Iteration 131800, loss = 0.562593
I0312 18:18:49.924633  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:18:49.924633  1600 solver.cpp:244]     Train net output #1: loss = 0.562593 (* 1 = 0.562593 loss)
I0312 18:18:49.924633  1600 sgd_solver.cpp:106] Iteration 131800, lr = 0.001
I0312 18:18:53.905515  1600 solver.cpp:228] Iteration 131900, loss = 0.627065
I0312 18:18:53.905515  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:18:53.905515  1600 solver.cpp:244]     Train net output #1: loss = 0.627065 (* 1 = 0.627065 loss)
I0312 18:18:53.905515  1600 sgd_solver.cpp:106] Iteration 131900, lr = 0.001
I0312 18:18:57.831428  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_132000.caffemodel
I0312 18:18:57.842958  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_132000.solverstate
I0312 18:18:57.847458  1600 solver.cpp:337] Iteration 132000, Testing net (#0)
I0312 18:18:57.847458  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:18:59.461374  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6252
I0312 18:18:59.461374  1600 solver.cpp:404]     Test net output #1: loss = 1.60996 (* 1 = 1.60996 loss)
I0312 18:18:59.471374  1600 solver.cpp:228] Iteration 132000, loss = 0.535003
I0312 18:18:59.471374  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:18:59.471374  1600 solver.cpp:244]     Train net output #1: loss = 0.535004 (* 1 = 0.535004 loss)
I0312 18:18:59.471374  1600 sgd_solver.cpp:106] Iteration 132000, lr = 0.001
I0312 18:19:03.433751  1600 solver.cpp:228] Iteration 132100, loss = 0.865848
I0312 18:19:03.433751  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:19:03.433751  1600 solver.cpp:244]     Train net output #1: loss = 0.865848 (* 1 = 0.865848 loss)
I0312 18:19:03.433751  1600 sgd_solver.cpp:106] Iteration 132100, lr = 0.001
I0312 18:19:07.386512  1600 solver.cpp:228] Iteration 132200, loss = 0.858215
I0312 18:19:07.386512  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 18:19:07.386512  1600 solver.cpp:244]     Train net output #1: loss = 0.858215 (* 1 = 0.858215 loss)
I0312 18:19:07.386512  1600 sgd_solver.cpp:106] Iteration 132200, lr = 0.001
I0312 18:19:11.339248  1600 solver.cpp:228] Iteration 132300, loss = 0.559666
I0312 18:19:11.339248  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:19:11.339248  1600 solver.cpp:244]     Train net output #1: loss = 0.559666 (* 1 = 0.559666 loss)
I0312 18:19:11.339248  1600 sgd_solver.cpp:106] Iteration 132300, lr = 0.001
I0312 18:19:15.287509  1600 solver.cpp:228] Iteration 132400, loss = 0.811508
I0312 18:19:15.287509  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:19:15.287509  1600 solver.cpp:244]     Train net output #1: loss = 0.811508 (* 1 = 0.811508 loss)
I0312 18:19:15.287509  1600 sgd_solver.cpp:106] Iteration 132400, lr = 0.001
I0312 18:19:19.235492  1600 solver.cpp:228] Iteration 132500, loss = 0.658549
I0312 18:19:19.235492  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:19:19.235492  1600 solver.cpp:244]     Train net output #1: loss = 0.658549 (* 1 = 0.658549 loss)
I0312 18:19:19.235492  1600 sgd_solver.cpp:106] Iteration 132500, lr = 0.001
I0312 18:19:23.185603  1600 solver.cpp:228] Iteration 132600, loss = 0.985747
I0312 18:19:23.186103  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.6875
I0312 18:19:23.186103  1600 solver.cpp:244]     Train net output #1: loss = 0.985747 (* 1 = 0.985747 loss)
I0312 18:19:23.186103  1600 sgd_solver.cpp:106] Iteration 132600, lr = 0.001
I0312 18:19:27.141741  1600 solver.cpp:228] Iteration 132700, loss = 0.726141
I0312 18:19:27.141741  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:19:27.141741  1600 solver.cpp:244]     Train net output #1: loss = 0.726141 (* 1 = 0.726141 loss)
I0312 18:19:27.141741  1600 sgd_solver.cpp:106] Iteration 132700, lr = 0.001
I0312 18:19:31.075006  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_132800.caffemodel
I0312 18:19:31.086490  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_132800.solverstate
I0312 18:19:31.090490  1600 solver.cpp:337] Iteration 132800, Testing net (#0)
I0312 18:19:31.090490  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:19:32.699584  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6254
I0312 18:19:32.699584  1600 solver.cpp:404]     Test net output #1: loss = 1.60105 (* 1 = 1.60105 loss)
I0312 18:19:32.709581  1600 solver.cpp:228] Iteration 132800, loss = 0.789328
I0312 18:19:32.709581  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:19:32.709581  1600 solver.cpp:244]     Train net output #1: loss = 0.789329 (* 1 = 0.789329 loss)
I0312 18:19:32.709581  1600 sgd_solver.cpp:106] Iteration 132800, lr = 0.001
I0312 18:19:36.672622  1600 solver.cpp:228] Iteration 132900, loss = 0.766639
I0312 18:19:36.672622  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:19:36.672622  1600 solver.cpp:244]     Train net output #1: loss = 0.76664 (* 1 = 0.76664 loss)
I0312 18:19:36.672622  1600 sgd_solver.cpp:106] Iteration 132900, lr = 0.001
I0312 18:19:40.621634  1600 solver.cpp:228] Iteration 133000, loss = 0.747101
I0312 18:19:40.621634  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:19:40.621634  1600 solver.cpp:244]     Train net output #1: loss = 0.747101 (* 1 = 0.747101 loss)
I0312 18:19:40.621634  1600 sgd_solver.cpp:106] Iteration 133000, lr = 0.001
I0312 18:19:44.570502  1600 solver.cpp:228] Iteration 133100, loss = 0.392545
I0312 18:19:44.570502  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:19:44.570502  1600 solver.cpp:244]     Train net output #1: loss = 0.392545 (* 1 = 0.392545 loss)
I0312 18:19:44.570502  1600 sgd_solver.cpp:106] Iteration 133100, lr = 0.001
I0312 18:19:48.535676  1600 solver.cpp:228] Iteration 133200, loss = 0.689106
I0312 18:19:48.535676  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:19:48.535676  1600 solver.cpp:244]     Train net output #1: loss = 0.689106 (* 1 = 0.689106 loss)
I0312 18:19:48.535676  1600 sgd_solver.cpp:106] Iteration 133200, lr = 0.001
I0312 18:19:52.493489  1600 solver.cpp:228] Iteration 133300, loss = 0.655523
I0312 18:19:52.493489  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:19:52.493489  1600 solver.cpp:244]     Train net output #1: loss = 0.655523 (* 1 = 0.655523 loss)
I0312 18:19:52.493489  1600 sgd_solver.cpp:106] Iteration 133300, lr = 0.001
I0312 18:19:56.451511  1600 solver.cpp:228] Iteration 133400, loss = 0.729594
I0312 18:19:56.451511  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:19:56.451511  1600 solver.cpp:244]     Train net output #1: loss = 0.729595 (* 1 = 0.729595 loss)
I0312 18:19:56.451511  1600 sgd_solver.cpp:106] Iteration 133400, lr = 0.001
I0312 18:20:00.418733  1600 solver.cpp:228] Iteration 133500, loss = 0.562099
I0312 18:20:00.418733  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:20:00.418733  1600 solver.cpp:244]     Train net output #1: loss = 0.562099 (* 1 = 0.562099 loss)
I0312 18:20:00.418733  1600 sgd_solver.cpp:106] Iteration 133500, lr = 0.001
I0312 18:20:04.405973  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_133600.caffemodel
I0312 18:20:04.415980  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_133600.solverstate
I0312 18:20:04.428104  1600 solver.cpp:337] Iteration 133600, Testing net (#0)
I0312 18:20:04.429116  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:20:06.043308  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6273
I0312 18:20:06.043308  1600 solver.cpp:404]     Test net output #1: loss = 1.5966 (* 1 = 1.5966 loss)
I0312 18:20:06.056809  1600 solver.cpp:228] Iteration 133600, loss = 0.601536
I0312 18:20:06.056809  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:20:06.056809  1600 solver.cpp:244]     Train net output #1: loss = 0.601536 (* 1 = 0.601536 loss)
I0312 18:20:06.056809  1600 sgd_solver.cpp:106] Iteration 133600, lr = 0.001
I0312 18:20:10.020416  1600 solver.cpp:228] Iteration 133700, loss = 0.704647
I0312 18:20:10.020416  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:20:10.020416  1600 solver.cpp:244]     Train net output #1: loss = 0.704647 (* 1 = 0.704647 loss)
I0312 18:20:10.020416  1600 sgd_solver.cpp:106] Iteration 133700, lr = 0.001
I0312 18:20:13.967717  1600 solver.cpp:228] Iteration 133800, loss = 0.39345
I0312 18:20:13.967717  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:20:13.967717  1600 solver.cpp:244]     Train net output #1: loss = 0.393451 (* 1 = 0.393451 loss)
I0312 18:20:13.967717  1600 sgd_solver.cpp:106] Iteration 133800, lr = 0.001
I0312 18:20:17.916467  1600 solver.cpp:228] Iteration 133900, loss = 0.568985
I0312 18:20:17.916467  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:20:17.916467  1600 solver.cpp:244]     Train net output #1: loss = 0.568985 (* 1 = 0.568985 loss)
I0312 18:20:17.916467  1600 sgd_solver.cpp:106] Iteration 133900, lr = 0.001
I0312 18:20:21.879398  1600 solver.cpp:228] Iteration 134000, loss = 0.710708
I0312 18:20:21.879398  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:20:21.879398  1600 solver.cpp:244]     Train net output #1: loss = 0.710708 (* 1 = 0.710708 loss)
I0312 18:20:21.879398  1600 sgd_solver.cpp:106] Iteration 134000, lr = 0.001
I0312 18:20:25.871647  1600 solver.cpp:228] Iteration 134100, loss = 0.650408
I0312 18:20:25.871647  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:20:25.872158  1600 solver.cpp:244]     Train net output #1: loss = 0.650408 (* 1 = 0.650408 loss)
I0312 18:20:25.872158  1600 sgd_solver.cpp:106] Iteration 134100, lr = 0.001
I0312 18:20:29.829067  1600 solver.cpp:228] Iteration 134200, loss = 0.510398
I0312 18:20:29.829067  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:20:29.829067  1600 solver.cpp:244]     Train net output #1: loss = 0.510399 (* 1 = 0.510399 loss)
I0312 18:20:29.829067  1600 sgd_solver.cpp:106] Iteration 134200, lr = 0.001
I0312 18:20:33.804575  1600 solver.cpp:228] Iteration 134300, loss = 0.520505
I0312 18:20:33.804575  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:20:33.804575  1600 solver.cpp:244]     Train net output #1: loss = 0.520505 (* 1 = 0.520505 loss)
I0312 18:20:33.804575  1600 sgd_solver.cpp:106] Iteration 134300, lr = 0.001
I0312 18:20:37.739570  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_134400.caffemodel
I0312 18:20:37.751060  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_134400.solverstate
I0312 18:20:37.755060  1600 solver.cpp:337] Iteration 134400, Testing net (#0)
I0312 18:20:37.755561  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:20:39.375501  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6247
I0312 18:20:39.375501  1600 solver.cpp:404]     Test net output #1: loss = 1.60296 (* 1 = 1.60296 loss)
I0312 18:20:39.385501  1600 solver.cpp:228] Iteration 134400, loss = 0.773091
I0312 18:20:39.385501  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:20:39.385501  1600 solver.cpp:244]     Train net output #1: loss = 0.773091 (* 1 = 0.773091 loss)
I0312 18:20:39.385501  1600 sgd_solver.cpp:106] Iteration 134400, lr = 0.001
I0312 18:20:43.380753  1600 solver.cpp:228] Iteration 134500, loss = 0.628756
I0312 18:20:43.380753  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:20:43.380753  1600 solver.cpp:244]     Train net output #1: loss = 0.628757 (* 1 = 0.628757 loss)
I0312 18:20:43.380753  1600 sgd_solver.cpp:106] Iteration 134500, lr = 0.001
I0312 18:20:47.366288  1600 solver.cpp:228] Iteration 134600, loss = 0.558887
I0312 18:20:47.366288  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:20:47.366288  1600 solver.cpp:244]     Train net output #1: loss = 0.558888 (* 1 = 0.558888 loss)
I0312 18:20:47.366288  1600 sgd_solver.cpp:106] Iteration 134600, lr = 0.001
I0312 18:20:51.392652  1600 solver.cpp:228] Iteration 134700, loss = 0.317187
I0312 18:20:51.392652  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:20:51.392652  1600 solver.cpp:244]     Train net output #1: loss = 0.317187 (* 1 = 0.317187 loss)
I0312 18:20:51.392652  1600 sgd_solver.cpp:106] Iteration 134700, lr = 0.001
I0312 18:20:55.364598  1600 solver.cpp:228] Iteration 134800, loss = 0.590289
I0312 18:20:55.364598  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:20:55.364598  1600 solver.cpp:244]     Train net output #1: loss = 0.590289 (* 1 = 0.590289 loss)
I0312 18:20:55.364598  1600 sgd_solver.cpp:106] Iteration 134800, lr = 0.001
I0312 18:20:59.354866  1600 solver.cpp:228] Iteration 134900, loss = 0.770928
I0312 18:20:59.354866  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:20:59.354866  1600 solver.cpp:244]     Train net output #1: loss = 0.770929 (* 1 = 0.770929 loss)
I0312 18:20:59.354866  1600 sgd_solver.cpp:106] Iteration 134900, lr = 0.001
I0312 18:21:03.357018  1600 solver.cpp:228] Iteration 135000, loss = 0.766213
I0312 18:21:03.357018  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:21:03.357018  1600 solver.cpp:244]     Train net output #1: loss = 0.766213 (* 1 = 0.766213 loss)
I0312 18:21:03.357018  1600 sgd_solver.cpp:106] Iteration 135000, lr = 0.001
I0312 18:21:07.342027  1600 solver.cpp:228] Iteration 135100, loss = 0.687704
I0312 18:21:07.342027  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:21:07.342027  1600 solver.cpp:244]     Train net output #1: loss = 0.687704 (* 1 = 0.687704 loss)
I0312 18:21:07.342027  1600 sgd_solver.cpp:106] Iteration 135100, lr = 0.001
I0312 18:21:11.361764  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_135200.caffemodel
I0312 18:21:11.376265  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_135200.solverstate
I0312 18:21:11.381273  1600 solver.cpp:337] Iteration 135200, Testing net (#0)
I0312 18:21:11.381273  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:21:13.038560  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6248
I0312 18:21:13.038560  1600 solver.cpp:404]     Test net output #1: loss = 1.60338 (* 1 = 1.60338 loss)
I0312 18:21:13.058568  1600 solver.cpp:228] Iteration 135200, loss = 0.630195
I0312 18:21:13.058568  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:21:13.058568  1600 solver.cpp:244]     Train net output #1: loss = 0.630195 (* 1 = 0.630195 loss)
I0312 18:21:13.058568  1600 sgd_solver.cpp:106] Iteration 135200, lr = 0.001
I0312 18:21:17.019073  1600 solver.cpp:228] Iteration 135300, loss = 0.479343
I0312 18:21:17.019073  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:21:17.019073  1600 solver.cpp:244]     Train net output #1: loss = 0.479343 (* 1 = 0.479343 loss)
I0312 18:21:17.019073  1600 sgd_solver.cpp:106] Iteration 135300, lr = 0.001
I0312 18:21:20.966475  1600 solver.cpp:228] Iteration 135400, loss = 0.658973
I0312 18:21:20.966475  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:21:20.966475  1600 solver.cpp:244]     Train net output #1: loss = 0.658974 (* 1 = 0.658974 loss)
I0312 18:21:20.966475  1600 sgd_solver.cpp:106] Iteration 135400, lr = 0.001
I0312 18:21:24.923311  1600 solver.cpp:228] Iteration 135500, loss = 0.820424
I0312 18:21:24.923311  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:21:24.923311  1600 solver.cpp:244]     Train net output #1: loss = 0.820424 (* 1 = 0.820424 loss)
I0312 18:21:24.923311  1600 sgd_solver.cpp:106] Iteration 135500, lr = 0.001
I0312 18:21:28.871641  1600 solver.cpp:228] Iteration 135600, loss = 0.557112
I0312 18:21:28.871641  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:21:28.871641  1600 solver.cpp:244]     Train net output #1: loss = 0.557113 (* 1 = 0.557113 loss)
I0312 18:21:28.871641  1600 sgd_solver.cpp:106] Iteration 135600, lr = 0.001
I0312 18:21:32.847410  1600 solver.cpp:228] Iteration 135700, loss = 0.567687
I0312 18:21:32.847410  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:21:32.847410  1600 solver.cpp:244]     Train net output #1: loss = 0.567687 (* 1 = 0.567687 loss)
I0312 18:21:32.847410  1600 sgd_solver.cpp:106] Iteration 135700, lr = 0.001
I0312 18:21:36.842806  1600 solver.cpp:228] Iteration 135800, loss = 0.573029
I0312 18:21:36.842806  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:21:36.842806  1600 solver.cpp:244]     Train net output #1: loss = 0.573029 (* 1 = 0.573029 loss)
I0312 18:21:36.842806  1600 sgd_solver.cpp:106] Iteration 135800, lr = 0.001
I0312 18:21:40.866822  1600 solver.cpp:228] Iteration 135900, loss = 0.420308
I0312 18:21:40.866822  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:21:40.866822  1600 solver.cpp:244]     Train net output #1: loss = 0.420308 (* 1 = 0.420308 loss)
I0312 18:21:40.866822  1600 sgd_solver.cpp:106] Iteration 135900, lr = 0.001
I0312 18:21:44.888923  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_136000.caffemodel
I0312 18:21:44.900913  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_136000.solverstate
I0312 18:21:44.904913  1600 solver.cpp:337] Iteration 136000, Testing net (#0)
I0312 18:21:44.905414  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:21:46.518052  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6257
I0312 18:21:46.518052  1600 solver.cpp:404]     Test net output #1: loss = 1.60931 (* 1 = 1.60931 loss)
I0312 18:21:46.528051  1600 solver.cpp:228] Iteration 136000, loss = 0.69713
I0312 18:21:46.528051  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:21:46.528051  1600 solver.cpp:244]     Train net output #1: loss = 0.697131 (* 1 = 0.697131 loss)
I0312 18:21:46.528051  1600 sgd_solver.cpp:106] Iteration 136000, lr = 0.001
I0312 18:21:50.479573  1600 solver.cpp:228] Iteration 136100, loss = 0.622503
I0312 18:21:50.479573  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:21:50.479573  1600 solver.cpp:244]     Train net output #1: loss = 0.622504 (* 1 = 0.622504 loss)
I0312 18:21:50.479573  1600 sgd_solver.cpp:106] Iteration 136100, lr = 0.001
I0312 18:21:54.430474  1600 solver.cpp:228] Iteration 136200, loss = 0.634105
I0312 18:21:54.430474  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:21:54.430474  1600 solver.cpp:244]     Train net output #1: loss = 0.634105 (* 1 = 0.634105 loss)
I0312 18:21:54.430474  1600 sgd_solver.cpp:106] Iteration 136200, lr = 0.001
I0312 18:21:58.398133  1600 solver.cpp:228] Iteration 136300, loss = 0.546778
I0312 18:21:58.398133  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:21:58.398635  1600 solver.cpp:244]     Train net output #1: loss = 0.546779 (* 1 = 0.546779 loss)
I0312 18:21:58.398635  1600 sgd_solver.cpp:106] Iteration 136300, lr = 0.001
I0312 18:22:02.401945  1600 solver.cpp:228] Iteration 136400, loss = 0.44691
I0312 18:22:02.401945  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:22:02.401945  1600 solver.cpp:244]     Train net output #1: loss = 0.44691 (* 1 = 0.44691 loss)
I0312 18:22:02.401945  1600 sgd_solver.cpp:106] Iteration 136400, lr = 0.001
I0312 18:22:06.407016  1600 solver.cpp:228] Iteration 136500, loss = 0.326877
I0312 18:22:06.407016  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:22:06.407016  1600 solver.cpp:244]     Train net output #1: loss = 0.326877 (* 1 = 0.326877 loss)
I0312 18:22:06.407016  1600 sgd_solver.cpp:106] Iteration 136500, lr = 0.001
I0312 18:22:10.353416  1600 solver.cpp:228] Iteration 136600, loss = 0.71911
I0312 18:22:10.353416  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:22:10.353416  1600 solver.cpp:244]     Train net output #1: loss = 0.719111 (* 1 = 0.719111 loss)
I0312 18:22:10.353416  1600 sgd_solver.cpp:106] Iteration 136600, lr = 0.001
I0312 18:22:14.338521  1600 solver.cpp:228] Iteration 136700, loss = 0.712906
I0312 18:22:14.338521  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:22:14.338521  1600 solver.cpp:244]     Train net output #1: loss = 0.712907 (* 1 = 0.712907 loss)
I0312 18:22:14.338521  1600 sgd_solver.cpp:106] Iteration 136700, lr = 0.001
I0312 18:22:18.422734  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_136800.caffemodel
I0312 18:22:18.435732  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_136800.solverstate
I0312 18:22:18.440732  1600 solver.cpp:337] Iteration 136800, Testing net (#0)
I0312 18:22:18.440732  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:22:20.070547  1600 solver.cpp:404]     Test net output #0: accuracy = 0.627
I0312 18:22:20.070547  1600 solver.cpp:404]     Test net output #1: loss = 1.60886 (* 1 = 1.60886 loss)
I0312 18:22:20.090555  1600 solver.cpp:228] Iteration 136800, loss = 0.617124
I0312 18:22:20.090555  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:22:20.090555  1600 solver.cpp:244]     Train net output #1: loss = 0.617125 (* 1 = 0.617125 loss)
I0312 18:22:20.090555  1600 sgd_solver.cpp:106] Iteration 136800, lr = 0.001
I0312 18:22:24.040712  1600 solver.cpp:228] Iteration 136900, loss = 0.429546
I0312 18:22:24.040712  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:22:24.040712  1600 solver.cpp:244]     Train net output #1: loss = 0.429547 (* 1 = 0.429547 loss)
I0312 18:22:24.040712  1600 sgd_solver.cpp:106] Iteration 136900, lr = 0.001
I0312 18:22:28.008662  1600 solver.cpp:228] Iteration 137000, loss = 0.735367
I0312 18:22:28.008662  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:22:28.008662  1600 solver.cpp:244]     Train net output #1: loss = 0.735368 (* 1 = 0.735368 loss)
I0312 18:22:28.008662  1600 sgd_solver.cpp:106] Iteration 137000, lr = 0.001
I0312 18:22:31.993674  1600 solver.cpp:228] Iteration 137100, loss = 0.84819
I0312 18:22:31.993674  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:22:31.993674  1600 solver.cpp:244]     Train net output #1: loss = 0.848191 (* 1 = 0.848191 loss)
I0312 18:22:31.993674  1600 sgd_solver.cpp:106] Iteration 137100, lr = 0.001
I0312 18:22:35.970047  1600 solver.cpp:228] Iteration 137200, loss = 0.530794
I0312 18:22:35.970047  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:22:35.970047  1600 solver.cpp:244]     Train net output #1: loss = 0.530795 (* 1 = 0.530795 loss)
I0312 18:22:35.970047  1600 sgd_solver.cpp:106] Iteration 137200, lr = 0.001
I0312 18:22:39.937100  1600 solver.cpp:228] Iteration 137300, loss = 0.773512
I0312 18:22:39.937100  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:22:39.937100  1600 solver.cpp:244]     Train net output #1: loss = 0.773513 (* 1 = 0.773513 loss)
I0312 18:22:39.937100  1600 sgd_solver.cpp:106] Iteration 137300, lr = 0.001
I0312 18:22:43.918294  1600 solver.cpp:228] Iteration 137400, loss = 0.597982
I0312 18:22:43.918294  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:22:43.918294  1600 solver.cpp:244]     Train net output #1: loss = 0.597983 (* 1 = 0.597983 loss)
I0312 18:22:43.918294  1600 sgd_solver.cpp:106] Iteration 137400, lr = 0.001
I0312 18:22:47.937265  1600 solver.cpp:228] Iteration 137500, loss = 0.482991
I0312 18:22:47.937265  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:22:47.937265  1600 solver.cpp:244]     Train net output #1: loss = 0.482992 (* 1 = 0.482992 loss)
I0312 18:22:47.937265  1600 sgd_solver.cpp:106] Iteration 137500, lr = 0.001
I0312 18:22:51.891372  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_137600.caffemodel
I0312 18:22:51.901373  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_137600.solverstate
I0312 18:22:51.911375  1600 solver.cpp:337] Iteration 137600, Testing net (#0)
I0312 18:22:51.911375  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:22:53.542846  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6258
I0312 18:22:53.542846  1600 solver.cpp:404]     Test net output #1: loss = 1.60765 (* 1 = 1.60765 loss)
I0312 18:22:53.564860  1600 solver.cpp:228] Iteration 137600, loss = 0.768775
I0312 18:22:53.564860  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:22:53.564860  1600 solver.cpp:244]     Train net output #1: loss = 0.768775 (* 1 = 0.768775 loss)
I0312 18:22:53.565356  1600 sgd_solver.cpp:106] Iteration 137600, lr = 0.001
I0312 18:22:57.542948  1600 solver.cpp:228] Iteration 137700, loss = 0.450859
I0312 18:22:57.543447  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:22:57.543447  1600 solver.cpp:244]     Train net output #1: loss = 0.45086 (* 1 = 0.45086 loss)
I0312 18:22:57.543447  1600 sgd_solver.cpp:106] Iteration 137700, lr = 0.001
I0312 18:23:01.556627  1600 solver.cpp:228] Iteration 137800, loss = 0.381218
I0312 18:23:01.556627  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:23:01.556627  1600 solver.cpp:244]     Train net output #1: loss = 0.381219 (* 1 = 0.381219 loss)
I0312 18:23:01.556627  1600 sgd_solver.cpp:106] Iteration 137800, lr = 0.001
I0312 18:23:05.591862  1600 solver.cpp:228] Iteration 137900, loss = 0.615709
I0312 18:23:05.591862  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:23:05.591862  1600 solver.cpp:244]     Train net output #1: loss = 0.615709 (* 1 = 0.615709 loss)
I0312 18:23:05.591862  1600 sgd_solver.cpp:106] Iteration 137900, lr = 0.001
I0312 18:23:09.576537  1600 solver.cpp:228] Iteration 138000, loss = 0.571345
I0312 18:23:09.576537  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:23:09.576537  1600 solver.cpp:244]     Train net output #1: loss = 0.571346 (* 1 = 0.571346 loss)
I0312 18:23:09.576537  1600 sgd_solver.cpp:106] Iteration 138000, lr = 0.001
I0312 18:23:13.650089  1600 solver.cpp:228] Iteration 138100, loss = 0.424349
I0312 18:23:13.650089  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:23:13.650089  1600 solver.cpp:244]     Train net output #1: loss = 0.424349 (* 1 = 0.424349 loss)
I0312 18:23:13.650089  1600 sgd_solver.cpp:106] Iteration 138100, lr = 0.001
I0312 18:23:17.627218  1600 solver.cpp:228] Iteration 138200, loss = 0.532125
I0312 18:23:17.627218  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:23:17.627218  1600 solver.cpp:244]     Train net output #1: loss = 0.532126 (* 1 = 0.532126 loss)
I0312 18:23:17.627712  1600 sgd_solver.cpp:106] Iteration 138200, lr = 0.001
I0312 18:23:21.585273  1600 solver.cpp:228] Iteration 138300, loss = 0.432211
I0312 18:23:21.585273  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:23:21.585273  1600 solver.cpp:244]     Train net output #1: loss = 0.432211 (* 1 = 0.432211 loss)
I0312 18:23:21.585273  1600 sgd_solver.cpp:106] Iteration 138300, lr = 0.001
I0312 18:23:25.525151  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_138400.caffemodel
I0312 18:23:25.537189  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_138400.solverstate
I0312 18:23:25.541708  1600 solver.cpp:337] Iteration 138400, Testing net (#0)
I0312 18:23:25.541708  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:23:27.152431  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6272
I0312 18:23:27.152431  1600 solver.cpp:404]     Test net output #1: loss = 1.60412 (* 1 = 1.60412 loss)
I0312 18:23:27.172430  1600 solver.cpp:228] Iteration 138400, loss = 0.477032
I0312 18:23:27.172430  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:23:27.172430  1600 solver.cpp:244]     Train net output #1: loss = 0.477032 (* 1 = 0.477032 loss)
I0312 18:23:27.172430  1600 sgd_solver.cpp:106] Iteration 138400, lr = 0.001
I0312 18:23:31.129787  1600 solver.cpp:228] Iteration 138500, loss = 0.615699
I0312 18:23:31.129787  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:23:31.129787  1600 solver.cpp:244]     Train net output #1: loss = 0.6157 (* 1 = 0.6157 loss)
I0312 18:23:31.129787  1600 sgd_solver.cpp:106] Iteration 138500, lr = 0.001
I0312 18:23:35.145470  1600 solver.cpp:228] Iteration 138600, loss = 0.646765
I0312 18:23:35.145470  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:23:35.145470  1600 solver.cpp:244]     Train net output #1: loss = 0.646766 (* 1 = 0.646766 loss)
I0312 18:23:35.145470  1600 sgd_solver.cpp:106] Iteration 138600, lr = 0.001
I0312 18:23:39.114440  1600 solver.cpp:228] Iteration 138700, loss = 0.682271
I0312 18:23:39.114440  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:23:39.114440  1600 solver.cpp:244]     Train net output #1: loss = 0.682271 (* 1 = 0.682271 loss)
I0312 18:23:39.114440  1600 sgd_solver.cpp:106] Iteration 138700, lr = 0.001
I0312 18:23:43.097913  1600 solver.cpp:228] Iteration 138800, loss = 0.553408
I0312 18:23:43.097913  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:23:43.097913  1600 solver.cpp:244]     Train net output #1: loss = 0.553409 (* 1 = 0.553409 loss)
I0312 18:23:43.097913  1600 sgd_solver.cpp:106] Iteration 138800, lr = 0.001
I0312 18:23:47.078181  1600 solver.cpp:228] Iteration 138900, loss = 0.404359
I0312 18:23:47.078181  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:23:47.078181  1600 solver.cpp:244]     Train net output #1: loss = 0.40436 (* 1 = 0.40436 loss)
I0312 18:23:47.078181  1600 sgd_solver.cpp:106] Iteration 138900, lr = 0.001
I0312 18:23:51.037426  1600 solver.cpp:228] Iteration 139000, loss = 0.351076
I0312 18:23:51.037426  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:23:51.037426  1600 solver.cpp:244]     Train net output #1: loss = 0.351076 (* 1 = 0.351076 loss)
I0312 18:23:51.037426  1600 sgd_solver.cpp:106] Iteration 139000, lr = 0.001
I0312 18:23:55.022305  1600 solver.cpp:228] Iteration 139100, loss = 0.833633
I0312 18:23:55.022305  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:23:55.022305  1600 solver.cpp:244]     Train net output #1: loss = 0.833633 (* 1 = 0.833633 loss)
I0312 18:23:55.022305  1600 sgd_solver.cpp:106] Iteration 139100, lr = 0.001
I0312 18:23:59.104547  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_139200.caffemodel
I0312 18:23:59.116075  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_139200.solverstate
I0312 18:23:59.120074  1600 solver.cpp:337] Iteration 139200, Testing net (#0)
I0312 18:23:59.120074  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:24:00.803493  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6263
I0312 18:24:00.803493  1600 solver.cpp:404]     Test net output #1: loss = 1.61128 (* 1 = 1.61128 loss)
I0312 18:24:00.827023  1600 solver.cpp:228] Iteration 139200, loss = 0.916421
I0312 18:24:00.827023  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:24:00.827023  1600 solver.cpp:244]     Train net output #1: loss = 0.916422 (* 1 = 0.916422 loss)
I0312 18:24:00.827023  1600 sgd_solver.cpp:106] Iteration 139200, lr = 0.001
I0312 18:24:04.885601  1600 solver.cpp:228] Iteration 139300, loss = 0.405446
I0312 18:24:04.885601  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:24:04.885601  1600 solver.cpp:244]     Train net output #1: loss = 0.405446 (* 1 = 0.405446 loss)
I0312 18:24:04.885601  1600 sgd_solver.cpp:106] Iteration 139300, lr = 0.001
I0312 18:24:08.842675  1600 solver.cpp:228] Iteration 139400, loss = 0.560535
I0312 18:24:08.842675  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:24:08.842675  1600 solver.cpp:244]     Train net output #1: loss = 0.560536 (* 1 = 0.560536 loss)
I0312 18:24:08.842675  1600 sgd_solver.cpp:106] Iteration 139400, lr = 0.001
I0312 18:24:12.814281  1600 solver.cpp:228] Iteration 139500, loss = 0.68002
I0312 18:24:12.814281  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:24:12.814781  1600 solver.cpp:244]     Train net output #1: loss = 0.680021 (* 1 = 0.680021 loss)
I0312 18:24:12.814781  1600 sgd_solver.cpp:106] Iteration 139500, lr = 0.001
I0312 18:24:16.786418  1600 solver.cpp:228] Iteration 139600, loss = 0.475694
I0312 18:24:16.786418  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:24:16.786418  1600 solver.cpp:244]     Train net output #1: loss = 0.475694 (* 1 = 0.475694 loss)
I0312 18:24:16.786418  1600 sgd_solver.cpp:106] Iteration 139600, lr = 0.001
I0312 18:24:20.773941  1600 solver.cpp:228] Iteration 139700, loss = 0.538413
I0312 18:24:20.773941  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:24:20.773941  1600 solver.cpp:244]     Train net output #1: loss = 0.538414 (* 1 = 0.538414 loss)
I0312 18:24:20.773941  1600 sgd_solver.cpp:106] Iteration 139700, lr = 0.001
I0312 18:24:24.732210  1600 solver.cpp:228] Iteration 139800, loss = 0.577335
I0312 18:24:24.732710  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:24:24.732710  1600 solver.cpp:244]     Train net output #1: loss = 0.577336 (* 1 = 0.577336 loss)
I0312 18:24:24.732710  1600 sgd_solver.cpp:106] Iteration 139800, lr = 0.001
I0312 18:24:28.697283  1600 solver.cpp:228] Iteration 139900, loss = 0.526321
I0312 18:24:28.697283  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:24:28.697283  1600 solver.cpp:244]     Train net output #1: loss = 0.526322 (* 1 = 0.526322 loss)
I0312 18:24:28.697283  1600 sgd_solver.cpp:106] Iteration 139900, lr = 0.001
I0312 18:24:32.664654  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_140000.caffemodel
I0312 18:24:32.676143  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_140000.solverstate
I0312 18:24:32.680143  1600 solver.cpp:337] Iteration 140000, Testing net (#0)
I0312 18:24:32.680657  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:24:34.301573  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6234
I0312 18:24:34.301573  1600 solver.cpp:404]     Test net output #1: loss = 1.6121 (* 1 = 1.6121 loss)
I0312 18:24:34.311818  1600 solver.cpp:228] Iteration 140000, loss = 0.418939
I0312 18:24:34.311818  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:24:34.311818  1600 solver.cpp:244]     Train net output #1: loss = 0.41894 (* 1 = 0.41894 loss)
I0312 18:24:34.311818  1600 sgd_solver.cpp:106] Iteration 140000, lr = 0.001
I0312 18:24:38.283349  1600 solver.cpp:228] Iteration 140100, loss = 0.568962
I0312 18:24:38.283349  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:24:38.283349  1600 solver.cpp:244]     Train net output #1: loss = 0.568963 (* 1 = 0.568963 loss)
I0312 18:24:38.283349  1600 sgd_solver.cpp:106] Iteration 140100, lr = 0.001
I0312 18:24:42.244447  1600 solver.cpp:228] Iteration 140200, loss = 0.613892
I0312 18:24:42.244447  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:24:42.244447  1600 solver.cpp:244]     Train net output #1: loss = 0.613892 (* 1 = 0.613892 loss)
I0312 18:24:42.244447  1600 sgd_solver.cpp:106] Iteration 140200, lr = 0.001
I0312 18:24:46.965236  1600 solver.cpp:228] Iteration 140300, loss = 0.374934
I0312 18:24:46.965236  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:24:46.965236  1600 solver.cpp:244]     Train net output #1: loss = 0.374934 (* 1 = 0.374934 loss)
I0312 18:24:46.965236  1600 sgd_solver.cpp:106] Iteration 140300, lr = 0.001
I0312 18:24:55.845736  1600 solver.cpp:228] Iteration 140400, loss = 0.722285
I0312 18:24:55.845736  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:24:55.845736  1600 solver.cpp:244]     Train net output #1: loss = 0.722285 (* 1 = 0.722285 loss)
I0312 18:24:55.845736  1600 sgd_solver.cpp:106] Iteration 140400, lr = 0.001
I0312 18:25:03.436650  1600 solver.cpp:228] Iteration 140500, loss = 0.381155
I0312 18:25:03.436650  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:25:03.436650  1600 solver.cpp:244]     Train net output #1: loss = 0.381156 (* 1 = 0.381156 loss)
I0312 18:25:03.436650  1600 sgd_solver.cpp:106] Iteration 140500, lr = 0.001
I0312 18:25:07.414532  1600 solver.cpp:228] Iteration 140600, loss = 0.589197
I0312 18:25:07.414532  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:25:07.414532  1600 solver.cpp:244]     Train net output #1: loss = 0.589198 (* 1 = 0.589198 loss)
I0312 18:25:07.414532  1600 sgd_solver.cpp:106] Iteration 140600, lr = 0.001
I0312 18:25:11.500875  1600 solver.cpp:228] Iteration 140700, loss = 0.79457
I0312 18:25:11.500875  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:25:11.500875  1600 solver.cpp:244]     Train net output #1: loss = 0.79457 (* 1 = 0.79457 loss)
I0312 18:25:11.500875  1600 sgd_solver.cpp:106] Iteration 140700, lr = 0.001
I0312 18:25:19.553776  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_140800.caffemodel
I0312 18:25:19.577265  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_140800.solverstate
I0312 18:25:19.582265  1600 solver.cpp:337] Iteration 140800, Testing net (#0)
I0312 18:25:19.582765  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:25:23.414815  1600 solver.cpp:404]     Test net output #0: accuracy = 0.625
I0312 18:25:23.414815  1600 solver.cpp:404]     Test net output #1: loss = 1.61161 (* 1 = 1.61161 loss)
I0312 18:25:23.444826  1600 solver.cpp:228] Iteration 140800, loss = 0.619816
I0312 18:25:23.444826  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:25:23.444826  1600 solver.cpp:244]     Train net output #1: loss = 0.619816 (* 1 = 0.619816 loss)
I0312 18:25:23.444826  1600 sgd_solver.cpp:106] Iteration 140800, lr = 0.001
I0312 18:25:32.746043  1600 solver.cpp:228] Iteration 140900, loss = 0.52587
I0312 18:25:32.746544  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:25:32.746544  1600 solver.cpp:244]     Train net output #1: loss = 0.52587 (* 1 = 0.52587 loss)
I0312 18:25:32.746544  1600 sgd_solver.cpp:106] Iteration 140900, lr = 0.001
I0312 18:25:41.981766  1600 solver.cpp:228] Iteration 141000, loss = 0.448413
I0312 18:25:41.982266  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:25:41.982266  1600 solver.cpp:244]     Train net output #1: loss = 0.448414 (* 1 = 0.448414 loss)
I0312 18:25:41.982266  1600 sgd_solver.cpp:106] Iteration 141000, lr = 0.001
I0312 18:25:51.238255  1600 solver.cpp:228] Iteration 141100, loss = 0.510561
I0312 18:25:51.238754  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:25:51.238754  1600 solver.cpp:244]     Train net output #1: loss = 0.510561 (* 1 = 0.510561 loss)
I0312 18:25:51.238754  1600 sgd_solver.cpp:106] Iteration 141100, lr = 0.001
I0312 18:26:00.320216  1600 solver.cpp:228] Iteration 141200, loss = 0.632659
I0312 18:26:00.320216  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:26:00.320216  1600 solver.cpp:244]     Train net output #1: loss = 0.63266 (* 1 = 0.63266 loss)
I0312 18:26:00.320216  1600 sgd_solver.cpp:106] Iteration 141200, lr = 0.001
I0312 18:26:09.186352  1600 solver.cpp:228] Iteration 141300, loss = 0.73717
I0312 18:26:09.186352  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:26:09.186352  1600 solver.cpp:244]     Train net output #1: loss = 0.737171 (* 1 = 0.737171 loss)
I0312 18:26:09.186352  1600 sgd_solver.cpp:106] Iteration 141300, lr = 0.001
I0312 18:26:18.569371  1600 solver.cpp:228] Iteration 141400, loss = 0.743971
I0312 18:26:18.569371  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:26:18.569371  1600 solver.cpp:244]     Train net output #1: loss = 0.743971 (* 1 = 0.743971 loss)
I0312 18:26:18.569371  1600 sgd_solver.cpp:106] Iteration 141400, lr = 0.001
I0312 18:26:27.867905  1600 solver.cpp:228] Iteration 141500, loss = 0.944706
I0312 18:26:27.867905  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:26:27.868407  1600 solver.cpp:244]     Train net output #1: loss = 0.944707 (* 1 = 0.944707 loss)
I0312 18:26:27.868407  1600 sgd_solver.cpp:106] Iteration 141500, lr = 0.001
I0312 18:26:37.121989  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_141600.caffemodel
I0312 18:26:37.151494  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_141600.solverstate
I0312 18:26:37.152496  1600 solver.cpp:337] Iteration 141600, Testing net (#0)
I0312 18:26:37.152496  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:26:41.094229  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6259
I0312 18:26:41.094229  1600 solver.cpp:404]     Test net output #1: loss = 1.61591 (* 1 = 1.61591 loss)
I0312 18:26:41.122836  1600 solver.cpp:228] Iteration 141600, loss = 0.702547
I0312 18:26:41.122836  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:26:41.122836  1600 solver.cpp:244]     Train net output #1: loss = 0.702548 (* 1 = 0.702548 loss)
I0312 18:26:41.122836  1600 sgd_solver.cpp:106] Iteration 141600, lr = 0.001
I0312 18:26:50.371641  1600 solver.cpp:228] Iteration 141700, loss = 0.615406
I0312 18:26:50.371641  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:26:50.371641  1600 solver.cpp:244]     Train net output #1: loss = 0.615406 (* 1 = 0.615406 loss)
I0312 18:26:50.371641  1600 sgd_solver.cpp:106] Iteration 141700, lr = 0.001
I0312 18:26:59.571527  1600 solver.cpp:228] Iteration 141800, loss = 0.655663
I0312 18:26:59.571527  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:26:59.571527  1600 solver.cpp:244]     Train net output #1: loss = 0.655663 (* 1 = 0.655663 loss)
I0312 18:26:59.571527  1600 sgd_solver.cpp:106] Iteration 141800, lr = 0.001
I0312 18:27:08.735080  1600 solver.cpp:228] Iteration 141900, loss = 0.55609
I0312 18:27:08.735080  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:27:08.735080  1600 solver.cpp:244]     Train net output #1: loss = 0.556091 (* 1 = 0.556091 loss)
I0312 18:27:08.735080  1600 sgd_solver.cpp:106] Iteration 141900, lr = 0.001
I0312 18:27:18.149185  1600 solver.cpp:228] Iteration 142000, loss = 0.661586
I0312 18:27:18.149185  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:27:18.149185  1600 solver.cpp:244]     Train net output #1: loss = 0.661587 (* 1 = 0.661587 loss)
I0312 18:27:18.149185  1600 sgd_solver.cpp:106] Iteration 142000, lr = 0.001
I0312 18:27:27.629357  1600 solver.cpp:228] Iteration 142100, loss = 0.630525
I0312 18:27:27.629357  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:27:27.629357  1600 solver.cpp:244]     Train net output #1: loss = 0.630526 (* 1 = 0.630526 loss)
I0312 18:27:27.629357  1600 sgd_solver.cpp:106] Iteration 142100, lr = 0.001
I0312 18:27:37.024840  1600 solver.cpp:228] Iteration 142200, loss = 0.550394
I0312 18:27:37.024840  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:27:37.024840  1600 solver.cpp:244]     Train net output #1: loss = 0.550394 (* 1 = 0.550394 loss)
I0312 18:27:37.024840  1600 sgd_solver.cpp:106] Iteration 142200, lr = 0.001
I0312 18:27:46.326948  1600 solver.cpp:228] Iteration 142300, loss = 0.358988
I0312 18:27:46.326948  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:27:46.326948  1600 solver.cpp:244]     Train net output #1: loss = 0.358989 (* 1 = 0.358989 loss)
I0312 18:27:46.326948  1600 sgd_solver.cpp:106] Iteration 142300, lr = 0.001
I0312 18:27:55.087182  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_142400.caffemodel
I0312 18:27:55.116683  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_142400.solverstate
I0312 18:27:55.116683  1600 solver.cpp:337] Iteration 142400, Testing net (#0)
I0312 18:27:55.116683  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:27:59.058014  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6244
I0312 18:27:59.058014  1600 solver.cpp:404]     Test net output #1: loss = 1.61271 (* 1 = 1.61271 loss)
I0312 18:27:59.078011  1600 solver.cpp:228] Iteration 142400, loss = 0.496173
I0312 18:27:59.078011  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:27:59.078011  1600 solver.cpp:244]     Train net output #1: loss = 0.496173 (* 1 = 0.496173 loss)
I0312 18:27:59.078011  1600 sgd_solver.cpp:106] Iteration 142400, lr = 0.001
I0312 18:28:08.517719  1600 solver.cpp:228] Iteration 142500, loss = 0.587986
I0312 18:28:08.517719  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:28:08.517719  1600 solver.cpp:244]     Train net output #1: loss = 0.587987 (* 1 = 0.587987 loss)
I0312 18:28:08.517719  1600 sgd_solver.cpp:106] Iteration 142500, lr = 0.001
I0312 18:28:17.852805  1600 solver.cpp:228] Iteration 142600, loss = 0.502705
I0312 18:28:17.852805  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:28:17.852805  1600 solver.cpp:244]     Train net output #1: loss = 0.502705 (* 1 = 0.502705 loss)
I0312 18:28:17.852805  1600 sgd_solver.cpp:106] Iteration 142600, lr = 0.001
I0312 18:28:27.144158  1600 solver.cpp:228] Iteration 142700, loss = 0.740035
I0312 18:28:27.144158  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:28:27.144158  1600 solver.cpp:244]     Train net output #1: loss = 0.740036 (* 1 = 0.740036 loss)
I0312 18:28:27.144158  1600 sgd_solver.cpp:106] Iteration 142700, lr = 0.001
I0312 18:28:36.472492  1600 solver.cpp:228] Iteration 142800, loss = 0.468034
I0312 18:28:36.472492  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:28:36.472492  1600 solver.cpp:244]     Train net output #1: loss = 0.468035 (* 1 = 0.468035 loss)
I0312 18:28:36.472492  1600 sgd_solver.cpp:106] Iteration 142800, lr = 0.001
I0312 18:28:45.684638  1600 solver.cpp:228] Iteration 142900, loss = 0.472238
I0312 18:28:45.684638  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:28:45.684638  1600 solver.cpp:244]     Train net output #1: loss = 0.472239 (* 1 = 0.472239 loss)
I0312 18:28:45.684638  1600 sgd_solver.cpp:106] Iteration 142900, lr = 0.001
I0312 18:28:54.816143  1600 solver.cpp:228] Iteration 143000, loss = 0.481183
I0312 18:28:54.816143  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:28:54.816143  1600 solver.cpp:244]     Train net output #1: loss = 0.481183 (* 1 = 0.481183 loss)
I0312 18:28:54.816143  1600 sgd_solver.cpp:106] Iteration 143000, lr = 0.001
I0312 18:29:04.308329  1600 solver.cpp:228] Iteration 143100, loss = 0.546976
I0312 18:29:04.308329  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:29:04.308329  1600 solver.cpp:244]     Train net output #1: loss = 0.546977 (* 1 = 0.546977 loss)
I0312 18:29:04.308329  1600 sgd_solver.cpp:106] Iteration 143100, lr = 0.001
I0312 18:29:13.500708  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_143200.caffemodel
I0312 18:29:13.524708  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_143200.solverstate
I0312 18:29:13.529709  1600 solver.cpp:337] Iteration 143200, Testing net (#0)
I0312 18:29:13.529709  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:29:17.445113  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6244
I0312 18:29:17.446121  1600 solver.cpp:404]     Test net output #1: loss = 1.61503 (* 1 = 1.61503 loss)
I0312 18:29:17.476197  1600 solver.cpp:228] Iteration 143200, loss = 0.430224
I0312 18:29:17.476197  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:29:17.476197  1600 solver.cpp:244]     Train net output #1: loss = 0.430225 (* 1 = 0.430225 loss)
I0312 18:29:17.476197  1600 sgd_solver.cpp:106] Iteration 143200, lr = 0.001
I0312 18:29:26.931635  1600 solver.cpp:228] Iteration 143300, loss = 0.32939
I0312 18:29:26.931635  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:29:26.931635  1600 solver.cpp:244]     Train net output #1: loss = 0.329391 (* 1 = 0.329391 loss)
I0312 18:29:26.931635  1600 sgd_solver.cpp:106] Iteration 143300, lr = 0.001
I0312 18:29:36.152500  1600 solver.cpp:228] Iteration 143400, loss = 0.447335
I0312 18:29:36.153002  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:29:36.153002  1600 solver.cpp:244]     Train net output #1: loss = 0.447336 (* 1 = 0.447336 loss)
I0312 18:29:36.153002  1600 sgd_solver.cpp:106] Iteration 143400, lr = 0.001
I0312 18:29:44.945397  1600 solver.cpp:228] Iteration 143500, loss = 0.577734
I0312 18:29:44.945896  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:29:44.945896  1600 solver.cpp:244]     Train net output #1: loss = 0.577735 (* 1 = 0.577735 loss)
I0312 18:29:44.945896  1600 sgd_solver.cpp:106] Iteration 143500, lr = 0.001
I0312 18:29:54.378743  1600 solver.cpp:228] Iteration 143600, loss = 0.686432
I0312 18:29:54.378743  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:29:54.378743  1600 solver.cpp:244]     Train net output #1: loss = 0.686433 (* 1 = 0.686433 loss)
I0312 18:29:54.378743  1600 sgd_solver.cpp:106] Iteration 143600, lr = 0.001
I0312 18:30:03.710232  1600 solver.cpp:228] Iteration 143700, loss = 0.699517
I0312 18:30:03.710232  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:30:03.710232  1600 solver.cpp:244]     Train net output #1: loss = 0.699517 (* 1 = 0.699517 loss)
I0312 18:30:03.710232  1600 sgd_solver.cpp:106] Iteration 143700, lr = 0.001
I0312 18:30:13.106696  1600 solver.cpp:228] Iteration 143800, loss = 0.613497
I0312 18:30:13.106696  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:30:13.106696  1600 solver.cpp:244]     Train net output #1: loss = 0.613498 (* 1 = 0.613498 loss)
I0312 18:30:13.106696  1600 sgd_solver.cpp:106] Iteration 143800, lr = 0.001
I0312 18:30:22.469373  1600 solver.cpp:228] Iteration 143900, loss = 0.585226
I0312 18:30:22.469373  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:30:22.469373  1600 solver.cpp:244]     Train net output #1: loss = 0.585227 (* 1 = 0.585227 loss)
I0312 18:30:22.469373  1600 sgd_solver.cpp:106] Iteration 143900, lr = 0.001
I0312 18:30:31.640884  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_144000.caffemodel
I0312 18:30:31.660884  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_144000.solverstate
I0312 18:30:31.670884  1600 solver.cpp:337] Iteration 144000, Testing net (#0)
I0312 18:30:31.670884  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:30:35.392658  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6249
I0312 18:30:35.392658  1600 solver.cpp:404]     Test net output #1: loss = 1.60983 (* 1 = 1.60983 loss)
I0312 18:30:35.403663  1600 solver.cpp:228] Iteration 144000, loss = 0.622408
I0312 18:30:35.403663  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:30:35.403663  1600 solver.cpp:244]     Train net output #1: loss = 0.622409 (* 1 = 0.622409 loss)
I0312 18:30:35.403663  1600 sgd_solver.cpp:106] Iteration 144000, lr = 0.001
I0312 18:30:44.738214  1600 solver.cpp:228] Iteration 144100, loss = 0.470442
I0312 18:30:44.738214  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:30:44.738214  1600 solver.cpp:244]     Train net output #1: loss = 0.470443 (* 1 = 0.470443 loss)
I0312 18:30:44.738214  1600 sgd_solver.cpp:106] Iteration 144100, lr = 0.001
I0312 18:30:54.107555  1600 solver.cpp:228] Iteration 144200, loss = 0.567218
I0312 18:30:54.108055  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:30:54.108055  1600 solver.cpp:244]     Train net output #1: loss = 0.567219 (* 1 = 0.567219 loss)
I0312 18:30:54.108055  1600 sgd_solver.cpp:106] Iteration 144200, lr = 0.001
I0312 18:31:03.387315  1600 solver.cpp:228] Iteration 144300, loss = 0.43978
I0312 18:31:03.387315  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:31:03.387315  1600 solver.cpp:244]     Train net output #1: loss = 0.439781 (* 1 = 0.439781 loss)
I0312 18:31:03.387315  1600 sgd_solver.cpp:106] Iteration 144300, lr = 0.001
I0312 18:31:12.792371  1600 solver.cpp:228] Iteration 144400, loss = 0.553631
I0312 18:31:12.792371  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:31:12.792371  1600 solver.cpp:244]     Train net output #1: loss = 0.553631 (* 1 = 0.553631 loss)
I0312 18:31:12.792371  1600 sgd_solver.cpp:106] Iteration 144400, lr = 0.001
I0312 18:31:22.149655  1600 solver.cpp:228] Iteration 144500, loss = 0.660641
I0312 18:31:22.149655  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:31:22.149655  1600 solver.cpp:244]     Train net output #1: loss = 0.660642 (* 1 = 0.660642 loss)
I0312 18:31:22.149655  1600 sgd_solver.cpp:106] Iteration 144500, lr = 0.001
I0312 18:31:30.986115  1600 solver.cpp:228] Iteration 144600, loss = 1.04364
I0312 18:31:30.986115  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:31:30.986115  1600 solver.cpp:244]     Train net output #1: loss = 1.04364 (* 1 = 1.04364 loss)
I0312 18:31:30.986115  1600 sgd_solver.cpp:106] Iteration 144600, lr = 0.001
I0312 18:31:40.299567  1600 solver.cpp:228] Iteration 144700, loss = 0.728936
I0312 18:31:40.299567  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:31:40.299567  1600 solver.cpp:244]     Train net output #1: loss = 0.728936 (* 1 = 0.728936 loss)
I0312 18:31:40.299567  1600 sgd_solver.cpp:106] Iteration 144700, lr = 0.001
I0312 18:31:49.585916  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_144800.caffemodel
I0312 18:31:49.605420  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_144800.solverstate
I0312 18:31:49.605420  1600 solver.cpp:337] Iteration 144800, Testing net (#0)
I0312 18:31:49.605420  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:31:53.556149  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6244
I0312 18:31:53.556149  1600 solver.cpp:404]     Test net output #1: loss = 1.61324 (* 1 = 1.61324 loss)
I0312 18:31:53.596153  1600 solver.cpp:228] Iteration 144800, loss = 0.691457
I0312 18:31:53.596153  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:31:53.596153  1600 solver.cpp:244]     Train net output #1: loss = 0.691458 (* 1 = 0.691458 loss)
I0312 18:31:53.596153  1600 sgd_solver.cpp:106] Iteration 144800, lr = 0.001
I0312 18:32:02.963490  1600 solver.cpp:228] Iteration 144900, loss = 0.85719
I0312 18:32:02.963490  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:32:02.963490  1600 solver.cpp:244]     Train net output #1: loss = 0.85719 (* 1 = 0.85719 loss)
I0312 18:32:02.963490  1600 sgd_solver.cpp:106] Iteration 144900, lr = 0.001
I0312 18:32:12.217694  1600 solver.cpp:228] Iteration 145000, loss = 0.591568
I0312 18:32:12.217694  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:32:12.218194  1600 solver.cpp:244]     Train net output #1: loss = 0.591569 (* 1 = 0.591569 loss)
I0312 18:32:12.218194  1600 sgd_solver.cpp:106] Iteration 145000, lr = 0.001
I0312 18:32:21.092350  1600 solver.cpp:228] Iteration 145100, loss = 0.765749
I0312 18:32:21.092350  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:32:21.092350  1600 solver.cpp:244]     Train net output #1: loss = 0.76575 (* 1 = 0.76575 loss)
I0312 18:32:21.092350  1600 sgd_solver.cpp:106] Iteration 145100, lr = 0.001
I0312 18:32:30.483027  1600 solver.cpp:228] Iteration 145200, loss = 0.509427
I0312 18:32:30.483027  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:32:30.483027  1600 solver.cpp:244]     Train net output #1: loss = 0.509428 (* 1 = 0.509428 loss)
I0312 18:32:30.483027  1600 sgd_solver.cpp:106] Iteration 145200, lr = 0.001
I0312 18:32:39.853950  1600 solver.cpp:228] Iteration 145300, loss = 0.911326
I0312 18:32:39.853950  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:32:39.853950  1600 solver.cpp:244]     Train net output #1: loss = 0.911326 (* 1 = 0.911326 loss)
I0312 18:32:39.853950  1600 sgd_solver.cpp:106] Iteration 145300, lr = 0.001
I0312 18:32:49.227705  1600 solver.cpp:228] Iteration 145400, loss = 0.979194
I0312 18:32:49.227705  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:32:49.227705  1600 solver.cpp:244]     Train net output #1: loss = 0.979195 (* 1 = 0.979195 loss)
I0312 18:32:49.227705  1600 sgd_solver.cpp:106] Iteration 145400, lr = 0.001
I0312 18:32:58.631106  1600 solver.cpp:228] Iteration 145500, loss = 0.475504
I0312 18:32:58.631106  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:32:58.631106  1600 solver.cpp:244]     Train net output #1: loss = 0.475504 (* 1 = 0.475504 loss)
I0312 18:32:58.631106  1600 sgd_solver.cpp:106] Iteration 145500, lr = 0.001
I0312 18:33:07.923503  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_145600.caffemodel
I0312 18:33:07.952005  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_145600.solverstate
I0312 18:33:07.957005  1600 solver.cpp:337] Iteration 145600, Testing net (#0)
I0312 18:33:07.957005  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:33:11.670502  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6246
I0312 18:33:11.670502  1600 solver.cpp:404]     Test net output #1: loss = 1.61464 (* 1 = 1.61464 loss)
I0312 18:33:11.690512  1600 solver.cpp:228] Iteration 145600, loss = 0.650747
I0312 18:33:11.690512  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:33:11.690512  1600 solver.cpp:244]     Train net output #1: loss = 0.650748 (* 1 = 0.650748 loss)
I0312 18:33:11.690512  1600 sgd_solver.cpp:106] Iteration 145600, lr = 0.001
I0312 18:33:20.646966  1600 solver.cpp:228] Iteration 145700, loss = 0.741309
I0312 18:33:20.647466  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:33:20.647466  1600 solver.cpp:244]     Train net output #1: loss = 0.74131 (* 1 = 0.74131 loss)
I0312 18:33:20.647466  1600 sgd_solver.cpp:106] Iteration 145700, lr = 0.001
I0312 18:33:30.083474  1600 solver.cpp:228] Iteration 145800, loss = 0.669357
I0312 18:33:30.083474  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:33:30.083474  1600 solver.cpp:244]     Train net output #1: loss = 0.669358 (* 1 = 0.669358 loss)
I0312 18:33:30.083474  1600 sgd_solver.cpp:106] Iteration 145800, lr = 0.001
I0312 18:33:39.495856  1600 solver.cpp:228] Iteration 145900, loss = 0.59091
I0312 18:33:39.495856  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:33:39.495856  1600 solver.cpp:244]     Train net output #1: loss = 0.59091 (* 1 = 0.59091 loss)
I0312 18:33:39.495856  1600 sgd_solver.cpp:106] Iteration 145900, lr = 0.001
I0312 18:33:48.842645  1600 solver.cpp:228] Iteration 146000, loss = 0.710586
I0312 18:33:48.842645  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:33:48.842645  1600 solver.cpp:244]     Train net output #1: loss = 0.710587 (* 1 = 0.710587 loss)
I0312 18:33:48.842645  1600 sgd_solver.cpp:106] Iteration 146000, lr = 0.001
I0312 18:33:58.190791  1600 solver.cpp:228] Iteration 146100, loss = 0.409709
I0312 18:33:58.190791  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:33:58.190791  1600 solver.cpp:244]     Train net output #1: loss = 0.409709 (* 1 = 0.409709 loss)
I0312 18:33:58.190791  1600 sgd_solver.cpp:106] Iteration 146100, lr = 0.001
I0312 18:34:07.130789  1600 solver.cpp:228] Iteration 146200, loss = 0.577056
I0312 18:34:07.130789  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:34:07.130789  1600 solver.cpp:244]     Train net output #1: loss = 0.577057 (* 1 = 0.577057 loss)
I0312 18:34:07.130789  1600 sgd_solver.cpp:106] Iteration 146200, lr = 0.001
I0312 18:34:16.445538  1600 solver.cpp:228] Iteration 146300, loss = 0.33138
I0312 18:34:16.445538  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:34:16.445538  1600 solver.cpp:244]     Train net output #1: loss = 0.331381 (* 1 = 0.331381 loss)
I0312 18:34:16.445538  1600 sgd_solver.cpp:106] Iteration 146300, lr = 0.001
I0312 18:34:25.706523  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_146400.caffemodel
I0312 18:34:25.735523  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_146400.solverstate
I0312 18:34:25.740525  1600 solver.cpp:337] Iteration 146400, Testing net (#0)
I0312 18:34:25.740525  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:34:29.680122  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6251
I0312 18:34:29.680122  1600 solver.cpp:404]     Test net output #1: loss = 1.61474 (* 1 = 1.61474 loss)
I0312 18:34:29.698123  1600 solver.cpp:228] Iteration 146400, loss = 0.534593
I0312 18:34:29.698123  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:34:29.698123  1600 solver.cpp:244]     Train net output #1: loss = 0.534593 (* 1 = 0.534593 loss)
I0312 18:34:29.698123  1600 sgd_solver.cpp:106] Iteration 146400, lr = 0.001
I0312 18:34:39.049892  1600 solver.cpp:228] Iteration 146500, loss = 0.620246
I0312 18:34:39.049892  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:34:39.049892  1600 solver.cpp:244]     Train net output #1: loss = 0.620247 (* 1 = 0.620247 loss)
I0312 18:34:39.049892  1600 sgd_solver.cpp:106] Iteration 146500, lr = 0.001
I0312 18:34:48.439347  1600 solver.cpp:228] Iteration 146600, loss = 0.446677
I0312 18:34:48.439347  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:34:48.439347  1600 solver.cpp:244]     Train net output #1: loss = 0.446677 (* 1 = 0.446677 loss)
I0312 18:34:48.439347  1600 sgd_solver.cpp:106] Iteration 146600, lr = 0.001
I0312 18:34:57.460911  1600 solver.cpp:228] Iteration 146700, loss = 0.519662
I0312 18:34:57.460911  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:34:57.460911  1600 solver.cpp:244]     Train net output #1: loss = 0.519663 (* 1 = 0.519663 loss)
I0312 18:34:57.460911  1600 sgd_solver.cpp:106] Iteration 146700, lr = 0.001
I0312 18:35:06.569401  1600 solver.cpp:228] Iteration 146800, loss = 0.579806
I0312 18:35:06.569401  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:35:06.569401  1600 solver.cpp:244]     Train net output #1: loss = 0.579807 (* 1 = 0.579807 loss)
I0312 18:35:06.569401  1600 sgd_solver.cpp:106] Iteration 146800, lr = 0.001
I0312 18:35:15.908823  1600 solver.cpp:228] Iteration 146900, loss = 0.742547
I0312 18:35:15.908823  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:35:15.908823  1600 solver.cpp:244]     Train net output #1: loss = 0.742548 (* 1 = 0.742548 loss)
I0312 18:35:15.908823  1600 sgd_solver.cpp:106] Iteration 146900, lr = 0.001
I0312 18:35:25.220294  1600 solver.cpp:228] Iteration 147000, loss = 0.474075
I0312 18:35:25.220795  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:35:25.220795  1600 solver.cpp:244]     Train net output #1: loss = 0.474076 (* 1 = 0.474076 loss)
I0312 18:35:25.220795  1600 sgd_solver.cpp:106] Iteration 147000, lr = 0.001
I0312 18:35:34.591336  1600 solver.cpp:228] Iteration 147100, loss = 0.47679
I0312 18:35:34.591336  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:35:34.591336  1600 solver.cpp:244]     Train net output #1: loss = 0.476791 (* 1 = 0.476791 loss)
I0312 18:35:34.591336  1600 sgd_solver.cpp:106] Iteration 147100, lr = 0.001
I0312 18:35:43.905702  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_147200.caffemodel
I0312 18:35:43.936702  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_147200.solverstate
I0312 18:35:43.941702  1600 solver.cpp:337] Iteration 147200, Testing net (#0)
I0312 18:35:43.941702  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:35:47.851665  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6259
I0312 18:35:47.851665  1600 solver.cpp:404]     Test net output #1: loss = 1.61566 (* 1 = 1.61566 loss)
I0312 18:35:47.876704  1600 solver.cpp:228] Iteration 147200, loss = 0.466989
I0312 18:35:47.876704  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:35:47.876704  1600 solver.cpp:244]     Train net output #1: loss = 0.46699 (* 1 = 0.46699 loss)
I0312 18:35:47.876704  1600 sgd_solver.cpp:106] Iteration 147200, lr = 0.001
I0312 18:35:56.790753  1600 solver.cpp:228] Iteration 147300, loss = 0.667998
I0312 18:35:56.790753  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:35:56.790753  1600 solver.cpp:244]     Train net output #1: loss = 0.667999 (* 1 = 0.667999 loss)
I0312 18:35:56.790753  1600 sgd_solver.cpp:106] Iteration 147300, lr = 0.001
I0312 18:36:06.263103  1600 solver.cpp:228] Iteration 147400, loss = 0.707864
I0312 18:36:06.263103  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:36:06.263103  1600 solver.cpp:244]     Train net output #1: loss = 0.707865 (* 1 = 0.707865 loss)
I0312 18:36:06.263103  1600 sgd_solver.cpp:106] Iteration 147400, lr = 0.001
I0312 18:36:15.758919  1600 solver.cpp:228] Iteration 147500, loss = 0.716003
I0312 18:36:15.758919  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:36:15.758919  1600 solver.cpp:244]     Train net output #1: loss = 0.716004 (* 1 = 0.716004 loss)
I0312 18:36:15.758919  1600 sgd_solver.cpp:106] Iteration 147500, lr = 0.001
I0312 18:36:25.151110  1600 solver.cpp:228] Iteration 147600, loss = 0.548968
I0312 18:36:25.151110  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:36:25.151110  1600 solver.cpp:244]     Train net output #1: loss = 0.548969 (* 1 = 0.548969 loss)
I0312 18:36:25.151110  1600 sgd_solver.cpp:106] Iteration 147600, lr = 0.001
I0312 18:36:34.376583  1600 solver.cpp:228] Iteration 147700, loss = 0.576825
I0312 18:36:34.376583  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:36:34.376583  1600 solver.cpp:244]     Train net output #1: loss = 0.576826 (* 1 = 0.576826 loss)
I0312 18:36:34.376583  1600 sgd_solver.cpp:106] Iteration 147700, lr = 0.001
I0312 18:36:43.430449  1600 solver.cpp:228] Iteration 147800, loss = 0.5013
I0312 18:36:43.430449  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:36:43.430449  1600 solver.cpp:244]     Train net output #1: loss = 0.501301 (* 1 = 0.501301 loss)
I0312 18:36:43.430449  1600 sgd_solver.cpp:106] Iteration 147800, lr = 0.001
I0312 18:36:52.529108  1600 solver.cpp:228] Iteration 147900, loss = 0.566766
I0312 18:36:52.529108  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:36:52.529108  1600 solver.cpp:244]     Train net output #1: loss = 0.566767 (* 1 = 0.566767 loss)
I0312 18:36:52.529108  1600 sgd_solver.cpp:106] Iteration 147900, lr = 0.001
I0312 18:37:01.814940  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_148000.caffemodel
I0312 18:37:01.831441  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_148000.solverstate
I0312 18:37:01.836441  1600 solver.cpp:337] Iteration 148000, Testing net (#0)
I0312 18:37:01.836441  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:37:05.802508  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6275
I0312 18:37:05.802508  1600 solver.cpp:404]     Test net output #1: loss = 1.61344 (* 1 = 1.61344 loss)
I0312 18:37:05.842511  1600 solver.cpp:228] Iteration 148000, loss = 0.835658
I0312 18:37:05.842511  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:37:05.842511  1600 solver.cpp:244]     Train net output #1: loss = 0.835659 (* 1 = 0.835659 loss)
I0312 18:37:05.842511  1600 sgd_solver.cpp:106] Iteration 148000, lr = 0.001
I0312 18:37:15.212586  1600 solver.cpp:228] Iteration 148100, loss = 0.652935
I0312 18:37:15.212586  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:37:15.212586  1600 solver.cpp:244]     Train net output #1: loss = 0.652936 (* 1 = 0.652936 loss)
I0312 18:37:15.212586  1600 sgd_solver.cpp:106] Iteration 148100, lr = 0.001
I0312 18:37:24.455334  1600 solver.cpp:228] Iteration 148200, loss = 0.532818
I0312 18:37:24.455334  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:37:24.455334  1600 solver.cpp:244]     Train net output #1: loss = 0.532819 (* 1 = 0.532819 loss)
I0312 18:37:24.455334  1600 sgd_solver.cpp:106] Iteration 148200, lr = 0.001
I0312 18:37:33.845233  1600 solver.cpp:228] Iteration 148300, loss = 0.576802
I0312 18:37:33.845233  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:37:33.845233  1600 solver.cpp:244]     Train net output #1: loss = 0.576803 (* 1 = 0.576803 loss)
I0312 18:37:33.845233  1600 sgd_solver.cpp:106] Iteration 148300, lr = 0.001
I0312 18:37:42.647758  1600 solver.cpp:228] Iteration 148400, loss = 0.499593
I0312 18:37:42.647758  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:37:42.647758  1600 solver.cpp:244]     Train net output #1: loss = 0.499594 (* 1 = 0.499594 loss)
I0312 18:37:42.647758  1600 sgd_solver.cpp:106] Iteration 148400, lr = 0.001
I0312 18:37:52.000114  1600 solver.cpp:228] Iteration 148500, loss = 0.67982
I0312 18:37:52.000114  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:37:52.000114  1600 solver.cpp:244]     Train net output #1: loss = 0.679821 (* 1 = 0.679821 loss)
I0312 18:37:52.000114  1600 sgd_solver.cpp:106] Iteration 148500, lr = 0.001
I0312 18:38:01.417376  1600 solver.cpp:228] Iteration 148600, loss = 0.550701
I0312 18:38:01.417876  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:38:01.417876  1600 solver.cpp:244]     Train net output #1: loss = 0.550702 (* 1 = 0.550702 loss)
I0312 18:38:01.417876  1600 sgd_solver.cpp:106] Iteration 148600, lr = 0.001
I0312 18:38:10.732733  1600 solver.cpp:228] Iteration 148700, loss = 0.606324
I0312 18:38:10.733233  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:38:10.733233  1600 solver.cpp:244]     Train net output #1: loss = 0.606325 (* 1 = 0.606325 loss)
I0312 18:38:10.733233  1600 sgd_solver.cpp:106] Iteration 148700, lr = 0.001
I0312 18:38:20.068078  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_148800.caffemodel
I0312 18:38:20.097079  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_148800.solverstate
I0312 18:38:20.102579  1600 solver.cpp:337] Iteration 148800, Testing net (#0)
I0312 18:38:20.102579  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:38:24.001080  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6268
I0312 18:38:24.001080  1600 solver.cpp:404]     Test net output #1: loss = 1.6181 (* 1 = 1.6181 loss)
I0312 18:38:24.025079  1600 solver.cpp:228] Iteration 148800, loss = 0.62899
I0312 18:38:24.025079  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:38:24.025079  1600 solver.cpp:244]     Train net output #1: loss = 0.62899 (* 1 = 0.62899 loss)
I0312 18:38:24.025578  1600 sgd_solver.cpp:106] Iteration 148800, lr = 0.001
I0312 18:38:32.881443  1600 solver.cpp:228] Iteration 148900, loss = 0.371959
I0312 18:38:32.881443  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.9375
I0312 18:38:32.881443  1600 solver.cpp:244]     Train net output #1: loss = 0.37196 (* 1 = 0.37196 loss)
I0312 18:38:32.881443  1600 sgd_solver.cpp:106] Iteration 148900, lr = 0.001
I0312 18:38:42.048835  1600 solver.cpp:228] Iteration 149000, loss = 0.360876
I0312 18:38:42.048835  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:38:42.048835  1600 solver.cpp:244]     Train net output #1: loss = 0.360877 (* 1 = 0.360877 loss)
I0312 18:38:42.048835  1600 sgd_solver.cpp:106] Iteration 149000, lr = 0.001
I0312 18:38:51.369833  1600 solver.cpp:228] Iteration 149100, loss = 0.822158
I0312 18:38:51.369833  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.703125
I0312 18:38:51.369833  1600 solver.cpp:244]     Train net output #1: loss = 0.822159 (* 1 = 0.822159 loss)
I0312 18:38:51.369833  1600 sgd_solver.cpp:106] Iteration 149100, lr = 0.001
I0312 18:39:00.758101  1600 solver.cpp:228] Iteration 149200, loss = 0.701568
I0312 18:39:00.758101  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:39:00.758101  1600 solver.cpp:244]     Train net output #1: loss = 0.701569 (* 1 = 0.701569 loss)
I0312 18:39:00.758101  1600 sgd_solver.cpp:106] Iteration 149200, lr = 0.001
I0312 18:39:10.172713  1600 solver.cpp:228] Iteration 149300, loss = 0.703303
I0312 18:39:10.172713  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:39:10.172713  1600 solver.cpp:244]     Train net output #1: loss = 0.703304 (* 1 = 0.703304 loss)
I0312 18:39:10.172713  1600 sgd_solver.cpp:106] Iteration 149300, lr = 0.001
I0312 18:39:19.526944  1600 solver.cpp:228] Iteration 149400, loss = 0.470164
I0312 18:39:19.526944  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:39:19.526944  1600 solver.cpp:244]     Train net output #1: loss = 0.470165 (* 1 = 0.470165 loss)
I0312 18:39:19.526944  1600 sgd_solver.cpp:106] Iteration 149400, lr = 0.001
I0312 18:39:28.404714  1600 solver.cpp:228] Iteration 149500, loss = 0.810112
I0312 18:39:28.404714  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:39:28.404714  1600 solver.cpp:244]     Train net output #1: loss = 0.810113 (* 1 = 0.810113 loss)
I0312 18:39:28.404714  1600 sgd_solver.cpp:106] Iteration 149500, lr = 0.001
I0312 18:39:37.780835  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_149600.caffemodel
I0312 18:39:37.811336  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_149600.solverstate
I0312 18:39:37.815335  1600 solver.cpp:337] Iteration 149600, Testing net (#0)
I0312 18:39:37.815835  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:39:41.736847  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6283
I0312 18:39:41.736847  1600 solver.cpp:404]     Test net output #1: loss = 1.61881 (* 1 = 1.61881 loss)
I0312 18:39:41.796422  1600 solver.cpp:228] Iteration 149600, loss = 0.495582
I0312 18:39:41.796422  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:39:41.796422  1600 solver.cpp:244]     Train net output #1: loss = 0.495582 (* 1 = 0.495582 loss)
I0312 18:39:41.796422  1600 sgd_solver.cpp:106] Iteration 149600, lr = 0.001
I0312 18:39:51.148267  1600 solver.cpp:228] Iteration 149700, loss = 0.513341
I0312 18:39:51.148267  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:39:51.148267  1600 solver.cpp:244]     Train net output #1: loss = 0.513342 (* 1 = 0.513342 loss)
I0312 18:39:51.148267  1600 sgd_solver.cpp:106] Iteration 149700, lr = 0.001
I0312 18:40:00.353713  1600 solver.cpp:228] Iteration 149800, loss = 0.810467
I0312 18:40:00.353713  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:40:00.353713  1600 solver.cpp:244]     Train net output #1: loss = 0.810467 (* 1 = 0.810467 loss)
I0312 18:40:00.353713  1600 sgd_solver.cpp:106] Iteration 149800, lr = 0.001
I0312 18:40:09.862689  1600 solver.cpp:228] Iteration 149900, loss = 0.691264
I0312 18:40:09.862689  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:40:09.862689  1600 solver.cpp:244]     Train net output #1: loss = 0.691265 (* 1 = 0.691265 loss)
I0312 18:40:09.862689  1600 sgd_solver.cpp:106] Iteration 149900, lr = 0.001
I0312 18:40:18.767526  1600 solver.cpp:228] Iteration 150000, loss = 0.619445
I0312 18:40:18.767526  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:40:18.767526  1600 solver.cpp:244]     Train net output #1: loss = 0.619445 (* 1 = 0.619445 loss)
I0312 18:40:18.767526  1600 sgd_solver.cpp:106] Iteration 150000, lr = 0.001
I0312 18:40:27.982149  1600 solver.cpp:228] Iteration 150100, loss = 0.635109
I0312 18:40:27.982149  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:40:27.982149  1600 solver.cpp:244]     Train net output #1: loss = 0.63511 (* 1 = 0.63511 loss)
I0312 18:40:27.982149  1600 sgd_solver.cpp:106] Iteration 150100, lr = 0.001
I0312 18:40:37.270185  1600 solver.cpp:228] Iteration 150200, loss = 0.560331
I0312 18:40:37.270185  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:40:37.270185  1600 solver.cpp:244]     Train net output #1: loss = 0.560332 (* 1 = 0.560332 loss)
I0312 18:40:37.270185  1600 sgd_solver.cpp:106] Iteration 150200, lr = 0.001
I0312 18:40:46.571100  1600 solver.cpp:228] Iteration 150300, loss = 0.307186
I0312 18:40:46.571100  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.953125
I0312 18:40:46.571100  1600 solver.cpp:244]     Train net output #1: loss = 0.307187 (* 1 = 0.307187 loss)
I0312 18:40:46.571100  1600 sgd_solver.cpp:106] Iteration 150300, lr = 0.001
I0312 18:40:55.884564  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_150400.caffemodel
I0312 18:40:55.919065  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_150400.solverstate
I0312 18:40:55.924064  1600 solver.cpp:337] Iteration 150400, Testing net (#0)
I0312 18:40:55.924064  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:40:59.945207  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6281
I0312 18:40:59.945207  1600 solver.cpp:404]     Test net output #1: loss = 1.61137 (* 1 = 1.61137 loss)
I0312 18:40:59.977207  1600 solver.cpp:228] Iteration 150400, loss = 0.665165
I0312 18:40:59.977207  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:40:59.977207  1600 solver.cpp:244]     Train net output #1: loss = 0.665165 (* 1 = 0.665165 loss)
I0312 18:40:59.977207  1600 sgd_solver.cpp:106] Iteration 150400, lr = 0.001
I0312 18:41:08.813696  1600 solver.cpp:228] Iteration 150500, loss = 0.671857
I0312 18:41:08.814198  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:41:08.814198  1600 solver.cpp:244]     Train net output #1: loss = 0.671858 (* 1 = 0.671858 loss)
I0312 18:41:08.814198  1600 sgd_solver.cpp:106] Iteration 150500, lr = 0.001
I0312 18:41:18.110224  1600 solver.cpp:228] Iteration 150600, loss = 0.387965
I0312 18:41:18.110224  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:41:18.110224  1600 solver.cpp:244]     Train net output #1: loss = 0.387965 (* 1 = 0.387965 loss)
I0312 18:41:18.110224  1600 sgd_solver.cpp:106] Iteration 150600, lr = 0.001
I0312 18:41:27.519717  1600 solver.cpp:228] Iteration 150700, loss = 0.43673
I0312 18:41:27.519717  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:41:27.519717  1600 solver.cpp:244]     Train net output #1: loss = 0.436731 (* 1 = 0.436731 loss)
I0312 18:41:27.519717  1600 sgd_solver.cpp:106] Iteration 150700, lr = 0.001
I0312 18:41:36.795367  1600 solver.cpp:228] Iteration 150800, loss = 0.551068
I0312 18:41:36.795367  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:41:36.795367  1600 solver.cpp:244]     Train net output #1: loss = 0.551069 (* 1 = 0.551069 loss)
I0312 18:41:36.795367  1600 sgd_solver.cpp:106] Iteration 150800, lr = 0.001
I0312 18:41:46.248476  1600 solver.cpp:228] Iteration 150900, loss = 0.5632
I0312 18:41:46.248476  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:41:46.248476  1600 solver.cpp:244]     Train net output #1: loss = 0.563201 (* 1 = 0.563201 loss)
I0312 18:41:46.248476  1600 sgd_solver.cpp:106] Iteration 150900, lr = 0.001
I0312 18:41:55.510004  1600 solver.cpp:228] Iteration 151000, loss = 0.63996
I0312 18:41:55.510004  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:41:55.510004  1600 solver.cpp:244]     Train net output #1: loss = 0.639961 (* 1 = 0.639961 loss)
I0312 18:41:55.510004  1600 sgd_solver.cpp:106] Iteration 151000, lr = 0.001
I0312 18:42:04.421128  1600 solver.cpp:228] Iteration 151100, loss = 0.546767
I0312 18:42:04.421128  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:42:04.421128  1600 solver.cpp:244]     Train net output #1: loss = 0.546768 (* 1 = 0.546768 loss)
I0312 18:42:04.421128  1600 sgd_solver.cpp:106] Iteration 151100, lr = 0.001
I0312 18:42:13.658807  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_151200.caffemodel
I0312 18:42:13.689306  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_151200.solverstate
I0312 18:42:13.693805  1600 solver.cpp:337] Iteration 151200, Testing net (#0)
I0312 18:42:13.693805  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:42:17.645303  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6271
I0312 18:42:17.645303  1600 solver.cpp:404]     Test net output #1: loss = 1.60656 (* 1 = 1.60656 loss)
I0312 18:42:17.675305  1600 solver.cpp:228] Iteration 151200, loss = 0.729492
I0312 18:42:17.675305  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:42:17.675305  1600 solver.cpp:244]     Train net output #1: loss = 0.729493 (* 1 = 0.729493 loss)
I0312 18:42:17.675305  1600 sgd_solver.cpp:106] Iteration 151200, lr = 0.001
I0312 18:42:26.958529  1600 solver.cpp:228] Iteration 151300, loss = 0.577475
I0312 18:42:26.958529  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:42:26.958529  1600 solver.cpp:244]     Train net output #1: loss = 0.577476 (* 1 = 0.577476 loss)
I0312 18:42:26.958529  1600 sgd_solver.cpp:106] Iteration 151300, lr = 0.001
I0312 18:42:36.267137  1600 solver.cpp:228] Iteration 151400, loss = 0.617019
I0312 18:42:36.267137  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:42:36.267137  1600 solver.cpp:244]     Train net output #1: loss = 0.617019 (* 1 = 0.617019 loss)
I0312 18:42:36.267137  1600 sgd_solver.cpp:106] Iteration 151400, lr = 0.001
I0312 18:42:45.627179  1600 solver.cpp:228] Iteration 151500, loss = 0.639213
I0312 18:42:45.627179  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:42:45.627179  1600 solver.cpp:244]     Train net output #1: loss = 0.639213 (* 1 = 0.639213 loss)
I0312 18:42:45.627179  1600 sgd_solver.cpp:106] Iteration 151500, lr = 0.001
I0312 18:42:54.713090  1600 solver.cpp:228] Iteration 151600, loss = 0.905491
I0312 18:42:54.713090  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:42:54.713090  1600 solver.cpp:244]     Train net output #1: loss = 0.905491 (* 1 = 0.905491 loss)
I0312 18:42:54.713090  1600 sgd_solver.cpp:106] Iteration 151600, lr = 0.001
I0312 18:43:03.971227  1600 solver.cpp:228] Iteration 151700, loss = 0.796705
I0312 18:43:03.971227  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:43:03.971227  1600 solver.cpp:244]     Train net output #1: loss = 0.796706 (* 1 = 0.796706 loss)
I0312 18:43:03.971227  1600 sgd_solver.cpp:106] Iteration 151700, lr = 0.001
I0312 18:43:13.105677  1600 solver.cpp:228] Iteration 151800, loss = 0.382698
I0312 18:43:13.105677  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:43:13.105677  1600 solver.cpp:244]     Train net output #1: loss = 0.382699 (* 1 = 0.382699 loss)
I0312 18:43:13.105677  1600 sgd_solver.cpp:106] Iteration 151800, lr = 0.001
I0312 18:43:22.496754  1600 solver.cpp:228] Iteration 151900, loss = 0.643162
I0312 18:43:22.497254  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:43:22.497254  1600 solver.cpp:244]     Train net output #1: loss = 0.643162 (* 1 = 0.643162 loss)
I0312 18:43:22.497254  1600 sgd_solver.cpp:106] Iteration 151900, lr = 0.001
I0312 18:43:31.763844  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_152000.caffemodel
I0312 18:43:31.777848  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_152000.solverstate
I0312 18:43:31.787850  1600 solver.cpp:337] Iteration 152000, Testing net (#0)
I0312 18:43:31.787850  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:43:35.744329  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6268
I0312 18:43:35.744329  1600 solver.cpp:404]     Test net output #1: loss = 1.61027 (* 1 = 1.61027 loss)
I0312 18:43:35.761330  1600 solver.cpp:228] Iteration 152000, loss = 0.530289
I0312 18:43:35.761330  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:43:35.761330  1600 solver.cpp:244]     Train net output #1: loss = 0.53029 (* 1 = 0.53029 loss)
I0312 18:43:35.761330  1600 sgd_solver.cpp:106] Iteration 152000, lr = 0.001
I0312 18:43:45.009740  1600 solver.cpp:228] Iteration 152100, loss = 0.547126
I0312 18:43:45.009740  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:43:45.009740  1600 solver.cpp:244]     Train net output #1: loss = 0.547126 (* 1 = 0.547126 loss)
I0312 18:43:45.009740  1600 sgd_solver.cpp:106] Iteration 152100, lr = 0.001
I0312 18:43:53.975180  1600 solver.cpp:228] Iteration 152200, loss = 0.509579
I0312 18:43:53.975180  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:43:53.975180  1600 solver.cpp:244]     Train net output #1: loss = 0.50958 (* 1 = 0.50958 loss)
I0312 18:43:53.975180  1600 sgd_solver.cpp:106] Iteration 152200, lr = 0.001
I0312 18:44:03.311233  1600 solver.cpp:228] Iteration 152300, loss = 0.670228
I0312 18:44:03.311233  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:44:03.311233  1600 solver.cpp:244]     Train net output #1: loss = 0.670228 (* 1 = 0.670228 loss)
I0312 18:44:03.311233  1600 sgd_solver.cpp:106] Iteration 152300, lr = 0.001
I0312 18:44:12.601583  1600 solver.cpp:228] Iteration 152400, loss = 0.607835
I0312 18:44:12.601583  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:44:12.601583  1600 solver.cpp:244]     Train net output #1: loss = 0.607836 (* 1 = 0.607836 loss)
I0312 18:44:12.601583  1600 sgd_solver.cpp:106] Iteration 152400, lr = 0.001
I0312 18:44:22.015600  1600 solver.cpp:228] Iteration 152500, loss = 0.475122
I0312 18:44:22.016103  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:44:22.016103  1600 solver.cpp:244]     Train net output #1: loss = 0.475123 (* 1 = 0.475123 loss)
I0312 18:44:22.016103  1600 sgd_solver.cpp:106] Iteration 152500, lr = 0.001
I0312 18:44:31.381777  1600 solver.cpp:228] Iteration 152600, loss = 0.56813
I0312 18:44:31.381777  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:44:31.381777  1600 solver.cpp:244]     Train net output #1: loss = 0.568131 (* 1 = 0.568131 loss)
I0312 18:44:31.381777  1600 sgd_solver.cpp:106] Iteration 152600, lr = 0.001
I0312 18:44:40.339151  1600 solver.cpp:228] Iteration 152700, loss = 0.638747
I0312 18:44:40.339151  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:44:40.339151  1600 solver.cpp:244]     Train net output #1: loss = 0.638748 (* 1 = 0.638748 loss)
I0312 18:44:40.339151  1600 sgd_solver.cpp:106] Iteration 152700, lr = 0.001
I0312 18:44:49.592943  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_152800.caffemodel
I0312 18:44:49.622946  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_152800.solverstate
I0312 18:44:49.632947  1600 solver.cpp:337] Iteration 152800, Testing net (#0)
I0312 18:44:49.632947  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:44:53.597738  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6268
I0312 18:44:53.598242  1600 solver.cpp:404]     Test net output #1: loss = 1.61864 (* 1 = 1.61864 loss)
I0312 18:44:53.625741  1600 solver.cpp:228] Iteration 152800, loss = 0.348072
I0312 18:44:53.625741  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.90625
I0312 18:44:53.625741  1600 solver.cpp:244]     Train net output #1: loss = 0.348073 (* 1 = 0.348073 loss)
I0312 18:44:53.625741  1600 sgd_solver.cpp:106] Iteration 152800, lr = 0.001
I0312 18:45:02.933189  1600 solver.cpp:228] Iteration 152900, loss = 0.813079
I0312 18:45:02.933689  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:45:02.933689  1600 solver.cpp:244]     Train net output #1: loss = 0.81308 (* 1 = 0.81308 loss)
I0312 18:45:02.933689  1600 sgd_solver.cpp:106] Iteration 152900, lr = 0.001
I0312 18:45:12.225075  1600 solver.cpp:228] Iteration 153000, loss = 0.396007
I0312 18:45:12.225075  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:45:12.225075  1600 solver.cpp:244]     Train net output #1: loss = 0.396008 (* 1 = 0.396008 loss)
I0312 18:45:12.225075  1600 sgd_solver.cpp:106] Iteration 153000, lr = 0.001
I0312 18:45:21.591745  1600 solver.cpp:228] Iteration 153100, loss = 0.662506
I0312 18:45:21.591745  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:45:21.591745  1600 solver.cpp:244]     Train net output #1: loss = 0.662507 (* 1 = 0.662507 loss)
I0312 18:45:21.592247  1600 sgd_solver.cpp:106] Iteration 153100, lr = 0.001
I0312 18:45:30.803289  1600 solver.cpp:228] Iteration 153200, loss = 0.804154
I0312 18:45:30.803289  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:45:30.803289  1600 solver.cpp:244]     Train net output #1: loss = 0.804155 (* 1 = 0.804155 loss)
I0312 18:45:30.803289  1600 sgd_solver.cpp:106] Iteration 153200, lr = 0.001
I0312 18:45:39.723198  1600 solver.cpp:228] Iteration 153300, loss = 0.694023
I0312 18:45:39.723198  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:45:39.723198  1600 solver.cpp:244]     Train net output #1: loss = 0.694023 (* 1 = 0.694023 loss)
I0312 18:45:39.723198  1600 sgd_solver.cpp:106] Iteration 153300, lr = 0.001
I0312 18:45:49.074944  1600 solver.cpp:228] Iteration 153400, loss = 0.666955
I0312 18:45:49.074944  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:45:49.074944  1600 solver.cpp:244]     Train net output #1: loss = 0.666956 (* 1 = 0.666956 loss)
I0312 18:45:49.074944  1600 sgd_solver.cpp:106] Iteration 153400, lr = 0.001
I0312 18:45:58.399252  1600 solver.cpp:228] Iteration 153500, loss = 0.597246
I0312 18:45:58.399252  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:45:58.399252  1600 solver.cpp:244]     Train net output #1: loss = 0.597247 (* 1 = 0.597247 loss)
I0312 18:45:58.399252  1600 sgd_solver.cpp:106] Iteration 153500, lr = 0.001
I0312 18:46:07.739475  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_153600.caffemodel
I0312 18:46:07.757474  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_153600.solverstate
I0312 18:46:07.761975  1600 solver.cpp:337] Iteration 153600, Testing net (#0)
I0312 18:46:07.761975  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:46:11.712266  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6267
I0312 18:46:11.712266  1600 solver.cpp:404]     Test net output #1: loss = 1.61885 (* 1 = 1.61885 loss)
I0312 18:46:11.732266  1600 solver.cpp:228] Iteration 153600, loss = 0.580735
I0312 18:46:11.732266  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:46:11.732266  1600 solver.cpp:244]     Train net output #1: loss = 0.580735 (* 1 = 0.580735 loss)
I0312 18:46:11.732266  1600 sgd_solver.cpp:106] Iteration 153600, lr = 0.001
I0312 18:46:21.107930  1600 solver.cpp:228] Iteration 153700, loss = 0.724654
I0312 18:46:21.107930  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:46:21.108435  1600 solver.cpp:244]     Train net output #1: loss = 0.724655 (* 1 = 0.724655 loss)
I0312 18:46:21.108435  1600 sgd_solver.cpp:106] Iteration 153700, lr = 0.001
I0312 18:46:30.119644  1600 solver.cpp:228] Iteration 153800, loss = 0.617355
I0312 18:46:30.119644  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:46:30.119644  1600 solver.cpp:244]     Train net output #1: loss = 0.617355 (* 1 = 0.617355 loss)
I0312 18:46:30.119644  1600 sgd_solver.cpp:106] Iteration 153800, lr = 0.001
I0312 18:46:39.481633  1600 solver.cpp:228] Iteration 153900, loss = 0.743704
I0312 18:46:39.481633  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.75
I0312 18:46:39.482134  1600 solver.cpp:244]     Train net output #1: loss = 0.743705 (* 1 = 0.743705 loss)
I0312 18:46:39.482134  1600 sgd_solver.cpp:106] Iteration 153900, lr = 0.001
I0312 18:46:48.778420  1600 solver.cpp:228] Iteration 154000, loss = 0.959977
I0312 18:46:48.778420  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:46:48.778420  1600 solver.cpp:244]     Train net output #1: loss = 0.959977 (* 1 = 0.959977 loss)
I0312 18:46:48.778420  1600 sgd_solver.cpp:106] Iteration 154000, lr = 0.001
I0312 18:46:58.212723  1600 solver.cpp:228] Iteration 154100, loss = 0.560694
I0312 18:46:58.212723  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:46:58.212723  1600 solver.cpp:244]     Train net output #1: loss = 0.560694 (* 1 = 0.560694 loss)
I0312 18:46:58.212723  1600 sgd_solver.cpp:106] Iteration 154100, lr = 0.001
I0312 18:47:07.635419  1600 solver.cpp:228] Iteration 154200, loss = 0.648918
I0312 18:47:07.635920  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:47:07.635920  1600 solver.cpp:244]     Train net output #1: loss = 0.648918 (* 1 = 0.648918 loss)
I0312 18:47:07.635920  1600 sgd_solver.cpp:106] Iteration 154200, lr = 0.001
I0312 18:47:16.848835  1600 solver.cpp:228] Iteration 154300, loss = 0.684515
I0312 18:47:16.848835  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:47:16.848835  1600 solver.cpp:244]     Train net output #1: loss = 0.684516 (* 1 = 0.684516 loss)
I0312 18:47:16.848835  1600 sgd_solver.cpp:106] Iteration 154300, lr = 0.001
I0312 18:47:25.818531  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_154400.caffemodel
I0312 18:47:25.834532  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_154400.solverstate
I0312 18:47:25.840032  1600 solver.cpp:337] Iteration 154400, Testing net (#0)
I0312 18:47:25.840032  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:47:29.802692  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6283
I0312 18:47:29.802692  1600 solver.cpp:404]     Test net output #1: loss = 1.61955 (* 1 = 1.61955 loss)
I0312 18:47:29.822693  1600 solver.cpp:228] Iteration 154400, loss = 0.535104
I0312 18:47:29.822693  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:47:29.822693  1600 solver.cpp:244]     Train net output #1: loss = 0.535105 (* 1 = 0.535105 loss)
I0312 18:47:29.822693  1600 sgd_solver.cpp:106] Iteration 154400, lr = 0.001
I0312 18:47:39.313295  1600 solver.cpp:228] Iteration 154500, loss = 0.6913
I0312 18:47:39.313295  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:47:39.313295  1600 solver.cpp:244]     Train net output #1: loss = 0.6913 (* 1 = 0.6913 loss)
I0312 18:47:39.313295  1600 sgd_solver.cpp:106] Iteration 154500, lr = 0.001
I0312 18:47:48.489006  1600 solver.cpp:228] Iteration 154600, loss = 0.703461
I0312 18:47:48.489006  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:47:48.489006  1600 solver.cpp:244]     Train net output #1: loss = 0.703462 (* 1 = 0.703462 loss)
I0312 18:47:48.489006  1600 sgd_solver.cpp:106] Iteration 154600, lr = 0.001
I0312 18:47:57.723563  1600 solver.cpp:228] Iteration 154700, loss = 0.553964
I0312 18:47:57.723563  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:47:57.723563  1600 solver.cpp:244]     Train net output #1: loss = 0.553965 (* 1 = 0.553965 loss)
I0312 18:47:57.723563  1600 sgd_solver.cpp:106] Iteration 154700, lr = 0.001
I0312 18:48:07.111764  1600 solver.cpp:228] Iteration 154800, loss = 0.731841
I0312 18:48:07.111764  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.765625
I0312 18:48:07.111764  1600 solver.cpp:244]     Train net output #1: loss = 0.731842 (* 1 = 0.731842 loss)
I0312 18:48:07.111764  1600 sgd_solver.cpp:106] Iteration 154800, lr = 0.001
I0312 18:48:16.003962  1600 solver.cpp:228] Iteration 154900, loss = 0.699771
I0312 18:48:16.003962  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:48:16.003962  1600 solver.cpp:244]     Train net output #1: loss = 0.699771 (* 1 = 0.699771 loss)
I0312 18:48:16.003962  1600 sgd_solver.cpp:106] Iteration 154900, lr = 0.001
I0312 18:48:25.191215  1600 solver.cpp:228] Iteration 155000, loss = 0.725191
I0312 18:48:25.191215  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.734375
I0312 18:48:25.191215  1600 solver.cpp:244]     Train net output #1: loss = 0.725191 (* 1 = 0.725191 loss)
I0312 18:48:25.191215  1600 sgd_solver.cpp:106] Iteration 155000, lr = 0.001
I0312 18:48:34.625632  1600 solver.cpp:228] Iteration 155100, loss = 0.614012
I0312 18:48:34.625632  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:48:34.625632  1600 solver.cpp:244]     Train net output #1: loss = 0.614012 (* 1 = 0.614012 loss)
I0312 18:48:34.625632  1600 sgd_solver.cpp:106] Iteration 155100, lr = 0.001
I0312 18:48:43.934672  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_155200.caffemodel
I0312 18:48:43.966672  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_155200.solverstate
I0312 18:48:43.972174  1600 solver.cpp:337] Iteration 155200, Testing net (#0)
I0312 18:48:43.972174  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:48:47.980449  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6284
I0312 18:48:47.980449  1600 solver.cpp:404]     Test net output #1: loss = 1.61314 (* 1 = 1.61314 loss)
I0312 18:48:48.003434  1600 solver.cpp:228] Iteration 155200, loss = 0.750599
I0312 18:48:48.003434  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.78125
I0312 18:48:48.003434  1600 solver.cpp:244]     Train net output #1: loss = 0.7506 (* 1 = 0.7506 loss)
I0312 18:48:48.003434  1600 sgd_solver.cpp:106] Iteration 155200, lr = 0.001
I0312 18:48:57.328604  1600 solver.cpp:228] Iteration 155300, loss = 0.426624
I0312 18:48:57.328604  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:48:57.328604  1600 solver.cpp:244]     Train net output #1: loss = 0.426625 (* 1 = 0.426625 loss)
I0312 18:48:57.328604  1600 sgd_solver.cpp:106] Iteration 155300, lr = 0.001
I0312 18:49:06.159538  1600 solver.cpp:228] Iteration 155400, loss = 0.766879
I0312 18:49:06.159538  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:49:06.159538  1600 solver.cpp:244]     Train net output #1: loss = 0.76688 (* 1 = 0.76688 loss)
I0312 18:49:06.159538  1600 sgd_solver.cpp:106] Iteration 155400, lr = 0.001
I0312 18:49:15.637163  1600 solver.cpp:228] Iteration 155500, loss = 0.619018
I0312 18:49:15.637163  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.796875
I0312 18:49:15.637163  1600 solver.cpp:244]     Train net output #1: loss = 0.619018 (* 1 = 0.619018 loss)
I0312 18:49:15.637163  1600 sgd_solver.cpp:106] Iteration 155500, lr = 0.001
I0312 18:49:25.018122  1600 solver.cpp:228] Iteration 155600, loss = 0.534892
I0312 18:49:25.018122  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.875
I0312 18:49:25.018122  1600 solver.cpp:244]     Train net output #1: loss = 0.534893 (* 1 = 0.534893 loss)
I0312 18:49:25.018122  1600 sgd_solver.cpp:106] Iteration 155600, lr = 0.001
I0312 18:49:34.350565  1600 solver.cpp:228] Iteration 155700, loss = 0.37743
I0312 18:49:34.350565  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.859375
I0312 18:49:34.350565  1600 solver.cpp:244]     Train net output #1: loss = 0.377431 (* 1 = 0.377431 loss)
I0312 18:49:34.350565  1600 sgd_solver.cpp:106] Iteration 155700, lr = 0.001
I0312 18:49:43.785924  1600 solver.cpp:228] Iteration 155800, loss = 0.435562
I0312 18:49:43.785924  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.890625
I0312 18:49:43.785924  1600 solver.cpp:244]     Train net output #1: loss = 0.435562 (* 1 = 0.435562 loss)
I0312 18:49:43.785924  1600 sgd_solver.cpp:106] Iteration 155800, lr = 0.001
I0312 18:49:53.152822  1600 solver.cpp:228] Iteration 155900, loss = 0.535042
I0312 18:49:53.152822  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.8125
I0312 18:49:53.152822  1600 solver.cpp:244]     Train net output #1: loss = 0.535042 (* 1 = 0.535042 loss)
I0312 18:49:53.152822  1600 sgd_solver.cpp:106] Iteration 155900, lr = 0.001
I0312 18:50:01.962833  1600 solver.cpp:454] Snapshotting to binary proto file examples/cifar100/snaps/cifar100_iter_156000.caffemodel
I0312 18:50:01.994835  1600 sgd_solver.cpp:273] Snapshotting solver state to binary proto file examples/cifar100/snaps/cifar100_iter_156000.solverstate
I0312 18:50:02.000335  1600 solver.cpp:337] Iteration 156000, Testing net (#0)
I0312 18:50:02.000335  1600 net.cpp:693] Ignoring source layer accuracy_training
I0312 18:50:05.969270  1600 solver.cpp:404]     Test net output #0: accuracy = 0.6251
I0312 18:50:05.969270  1600 solver.cpp:404]     Test net output #1: loss = 1.61985 (* 1 = 1.61985 loss)
I0312 18:50:05.999291  1600 solver.cpp:228] Iteration 156000, loss = 0.570598
I0312 18:50:05.999291  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:50:05.999291  1600 solver.cpp:244]     Train net output #1: loss = 0.570598 (* 1 = 0.570598 loss)
I0312 18:50:05.999291  1600 sgd_solver.cpp:106] Iteration 156000, lr = 0.001
I0312 18:50:15.302556  1600 solver.cpp:228] Iteration 156100, loss = 0.531414
I0312 18:50:15.302556  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.84375
I0312 18:50:15.302556  1600 solver.cpp:244]     Train net output #1: loss = 0.531414 (* 1 = 0.531414 loss)
I0312 18:50:15.302556  1600 sgd_solver.cpp:106] Iteration 156100, lr = 0.001
I0312 18:50:24.779314  1600 solver.cpp:228] Iteration 156200, loss = 0.527615
I0312 18:50:24.779314  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.828125
I0312 18:50:24.779314  1600 solver.cpp:244]     Train net output #1: loss = 0.527616 (* 1 = 0.527616 loss)
I0312 18:50:24.779314  1600 sgd_solver.cpp:106] Iteration 156200, lr = 0.001
I0312 18:50:34.006034  1600 solver.cpp:228] Iteration 156300, loss = 0.721498
I0312 18:50:34.006034  1600 solver.cpp:244]     Train net output #0: accuracy_training = 0.71875
I0312 18:50:34.006034  1600 solver.cpp:244]     Train net output #1: loss = 0.721498 (* 1 = 0.721498 loss)
I0312 18:50:34.006034  1600 sgd_solver.cpp:106] Iteration 156300, lr = 0.001
I0312 18:50:43^C